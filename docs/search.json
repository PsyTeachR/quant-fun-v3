[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fundamentals of Quantitative Analysis",
    "section": "",
    "text": "Overview\nBook Name: Fundamentals of Quantitative Analysis.\nSummary: Materials for the MSc Conversion Research Methods 1 and 2 courses at the University of Glasgow School of Psychology & Neuroscience.\nAuthors: James Bartlett and Wil Toivo. This version of the book was adapted from a previous version written by Emily Nordmann and Phil McAleer.\nAim: This course covers data skills such as creating reproducible documents with R Markdown, data wrangling, and data visualisation with the tidyverse family of packages. It also introduces statistical concepts such as Null Hypothesis Significance Testing (NHST), as well as demonstrating how to perform numerous analyses based around the general linear model including regression and ANOVA.\nContact: This book is a living document and will be regularly checked and updated for improvements. Should you have any issues using the book or have any queries, please contact James Bartlett and Wil Toivo.\nR Version: This book has been written with R version 4.4.1 (2024-06-14 ucrt)."
  },
  {
    "objectID": "instructions.html#sec-setup",
    "href": "instructions.html#sec-setup",
    "title": "1  How to Use this Book",
    "section": "\n1.1 Setup",
    "text": "1.1 Setup\n\n1.1.1 Install booktem\n# install.packages(\"devtools\")\ndevtools::install_github(\"debruine/booktem\")\n\n1.1.2 Quarto Options\nThe file _quarto.yml contains various options that you can set to change the format and look of your book.\n\n1.1.2.1 Language Options\nThere is some default text for things like the “authors” list and “table of contents” that might need translations. Set the lang key to the 2-letter language code for your language.\nYou can make a custom translation by translating the values in the include/_language.yml file.\nlang: en\n# language: include/_language.yml\n\n1.1.2.2 Project Options\nThe project key defines the inputs and outputs for the book (quarto reference).\n\n\n\n\n\n\nproject key\n\n\n\n\n\nproject:\n  type: book\n  output-dir: docs\n  resources: resources \n\n\n\nThe output-dir key defines the directory where the rendered web files will be saved. This is set to docs in order to be compatible with GitHub Pages, but you can change this if you are working with a different repository that expects the web files to be in a different directory.\nThe resources key specifies a directory that is copied verbatim to the output directory. This is where you should put, for example, data files that you want to make accessible online (sometimes they don’t automatically copy over when linked).\n\n1.1.2.3 Book Options\nThe book key defines options that affect the look and function of the book (quarto reference).\n\n\n\n\n\n\nbook key\n\n\n\n\n\nbook:\n  title: Book\n  subtitle: ~\n  author: ~\n  doi: ~\n  license: CC-BY 4.0\n  description: ~\n  cover-image: images/logos/logo.png\n  image: images/logos/logo.png\n  favicon: images/logos/logo.png\n  cookie-consent: false\n  google-analytics: ~\n  page-navigation: true\n  search: true\n  # comments:\n  #   hypothesis:\n  #     theme: clean\n  #     openSidebar: false\n  downloads: ~\n  sharing: ~\n  sidebar:\n    title: ~\n    logo: ~\n    search: true\n    contents: ~\n    style: floating\n    background: ~\n    foreground: ~\n    border: true\n    alignment: left\n    collapse-level: 3\n    pinned: true\n    header: \"\"\n    footer: \"\"\n  margin-header: ~\n  page-footer:\n    left: ~\n    right: ~\n  chapters:\n  - index.qmd\n  - instructions.qmd\n  appendices:\n  - references.qmd\n\n\n\n\n1.1.2.4 html Options\nThe format key defines options for specific formats, such as html or pdf. We’ll only be using html here (quarto reference).\n\n\n\n\n\n\nformat:html key\n\n\n\n\n\nformat:\n  html:\n    theme:\n      light:\n      - flatly\n      - include/light.scss\n      dark:\n      - darkly\n      - include/dark.scss\n    css:\n    - https://use.fontawesome.com/releases/v5.13.0/css/all.css\n    - include/booktem.css\n    - include/glossary.css\n    - include/style.css\n    df-print: kable\n    code-link: true\n    code-fold: false\n    code-line-numbers: true\n    code-overflow: wrap\n    code-copy: hover\n    highlight-style: a11y\n    mainfont: ~\n    monofont: ~\n    include-after-body: [include/script.js]\n\n\n\n\n1.1.3 Crossrefs\nSection links must start with sec- and look like this: Section 1.1.5.\n## Section Title {#sec-section-title}\n\nInternal links look like this: @sec-section-title\nFigure links must start with fig- and look like this: Figure 1.1.\n\n\n\n\nFigure 1.1: A histogram of a Poisson distribution with lambda = 3\n\n\n\nTable links must start with tbl- and look like this: Table 1.1.\n\n\n\n\n\nTable 1.1: The authors of this book\n\nfirst_name\nlast_name\n\n\n\nLisa\nDeBruine\n\n\nDaniël\nLakens\n\n\n\n\n\n\n\nSee the quarto documentation for more information.\n\n1.1.4 References\nZotero export - keep updated\n\n1.1.5 Snippets\nSnippets in RStudio provide shortcuts to syntax. For example, in an RMarkdown document, type “r” and shift-tab to expand a code chunk.\nYou can add your own snippets. Under the Tools menu, choose Edit Code Snippets... and paste the following text into the end of the appropriate sections.\n\n1.1.5.1 Markdown\nsnippet gls\n    r glossary(\"${1:term}\")\n    \nsnippet gls2\n    r glossary(\"${1:term}\", \"${2:display}\")\n    \nsnippet h1\n    # ${1:title} {#sec-${2:ref}}\n    \nsnippet h2\n    ## ${1:title} {#sec-${2:ref}}\n    \nsnippet h3\n    ### ${1:title} {#sec-${2:ref}}\n    \nsnippet h4\n    #### ${1:title} {#sec-${2:ref}}\n    \nsnippet h5\n    ##### ${1:title} {#sec-${2:ref}}\n\n1.1.6 Customize\n\n1.1.6.1 Page Footer\nThe default footer includes license YEAR, author, and github and twitter icons, but you can customize this in the _quarto.yml file under page-footer:. See the quarto documentation for more options. See the available icons at https://icons.getbootstrap.com/."
  },
  {
    "objectID": "instructions.html#sec-layout",
    "href": "instructions.html#sec-layout",
    "title": "1  How to Use this Book",
    "section": "\n1.2 Layout",
    "text": "1.2 Layout\n\n1.2.1 Conventions\nThis book will use the following conventions:\n\nCode: list(number = 1, letter = \"A\")\n\nFile paths: data/sales.csv\n\nMenu/interface options: Tools &gt; Global Options… &gt; Pane Layout\n\nR Packages: tidyverse\n\nGlossary items: alphaThe threshold chosen in Neyman-Pearson hypothesis testing to distinguish test results that lead to the decision to reject the null hypothesis, or not, based on the desired upper bound of the Type 1 error rate. An alpha level of 5% it most commonly used, but other alpha levels can be used as long as they are determined and preregistered by the researcher before the data is analyzed.\n\nCitations: Wickham et al. (2022)\n\nInternal links: Section 1.2.1\n\nExternal links: Mastering Shiny\n\nMac-specific: Cmd-Shift-F10\n\nWindows-specific: Ctl-Shift-F10\n\n\nA list of mac and windows keyboard shortcuts.\n\n1.2.2 Figures\nIt is best practice to set a custom ggplot theme, then each subsequent plot will use that theme. You can put this code in R/my_setup.R after loading ggplot2.\nStart with a built-in theme and then add any tweaks with the theme() function.\n\nlibrary(ggplot2)\n\nmy_theme &lt;- theme_minimal(base_size = 16) + \n            theme(panel.background = element_rect(fill = \"red\", \n                                                  color = \"black\", \n                                                  size = 5),\n                  panel.grid = element_blank())\n\nWarning: The `size` argument of `element_rect()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\ntheme_set(my_theme)\n\n\nggplot(midwest, aes(popdensity, percollege)) +\n  geom_point(alpha = 0.5) +\n  labs(x = \"Population Density\", y = \"Percent College Educated\")\n\n\n\nFigure 1.2: Demographic information of midwest counties from 2000 US census\n\n\n\n\n1.2.3 Tables\n\nhead(beaver1)\n\n\n\nBeavers \n\nday\ntime\ntemp\nactiv\n\n\n\n346\n840\n36.33\n0\n\n\n346\n850\n36.34\n0\n\n\n346\n900\n36.35\n0\n\n\n346\n910\n36.42\n0\n\n\n346\n920\n36.55\n0\n\n\n346\n930\n36.69\n0\n\n\n\n\n\n\n\n1.2.4 Callout boxes\nSee the quarto reference for more options.]{.aside}\n\n\n\n\n\n\nNote\n\n\n\n.callout-note: Informational asides.\n\n\n\n\n\n\n\n\nClick to expand\n\n\n\n\n\ncolapse = “true”: Expanded!\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n.callout-tip: Tips\n\n\n\n\n\n\n\n\nWarning\n\n\n\n.callout-warning: Notes to warn you about something.\n\n\n\n\n\n\n\n\nCaution\n\n\n\n.callout-caution: Notes about things that could cause serious errors.\n\n\n\n\n\n\n\n\nImportant\n\n\n\n.callout-important: Notes about things that are important.\n\n\n\n1.2.5 Code and Output\n\n# code chunks\npaste(\"Code\", \"Output\", 1, sep = \" \")\n\n[1] \"Code Output 1\"\n\n\n\n\n\nFilename or header\n\n# code chunks with filename\na &lt;- 1\n\n\n\n\n```{r, fig.width = 2, fig.height = 2}\n# code chunks with visible headers\nhist(rnorm(100000))\n```\n\n\n## Markdown Example\n\n* Inline code: `r nrow(iris)`\n* *Italics*\n* **Bold**\n* [Linked text](https://psyteachr.github.io)\n\n1.2.6 Fonts"
  },
  {
    "objectID": "instructions.html#sec-extras",
    "href": "instructions.html#sec-extras",
    "title": "1  How to Use this Book",
    "section": "\n1.3 Extras",
    "text": "1.3 Extras\n\n1.3.1 Glossary\nBooks are set up with lightweight glossary functions from the glossary package.\n\n# code in R/my_setup.R to initialise the glossary on each page\nlibrary(glossary)\nglossary_path(\"include/glossary.yml\")\nglossary_popup(\"click\") # \"click\", \"hover\" or \"none\"\n\nEdit the file glossary.yml with your glossary terms like this:\nalpha: |\n  The threshold chosen in Neyman-Pearson hypothesis testing to distinguish test results that lead to the decision to reject the null hypothesis, or not, based on the desired upper bound of the Type 1 error rate. An alpha level of 5% it most commonly used, but other alpha levels can be used as long as they are determined and preregistered by the researcher before the data is analyzed.\np-value: |\n  The probability of the observed data, or more extreme data, if the null hypothesis is true. The lower the p-value, the higher the test statistic, and less likely it is to observe the data if the null hypothesis is true.\nLook up a term from the glossary file with glossary(\"alpha\"): alphaThe threshold chosen in Neyman-Pearson hypothesis testing to distinguish test results that lead to the decision to reject the null hypothesis, or not, based on the desired upper bound of the Type 1 error rate. An alpha level of 5% it most commonly used, but other alpha levels can be used as long as they are determined and preregistered by the researcher before the data is analyzed.\nDisplay a different value for the term with glossary(\"alpha\", \"$\\\\alpha$\"): \\(\\alpha\\)The threshold chosen in Neyman-Pearson hypothesis testing to distinguish test results that lead to the decision to reject the null hypothesis, or not, based on the desired upper bound of the Type 1 error rate. An alpha level of 5% it most commonly used, but other alpha levels can be used as long as they are determined and preregistered by the researcher before the data is analyzed.\nUse an inline definition instead of the glossary file with glossary(\"beta\", def = \"The second letter of the Greek alphabet\"): betaThe second letter of the Greek alphabet\nJust show the definition with glossary(\"p-value\", show = \"def\"): The probability of the observed data, or more extreme data, if the null hypothesis is true. The lower the p-value, the higher the test statistic, and less likely it is to observe the data if the null hypothesis is true.\nShow the table of terms defined on this page with glossary_table():\n\n\n\n\nterm\ndefinition\n\n\n\nalpha\nThe threshold chosen in Neyman-Pearson hypothesis testing to distinguish test results that lead to the decision to reject the null hypothesis, or not, based on the desired upper bound of the Type 1 error rate. An alpha level of 5% it most commonly used, but other alpha levels can be used as long as they are determined and preregistered by the researcher before the data is analyzed.\n\n\nbeta\nThe second letter of the Greek alphabet\n\n\np-value\nThe probability of the observed data, or more extreme data, if the null hypothesis is true. The lower the p-value, the higher the test statistic, and less likely it is to observe the data if the null hypothesis is true.\n\n\n\n\n\n\n1.3.2 FontAwesome\nThe fontAwesome quarto extension allows you to use the free icons with syntax like:\n{{&lt; fa dragon &gt;}}\n{{&lt; fa brands github size = 5x title=\"(github logo)\" &gt;}}\nTo install it, just run this code in the Terminal pane of RStudio (not the Console pane).\nquarto install extension quarto-ext/fontawesome\n\n\n\n\nWickham, H., Bryan, J., & Barrett, M. (2022). Usethis: Automate package and project setup. https://CRAN.R-project.org/package=usethis"
  },
  {
    "objectID": "webexercises.html#example-questions",
    "href": "webexercises.html#example-questions",
    "title": "Appendix A — Webexercises",
    "section": "\nA.1 Example Questions",
    "text": "A.1 Example Questions\n\nA.1.1 Fill-In-The-Blanks (fitb())\nCreate fill-in-the-blank questions using fitb(), providing the answer as the first argument.\n\n2 + 2 is \n\n\nYou can also create these questions dynamically, using variables from your R session.\n\nThe square root of 36 is: \n\n\nThe blanks are case-sensitive; if you don’t care about case, use the argument ignore_case = TRUE.\n\nWhat is the letter after D? \n\n\nIf you want to ignore differences in whitespace use, use the argument ignore_ws = TRUE (which is the default) and include spaces in your answer anywhere they could be acceptable.\n\nHow do you load the tidyverse package? \n\n\nYou can set more than one possible correct answer by setting the answers as a vector.\n\nType a vowel: \n\n\nYou can use regular expressions to test answers against more complex rules.\n\nType any 3 letters: \n\n\nA.1.2 Multiple Choice (mcq())\n\n“Never gonna give you up, never gonna: \nlet you go\nturn you down\nrun away\nlet you down”\n“I \nbless the rains\nguess it rains\nsense the rain down in Africa” -Toto\n\nA.1.3 True or False (torf())\n\nTrue or False? You can permute values in a vector using sample(). \nTRUE\nFALSE\n\n\nA.1.4 Longer MCQs (longmcq())\nWhen your answers are very long, sometimes a drop-down select box gets formatted oddly. You can use longmcq() to deal with this. Since the answers are long, It’s probably best to set up the options inside an R chunk with echo=FALSE.\nWhat is a p-value?\n\nthe probability that the null hypothesis is truethe probability of the observed, or more extreme, data, under the assumption that the null-hypothesis is truethe probability of making an error in your conclusion\n\nWhat is true about a 95% confidence interval of the mean?\n\n95% of the data fall within this rangeif you repeated the process many times, 95% of intervals calculated in this way contain the true meanthere is a 95% probability that the true mean lies within this range"
  },
  {
    "objectID": "webexercises.html#checked-sections",
    "href": "webexercises.html#checked-sections",
    "title": "Appendix A — Webexercises",
    "section": "\nA.2 Checked sections",
    "text": "A.2 Checked sections\nCreate sections with the class webex-check to add a button that hides feedback until it is pressed. Add the class webex-box to draw a box around the section (or use your own styles).\n\nI am going to learn a lot: \nTRUE\nFALSE\n\nWhat is a p-value?\n\nthe probability that the null hypothesis is truethe probability of the observed, or more extreme, data, under the assumption that the null-hypothesis is truethe probability of making an error in your conclusion"
  },
  {
    "objectID": "webexercises.html#hidden-solutions-and-hints",
    "href": "webexercises.html#hidden-solutions-and-hints",
    "title": "Appendix A — Webexercises",
    "section": "\nA.3 Hidden solutions and hints",
    "text": "A.3 Hidden solutions and hints\nYou can fence off a solution area that will be hidden behind a button using hide() before the solution and unhide() after, each as inline R code. Pass the text you want to appear on the button to the hide() function.\nIf the solution is a code chunk, instead of using hide() and unhide(), simply set the webex.hide chunk option to TRUE, or set it to the string you wish to display on the button.\nRecreate the scatterplot below, using the built-in cars dataset.\n\n\n\n\n\n\n\n\n\n\nI need a hint\n\nSee the documentation for plot() (?plot)\n\n\n\n\n\nClick here to see the solution\n\nplot(cars$speed, cars$dist)"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Alter, U., Dang, C., Kunicki, Z. J., & Counsell, A. (2024). The\nVSSL scale: A brief instructor tool for\nassessing students’ perceived value of software to learning statistics.\nTeaching Statistics, 46(3). https://doi.org/10.1111/test.12374\n\n\nBakker, M., Veldkamp, C. L. S., Akker, O. R. van den, Assen, M. A. L. M.\nvan, Crompvoets, E., Ong, H. H., & Wicherts, J. M. (2020).\nRecommendations in pre-registrations and internal review board proposals\npromote formal power analyses but do not increase sample size. PLoS\nONE, 15(7), e0236079. https://doi.org/10.1371/journal.pone.0236079\n\n\nBartlett, J. E., Jenks, R., & Wilson, N. (2022). No\nMeaningful Difference in\nAttentional Bias Between\nDaily and Non-Daily\nSmokers. Journal of Trial & Error. https://doi.org/10.36850/e11\n\n\nBartlett, J., & Charles, S. (2022). Power to the\nPeople: A Beginner’s\nTutorial to Power Analysis using\njamovi. Meta-Psychology, 6. https://doi.org/10.15626/MP.2021.3078\n\n\nBem, D. J. (2011). Feeling the future: Experimental\nevidence for anomalous retroactive influences on cognition and affect.\nJournal of Personality and Social Psychology, 100(3),\n407–425. https://doi.org/10.1037/a0021524\n\n\nBinfet, J.-T., Green, F. L. L., & Draper, Z. A. (2022). The\nImportance of Client–Canine\nContact in Canine-Assisted\nInterventions: A Randomized\nControlled Trial. Anthrozoös,\n35(1), 1–22. https://doi.org/10.1080/08927936.2021.1944558\n\n\nBlanca, M. J., Alarcón, R., Arnau, J., Bono, R., & Bendayan, R.\n(2018). Effect of variance ratio on ANOVA robustness:\nMight 1.5 be the limit? Behavior Research Methods,\n50(3), 937–962. https://doi.org/10.3758/s13428-017-0918-2\n\n\nChampely, S. (2020). Pwr: Basic functions for power analysis.\nhttps://CRAN.R-project.org/package=pwr\n\n\nDasu, T., & Johnson, T. (2003). Exploratory data mining and data\ncleaning. Wiley-Interscience.\n\n\nDawtry, R. J., Sutton, R. M., & Sibley, C. G. (2015). Why\nWealthier People Think\nPeople Are Wealthier, and\nWhy It Matters: From\nSocial Sampling to Attitudes to\nRedistribution. Psychological Science,\n26(9), 1389–1400. https://doi.org/10.1177/0956797615586560\n\n\nEvans, C., Cipolli, W., Draper, Z. A., & Binfet, J.-T. (2023).\nRepurposing a Peer-Reviewed\nPublication to Engage Students in\nStatistics: An Illustration of\nStudy Design, Data\nCollection, and Analysis. Journal of\nStatistics and Data Science Education, 0(0), 1–21. https://doi.org/10.1080/26939169.2023.2238018\n\n\nHoffman, H. J., & Elmi, A. F. (2021). Do Students\nLearn More from Erroneous\nCode? Exploring Student\nPerformance and Satisfaction in an\nError-Free Versus an\nError-full SAS® Programming\nEnvironment. Journal of Statistics and Data Science\nEducation, 0(0), 1–13. https://doi.org/10.1080/26939169.2021.1967229\n\n\nIrving, D., Clark, R. W. A., Lewandowsky, S., & Allen, P. J. (2022).\nCorrecting statistical misinformation about scientific findings in the\nmedia: Causation versus correlation. Journal of\nExperimental Psychology. Applied. https://doi.org/10.1037/xap0000408\n\n\nJames, E. L., Bonsall, M. B., Hoppitt, L., Tunbridge, E. M., Geddes, J.\nR., Milton, A. L., & Holmes, E. A. (2015). Computer\nGame Play Reduces\nIntrusive Memories of\nExperimental Trauma via\nReconsolidation-Update\nMechanisms: Psychological Science, 26(8),\n1201–1215. https://doi.org/10.1177/0956797615583071\n\n\nKnief, U., & Forstmeier, W. (2021). Violating the normality\nassumption may be the lesser of two evils. Behavior Research\nMethods, 53(6), 2576–2590. https://doi.org/10.3758/s13428-021-01587-5\n\n\nLakens, D. (2022). Sample Size Justification.\nCollabra: Psychology, 8(1), 33267. https://doi.org/10.1525/collabra.33267\n\n\nLopez, A., Choi, A. K., Dellawar, N. C., Cullen, B. C., Avila Contreras,\nS., Rosenfeld, D. L., & Tomiyama, A. J. (2023). Visual cues and food\nintake: A preregistered replication of Wansink\net al (2005). Journal of Experimental Psychology: General. https://doi.org/10.1037/xge0001503.supp\n\n\nNordmann, E., McAleer, P., Toivo, W., Paterson, H., & DeBruine, L.\nM. (2022). Data Visualization Using\nR for Researchers Who\nDo Not Use R.\nAdvances in Methods and Practices in Psychological Science,\n5(2), 25152459221074654. https://doi.org/10.1177/25152459221074654\n\n\nPrzybylski, A. K., & Weinstein, N. (2017). A\nLarge-Scale Test of the\nGoldilocks Hypothesis:\nQuantifying the Relations Between\nDigital-Screen Use and the\nMental Well-Being of\nAdolescents. Psychological Science,\n28(2), 204–215. https://doi.org/10.1177/0956797616678438\n\n\nR Core Team. (2024). R: A language and environment for statistical\ncomputing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nWeissgerber, T. L., Winham, S. J., Heinzen, E. P., Milin-Lazovic, J. S.,\nGarcia-Valencia, O., Bukumiric, Z., Savic, M. D., Garovic, V. D., &\nMilic, N. M. (2019). Reveal, Don’t Conceal.\nCirculation, 140(18), 1506–1518. https://doi.org/10.1161/CIRCULATIONAHA.118.037777\n\n\nWickham, H. (2014). Tidy Data. Journal of Statistical\nSoftware, 59, 1–23. https://doi.org/10.18637/jss.v059.i10\n\n\nWickham, H. (2017). Tidyverse: Easily install and load the\n’tidyverse’. https://CRAN.R-project.org/package=tidyverse\n\n\nWingen, T., Berkessel, J. B., & Englich, B. (2020). No\nReplication, No Trust?\nHow Low Replicability\nInfluences Trust in Psychology.\nSocial Psychological and Personality Science, 11(4),\n454–463. https://doi.org/10.1177/1948550619877412\n\n\nWitt, J. K., Tenhundfeld, N. L., & Tymoski, M. J. (2018). Is there a\nchastity belt on perception? Psychological Science,\n29(1), 139–146.\n\n\nWoodworth, R. J., O’Brien-Malone, A., Diamond, M. R., & Schüz, B.\n(2018). Data from, “Web-based Positive\nPsychology Interventions: A\nReexamination of Effectiveness.”\nJournal of Open Psychology Data, 6(1), 1. https://doi.org/10.5334/jopd.35\n\n\nZhang, T., Kim, T., Brooks, A. W., Gino, F., & Norton, M. I. (2014).\nA “Present” for the Future:\nThe Unexpected Value of\nRediscovery. Psychological Science,\n25(10), 1851–1860. https://doi.org/10.1177/0956797614542274"
  },
  {
    "objectID": "00-foreword.html",
    "href": "00-foreword.html",
    "title": "Foreword",
    "section": "",
    "text": "Welcome to the Fundamentals of Quantitative Analysis\nThis book has been written and designed to help you learn core data skills through R and RStudio. These skills will lead to you being able to manipulate and analyse quantitative data - a key component of any accredited Psychology programme. In addition to this book the team will support you with helpful skills demonstration videos, and we would encourage you to use Teams to ask any questions that you have.\nThe ability to work with quantitative data is a key skill for Psychologists and by using R as our tool, for working with data, we can also promote reproducible research practices. Although at first it may seem like writing a programming script is more time-consuming than other point-and-click approaches, this is not the case! Once you have written a script that does what you need it to do, you can easily re-run your analysis without having to go through each step again manually which is a) easier and b) less likely to result in errors if you do something slightly different or forget one of the steps.\nCrucially, with an analysis script other researchers can also see how you got from the raw data to the statistics you report in your final paper. Sharing analysis scripts online on sites such as the Open Science Framework is now seen as an important open science practice. Even if you don’t continue with quantitative research, in the future, the skills you develop on this course will allow you to evaluate quantitative research and to understand what goes on behind the scenes with data before the conclusions are presented, allowing you to become much more confident and competent consumers and users of research.\n\n\nHow to use this book and the accompanying videos\nWithin the book itself, for many of the initial chapters, we will provide the code you need to use. We would always strongly encourage you to type out the code yourself, as this is good practice for learning to code, but remember you can copy and paste from the book if you need to. Typing the code will seem much slower at first and you will make errors, lots of them, but you will learn much more quickly this way so do try to write the code yourself where you can.\nWe also provide the solutions to many of the activities. No-one is going to check whether you tried to figured out an activity yourself rather than going straight to the solution but remember this, if you copy and paste without thinking, you will learn nothing. Learning data skills and the knowledge that underpins those skills is much like learning a language - the more you practice and the more you use it, the better you become.\nAdditionally, a number of the chapters of this book have an associated video or videos. These videos are there to support you as you get comfortable in your data skills. However, it is important that you use them wisely. You should always try to work through each chapter of the book (or if you prefer each activity) on your own first, and only then watch the video if you get stuck, or for extra information.\nFinally, this book is a living document. What that means is that on occasion we will make updates to the book such as fixing typos and including additional detail or activities. When substantial changes are made, we will create new support materials such as an accompanying video. However, it would be impossible to record a new video every time we make a minor change to an activity, therefore, sometimes there may be slight differences between the videos and the content of this book. Where there are differences between the book and the video, the book should always be considered the definitive version.\n\n\nIntended Learning Outcomes\nBy the end of this course students will be able to:\n\nClean and wrangle data into appropriate forms for analysis\nVisualise data using a range of plots\nConduct and interpret a core set of statistical tests (t-test, correlation, ANOVA, regression)"
  },
  {
    "objectID": "01-programming-basics.html#r-and-rstudio",
    "href": "01-programming-basics.html#r-and-rstudio",
    "title": "1  Introduction to programming with R/R Studio",
    "section": "\n1.1 R and RStudio",
    "text": "1.1 R and RStudio\nR is a programming language that you will write code in and RStudio is an Integrated Development Environment (IDE) which makes working with R easier. Think of it as knowing English and using a plain text editor like NotePad to write a book versus using a word processor like Microsoft Word. You could do it, but it would not look as good and it would be much harder without things like spell-checking and formatting.\nIn a similar way, you can use R without RStudio but we wouldn not recommend it. The key thing to remember is that although you will do all of your work using RStudio for this course, you are actually using two pieces of software. This means that you will need both, you need to keep both up-to-date, and you should cite both in any work you do (see the Appendix on citing R and RStudio when needed).\nBut first we need to look at starting up R and RStudio. There are two ways you can use R for Psychology as a student here at the University of Glasgow. First, you can use a online version of R and R through your web browser and we will refer to this as the R server. Second, you can download and install R and RStudio for free on your laptop or desktop computer.\n\n1.1.1 Installing R and RStudio on your computer\nWe recommend wherever possible installing R and RStudio on your own computer. This is known as a local installation as you do not need to be connected to the internet to use it. We find it is easier to save and manage your files, and you can take your computer wherever you go.\nHowever, we appreciate not everyone has a computer that will support R and RStudio. All of our computer lab and library spaces have R and RStudio installed, so you will always be able to access those for working through the materials and your assignments. If you cannot install R and RStudio on your computer and there are accessibility issues preventing you from using the university computers, please come and speak with your course leads who will advise alternative options.\nTo install R and RStudio on your computer, please see the Installing R/RStudio guide which we use across all of our books. The guide covers installing R/RStudio on a Windows computer, Mac, and accessing the software on one of the university computers. Please install R and RStudio before continuing with the chapter."
  },
  {
    "objectID": "01-programming-basics.html#getting-to-know-r-studio",
    "href": "01-programming-basics.html#getting-to-know-r-studio",
    "title": "1  Introduction to programming with R/R Studio",
    "section": "\n1.2 Getting to know R Studio",
    "text": "1.2 Getting to know R Studio\nBy default, RStudio has four windows:\n\nThe console, where you can type R code in the bottom left (as shown in Figure Figure 1.1).\nEventually, there will be a script editor in the top left, but you will not see this when you open RStudio for the first time.\nThe environment window in top right, where you will see things like data, functions, and objects that you create.\nFinally, the bottom right window shows files, plots, packages, and help documentation.\n\n\n\n\n\nFigure 1.1: RStudio interface\n\n\n\nYou will learn more about how to use the features included in RStudio throughout this course, but we recommend watching the RStudio Essentials 1 series of videos from the Posit team (the company who maintain RStudio). The video we link here lasts around 30 minutes and gives a tour of the main parts of RStudio.\n\n1.2.1 Console vs. scripts\nWhen you first open up RStudio, you will not see an R script like above, there will just be the console window taking up the whole left half. You can write code in the console to test it out, but you cannot save that code anywhere, and you would lose all your code if you closed down RStudio.\nFor this chapter only, we will use the console window to show you some simple R code, but from Chapter 2 - Creating reproducible documents - we will teach you to work in a type of R script called an R Markdown document which ends with the file name .Rmd.\nYou can open a new file in a number of ways, but the simplest is in the top menu of RStudio, selecting File &gt;&gt; New File &gt;&gt; R Markdown and clicking OK. You will then be able to see the extra pane in the top left like Figure Figure 1.1."
  },
  {
    "objectID": "01-programming-basics.html#writing-code-with-functions-and-arguments",
    "href": "01-programming-basics.html#writing-code-with-functions-and-arguments",
    "title": "1  Introduction to programming with R/R Studio",
    "section": "\n1.3 Writing code with functions and arguments",
    "text": "1.3 Writing code with functions and arguments\nR code is made up of functions and arguments that go into the functions to create outputs. Functions in R execute specific tasks and normally take one or more arguments. You can think of these concepts like a spoken language as verbs (function) that require a subject and an object (arguments). You could also think of them as a kind of recipe. Some recipes (function) are quite simple and have one or two ingredients (arguments), while other recipes are more complicated with many ingredients (arguments).\nYou can spot functions as they end in round brackets (known as parentheses, ()), and the arguments go within the round brackets. They tend to look a bit like this:\n\nfunction_name(argument1 = value, argument2 = value)\n\nThat would be the layout of a function with two arguments and each argument takes a value. Bare with us as these concepts might feel super abstract until you start using them.\nYou will learn to use many functions throughout this book and you can look up all the arguments that a function takes in the help documentation by using the format ?function. You will see some arguments are required while others are optional. Optional arguments will often use what is known as a default setting, value, or option (normally specified in the help documentation) if you do not enter any value.\nAs an example, let us look at the help documentation for the function rnorm() - a function which randomly generates a set of numbers from what is known as the Normal Distribution.\n\n1.3.1 Activity 1 - Finding help documentation for functions\nOpen up RStudio and in the console window (bottom left), type the following code:\n\n?rnorm\n\nThe help documentation for rnorm() should appear in the bottom right help panel. In the Usage section of the help, we see that rnorm() takes the following form:\n\nrnorm(n, mean = 0, sd = 1)\n\nIn the Arguments section of the help, there are explanations for each of the arguments:\n\nn is the number of observations/numbers/data points we want to create,\nmean is the mean of the observations/numbers/data points we will create.\nand sd is the standard deviation of the observations/numbers/data points we will create.\n\nIn the Details section of the help, it notes that if no values are entered for mean and sd it will use a default of 0 for the mean and 1 for the standard deviation. So, these are the values the function will use for its arguments of mean and sd if you do not state any. However, because there is no default value for n, this means that you must state a value for the arguments n, otherwise the code will not run.\nThis is all still a little abstract, so let us try an example. Still using rnorm() let us set the required argument n to ask R to produce 5 random numbers.\n\n1.3.2 Activity 2 - Running your first function\nType the following two lines of code into your console window. Press enter/return on your keyboard at the end of each line to “run” that line. So, type set.seed(10072024) and press enter/return and then type rnorm(n = 5) and press enter/return. You will now see these numbers in your console window:\n\n\n[1] -0.6773381  2.9686894 -1.0461339 -1.4800300  0.4313315\n\n\nThese numbers have a mean close to 0 (M = 0.039) and a standard deviation (SD) close to 1 (SD = 1.784) - they are not exact because you only sampled a very small set and that sampling is random.\n\n\n\n\n\n\nWhat does set.seed() do?\n\n\n\n\n\nYou can get R to generate seemingly random numbers, but they are not totally random. Computers generate random numbers through a predictable process, but they pick a starting point based on something like the clock time. If you run rnorm(n = 5) several times in the console, you will see the five numbers are different each time. However, when you run set.seed(10072024) first, you will get the same five numbers every time, which is useful when you want a random but reproducible set of numbers.\n\n\n\nNow, we can play with the function and change the additional arguments to produce a different set of numbers. This time we will say we want 5 numbers again (n = 5) but we want our mean closer to 10 (mean = 10) and our standard deviation closer to 2 (sd = 2). We would do that as follows and you should see the output numbers below.\n\nset.seed(10072024)\n\nrnorm(n = 5, mean = 10, sd = 2)\n\n[1]  8.645324 15.937379  7.907732  7.039940 10.862663\n\n\nThis time, we created 5 random numbers again, but this set has a mean close to 10 (M = 10.079) and a SD close to 2 (SD = 3.569). Hopefully, you are starting to get a sense of arguments within functions, how you can change them, and how you can always remember to use the help documentation to understand what arguments a function requires.\nOver time, you start to remember which arguments you need within functions you commonly use, but even experienced R users have to regularly check the documentation. Coding is not a memory test, so do not worry if you find yourself needing to constantly look up the name of arguments.\n\n\n\n\n\n\nError mode\n\n\n\nOne thing that can be intimidating at first is making **&lt;a href=‘https://psyteachr.github.io/glossary/e#error’ target=’_blank’ class=‘glossary’ title=‘The statistical error in a linear model is how much an observation’s value differs from the (typically unobserved) true value of a population parameter.’&gt;errors**. They have little red marks and produce sometimes vague messages to try and explain what went wrong. You will make many errors as you learn and over time, you do not stop making errors, but you get faster at working out what went wrong and how you can fix it. So, we will introduce you to common errors as we work through the book to help with problem solving.\nTry and run the following code in the console:\n\nrnorm(mean = 10, sd = 2)\n\nYou should get an error saying something like Error in rnorm(mean = 10, sd = 2): argument \"n\" is missing, with no default. This error message is useful as it is telling us we forget to state the n argument which has no default value, so the function has no idea how many observations to give you. You would fix this error by adding a value for n within the function.\n\n\n\n1.3.3 Stating argument names\nIn the examples above, we have written out the argument names in our code (for example, we wrote n = 5, mean = 10, sd = 2), however, this is not strictly necessary. The following two lines of code would produce very similar outputs with the same number of values and similar means and standard deviations. Remember though: each time you run rnorm(), it will produce a slightly different set of numbers unless you set a seed.\n\nrnorm(n = 6, mean = 3, sd = 1)\nrnorm(6, 3, 1)\n\nThe main thing is that both lines of code would still work - the code knows what to do with the numbers. Both options work as the code is following a set order of arguments: n then mean then sd. If you do not write out the argument names, the code will use the default order of arguments, which for rnorm will assume that the first number you enter is n, the second number is mean, and the third number is sd.\nSo, you can write the argument names or not, but it is important to know the default order if you choose not to write the argument names. Alternatively, if you write out the argument names, then you can write the arguments in whatever order you like. The code below will still work and produce six numbers with a mean close to 3 and a standard deviation close to 1.\n\nrnorm(sd = 1, \n      n = 6, \n      mean = 3)\n\nWhen you are first learning R, we recommend writing out the argument names every time as it can help you remember and understand what each part of the function is doing. However, as your skills progress you may find it quicker to omit the argument names and you will also see examples of code online that do not use argument names. In this course, we will always write out the argument names the first time we use each function, but afterwards, we may omit them.\n\n\n\n\n\n\nWarning\n\n\n\nIf you do omit argument names, it is important to check the values you use for arguments are the ones you intended to you. The sneakiest errors are the ones that “work” in that they do not produce an error, but they are doing something different to what you expect. For example, if you wanted five numbers with a mean of 1 and SD of 2, rnorm(5, 2, 1) would work, but we accidentally entered the mean and SD the wrong way around.\n\n\n\n1.3.4 Tab auto-complete\nOne very useful feature of RStudio is the tab auto-complete for functions (see Figure Figure 1.2). If you write the name of the function and then press the tab key on your keyboard, RStudio will show you the arguments that function takes along with a brief description. If you press enter on the argument name, it will fill in the name for you, just like auto-complete on your phone.\nYou can also use the tab button when writing a function name to auto-complete that function name or to find functions that start with certain letters. This feature can be really helpful if you cannot quite remember the name of a function or argument.\n\n\n\n\nFigure 1.2: Tab auto-complete"
  },
  {
    "objectID": "01-programming-basics.html#packages",
    "href": "01-programming-basics.html#packages",
    "title": "1  Introduction to programming with R/R Studio",
    "section": "\n1.4 Base R and packages",
    "text": "1.4 Base R and packages\nWhen you install R, you will have access to a range of functions including options for data wrangling and statistical analysis. The functions that are included in the default installation of R are typically referred to as Base R and there is a useful cheat sheet that shows many Base R functions about halfway down this page under Contributed Cheatsheets here, along with a host of other cheatsheets you might find useful.\nHowever, the power of R is that it is extendable and open source. If a function does not exist or does not work very well, anyone can create a new package that contains data and/or code to allow you to perform new tasks. You can think of Base R as the default apps that come on your phone and other packages as additional apps; the ones that you really want to use to make the phone your own, but you need to download them separately.\n\n1.4.1 Activity 3 - Install the tidyverse to your own computer\nTo use a package, you must first install it. The following code installs the package tidyverse, a package we will use extensively throughout this course and introduce in the next chapter.\n\n\n\n\n\n\nWarning\n\n\n\nPlease do not complete this activity if you are working on the online R server or if you are using the computers in a University lab or Boyd Orr Building. You should only complete this activity on your own device. The university computers and server already have a version of all the packages we introduce you to, and installing a new version can cause problems by having a conflict between one version on your user profile and another version on the system profile.\n\n\nIf you are working on your own computer, use the code below to install the tidyverse and typing it into the console and pressing enter/return. Remember: if you are using the online R server or using a university computer, then skip this activity.\n\ninstall.packages(\"tidyverse\")\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you have a Windows computer and get an error message that says something like “WARNING: Rtools is required to build R packages” you may need to download and install an extra bit of software called Rtools. This was part of the R/RStudio installation instructions, so please see Installing R for more detailed instructions.\n\n\nYou only need to install a package once, but each time you start R / RStudio, you must load the packages you want to use. This is like how you need to install an app on your phone once, but you need to open it every time you want to use it.\nTo load packages, we use the function library() which loads packages into your working library. Typically, you would start any analysis script by loading all of the packages you need, but we will come back to that in the next chapter.\n\n1.4.2 Activity 4 - Load the tidyverse\nRun the code below to load the tidyverse into your working library. You must complete this activity regardless of whether you are using your own computer or the university computers / online server.\n\nlibrary(tidyverse)\n\nOften when you load packages you get information in your console window. Some packages will provide little messages to tell you what it has done or warn you about something. Sometimes these messages can look like errors and make you panic, but try and read over what it is saying first. For example, you should have something that looks like Figure Figure 1.3 when you load tidyverse. You might think you have done something wrong as it has little red crosses, but it is just telling you that it has loaded a set of packages and there are some conflicts.\n\n\n\n\nFigure 1.3: Example loading message from tidyverse.\n\n\n\nNow that we have loaded the tidyverse package, we can use any of the functions it contains but remember, you must run the library() function every time you start R.\n\n1.4.3 Package updates\nIn addition to updates to R and R Studio, the creators of packages also update their code. This can be to add additional functions to a package, or it can be to fix errors.\nOne thing to avoid is unintentionally updating an installed package. When you run install.packages(), it will always install the latest version of the package and it will overwrite any older versions you may have installed. Often this is not a problem, but sometimes you will find that the update means your code no longer works as the package has changed substantially. It is possible to revert back to an older version of a package but try to avoid updating a package unintentionally.\n\n\n\n\n\n\nWarning\n\n\n\nTo avoid accidentally overwriting a package with a later version, you should never include install.packages() in your analysis scripts in case you, or someone else runs the code by mistake. Remember, the online server and university computers will already have all of the packages you need for this course, so you only need to install packages if you are using your own computer.\n\n\n\n1.4.4 Package conflicts\nThere are thousands of different R packages and each package has many functions. Unfortunately, different people develop different packages and sometimes they use the same name for different functions. For example, the packages dplyr and MASS both have a function called select(). Do not run the below code, but if you did you would see a warning telling you that there is a conflict.\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(MASS)\n\n\nAttaching package: 'MASS'\n\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\n\nYou would see a warning that The following object is masked from 'package:dplyr': select.\nIn this case, R is telling you that the function select() in the dplyr package is being hidden (or ‘masked’) by another function with the same name from the MASS package. If you were to try and use select(), R would use the function from the package that was loaded most recently - in this case it would use the function from MASS. This can be an issue because you think you are using one function but really you are using another. They often work differently and you get odd issues in your code that you do not expect.\nThere are various solutions but one simple one - if you already know of the clash - is to specify which package you want to use for a particular function by writing the code in the format package::function, meaning “use the function from the package”, for example:\n\ndplyr::select()\nMASS::select()\n\nClashes are inevitable in your learning and when you see one, you will probably not spot it at first but you will learn to resolve them quickly."
  },
  {
    "objectID": "01-programming-basics.html#objects",
    "href": "01-programming-basics.html#objects",
    "title": "1  Introduction to programming with R/R Studio",
    "section": "\n1.5 Objects",
    "text": "1.5 Objects\nSo far, you have learnt about packages, and functions and arguments. Earlier we said functions give us outputs and another name for outputs - or at least specific types of outputs - are objects.\nObjects are the output of functions but you can also create objects without functions. Most of your coding will involve creating and manipulating objects. Objects contain stuff, which could be numbers, words, or the result of functions, operations, and analyses.\nThe first key thing to know about objects is how to create them and to give them content. You assign content to an object using &lt;- - often called the “left arrow” or the assignment operator which you can read as “assigned to”. Note that we do not use the = symbol as an assignment operator. There is a large discussion on why objects are assigned content and not equal to content but that is for another time. For now, just remember that we assign (&lt;-) content, be it words, numbers, or function output, to objects.\n\n1.5.1 Activity 5 - Create some objects\nType the following code into the console window and run each line. You should see that name, age, today, new_year, and data appear in the environment pane like Figure Figure 1.4.\n\nname &lt;- \"James\"\nage &lt;- 16 + 14 \ntoday &lt;- Sys.Date()\nnew_year &lt;- as.Date(\"2025-01-01\")\ndata &lt;- rnorm(n = 10, mean = 15, sd = 3)\n\n\n\n\n\nFigure 1.4: Objects in the environment. Feel free to change your numbers and check that they match the environment!\n\n\n\nNote that in these examples, name,age, and new_year would always contain the values James, 30, and the date of New Year’s Day 2025, but today will draw the date from the operating system on the day you are using the computer, and data will be a randomly generated set of data - as we saw earlier - so the values of these objects will not be static.\n\n\n\n\n\n\nTry this\n\n\n\nTry changing the name to your name and the age to your age, and seeing if they update in the environment window.\n\n\nImportantly, for what we will learn in future chapters, you can use different objects in calculations and interact with each other. For example:\n\nage + 10\n\n[1] 40\n\n\n\nnew_year - today\n\nTime difference of 110 days\n\n\n\nmean(data)\n\n[1] 15.02667\n\n\nFinally, you can store the result of these operations on objects in a new object as below:\n\ndecade &lt;- age + 10\n\nRemember that you may find it helpful to read &lt;- as contains or assigned to, e.g., name contains the text James or James is assigned to the object name.\nYou will constantly be creating objects throughout this course and you will learn more about them and how they behave as we go along. For now, it is enough to understand that they are a way of saving values, that these values can be numbers, text, or the result of operations, and that you can use objects in further operations to create new objects.\n\n\n\n\n\n\nWhat should I call objects?\n\n\n\nIn coding, we are trying to balance keeping objects names as short as possible to be easy to type repeatedly, while being informative enough that you know what they represent days, weeks, or months later when they are not fresh in your memory.\nFor example, dob might save time now, but birth_date will be easier to understand in future.\n\n\n\n1.5.2 Looking after the environment\nNow that you are starting to learn about the other windows in RStudio like the environment window, if you have been writing a lot of code, you may find that the environment window (or workspace) becomes cluttered with many objects. This can make it difficult to figure out which object you need and you run the risk of using the wrong value or data frame. If you are working on a new dataset, or if you have tried lots of different code before getting the final version, it is good practice to remember to clear the environment to avoid using the wrong object. You can do this in several ways.\n\nTo remove individual objects, you can type rm(object_name) in the console. Try this now to remove one of the objects you created in the previous section. For example, you would remove the object age by writing rm(age).\nTo clear all objects from the environment, run rm(list = ls()) in the console.\nTo clear all objects from the environment, you can also click the broom icon in the environment pane like Figure Figure 1.5.\n\n\n\n\n\nFigure 1.5: Clearing the workspace."
  },
  {
    "objectID": "01-programming-basics.html#global-options",
    "href": "01-programming-basics.html#global-options",
    "title": "1  Introduction to programming with R/R Studio",
    "section": "\n1.6 Global options",
    "text": "1.6 Global options\nWhen you open RStudio, it will show you what you were last working on, including your code and any objects you have created, assuming this is not the first time you have used RStudio. This might sound helpful, but it can cause more problems than it is worth because it means that you risk accidentally using an old version of an object.\nFor example, you might have Date in the environment from the last time you did some work and you start working on the wrong Date without realising. In reality, we recommend changing the settings so that each time you start RStudio, it opens a fresh new environment.\nYou can do this by clicking on the top menu Tools &gt;&gt; Global Options... and then deselecting boxes so that your General box looks like Figure Figure 1.6 and applying the changes to save your selections.\n\n\n\n\nFigure 1.6: Global options - you want to make your global options look similar, in terms of what is ticked, to the above. The main thing is to make sure that you untick Restore RData into workspace at startup, and set Save workspace to .RData on exit to Never. Unticking the History options are optional but can help. The update option is really just in case you want to.\n\n\n\nThat should save a lot of hassle going forward. You will still encounter issues of course, so we are going to end this chapter by outlining where you can get help."
  },
  {
    "objectID": "01-programming-basics.html#getting-help",
    "href": "01-programming-basics.html#getting-help",
    "title": "1  Introduction to programming with R/R Studio",
    "section": "\n1.7 Getting Help",
    "text": "1.7 Getting Help\n\n1.7.1 Help and additional resources\nLearning to code really means trying stuff out, searching for help online when it does not work, and finding examples of code to adapt to your own needs.\nIf you are having difficulty with any of the content in this book, then you can of course ask for help from the course team but learning to problem solve effectively is a key skill that you will develop throughout this course and beyond.\nThere are a wealth of additional resources in the Appendix of this book, so it might be worth checking them out, but here are four approaches we take to resolving an issue when we hit a problem.\n\nUse the help documentation. If you are struggling to understand how a function works or what the arguments are, remember the ?function command.\nThink about when you last had to use this function or code successfully. Look back on what you did then and see what is the difference.\nIf you get an error message, copy and paste it into Google. It is very likely someone else has had the same problem.\nTrying Googling your question in the style of the package name or function name and what you want to do. For example, arrange data tidyverse or maybe sort data in R.\n\nIf those approaches do not work, in addition to these course materials and the other PsyTeachR books from other courses we run, there are many excellent online resources for learning data skills that can serve as quick guides:\n\nIndividual package cheat sheets which you can find via the top menu: Help &gt;&gt; Cheat Sheets.\nR Cookbook.\nStackOverflow.\nR for Data Science.\n\n1.7.2 Debugging tips\nAnother top skill for resolving issues is what is known as debugging - fixing your coding mistakes. A large part of coding is trying to figure why your code does not work and this is true whether you are a novice or an expert. As you progress through this course, try and keep a record of mistakes you make and how you fixed them. We will highlight common mistakes to look out for throughout the book but you will undoubtedly make (and fix) new mistakes yourself.\nYou never stop making mistakes, you just get better at problem solving and having a list of strategies that worked in the past. That is why we include error mode as a set of activities to develop your problem solving skills and normalise making errors.\nAs a short list of suggestions when you come across an error, keep in mind:\n\nHave you loaded the correct packages for the functions you are trying to use? One common mistake is to write the code to load the package, e.g., library(tidyverse) but then forget to press enter/return to run it.\nHave you made a typo? Coding has to be specific on spelling and data is not the same as DATA, and t.test is not the same as t_test.\nIs there a package conflict? Have you tried specifying the package and function with package::function?\nIs it definitely an error? Not all red text in R / RStudio means an error. Sometimes it is just giving you a message with information.\n\n1.7.3 Activity 6 - Reset your R session\nFinally, if you find that your code is not working and you cannot figure out why, it might be worth starting a new session. This will clear the environment and detach all loaded packages. Think of it like restarting your phone.\nWhen you open up R and start writing code, loading packages, and creating objects, you are typically doing so in a new session. In addition to clearing your environment workspace, it can sometimes be useful to start a new session. This will happen automatically each time you start RStudio on your computer, although sessions can persist if you use the online server.\nThis last activity shows a quick way to restart R from inside RStudio. On the Top Menu, click Session &gt;&gt; Restart R like Figure Figure 1.7.\n\n\n\n\nFigure 1.7: Restarting your R session from within RStudio.\n\n\n\nTry not to worry about making mistakes. Accept that you will make them and learn from them. We are always here to help if you are struggling, so reach out to the course team, post on Teams, or attend a graduate teaching assistant (GTA) session."
  },
  {
    "objectID": "01-programming-basics.html#test-yourself",
    "href": "01-programming-basics.html#test-yourself",
    "title": "1  Introduction to programming with R/R Studio",
    "section": "\n1.8 Test yourself",
    "text": "1.8 Test yourself\nThroughout the book, you will find additional questions and activities like these to help you check your understanding. Some will have blanks to fill in, some will be multiple choice, but the chapters include the answers and explanations to check your understanding against. You are always welcome to ask further questions to the course team though.\n\n1.8.1 Knowledge check\nQuestion 1. Why should you never include the code install.packages() in your analysis scripts?\n\nYou should use library() insteadPackages are already part of Base RYou (or someone else) may accidentally install a package update that stops your code workingYou already have the latest version of the package\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nRemember, when you run install.packages() it will always install the latest version of the package and it will overwrite any older versions of the package you may have installed.\n\n\n\nQuestion 2. What will the following code produce?\n\nrnorm(6, 50, 10)\n\n\nA dataset with 10 numbers that has a mean of 6 and an SD of 50A dataset with 6 numbers that has a mean of 50 and an SD of 10A dataset with 50 numbers that has a mean of 10 and an SD of 6A dataset with 50 numbers that has a mean of 10 and an SD of 6\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nThe default form for rnorm() is rnorm(n, mean, sd). If you need help remembering what each argument of a function does, look up the help documentation by running ?rnorm.\n\n\n\nQuestion 3. If you have two packages that have functions with the same name and you want to specify exactly which package to use, what code would you use?\n\npackage::functionfunction::packagelibrary(package)install.packages(package)\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nYou should use the form package::function, for example dplyr::select. Remember that when you first load your packages R will warn you if any functions have the same name - remember to look out for this!\n\n\n\nQuestion 4. Which of the following is most likely to be the input to an argument?\n\n35&lt;-read_csv()\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nread_csv() looks like a function as it has the round brackets at the end and the &lt;- is the assignment symbol, so it is most likely that 35 might be the input to an argument as it is just a value.\n\n\n\nQuestion 5. An easy way to spot functions is to look for\n\ncomputersnumbersround brackets\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nRemember that functions tend to have round brackets or parentheses at the end of their name and the arguments and values go inside the parentheses.\n\n\n\nQuestion 6. The job of &lt;- is to send the output from the function to a/an\n\nargumentobjectassignment\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nThis is the assignment operator (&lt;-) and we use it to assign content such as the output of functions to an object.\n\n\n\n\n1.8.2 Error mode\nThe following questions are designed to introduce you to making and fixing errors. Try and run the code, look at the error message, and see if you can fix it before checking the answer. Consider keeping a note of what kind of error messages you receive and how you fixed them, so you have a bank of solutions when you tackle errors independently.\nQuestion 7. Type the following code into the console and press enter/return: rnorm(n = 10, meen = 5, sd = 1). You should get an error saying something like Error in rnorm(n = 10, meen = 5, sd = 1) : unused argument (meen = 5). How can you fix it?\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nWe accidentally spelt one of the arguments incorrectly. If you look closely, you will see that we typed meen spelt with two es instead of one e when we should have typed mean.\n\n\n\nQuestion 8. To end on a sneaky one that we have not covered in this chapter, type the following code into the console and press enter/return: rnorm(n = 10, mean = 5, sd = 1. What happened and how can you fix it? Before checking the explain this answer box below, maybe try and Google what happens to see if you can describe it and find a solution.\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nWe missed the final bracket, so we start the function name rnorm(, enter our arguments, but there is no closing bracket. You will see in the console like Figure Figure 1.8, there is a little + symbol and you can enter new code, but there is no output.\n\n\n\n\nFigure 1.8: An R function without a closing bracket in the console.\n\n\n\nThis can be really frustrating as it looks like nothing is happening, but when you did not add a closing bracket, R is just sitting there waiting for you to add something else. To fix it, you can either type ) and press enter/return to finish the function and it should work, or you can press the escape (esc) key to cancel the code and start again."
  },
  {
    "objectID": "01-programming-basics.html#words-from-this-chapter",
    "href": "01-programming-basics.html#words-from-this-chapter",
    "title": "1  Introduction to programming with R/R Studio",
    "section": "\n1.9 Words from this Chapter",
    "text": "1.9 Words from this Chapter\nBelow, you will find a list of words that we used in this chapter that might be new to you in case you need to refer back to what they mean. The links in this table take you to the entry for the words in the PsyTeachR Glossary. Note that numerous members of the team wrote entries in the Glossary and as such the entries may use slightly different terminology from what we used in the chapter.\n\n\n\n\nterm\ndefinition\n\n\n\nargument\nA variable that provides input to a function.\n\n\nassignment-operator\nThe symbol &lt;-, which functions like = and assigns the value on the right to the object on the left\n\n\nbase-r\nThe set of R functions that come with a basic installation of R, before you add external packages.\n\n\nconflict\nHaving two packages loaded that have a function with the same name.\n\n\nconsole\nThe pane in RStudio where you can type in commands and view output messages.\n\n\ndefault-value\nA value that a function uses for an argument if it is skipped.\n\n\nenvironment\nA data structure that contains R objects such as variables and functions\n\n\nerror\nThe statistical error in a linear model is how much an observation's value differs from the (typically unobserved) true value of a population parameter.\n\n\nfunction\nA named section of code that can be reused.\n\n\nmean\nA descriptive statistic that measures the average value of a set of numbers.\n\n\nnormal-distribution\nA symmetric distribution of data where values near the centre are most probable.\n\n\nobject\nA word that identifies and stores the value of some data for later use.\n\n\npackage\nA group of R functions.\n\n\nr-markdown\nThe R-specific version of markdown: a way to specify formatting, such as headers, paragraphs, lists, bolding, and links, as well as code blocks and inline code.\n\n\nrstudio\nAn integrated development environment (IDE) that helps you process R code.\n\n\nscript\nA plain-text file that contains commands in a coding language, such as R.\n\n\nsession\nWhen you start R/RStudio and executive code to fill the workspace until you close R/RStudio\n\n\nstandard-deviation\nA descriptive statistic that measures how spread out data are relative to the mean.\n\n\ntidyverse\nA set of R packages that help you create and work with tidy data"
  },
  {
    "objectID": "02-intro-to-r.html#using-your-working-directory",
    "href": "02-intro-to-r.html#using-your-working-directory",
    "title": "\n2  Intro to R\n",
    "section": "\n2.1 Using your Working Directory",
    "text": "2.1 Using your Working Directory\nBefore you starting to work with data in R, and before you can save the output of what you’ve created (which you almost always will want to do), you first need to tell R where the working directoryThe filepath where R is currently loading files from and saving files to. is. What this means is that we tell R where the files we are going to use (such as our raw data) are located, and where we want to save any files you have created. Think of it just like when you have different course modules, and you have separate folders for each topic e.g. biology, history and so on. When working with data, it’s useful to have all the data sets and files you need nicely organised in folders.\nWe would highly recommend making a new folder for this course, maybe called “PsychResearchMethods”, “ResearchMethodsLabs”, or “FundamentalsOfQuantAnalysis” and then add sub-folders, inside that folder as you carry out each chapter, saving any data, scripts, and portfolio files for each chapter into these folders. The main thing is that you call the folder something sensible so that you know what it is and where it is. However, see the red warning box below!\n\n\n\nWhatever you do, don’t call the folder your keep your data skills work in “R”. If you do this, sometimes R has an identity crisis and won’t save or load your files properly. It can also really damage your setup of R and lead you to having to reinstall everthing. The reason being is that, remembering packages from the first chapter, R tends to save all the packages in a folder called R. If there is another folder called R then it gets confused and stops working properly. You can of course have a folder called “my_Rwork” but just not “R” by itself.\n\n\n\nTop tip 1: If you’re using R on your laptop rather than the server, it can also be a good idea to save your work onto a cloud storage server like OneDrive so that you never lose your work. Particularly if the work relates to assignments. Just like your written work, you wouldn’t want to lose your coding work!\nTop tip 2: Coding is every so slightly easier when file names and folder names do not have spaces in them. We would suggest folder names like “PsychResearchMethods” instead of “Psych Research Methods”.\n\n2.1.1 Activity 1: Create your a folder for all your work\n\nChoose a location for the work and assignments you will do for this module and then create a folder and the necessary sub-folders for each chapter. These will be blank for now but we will add to them over the semester.\n\n2.1.2 Activity 1b: Upload data files to the server\nNote: This activity (activity 1b) is only for those using the University of Glasgow R Server - if you are using a local installation on your own device you will not need to do this activity and skip down to Activity 2.\nThe main disadvantage to using the R server is that you will need create folders on the server and then upload and download any files you are working on to and from the server. Please be aware that there is no link between your computer and the R server. If you change files on the server, they won’t appear on your computer until you download them from the server, and you need to be very careful when you submit your assessment files that you’re submitting the right file. This is the main reason we recommend installing R on your computer if you can.\nGoing forward throughout this book, if you’re using the server, you’ll do an extra step where you also upload them to the sever. We’re not going to use any data files in this session but let’s try an example to make it clear how you get the data files on to the server.\n\nLog on to the R server using the link on the main course Moodle page.\nIn the file pane click New folder and create the same structure you created on your computer.\nDownload ahi-cesd.csv and participant-info.csv into the chapter folder on your computer. To download a file from this book, right click the link and select “save link as”. Make sure that both files are saved as “.csv”. Do not open them on your machine as often other software like Excel can change setting and ruin the files.\nNow that the files are stored on your computer, go to RStudio on the server and click Upload then Browseand choose the folder for the chapter you’re working on.\nClick Choose file and go and find the data you want to upload.\n\n2.1.3 Activity 2: Set the working directory\nOk great, now that we have a folder structure that will keep everything nice and ordered you need to set the working directory by clicking on the top menu, Session &gt;&gt; Set Working Directory &gt;&gt; Choose Directory and then select the relevant folder for this chapter as your working directory.\nNote: Setting the working directory means that you are telling R where the data is that you want to work on. It is also where you are going to save files and output. More often than not, when learning, the most common error is because people have not set the working directory and R does not know where the data is!\nTop tip: One of the first things we always do when we open R in RStudio is set the working directory to where our data is.\n\n\n\n\nSetting the working directory"
  },
  {
    "objectID": "02-intro-to-r.html#r-markdown-for-data-skills-and-portfolio-assignments",
    "href": "02-intro-to-r.html#r-markdown-for-data-skills-and-portfolio-assignments",
    "title": "\n2  Intro to R\n",
    "section": "\n2.2 R Markdown for data skills and portfolio assignments",
    "text": "2.2 R Markdown for data skills and portfolio assignments\nOk great, we now have a folder structure we are going to use and we have told R where it is so now let’s write some code!\nFor the duration of this data skills book and the related assignments you will use a worksheet format called R Markdown (abbreviated as Rmd) which is a great way to create dynamic documents with embedded chunks of code. Remember you saw scripts in Chapter 1? Well R Markdown is like a script but has some excellent features that make it so much better.\nR Markdown documents are self-contained and fully reproducible (if you have the necessary data, you should be able to run someone else’s analyses with the click of a button) which makes it very easy to share. This is an important part of your open science training as one of the reasons we teach data skills this way is that it enables us to share open and reproducible information. Using these worksheets enables you to keep a record of all the code you write during this course, and when it comes time for the portfolio assignments, we can give you a task you can and then fill in the required code.\nFor more information about R Markdown feel free to have a look at their main webpage sometime http://rmarkdown.rstudio.com but for now, the key advantage to know about is that it allows you to write code into a document, along with regular text, and then knit it using the package knitr to create your document as either a webpage (HTML), a PDF, or Word document (.docx). This will become more clear with an example!\n\n2.2.1 Activity 3: Open and save a new R Markdown document\n\nOpen a new R Markdown document by clicking the ‘new item’ icon and then click ‘R Markdown’ as shown here:\n\n\n\n\n\nOpening a new R Markdown document\n\n\n\n\nYou will now be prompted to give it a title so let’s call it “Intro to R”.\nAlso, change the author name to your GUID as this will be good practice for the portfolio assignments. * Leave the output format selected as HTML for now!\n\nOnce you click OK this will open a new R Markdown document.\n\nSave this R Markdown document, by clicking File &gt;&gt; Save as from the top menu, and name this file “Intro to R” as well.\n\nIf you’ve set the working directory correctly, you should now see this file appear in your file viewer pane in the bottom right hand corner like in the example below (your file names and folders will be different depending on what you called the folders and file).\n\n\n\n\nNew file in working directory\n\n\n\n\n2.2.2 Activity 4: Create a new code chunk\nGreat. We now have our R Markdown document so let’s start using it to see how we can combine code and text to create an informative document.\nWhen you first open a new R Markdown document you will see a bunch of default text that looks like this:\n\n\n\n\nNew R Markdown text\n\n\n\nThe default text is just there to give you some examples of what you can do with R Markdown but we are going to show you that as well so do the following:\n\nDelete everything below line 7\nOn line 8 type “About me”\nClick on the Top Menu: Code &gt;&gt; Insert Chunk from the top menu.\n\nYour Markdown document should now look something like this:\n\n\n\n\nNew R chunk\n\n\n\nWhat you have created is called a code chunk. In R Markdown, anything written outside of a code chunk is assumed to be just normal text, just like you would have in a text editor, and anything written inside the code chunk is assumed to be code. This makes it easy to combine both text and code in one document.\n\n\n\nWhen you create a new code chunk you should notice that the grey box starts and ends with three back ticks, followed by the {r}, and then it ends with three back ticks again. This is the structure that creates a code chunk. You could actually just type this structure instead of using the Insert approach but when learning it does help a bit!\n\n\nOne common mistake is to accidentally delete these back ticks. A useful thing to notice is that code chunks tend to have a different color background - in the default viewing settings a code chunk is grey and the normal text is white. You can use this to look for mistakes. If the colour of certain parts of your Markdown doesn’t look right, check that you haven’t deleted the backticks.\n\n\nIn addition, remember it is backticks (i.e. this `) and not single quotes (i.e. not this ’)!\n\n\n\n\n2.2.3 Activity 5: Write some code\nAwesome! You are doing great and learning more than you think you are!\nNow we’re going to use the code examples you read about in Programming Basics to add some code to our R Markdown document.\n\nIn your code chunk write the below code but replace the values of name/age/birthday with your own details). Remember that the four lines of code should all be inside the code chunk!\n\nNote: Text and dates need to be contained in quotation marks, e.g. “my name”. Numerical values are written without quotation marks, e.g. 45.\nTop tip: Missing and/or unnecessary quotation marks are a common cause of code not working - remember this!\n\nname &lt;- \"Emily\" \nage &lt;- 35\ntoday &lt;- Sys.Date()\nnext_birthday &lt;- as.Date(\"2021-07-11\")"
  },
  {
    "objectID": "02-intro-to-r.html#running-code-in-r-markdown",
    "href": "02-intro-to-r.html#running-code-in-r-markdown",
    "title": "\n2  Intro to R\n",
    "section": "\n2.3 Running code in R Markdown",
    "text": "2.3 Running code in R Markdown\nBrilliant! We now have code in our code chunk and now we are going to run the code! Running the code just trying to make it work, or seeing if it works! When you’re working in an R Markdown document, there are several ways to run your lines of code.\n\nFirst, one slow option is you can highlight the code you want to run and then click Run &gt;&gt; Run Selected Line(s).\n\n\n\n\n\nSlow method of running code\n\n\n\n\nAlternatively, you can press the green “play” button at the top-right of the code chunk and this will run all lines of code in that chunk.\n\n\n\n\n\nSlightly faster method of running code that runs all lines within the code chunk!\n\n\n\nEven better though is to learn some of the keyboard shortcuts below so it becomes more natural and fluid in your typing and makes your learning easier!\n\nTo run a single line of code, make sure that the cursor is in the line of code you want to run and press ctrl + enter.\nIf you want to run all of the code in the code chunk, press ctrl + shift + enter. Note: When using this last method of running lines of code - by positioning the cursor on the line and using ctrl + enter on your keyboard, note that the cursor does not have to be at any specific point of the line, i.e. it does not have to be at the start, middle or the end, it can literally be anywhere.\n\n\n2.3.1 Activity 6: Run your code\n\nNow run your code using one of the methods above. You should see the variables name, age, today, and next_birthday appear in the environment pane in the top right corner.\nClear out the environment using the broom handle approach we saw in Chapter 1 and try a different method to see which works best for you!\n\n2.3.2 Activity 7: Inline code\nSuperb! Our code works and we know how to run it. But one of the incredible benefits we said about R Markdown is that you can mix text and code. Even better is that you can combined code into a sentence to put specific outputs of your code, like a value, using what is called inline code. Think about a time you’ve had to copy and paste a value or text from one file in to another and you’ll know how easy it can be to make mistakes. Inline code avoids this. It’s easier to show you what inline code does rather than to explain it so let’s have a go.\nFirst, copy and paste this text exactly (do not change anything) to the underneath and outside your code chunk - this will be the white section under the grey code chunk if you are using default views.\n\nMy name is `r name` and I am `r age` years old. \n\nIt is `r next_birthday - today` days until my birthday.\n\nOk so nothing happened there but that is because we have not done the last magic step - in the next activity!\n\n2.3.3 Activity 8: Knitting your file\nAs our final step we are going to knit our file. This means that we’re going to compile (i.e. turn) our code into a document that is more presentable. * From the top menu, click Knit &gt;&gt; Knit to HMTL. R Markdown will now create a new HTML document and it will automatically save this file in your working directory.\nNow let’s look at this outputted HTML document and at the sentence we copied in from Activity 7. As if by magic, that slightly odd bit of text you copied and pasted now appears as a normal sentence with the values pulled in from the objects you created.\nMy name is Emily and I am 35 years old. It is -1062 days until my birthday.\nPretty amazing isn’t it! We’re not going to use inline coding very often in the rest of the course but hopefully you can see just how useful this would be when writing up a report with lots of numbers! R Markdown is an incredibly powerful and flexible format - this book was written using it! The key thing about using inline coding is the structure, i.e. the backtick, followed by the lower case r, then space, then the code, then another backtick. You will get the hang of it as the semester goes on with a little practice.\nThere are a few final things to note about knitting that will be useful for going forward with your data skills learning and assignments:\n\nR Markdown will only knit if your code works - this is a good way of checking for assignments whether you’ve written functioning code!\nYou can choose to knit to a Word document rather than HTML. This can be useful for e.g., sharing with others, however, it may lose some functionality and it probably won’t look as good so we’d recommend always knitting to HTML.\nYou can choose to knit to PDF, however, unless you’re using the server this requires a LaTex installation and is quite complicated. If you don’t already know what LaTex is and how to use it, do not knit to PDF. If you do know how to use LaTex, you don’t need us to give you instructions!\nR will automatically open the knitted HTML file in the viewer, however, you can also navigate to the folder it is stored in and open the HTML file in your web browser (e.g., Chrome or Firefox)."
  },
  {
    "objectID": "02-intro-to-r.html#finished",
    "href": "02-intro-to-r.html#finished",
    "title": "\n2  Intro to R\n",
    "section": "\n2.4 Finished",
    "text": "2.4 Finished\nAnd you’re done! On your very first time using R you’ve not only written functioning code but you’ve written a reproducible output! You could send someone else your R Markdown document and they would be able to produce exactly the same HTML document as you, just by pressing knit.\nThe key thing we want you to take away from this chapter is that the data skills that you are going to learn can be broken down into manageable chunks and that is how we are going to teach you to help you learn them. The skills might be very new to a lot of you, but we’re going to take you through it step-by-step. You’ll be amazed at how quickly you can start producing professional-looking data visualisations and analysis.\nIf you have any questions about anything contained in this chapter or in Programming Basics, please remember to ask us!"
  },
  {
    "objectID": "02-intro-to-r.html#test-yourself",
    "href": "02-intro-to-r.html#test-yourself",
    "title": "\n2  Intro to R\n",
    "section": "\n2.5 Test Yourself",
    "text": "2.5 Test Yourself\n\nOne of the key first steps when we open RStudio is to:\n\nset your working directoryput on some top tunes as we will be here a whilebuild some foldersmake a coffee\n\n\n\n\n\nExplain This Answers\n\n\nOne of the most common issues we see is that code doesn’t work first time because people have forgotten to set the working directory. The working directory is the file you want to save any files to, or any output, or contains your data. Code needs to know where the data is so we set the working directory as the first step when we open RStudio\n\n\n\n\nWhen using the default environment color settings for RStudio what color would the background of a code chunk be in R Markdown? \nwhite\nred\ngreen\ngrey\nWhen using the default environment color settings for RStudio what color would the background of normal text be in R Markdown? \nwhite\nred\ngreen\ngrey\n\n\n\nExplain These Answers\n\n\nAssuming you haven’t changed any of the settings in RStudio, code chunks will tend to have a grey background and normal text will tend to have a white background. This is a good way to check that you have closed and opened code chunks correctly.\n\n\n\n\nCode chunks are started with:\n\nthree single quotesthree backticksthree double quotesthree single clefs\n\n\n\n\n\nExplain This Answers\n\n\nCode chunks always take the same general format of three backticks followed by curly parentheses and a lower case r inside the parentheses. Often people mistake these backticks for single quotes but that won’t work. If you have set your code chunk correctly, using backticks, the background color will change!\n\n\n\n\nInline coding is:\n\nwhere you nicely organise your code in a linewhere you make sure all the code is nicely indented from the sidean exuberant way of exclaiming you have written good code!an approach of intergrating code and text in a sentence outside of a code chunk\n\n\n\n\n\nExplain This Answers\n\n\nInline coding is an incredibly useful approach for merging text and code in a sentence outside of a code chunk. It can be really useful for when you want to add values from your code directly into your text. Copying and pasting can create errors easily so better to code it when you can!"
  },
  {
    "objectID": "02-intro-to-r.html#words-from-this-chapter",
    "href": "02-intro-to-r.html#words-from-this-chapter",
    "title": "\n2  Intro to R\n",
    "section": "\n2.6 Words from this Chapter",
    "text": "2.6 Words from this Chapter\nBelow you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the PsyTeachR Glossary. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter.\n\n\n\n\nterm\ndefinition\n\n\n\nchunk\n\n\n\nHTML\n\n\n\nknit\n\n\n\nR markdown\n\n\n\nreproducible research\n\n\n\nworking directory\nThe filepath where R is currently loading files from and saving files to.\n\n\n\n\n\nEnd of Chapter\nThat is end of this chapter. Be sure to look again at anything you were unsure about and make some notes to help develop your own knowledge and skills. It would be good to write yourself some questions about what you are unsure of and see if you can answer them later or speak to someone about them. Good work today!"
  },
  {
    "objectID": "04-wrangling-1.html#tidyverse",
    "href": "04-wrangling-1.html#tidyverse",
    "title": "4  Data wrangling 1: Join, select, and mutate",
    "section": "\n4.2 Tidyverse",
    "text": "4.2 Tidyverse\nIn the first chapter we introduced a package called tidyverse and it is going to be at the core of a lot of the data skills you develop. The tidyverse https://www.tidyverse.org/ (Wickham, 2017) is actually a collection of packages developed by a team led by the world-famous data scientist Hadley Wickham. Those core packages contained within tidyverse are dplyr, tidyr, readr, purrr, ggplot2, and tibble, and within these six core packages you will have access to functions that will pretty much cover everything you need in order to be able to wrangle and visualise your data.. Again, don’t worry about trying to remember all the different packages and what they all do, that will come with practice. The main thing to note however is that previously when you typed library(tidyverse) into your code, you will have seen that it loads in all of these packages in one go. You will learn how to use a whole host of functions from the tidyverse as we progress, but in this chapter we are going to focus on functions from the dplyr package, mainly for data wrangling, and ggplot2 for visualisation (i.e. creating images and figures).\nLooking at the dplyr package specifically, it contains six very important functions based on common English verbs to help readability of the code. These six verbs are often referred to as the Wickham Six “one-table” dplyr verbs as they perform actions on a single table of data. Those six functions are:\n\n\nFunction\nDescription\n\n\n\nselect()\nInclude or exclude certain variables (columns)\n\n\nfilter()\nInclude or exclude certain observations (rows)\n\n\nmutate()\nCreate new variables (columns)\n\n\narrange()\nChange the order of observations (rows)\n\n\ngroup_by()\nOrganize the observations (rows) into groups\n\n\nsummarise()\nCreate summary variables for groups of observations\n\n\n\nJust looking at the names gives you some idea of what the functions do. For example, select(), which we saw previously, selects columns! But don’t be fooled, although the operations of these functions may seem very simplistic, it’s amazing what you can accomplish when you string them together. Hadley Wickham, in fact, has claimed that 90% of data analysis can be reduced to the operations described by these six functions. You are going to use the functions but we will introduce them today just to show what they can do.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data wrangling 1: Join, select, and mutate</span>"
    ]
  },
  {
    "objectID": "04-wrangling-1.html#intro-to-the-babynames-database",
    "href": "04-wrangling-1.html#intro-to-the-babynames-database",
    "title": "4  Data wrangling 1: Join, select, and mutate",
    "section": "\n4.3 Intro to the babynames database",
    "text": "4.3 Intro to the babynames database\nTo demonstrate the power of the six dplyr verbs we will use them to work with data from the babynames package. The babynames dataset has historical information about the births of babies in the U.S. from 1880 to the present day and is a nice understandable dataset that will allow us to us just focus on getting to know the functions across a series of activities, beginning now!\n\n4.3.1 Activity 1: Set-up\nComplete the following series of steps. If you are unsure, try consulting the previous two chapters, keeping in mind that this is something we have done before!\n\nOpen RStudio and set the working directory to your chapter folder. Ensure the environment is clear.\n\nIf you are working on the Rserver, avoid a number of issues by restarting the session - top menu: Session &gt;&gt; Restart R\n\n\n\nOpen a new R Markdown document and save it in your working directory. Call the file “DataWrangling1.Rmd”.\n\nIf you are working on your own computer, install the package babynames using the install.packages() function - you will need quotation marks around the package name. Remember, never install packages if you are working on a university computer or on the Rserver.\nDelete the default R Markdown default text (i.e. everything from line 12 down) and insert a new code code chunk that loads the packages babynames and tidyverse using library() function and run this code chunk.\n\nNote that the order of packages is deliberate!\n\n\n\n\nlibrary(babynames)\nlibrary(tidyverse)\n\n\n\n\nOn the order of libraries\n\n\nIn the first chapter you will recall we mentioned the issue of conflicts - the situation where two packages loaded into the library have functions with the same name but different approaches or jobs. The default approach that R takes in this situation is to “mask” the function from the library that was loaded in first. That means that it will use the function from the library loaded in most recently. As tidyverse contains the functions that you will use most of the time, the safest approach is to always load in the tidyverse last, regardless of the other packages you are loading in. In truth, as with everything in life, there is an additional complication involved that sometimes arises but for now taking the approach of running library(tidyverse) last is going to save a lot of issues.\n\n\n\n\n4.3.2 Activity 2: Look at the data\nGreat! Now that we have our packages loaded in let’s look at our data. The package babynames is a bit unique in that it contains an object of the same name, babynames, that contains all the data about, well, baby names, and we can look at that object to get a sense of our data.\n\nHave a look at your data by typing the word babynames into your console window and running it.\n\n\nbabynames\n\nYou should see something like the following output:\n\n\n\n\n\nyear\nsex\nname\nn\nprop\n\n\n\n1880\nF\nMary\n7065\n0.0723836\n\n\n1880\nF\nAnna\n2604\n0.0266790\n\n\n1880\nF\nEmma\n2003\n0.0205215\n\n\n1880\nF\nElizabeth\n1939\n0.0198658\n\n\n1880\nF\nMinnie\n1746\n0.0178884\n\n\n1880\nF\nMargaret\n1578\n0.0161672\n\n\n\n\n\n\nThe first line tells us “# A tibble: 1924665 x 5”. What this means is that the object we are looking at is actually a tibble, a type of two dimensional table with some unique properties, and we have data across 1924665 variables (columns) with 1924665 million observations (rows). Yes, this dataset contains over 1.9 million observations. Interested in analyzing these data by hand? No thanks!\nLooking at the column names you start to get a sense of what the data is. The variables (columns) are as follows:\n\n\n\n\n\n\n\nvariable\ntype\ndescription\n\n\n\nyear\ndouble (numeric)\nyear of birth\n\n\nsex\ncharacter\nrecorded sex of baby (F = female, M = male)\n\n\nname\ncharacter\nforename given to baby\n\n\nn\ninteger\nnumber of babies given that name\n\n\nprop\ndouble (numeric)\nproportion of all babies of that sex\n\n\n\nAs such, each row represents data about births for a given name and sex in a given year. For example, the first row of the data tells us that in the year 1880, there were 7065 baby girls (F) born in the U.S.A who were given the name Mary, and this accounted for 7.238359% of all baby girls that year.\n\n4.3.3 Activity 3: Your first plot\nBrilliant! Now we know what our data looks like in terms of the table - or really the tibble - let’s show you a quick code to help visualise some of this data.\n\nIn a new code chunk in your R Markdwon file, type the code below and run it.\n\n\ndat &lt;- babynames %&gt;% \n  filter(name %in% c(\"Emily\",\n                     \"Kathleen\",\n                     \"Alexandra\",\n                     \"Beverly\"), sex==\"F\")\n\nggplot(data = dat,\n       aes(x = year,\n           y = prop, \n           colour = name))+\n  geom_line()  \n\nAnd you should see this output:\n\n\n\n\nProportion of four baby names from 1880 to 2014\n\n\n\nNow we know that the code right now will not make much sense to you but don’t worry about that as we don’t expect you to fully understand the code just yet. The point is really to show you how much you can accomplish with very little code. The code creates a figure (Figure @ref(fig:babynames-plot-real)) showing the popularity of four girl baby names - Alexandra, Beverly, Emily, and Kathleen - from 1880 to 2014. Popularity here is expressed in proportion (y-axis) in different years (x-axis). As you will come to learn, ggplot() is the main visualisation function, and geom_line() creates a linegraph.\n\nNow change the names in your code chunk to some female names you like and run the code to see how the Figure changes.\nNow change the names in your code chunk to some male names and change the sex from “F” to “M”. Run the code and see what happens. Post the photos of your new plots on the Teams channel.\nNow change the code to what you want to display and post an image of your favorite figure that you have created on the TEAMS channel and get some praise from the TEAM!\n\n\n\nBut I want to display male AND female names!\n\nThis is more complicated than you might first imagine so only read on if you’re feeling confident. If you remove the filter for sex when creating dat and then run the plot code again, it will make a very messy looking plot (try it). This is because for most names there will be two data points because although the numbers might be small for gendered names, there is usually always at least one baby of the non-dominant name gender that has been assigned that name.\nYou can get around this by adding an additional line of code that produces separate plots by sex. See here:\n\ndat2 &lt;- babynames %&gt;% \n  filter(name %in% c(\"Emily\",\"Kathleen\",\"Alexandra\",\"Beverly\"))\n\nggplot(data = dat2,aes(x = year,y = prop, colour=name))+\n  geom_line() +\n  facet_wrap(~sex, scales = \"free_y\", nrow = 2)\n\n\nPlots by sex with different scales\n\n\nThe facet_wrap() function is one that can split up figures based on a given variable - in this case sex, meaning give me a plot for all the different sex categories we have. The scales argument tells the code that it can use different scales on the y-axis for each plot - when there’s a large difference between the two scales this is helpful to allow you to see the data in both sets (run this code and then remove the scales argument and run it again to see the difference) although it does run the risk of people misinterpreting the data if the difference between the scales isn’t made clear.\nOn the other hand, if the scales for your two groups are fairly similar, it’s better to keep the same scales to aid comparison. This time we will filter the dataset for gender neutral names where it might make more sense to have them on the same scale - again try it with and without the scales argument to see what happens\n\ndat3 &lt;- babynames %&gt;% \n  filter(name %in% c(\"Sam\",\"Alex\",\"Jordan\",\"Drew\"))\n\nggplot(data = dat3,aes(x = year,y = prop, colour=name))+\n  geom_line() +\n  facet_wrap(~sex, nrow = 2)\n\n\nPlots by sex with the same scale\n\n\n\nAs a side point, because in most countries assigned sex at birth is binary, there is no data on intersex, trans or non-binary names. In lieu of that, here’s the Wikipedia page about gender-neutral names and naming laws around the world which will hopefully make you question why we ascribe someone’s entire gender identity to a bunch of sounds and letters we use to label them.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data wrangling 1: Join, select, and mutate</span>"
    ]
  },
  {
    "objectID": "04-wrangling-1.html#six-functions-for-wrangling-the-babynames",
    "href": "04-wrangling-1.html#six-functions-for-wrangling-the-babynames",
    "title": "4  Data wrangling 1: Join, select, and mutate",
    "section": "\n4.7 Six functions for wrangling the babynames\n",
    "text": "4.7 Six functions for wrangling the babynames\n\nOk so now we have a fairly code understanding of the babynames, let’s use it to learn a bit more about the six functions from dplyr that make up a lot of data wrangling!\n\n4.7.1 Activity 7: Creating new variables with mutate()\n\nDoing really well! Only a little more to go we promise! OK so we have really learnt a lot about changing the data we have but sometimes we need to create a new variable that doesn’t exist in our dataset. For instance, we might want to figure out what decade a particular year belongs to in out babynames data and add that to our data! To create new variables, we use the function mutate().\n\nType and run the below code in a new code chunk.\n\nHere, you are mutating a new column onto the data and storing it in the object baby_decades\n\nthe first argument is the original data, babynames\n\nthe second argument is the name of the new column decade followed by what you want in that column - the decade.\nwe are creating the decades using the code `floor(year/10)*10. This seems complicated but it says take the year and divide by 10, then get rid of the decimal places, and then multiply by 10. So for example, 1945/10 = 194.5, and if you get rid of the decimal places that becomes 194, and multiply it by 10 gives you 1940s!.\n\n\n\n\nbaby_decades &lt;- mutate(.data = babynames,\n                  decade = floor(year/10) *10)\nbaby_decades\n\nThe start of the data will look something like this with the new column called decade mutated on:\n\n\n\n\n\nyear\nsex\nname\nn\nprop\ndecade\n\n\n\n1880\nF\nMary\n7065\n0.0723836\n1880\n\n\n1880\nF\nAnna\n2604\n0.0266790\n1880\n\n\n1880\nF\nEmma\n2003\n0.0205215\n1880\n\n\n1880\nF\nElizabeth\n1939\n0.0198658\n1880\n\n\n1880\nF\nMinnie\n1746\n0.0178884\n1880\n\n\n1880\nF\nMargaret\n1578\n0.0161672\n1880\n\n\n\n\n\n\nBut mutates can be much simpler like this example here. Have a look at the code and then answer the question below:\n\nbaby_where &lt;- mutate(.data = babynames,\n                  country = \"USA\")\n\nWhat will be stored in the object baby_where?\n\na tibble with one column called country that contains the decade people were borna tibble with all the original data and a new column called country stating USAa tibble with all the original data and a new column stating usaa tibble with all the original data arranged by the country USA\n\n\n\nExplain this Answer\n\nThis code will create a new object storing a tibble that has all the original data and a new column called country that states USA for each row. The mutate() adds to what is already there unless you add a select() or filter() to remove columns or rows. Note that one of the answers is wrong because it states usa in lowercase but the code states it in uppercase, i.e. USA. Remember to be specific."
  },
  {
    "objectID": "04-wrangling-1.html#dw1-a9",
    "href": "04-wrangling-1.html#dw1-a9",
    "title": "4  Data wrangling 1: Join, select, and mutate",
    "section": "\n4.5 Introducing Pipes",
    "text": "4.5 Introducing Pipes\nThe final activity for this chapter essentially repeats what we’ve already covered but in a slightly different way. In the previous activities, you created new objects with new variables or groupings and then you called summarise() on those new objects in separate lines of code. As a result, you had multiple objects in your environment pane and you need to make sure that you keep track of the different names.\nInstead, you can use pipes. Pipes are written as %&gt;% and can be read as “and then”. Pipes allow you to string together ‘sentences’ of code into ‘paragraphs’ so that you don’t need to create intermediary objects. Really, this is something that is easier to show than tell.\nThe below code does very similar to all the code we wrote above but it only creates one object.\n\npipe_summary &lt;- babynames %&gt;%\n  mutate(decade = floor(year/10) *10) %&gt;%\n  filter(name %in% c(\"Emily\",\n                     \"Kathleen\",\n                     \"Alexandra\",\n                     \"Beverly\"), sex==\"F\") %&gt;%\n  group_by(name, \n           decade) %&gt;%\n  summarise(mean_decade = mean(n))\n\n`summarise()` has grouped output by 'name'. You can override using the\n`.groups` argument.\n\n\nAgain, just to note, you may see a warning when you run the above code regarding groups in the - this is similar to the previous time we saw the message and it is just letting you know what the output is grouped by. Nothing to worry about it basically. And if we then, as is good practice, look at the output from the above code, the first few lines would gives us:\n\n\n\n\n\nname\ndecade\nmean_decade\n\n\n\nAlexandra\n1890\n6.500000\n\n\nAlexandra\n1900\n8.285714\n\n\nAlexandra\n1910\n32.700000\n\n\nAlexandra\n1920\n37.000000\n\n\nAlexandra\n1930\n44.400000\n\n\nAlexandra\n1940\n117.100000\n\n\n\n\n\n\nNow just to explain a little more, the reason that this function, the %&gt;%, is called a pipe is because it ‘pipes’ the data through to the next function. When you wrote the code previously, the first argument of each function was the dataset you wanted to work on. When you use pipes it will automatically take the data from the previous line of code so you don’t need to specify it again.\n\n\n\nRead your pipe like a paragraph\n\n\nWhen learning to code it can be a useful practice to read your code ‘out loud’ in full sentences to help you understand what it is doing. You can read the code above as “starting with babynames, create a new variable called decade AND THEN keep only the names Emily, Kathleen, Alexandra and Beverly and that belong to female babies, AND THEN group the dataset by name and decade AND THEN calculate the mean number of babies with each name per decade.” Try doing this each time you write a new bit of code and you should find the code becomes much easier to follow\n\n\n\nSome people find pipes a bit tricky to understand from a conceptual point of view, however, it’s well worth learning to use them as when your code starts getting longer they are much more efficient and mean you have to write less code which is always a good thing!",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data wrangling 1: Join, select, and mutate</span>"
    ]
  },
  {
    "objectID": "04-wrangling-1.html#dw1-fin",
    "href": "04-wrangling-1.html#dw1-fin",
    "title": "4  Data wrangling 1: Join, select, and mutate",
    "section": "\n4.6 Finished!",
    "text": "4.6 Finished!\nBrilliant! That has been a lot of information but hopefully it has started to give you a sense of some of the approaches to data wrangling and the main functions we will use as we get deeper into the book!",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data wrangling 1: Join, select, and mutate</span>"
    ]
  },
  {
    "objectID": "04-wrangling-1.html#ld-test",
    "href": "04-wrangling-1.html#ld-test",
    "title": "4  Data wrangling 1: Join, select, and mutate",
    "section": "\n4.7 Test yourself",
    "text": "4.7 Test yourself\nTo end the chapter, we have some knowledge check questions to test your understanding of the concepts we covered in the chapter. We then have some error mode tasks to see if you can find the solution to some common errors in the concepts we covered in this chapter.\n\n4.7.1 Knowledge check\nQuestion 1. Which of the following functions would you use if you wanted to keep only certain columns?\n\nselect()arrange()mutate()inner_join()\n\nQuestion 2. Which of the following functions would you use if you wanted to join two data sets by their shared identifier?\n\nselect()arrange()mutate()inner_join()\n\nQuestion 3. Which of the following functions would you use if you wanted to add or modify a column?\n\nselect()arrange()mutate()inner_join()\n\nQuestion 4. When you use mutate(), which additional function could you use to recode an existing variable?\n\narrange()case_when()case_match()filter()\n\nQuestion 5. When you use mutate(), which additional function could you use to create a new variable depending on specific criteria you set?\n\narrange()case_when()case_match()filter()\n\n\n4.7.2 Error mode\nThe following questions are designed to introduce you to making and fixing errors. For this topic, we focus on data wrangling using the functions inner_join(), select(), and mutate(). Remember to keep a note of what kind of error messages you receive and how you fixed them, so you have a bank of solutions when you tackle errors independently.\nCreate and save a new R Markdown file for these activities. Delete the example code, so your file is blank from line 10. Create a new code chunk to load tidyverse and the two data files:\n\n# Load the tidyverse package\nlibrary(tidyverse)\n\n# Load the two data files\ndat &lt;- read_csv(\"data/ahi-cesd.csv\")\npinfo &lt;- read_csv(\"data/participant-info.csv\")\n\nBelow, we have several variations of a code chunk error or misspecification. Copy and paste them into your R Markdown file below the code chunk to load tidyverse and the data. Once you have copied the activities, click knit and look at the error message you receive. See if you can fix the error and get it working before checking the answer.\nQuestion 6. Copy the following code chunk into your R Markdown file and press knit. This…works, but we want 54 columns rather than 55 columns. Some of the columns do not look quite right?\n```{r}\nall_dat &lt;- inner_join(x = dat, \n                      y = pinfo, \n                      by = c(\"id\"))\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nThis was a prompt to look out for duplicate columns when we do not specify all the common columns between the data sets you want to join. You join by “id” which works, but because you did not also add “intervention”, you get .x and .y appended to two “intervention” columns.\n\nall_dat &lt;- inner_join(x = dat, \n                      y = pinfo, \n                      by = c(\"id\", \"intervention\"))\n\n\n\n\nQuestion 7. Copy the following code chunk into your R Markdown file and press knit. You should receive an error like ! Can't subset columns that don't exist. x Column \"interventnion\" doesnt exist.\n```{r}\nselect_data &lt;- select(.data = pinfo,\n                      id,\n                      intervetnion,\n                      sex, \n                      age, \n                      educ, \n                      income)\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nThis is an example of a sneaky typo causing an error. R is case and spelling sensitive, so it does not know what you mean when you asked it to select the column “intervetnion” rather than “intervention”. To fix the error, you just need to fix the typo:\n\nselect_data &lt;- select(.data = pinfo,\n                      id,\n                      intervention,\n                      sex, \n                      age, \n                      educ, \n                      income)\n\n\n\n\nQuestion 8. Copy the following code chunk into your R Markdown file and press knit. You should receive an error like ! Cant convert \"..1 (left)\" &lt;character&gt; to &lt;double&gt;.\n```{r}\nrecode_variable &lt;- mutate(pinfo,\n                          sex = case_match(sex,\n                                           \"1\" ~ \"Female\",\n                                           \"2\" ~ \"Male\"))\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nThis is the opposite problem to what we warned about in the case_match section. You need to honour data types and we have not converted sex to a factor or character in this example. So, R does not know how to match the character “1” against the number/double 1 in the data. To fix the error, you need to remove the double quotes to give R a number/double like it can see in the data:\n\nrecode_variable &lt;- mutate(pinfo,\n                          sex = case_match(sex,\n                                           1 ~ \"Female\",\n                                           2 ~ \"Male\"))\n\n\n\n\nQuestion 9. Copy the following code chunk into your R Markdown file and press knit. We want to create two groups depending on if we consider a participant a teenager if they are younger than 20, or not a teenger if they are 20 years or older. The code below…works? This is a sneaky one, so think about the criteria we want vs the criteria we set.\n```{r}\nage_groups &lt;- mutate(pinfo,\n                      age_groups = case_when(\n                        age &lt; 20 ~ \"Teenager\",\n                        age &gt; 20 ~ \"Not a teenager\"))\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nThis is a really sneaky one as it does not actually affect a participant in the data, but there is a small mismatch between the criteria we want and the criteria we set.\nIn our “teenager” group, this is accurate as we want to classify them if they are younger than 20. However, in the “not a teenager” group we currently set the criterion if they are older than 20, i.e., 21 or older. This would mean 20 year old participants are stuck in the middle with no group.\nWe see this kind of mistake a lot, so think carefully about your Boolean expression and check examples in the console if you are unsure. To fix, you could use:\n\nage_groups &lt;- mutate(pinfo,\n                      age_groups = case_when(\n                        age &lt; 20 ~ \"Teenager\",\n                        age &gt; 19 ~ \"Not a teenager\"))\n\nor\n\nage_groups &lt;- mutate(pinfo,\n                      age_groups = case_when(\n                        age &lt; 20 ~ \"Teenager\",\n                        age &gt;= 20 ~ \"Not a teenager\"))"
  },
  {
    "objectID": "04-wrangling-1.html#words-from-this-chapter",
    "href": "04-wrangling-1.html#words-from-this-chapter",
    "title": "4  Data wrangling 1: Join, select, and mutate",
    "section": "\n4.8 Words from this Chapter",
    "text": "4.8 Words from this Chapter\nBelow you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the PsyTeachR Glossary. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter.\n\n\n\n\nterm\ndefinition\n\n\n\narrange()\nOrder the rows of a data set by the values of one or more columns.\n\n\nboolean-expression\nA logical statement in programming to evaluate a condition and return a Boolean value, which can be TRUE or FALSE.\n\n\ncase_match()\nYou can switch values from old to new. Statements are evaluated sequentially, meaning the old value is replaced with the first new value it matches.\n\n\ncase_when()\nAn if else statement to check old values against a set of criteria. Statements are evaluated sequentially, meaning each observation is checked against the criteria, and it receives the first match it passes.\n\n\ndata-wrangling\nThe process of preparing data for visualisation and statistical analysis.\n\n\nfunction\nA named section of code that can be reused.\n\n\ninner-join\nA mutating join that returns all the rows that have a match in the other table.\n\n\nmutate()\nYou can create new columns that are functions of existing variables. You can also modify variables if the name is the same as an existing column.\n\n\npackage\nA group of R functions.\n\n\nselect()\nSelect, reorder, or rename variables in your data set."
  },
  {
    "objectID": "05-wrangling-2.html#learning-to-wrangle-is-there-a-chastity-belt-on-perception",
    "href": "05-wrangling-2.html#learning-to-wrangle-is-there-a-chastity-belt-on-perception",
    "title": "5  Data wrangling 2: Filter, summarise, and pipes",
    "section": "\n5.1 Learning to wrangle: Is there a chastity belt on perception",
    "text": "5.1 Learning to wrangle: Is there a chastity belt on perception\nToday we are going to be using data from the paper Is there a Chastity Belt on Perception(Witt et al., 2018). We recommend reading the paper’s abstract for contetx, but to summarise the research question is: does your ability to perform an action influence your perception? For instance, does your ability to hit a tennis ball influence how fast you perceive the ball to be moving? Or to phrase another way, do expert tennis players perceive the ball moving slower than novice tennis players?\nThis experiment does not use tennis players however. Instead they used the Pong task: “a computerised game in which participants aim to block moving balls with various sizes of paddles”. A bit like a very classic retro arcade game. Participants tend to estimate the balls as moving faster when they have to block it with a smaller paddle as opposed to when they have a bigger paddle. You can read the paper to get more details if you wish but hopefully that gives enough of an idea to help you understand the wrangling we will do on the data. We have cleaned up the data a little to start with. Let’s begin!\n\n5.1.1 Activity 1: Set-up Data Wrangling 2\n\nFirst, download PongBlueRedBack 1-16 Codebook.csv into your chapter folder.\n\nIf you are having trouble downloading .csv files directly you may prefer to download the data as a zip file and unzip it from this link: PongBlueRedBack 1-16 Codebook.zip. Again just unzip it into your chapter folder.\n\n\nNext, set the working directory to your chapter folder. Ensure the environment is clear.\n\nIf you’re using the Rserver, avoid a number of issues by restarting the session - click Session - Restart R\n\n\n\nNow, open a new R Markdown document and save it in your working directory and call the file something informative like “DataWrangling2”.\nNext, delete the default R Markdown welcome text and insert a new code chunk.\nFinally, copy and paste the below code into this code chunk and then run the code.\n\n\nlibrary(\"tidyverse\")\npong_data &lt;- read_csv(\"data/PongBlueRedBack 1-16 Codebook.csv\")\nsummary(pong_data)\n\nRemember:  We use the read_csv() function to load in data, and the data filename must be a) in quotation marks and b) spelt exactly as the filename states, including spaces and the file extension (in this case .csv)\nIf you have done this task correctly you should see the following output:\n\n\n  Participant     JudgedSpeed      PaddleLength   BallSpeed    TrialNumber    \n Min.   : 1.00   Min.   :0.0000   Min.   : 50   Min.   :2.0   Min.   :  1.00  \n 1st Qu.: 4.75   1st Qu.:0.0000   1st Qu.: 50   1st Qu.:3.0   1st Qu.: 72.75  \n Median : 8.50   Median :1.0000   Median :150   Median :4.5   Median :144.50  \n Mean   : 8.50   Mean   :0.5471   Mean   :150   Mean   :4.5   Mean   :144.50  \n 3rd Qu.:12.25   3rd Qu.:1.0000   3rd Qu.:250   3rd Qu.:6.0   3rd Qu.:216.25  \n Max.   :16.00   Max.   :1.0000   Max.   :250   Max.   :7.0   Max.   :288.00  \n BackgroundColor      HitOrMiss       BlockNumber   \n Length:4608        Min.   :0.0000   Min.   : 1.00  \n Class :character   1st Qu.:0.0000   1st Qu.: 3.75  \n Mode  :character   Median :1.0000   Median : 6.50  \n                    Mean   :0.6866   Mean   : 6.50  \n                    3rd Qu.:1.0000   3rd Qu.: 9.25  \n                    Max.   :1.0000   Max.   :12.00  \n\n\nsummary(), from the base package - the default packages automatically installed - provides a quick overview of the variables in your dataset and can be useful as a quick check that you have indeed imported the correct data. It will also provide some basic descriptive statistics and some information on whether the data is character (text) data which can also be useful to check.\nAn alternative approach for looking at data types would be to use the glimpse() function, from the dplyr package, loaded in with tidyverse. Try the following in your console window:\n\nglimpse(pong_data)\n\nAnd you will see:\n\n\nRows: 4,608\nColumns: 8\n$ Participant     &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ JudgedSpeed     &lt;dbl&gt; 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, …\n$ PaddleLength    &lt;dbl&gt; 50, 250, 50, 250, 250, 50, 250, 50, 250, 50, 50, 250, …\n$ BallSpeed       &lt;dbl&gt; 5, 3, 4, 3, 7, 5, 6, 2, 4, 4, 7, 7, 3, 6, 5, 7, 2, 5, …\n$ TrialNumber     &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,…\n$ BackgroundColor &lt;chr&gt; \"red\", \"blue\", \"red\", \"red\", \"blue\", \"blue\", \"red\", \"r…\n$ HitOrMiss       &lt;dbl&gt; 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, …\n$ BlockNumber     &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n\n\nAnd if you look at that table you can see the eight column names followed by &lt;dbl&gt;, short for double, or &lt;chr&gt; short for character. Again, this might not mean that much to you but as you progress you will become very adept at recognising the type of data you are working with, as the type of data changes what you can do to the data.\n\n5.1.2 Activity 2: Look at your data\nGreat! Now that we have the data loaded in, let’s have a look at the pong_data and see how it is organized. Again you can do this various ways, but today, click on pong_data in your environment pane.\nIn the dataset you will see that each row (observation) represents one trial per participant and that there were 288 trials for each of the 16 participants. The columns (variables) we have in the dataset are as follows:\n\n\n\n\n\n\n\nVariable\nType\nDescription\n\n\n\nParticipant\ndouble\nparticipant number\n\n\nJudgedSpeed\ndouble\nspeed judgement (1 = fast, 0 = slow)\n\n\nPaddleLength\ndouble\npaddle length (pixels)\n\n\nBallSpeed\ndouble\nball speed (2 pixels/4ms)\n\n\nTrialNumber\ndouble\ntrial number\n\n\nBackgroundColor\ncharacter\nbackground display colour\n\n\nHitOrMiss\ndouble\nhit ball = 1, missed ball = 0\n\n\nBlockNumber\ndouble\nblock number (out of 12 blocks)\n\n\n\nJust as we saw with glimpse(), some of the data is double - i.e. numbers - and some of the data is character - i.e. text. We will use this data to master our skills of the Wickham Six verbs, taking each verb in turn. You should refer to the explanations and example code in the previous chapter to help you complete these. Remember the six main functions were:\n\n\nFunction\nDescription\n\n\n\nselect()\nInclude or exclude certain variables (columns)\n\n\nfilter()\nInclude or exclude certain observations (rows)\n\n\nmutate()\nCreate new variables (columns)\n\n\narrange()\nChange the order of observations (rows)\n\n\ngroup_by()\nOrganize the observations (rows) into groups\n\n\nsummarise()\nCreate summary variables for groups of observations\n\n\n\nNow, let’s do some wrangling!!! And don’t forget, it can help to take a new code chunk on each activity and write yourself some notes between the code chunks!\n\n5.1.3 Activity 3: select()\n\nWe are going to start with some selections!\n\nEither by inclusion (stating all the variables you want to keep) or exclusion (stating all the variables you want to drop), select only the Participant, PaddleLength, TrialNumber, BackgroundColor and HitOrMiss columns from pong_data and store it in a new object named select_dat.\n\n5.1.4 Activity 4: Reorder the variables\nGood work! Now, we previously mentioned that select() can also be used to reorder the columns in a tibble, as the new tibble will display the variables in the order that you entered them.\n\nUse select() to keep only the columns Participant, JudgedSpeed, BallSpeed, TrialNumber, and HitOrMiss from pong_data but have them display in alphabetical order, left to right. Save this tibble in a new object named reorder_dat.\n\n5.1.5 Activity 5: arrange()\n\nWe are now master of selections!!! Let’s move on to a different skill and test our ability to change the order of the data in the rows.\n\nArrange the data by the following two variables: HitOrMiss (putting hits - 1 - first), and JudgedSpeed (putting fast judgement - 1 - first) and store this in an object named arrange_dat.\n\n5.1.6 Activity 6: filter()\n\nGreat! But what about keeping and removing some of the rows with filter()! You may need to refer back to the different boolean operations to complete this activity!\nUse filter() to extract all Participants in the original pong_data that had:\n\na fast speed judgement;\nfor speeds 2, 4, 5, and 7;\nbut missed the ball.\n\nStore this remaining data in a new object called pong_fast_miss\n\n\nHelpful Hint\n\n\nThere are three parts to this filter so it is best to think about them individually and then combine them.\n\nFilter all fast speed judgements (JudgedSpeed)\nFilter for the speeds 2, 4, 5 and 7 (BallSpeed)\nFilter for all Misses (HitOrMiss)\n\nYou could do this in three filters where each one uses the output of the preceding one, or remember that filter functions can take more than one argument. You may also need to use == instead of just =.\n\n\n\n\n\n\nThe filter function is very useful but if used wrongly can give you very misleading findings. This is why it is very important to always check your data after you perform an action. Let’s say you are working in comparative psychology and have run a study looking at how cats, dogs and horses perceive emotion. Let’s say the data is all stored in the tibble animal_data and there is a column called animals that tells you what type of animal your participant was. Imagine you wanted all the data from just cats:\n\n\nfilter(animal_data, animals == “cat”)\n\n\nExactly! But what if you wanted cats and dogs?\n\n\nfilter(animal_data, animals == “cat”, animals == “dog”)\n\n\nRight? Wrong! This actually says “give me everything that is a cat and a dog”. But nothing is a cat and a dog, that would be weird - like a dat or a cog. In fact you want everything that is either a cat or a dog, so you could do:\n\n\nfilter(animal_data, animals == “cat”| animals == “dog”)\n\n\nOr you could do:\n\n\nfilter(animal_data, animals %in% c(“cat”, “dog”))\n\n\nYou used this last approach, using %in%, when producing your own graph of babynames. It is a very helpful function so don’t forget it exists!\n\n\n\n\n5.1.7 Activity 7: mutate()\n\nBrilliant work on getting this far! You really are starting to get the hang of wrangling! Now, let’s test our skills on mutate() but first we want to introduce a new function to help understand what we can do with mutate().\nPreviously you learned how the mutate() function lets us create a new variable in our dataset. However, it also has another useful function in that it can be combined with recode() to create new columns with recoded values - where you change how different categories in a variable are represented. For example, the code below adds a new column to pong_data in which the judged speed is converted into a text label where 1 will become Fast, and 0 will become “Slow”. Run the code and look at the output!\n\npong_data_mut1 &lt;- mutate(pong_data, \n                    JudgedSpeedLabel = recode(JudgedSpeed, \n                                                    \"1\" = \"Fast\", \n                                                    \"0\" = \"Slow\"))\n\nThe code here is a bit complicated but we will explain:\n\n\nJudgedSpeedLabel is the name of your new column,\n\nJudgedSpeed is the name of the old column and the one to take information from\n\nNote that if you gave the recoded variable the same name as the original it would overwrite it.\n\n\nFast and Slow are the new codings of 1 and 0 respectively in the new column\n\nThe mutate() function is also handy for making some calculations on or across columns in your data. For example, say you realise you made a mistake in your experiment where your participant numbers should be 1 higher for every participant, i.e. Participant 1 should actually be numbered as Participant 2, etc. You could do something like:\n\npong_data_mut2 &lt;- mutate(pong_data, \n                         Participant = Participant + 1)\n\nNote here, in this second example, you are giving the new column the same name as the old column Participant. Again, happens here is that you are overwriting the old data with the new data! So watch out, mutate can create a new column or overwrite an existing column, depending on what you tell it to do!\nOk great! Now, imagine you realise that there is a mistake in your dataset and that all your trial numbers are wrong. The first trial (trial number 1) was a practice so should be excluded and your experiment actually started on trial 2. Your turn! You can either do this following activity in two separate steps and create a new object each time, or you can uses pipes %&gt;% and do it it one line of code. The final tibble should be stored in an object called pong_data_renumbered.\n\nFilter out all trials with the number 1 (TrialNumber column) from pong_data.\nThen use the mutate() function to renumber all the remaining trial numbers, starting them at one again instead of two, overwriting the values that were in the TrialNumber column.\n\n\n\nHelpful Hint\n\n\n\nStep 1. filter(TrialNumber does not equal 1). Remember to store this output in a variable if you are not using pipes.\nStep 2. mutate(TrialNumber = TrialNumber minus 1)\n\n\n\n\n5.1.8 Activity 8: Summarising data\nExcellent! And now that we have done some wrangling we want to calculate some descriptive statistics for the data using summarise(). summarise() has a range of internal functions that make life really easy, e.g. mean, sum, max, min, etc. See the dplyr cheatsheet for more examples. And additional one that we will use from time-to-time is na.rm = TRUE which we can add when calculating descriptive statistics to say what to do if there are missing values. Missing values often appear as NA and the job of na.rm is to say whether to remove (rm) the NAs (na.rm = TRUE) or not (na.rm = FALSE). If you try to calculate values from data that have NAs, such as the mean, it would return NA as the result because it doesn’t know how to average nothing. This dataset has no missing values but we will show you how to use it here and try to remember this argument exists, as you will use it often and it save you a lot of time!\nBack to the activity. Here, using the data in pong_data_renumbered we will calculate:\n\nThe total (sum) number of hits for each combination of background colour and paddle length.\nThe mean number of hits for each combination of background colour and paddle length\n\nRemember though, because we want to produce descriptive statistics by groups (background colour and paddle length), there are two steps:\n\nFirst we group the data by BackgroundColor and PaddleLength using group_by().\nThen, we use summarise() to calculate the total and mean number of hits (HitOrMiss) using the grouped data\n\nWe will do this activity using pipes to reduce the amount of code we write. Remember to try and read the code out loud and to pronounce %&gt;% as ‘and then’. Copy and paste the below code into a new code chunk and run the code.\n\npong_data_hits &lt;- pong_data_renumbered %&gt;% \n  group_by(BackgroundColor, \n           PaddleLength) %&gt;% \n  summarise(total_hits = sum(HitOrMiss, \n                             na.rm = TRUE),\n            meanhits = mean(HitOrMiss, \n                            na.rm = TRUE))\n\n`summarise()` has grouped output by 'BackgroundColor'. You can override using\nthe `.groups` argument.\n\n\n\n\n\nRemember, if you get what looks like an error that says “summarise() has grouped output by ‘BackgroundColor’. You can override using the .groups argument.”, don’t worry, this isn’t an error it’s just the code telling you how the final object is grouped.\n\n\n\n\nView pong_data_hits and answer the following questions to see if you have completed the task correctly.\n\n\nWhat was the total number of hits made with the small paddle (50) and the blue colour background?\n\n52710575161059\n\n\n\n\nTo three decimal places, what was the mean number of hits made with the small paddle (50) and the blue colour background?\n\n0.9220.4590.4510.92\n\n\n\nNote:\n\nThe name of the column within pong_data_hits is total_hits; this is what you called it in the above code. You could have called it anything you wanted but always try to use something sensible.\nMake sure to call your variables something you (and anyone looking at your code) will understand and recognize later (i.e. not variable1, variable2, variable3. etc.), and avoid spaces (use_underscores_never_spaces)."
  },
  {
    "objectID": "05-wrangling-2.html#ungrouping-counting-pipes---quick-notes",
    "href": "05-wrangling-2.html#ungrouping-counting-pipes---quick-notes",
    "title": "5  Data wrangling 2: Filter, summarise, and pipes",
    "section": "\n5.7 Ungrouping, counting, pipes - quick notes!",
    "text": "5.7 Ungrouping, counting, pipes - quick notes!\nYou have done some superb work today! Congratulations. You should be really proud of yourself. Before ending we just want to show a couple more new functions and approaches that will help in future activities.\n\n5.7.1 Counting data\nFirst we want to look at different ways of counting your observations. Often it is helpful to know how many observations you have, either in total, or broken down by groups. This can help you spot if something has gone wrong in a calculation, for example, if you’ve done something with the code and your mean or median is only being calculated using a subset of the values you intended.\nThere are two ways of counting the number of observations. The first uses summarise() and the function n() within the summarise(). For example, the below code is the same as the previous activity, but with an extra line that will add a column called n to the table that contains the number of observations in each group. This is useful for when you want to add a column of counts to a table of other descriptive statistics.\n\n\nNote: the function is n() and takes no arguments it is just left blank as shown, n(). However, as in other functions, the n prior to the = could be called anything you want the column to be called, e.g. n = n() or number = n() would do the same but just give different names to the column.\n\n\npong_count &lt;- pong_data_renumbered %&gt;% \n  group_by(BackgroundColor, \n           PaddleLength) %&gt;% \n  summarise(total_hits = sum(HitOrMiss, \n                             na.rm = TRUE),\n            meanhits = mean(HitOrMiss, \n                            na.rm = TRUE),\n            n = n())\n\nHowever, if you’re just interested in counts rather than also calculating descriptives, this above method is a bit clunky. Instead, we can use the function count() which is specifically designed to count observations and doesn’t require the use of summarise() or group_by().\nTo count the total number of observations in the dataset for example we would do:\n\npong_data %&gt;% # take pong_data\n  count() # and then count the observations in it\n\nAnd it would give the answer of:\n\n\n\n\n\nn\n\n\n4608\n\n\n\n\n\nAlternatively, to count the number of observations in each level of a variable you could do:\n\npong_data %&gt;%\n  count(BackgroundColor)\n\nAnd it would give the answer of:\n\n\n\n\n\nBackgroundColor\nn\n\n\n\nblue\n2304\n\n\nred\n2304\n\n\n\n\n\n\nWhich method you use will depend on whether you want to add the counts to a table of other descriptives, but both functions are useful to know.\n\n5.7.2 Ungrouping data\nAfter grouping data together using the group_by() function and then performing a task on it, e.g. filter(), it can be very good practice to ungroup the data before performing another function - by piping it into the ungroup() function - this is related to what the warnings about summarise() mean as they are changing the groupings so removing all groupings can be good to do. Forgetting to ungroup the dataset won’t always affect further processing, but can really mess up other things. Again just a good reminder to always check the data you are getting out of a function a) makes sense and b) is what you expect.\nThis is an example of how you might use the function:\n\npong_data_ungroup &lt;- pong_data %&gt;%\n  group_by(BackgroundColor, \n           PaddleLength) %&gt;%\n  summarise(total_hits = sum(HitOrMiss)) %&gt;%\n  ungroup\n\n\n5.7.3 Recapping Pipes (%&gt;%)\nAnd finally today we just want to throw in a quick recap on pipes. We have used pipes a little above but you might still not have got the hang of it so reading through this will help a little. Remember where pipes become most useful is when we string a series of functions together, rather than using them as separate steps and having to save the data each time under a new variable name and getting ourselves all confused. In non-piped code we have to create a new object each time, for example, data, data_filtered, data_arranged, data_grouped, data_summarised just to get to the final one we actually want. This creates a lot of variables and tibbles in our environment and can make everything unclear, difficult to follow, and eventually slow down our computer. Piped code however uses one variable name, saving space in the environment, and is clear and easy to read. With pipes we skip unnecessary steps and avoid cluttering our environment.\nHere is an example of code that doesn’t use pipes to find how many hits there were with the large paddle length and the red background:\n\nFirst we group the data accordingly, storing it in pong_data_group\n\nAnd then we summarise it, storing the answer in total_hits\n\nAnd finally we filter just the red, large paddle hits\n\n\npong_data_group &lt;- group_by(pong_data, \n                            BackgroundColor, \n                            PaddleLength)\n\npong_data_hits &lt;- summarise(pong_data_group, \n                            total_hits = sum(HitOrMiss))\n\npong_data_hits_red_large &lt;- filter(pong_data_hits, \n                                   BackgroundColor == \"red\", \n                                   PaddleLength == 250)\n\nAlternatively we can make our code even more efficient, using less code, by stringing our sequence of functions together using pipes. This would look like:\n\npong_data_hits_red_large &lt;- pong_data %&gt;% \n  group_by(BackgroundColor, \n           PaddleLength) %&gt;% \n  summarise(total_hits = sum(HitOrMiss)) %&gt;% \n  filter(BackgroundColor == \"red\", \n         PaddleLength == 250) \n\nSo the code becomes easier to read as you remember the data goes into one function “and then” into another, “and then” into another, and so on.\nIt is also worth remembering that whilst pipes and code can be written in a single line, but it is much easier to see what the pipe is doing if each function takes its own line. You just have to remember that every time you add a function to the pipeline, add a %&gt;% first and note that when using separate lines for each function, the %&gt;% must appear at the end of the line and not the start of the next line. Compare the two examples below. The first won’t work but the second will because the second puts the pipes at the end of the line where they need to be!\n\n# Piped version that won't work \ndata_arrange &lt;- pong_data \n                %&gt;% filter(PaddleLength == \"50\")\n                %&gt;% arrange(BallSpeed) \n\n# Piped version that will work \ndata_arrange &lt;- pong_data %&gt;%\n                filter(PaddleLength == \"50\") %&gt;%\n                arrange(BallSpeed)"
  },
  {
    "objectID": "05-wrangling-2.html#dw2-fin",
    "href": "05-wrangling-2.html#dw2-fin",
    "title": "5  Data wrangling 2: Filter, summarise, and pipes",
    "section": "\n5.4 Finished!",
    "text": "5.4 Finished!\nBrilliant work again! We have now learned a number of functions and verbs that you will need as you progress through this book. You will use them in the next chapter so be sure to go over these and try them out to make yourself more comfortable with them. If you have any questions please post them on Teams. Happy Wrangling!"
  },
  {
    "objectID": "05-wrangling-2.html#dw2-test",
    "href": "05-wrangling-2.html#dw2-test",
    "title": "5  Data wrangling 2: Filter, summarise, and pipes",
    "section": "\n5.5 Test yourself",
    "text": "5.5 Test yourself\n\n5.5.1 Knowledge Questions\n\nWhat type of data would these most likely be:\n\n\nMale = \nCharacter\nNumeric\nInteger\n7.15 = \nCharacter\nDouble\nInteger\n137 = \nCharacter\nDouble\nInteger\n\n\n\nExplain these answers\n\n\nThere is a lot of different types of data and as well as different types of levels of measurements and it can get very confusing. It’s important to try to remember which is which because you can only do certain types of analyses on certain types of data and certain types of measurements. For instance, you can’t take the average of Characters just like you can’t take the average of Categorical data. Likewise, you can do any maths on Double data, just like you can on Interval and Ratio data. Integer data is funny in that sometimes it is Ordinal and sometimes it is Interval, sometimes you should take the median, sometimes you should take the mean. The main point is to always know what type of data you are using and to think about what you can and cannot do with them.\n\nNote that the last answer, 137, could also be double as it isn’t clear if it could take a decimal or not.\n\n\n\n\n\nWhich of the Wickham Six would you use to sort columns from smallest to largest:\n\nselectfiltermutatearrangegroup_bysummarise\n\n\nWhich of the Wickham Six would you use to calculate the mean of a column:\n\nselectfiltermutatearrangegroup_bysummarise\n\n\nWhich of the Wickham Six would you use to remove certain observations - e.g. remove all males:\n\nselectfiltermutatearrangegroup_bysummarise\n\n\nWhat does this line of code say? data %&gt;% filter() %&gt;% group_by() %&gt;% summarise():\n\ntake the data and then group it and then filter it and then summarise ittake the data and then filter it and then group it and then summarise ittake the data and then summarise it and then filter it and then group ittake the data and then group it and then summarise it and then filter it\n\n\n\n5.5.2 Debugging tips\nThere are no debugging challenges today as we have done a lot of work but here are some tips to keep in mind.\n\nRemember to run the library and not just write the code\nMake sure you have spelt the data file name exactly as it is shown. Spaces and everything. Do not change the name of the csv file, fix your code instead. If you have a different name for your file than someone else then your code is not reproducible.\nRemember when uploading data we use read_csv() which has an underscore, whereas the data file itself will have a dot in its name, filename.csv.\nCheck that the datafile is actually in the folder you have set as your working directory.\nRemember to start a new session each time you start a new analysis - the more functions and packages you use the great a chance of conflicting functions.\nWatch the spelling of functions and remember to put the data first. Often people forget to include the data as they are focussing on what they want to do.\nAlways look at the output of your functions as you build the code. Often code runs but it doesn’t do what you think it is doing because you wrote the code wrong. Code only does what you tell it to do!\nWhen using pipes, remember that you only need the data once, at the start.\nIf separating pipes across different lines, remember the line ends with the pipe, it does not start with the pipe.\nAnd lastly, remember that only the data changes, the skills stay the same. Always look back to when you had the code working and go from there."
  },
  {
    "objectID": "05-wrangling-2.html#dw2-sols",
    "href": "05-wrangling-2.html#dw2-sols",
    "title": "5  Data wrangling 2: Filter, summarise, and pipes",
    "section": "\n5.9 Solutions to Activities",
    "text": "5.9 Solutions to Activities\nBelow you will find the solutions to the above questions. Only look at them after giving the questions a good try and speaking to the tutor about any issues.\n\n5.9.1 Activity 3\n\nTo include variables we would name all the variables we want:\n\n\nselect_dat &lt;- select(pong_data, \n                     Participant, \n                     PaddleLength, \n                     TrialNumber, \n                     BackgroundColor, \n                     HitOrMiss)\n\n\nin contrast, to exclude variables we would name the ones we don’t want and put a - prior to the name:\n\n\nselect_dat &lt;-select(pong_data, \n                    -JudgedSpeed, \n                    -BallSpeed, \n                    -BlockNumber)\n\n\n5.9.2 Activity 4\n\nTo reorder variables using the select() we state the order of the variables we want them in. Note that this only works on column order.\n\n\nreorder_dat &lt;- select(pong_data, \n                      BallSpeed, \n                      HitOrMiss, \n                      JudgedSpeed, \n                      Participant, \n                      TrialNumber)\n\n\n5.9.3 Activity 5\n\nTo arrange the rows by certain columns we use arrange() but you need to remember to include desc() to change it from running smallest-to-largest to largest-to-smallest.\n\n\narrange_dat &lt;- arrange(pong_data, \n                       desc(HitOrMiss), \n                       desc(JudgedSpeed))\n\n\n5.9.4 Activity 6\n\nRemembering that filters can take more than one argument then the below code would filter for data where:\nJudgedSpeed is 1 AND\nBallSpeed is either 2, 4, 5, or 7, AND\nHitOrMiss is 0.\n\n\npong_fast_miss &lt;- filter(pong_data, \n                         JudgedSpeed == 1, \n                         BallSpeed %in% c(\"2\", \"4\", \"5\", \"7\"), \n                         HitOrMiss == 0)\n\n\n5.9.5 Activity 7\nIf you didn’t use pipes then the following code would be appropriate:\n\nFirst you filter. And remember that you can call the first object pong_data_filt anything that makes sense to you and others.\nThen in a separate step you mutate.\n\n\npong_data_filt &lt;- filter(pong_data, \n                         TrialNumber &gt;= 2) \n\npong_data_renumbered &lt;- mutate(pong_data_filt, \n                               TrialNumber = TrialNumber - 1)\n\nAnd if you used pipes this would be the solution:\n\nRemember you include the data once, and the pipes end the line, they do not start the line.\n\n\npong_data_renumbered &lt;- filter(pong_data, \n                               TrialNumber &gt;= 2) %&gt;%\n  mutate(TrialNumber = TrialNumber - 1)\n\nwhich could also be written as below - which some find better to remember the data goes in first and only once:\n\npong_data_renumbered &lt;- pong_data %&gt;%\n  filter(TrialNumber &gt;= 2) %&gt;%\n  mutate(TrialNumber = TrialNumber - 1)"
  },
  {
    "objectID": "05-wrangling-2.html#words-from-this-chapter",
    "href": "05-wrangling-2.html#words-from-this-chapter",
    "title": "5  Data wrangling 2: Filter and summarise",
    "section": "\n5.7 Words from this Chapter",
    "text": "5.7 Words from this Chapter\nBelow you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the PsyTeachR Glossary. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter.\n\n\n\n\nterm\ndefinition\n\n\n\ncharacter\nA data type representing strings of text.\n\n\ncount()\nCount the observations in your data set, or the number of observations in one or more variables.\n\n\ndata-frame\nA container data type for storing tabular data.\n\n\ndouble\nA data type representing a real decimal number\n\n\nfactor\nA data type where a specific set of values are stored with labels; An explanatory variable manipulated by the experimenter\n\n\nfilter()\nThe ability to subset a data frame to keep all observations/rows that satisfy one or more conditions.\n\n\nfunction\nA named section of code that can be reused.\n\n\ngroup_by()\nTake an existing data frame or tibble and convert it to a grouped data frame.\n\n\ninteger\nA data type representing whole numbers.\n\n\nnumeric\nA data type representing a real decimal number or integer.\n\n\nsummarise()\nCreates a new data frame to summarise all the observations you provide. You can also group by an additional variable to create separate summary statistics.\n\n\ntibble\nA container for tabular data with some different properties to a data frame\n\n\nungroup()\nRemove a grouping property from a grouped data frame or tibble."
  },
  {
    "objectID": "03-loading-data.html#getting-ready-to-work-with-data",
    "href": "03-loading-data.html#getting-ready-to-work-with-data",
    "title": "\n3  Starting with data\n",
    "section": "\n3.1 Getting ready to work with data",
    "text": "3.1 Getting ready to work with data\nIn this chapter you will learn how to load the packages required to work with the data. You’ll then load the data into RStudio before getting it organised into a format (or structure) that helps us answer our research question. And a top tip to remember is to always think back to what we have done before - for instance, if you can’t remember what packages are, go back and revise the Programming Basics.\nBefore we begin working with the data we need to do some set-up and get the data into our working directory.\n\n3.1.1 Activity 1: Set-up the data, working directory and Rmd file\n\nDownload ahi-cesd.csv and participant-info.csv into the folder on your computer you want to use for this chapter!\n\nTo download a file from this book, right click the link and select “save link as”. Make sure that both files are saved as “.csv”. Do not open them on your machine as often other software like Excel can change setting and ruin the files and cause you problems. We will look at the data once we load it into R and RStudio.\nIf you are working on the server, you will need to upload the files to the server as well.\n\n\nNext, open RStudio and ensure the environment is clear.\n\nIf you’re on the server, avoid a number of issues by restarting the session - click Session - Restart R\n\n\n\nSet the working directory to your chapter folder. You might want to refer to Activity 2 in Chapter 2 if you are unsure about this step.\nNow open a new R Markdown document (.Rmd file) and save it in your working directory. Call the file “LoadingData”. You can refer to Activity 3 in Chapter 2\n\n\nNote: Your R Markdown file (LoadingData.Rmd) must be in the same folder as the datafiles or the code we are going to write will not work.\n\n\nFinally, delete the default R Markdown text and insert a new code chunk. Remember to only delete the text and code that comes below/after line 7.\n\nWe are now ready to begin working with the data. A top tip is to use the white space to take any notes that might help you for each activity and to make reminders to yourself about what things do!\n\n3.1.2 Activity 2: Loading a package to our library\nToday we need to use the tidyverse package. You will use this package in almost every single chapter of this course as the functions it contains are those we use for data wrangling, descriptive statistics, and visualisation. So let’s load that package into our library using the library() function.\n\nTo load the tidyverse type the following code into your code chunk and then run it.\nRemember that sometimes in the console window you will see information about the package you have loaded, but sometimes you won’t. You should however see the line of code you have just run repeated in the console window. If you see any red text, be sure to read it as it might be a warning, an error or a message.\n\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "03-loading-data.html#the-data",
    "href": "03-loading-data.html#the-data",
    "title": "\n3  Starting with data\n",
    "section": "\n3.2 The data",
    "text": "3.2 The data\nFor this chapter we are going to be using real data from the following paper:\nWoodworth, R.J., O’Brien-Malone, A., Diamond, M.R. and Schüz, B., 2018. Data from, ‘Web-based Positive Psychology Interventions: A Reexamination of Effectiveness’. Journal of Open Psychology Data, 6(1).\nIt would be good to read through this paper even briefly, or just the abstract, to give you a sense of what the paper is about and what the data might look like, but in summary the files contain data from two scales as well as demographic information about participants. The two scales are:\n\nthe Authentic Happiness Inventory (AHI),\nand the Center for Epidemiological Studies Depression (CES-D) scale.\n\n\n3.2.1 Activity 3: Read in data\nNow that we have our data in our folder we need to read in the data - “read” in this sense just means to bring the data into RStudio and store it in an object so we can work with it. To do this we will use the function read_csv() that allows us to read in .csv files. There are also functions that allow you to read in Excel files (e.g. .xlsx) and other formats, however in this course we will only use .csv files as they are not software specific and therefore are better for when looking to practice open science! A .csv file can be read by any basic text editor on nearly all machines.\n\nThe code chunk below reads in both datafiles. Type it into your code chunk and run them. Let’s look at what they do.\nFirst, we create an object called dat that contains the data in the ahi-cesd.csv file.\nNext we then create an object called info that contains the data in the participant-info.csv.\nNote how both lines have the same format of object &lt;- function(\"datafile_name.csv\")\n\nit is imperative that you have the double quotation marks around the datafile name and that the datafile name is spelt correctly and includes the .csv part.\nand remember that &lt;- is called the assignment operator but we can read it as “assigned to”. For example, the first line can be read as the data in ahi-cesd.csv is assigned to the object called dat.\n\n\n\n\ndat &lt;- read_csv(\"ahi-cesd.csv\")\npinfo &lt;- read_csv(\"participant-info.csv\")\n\nIf you have done this activity correctly, and the preceding activities, you should now see that the objects dat and pinfo have appeared in the environment pane. If they are not there then you should check the spelling of the filenames and the structure of the code lines as well as maybe the working directory.\n\n\n\nWATCH OUT! There is also a function called read.csv(). Be very careful NOT to use this function instead of read_csv() as they have different ways of naming columns. For the activities and the assignments we will always ask and expect you to use read_csv(). This is really a reminder to watch spelling on functions and to be careful to use the right functions."
  },
  {
    "objectID": "03-loading-data.html#looking-at-data",
    "href": "03-loading-data.html#looking-at-data",
    "title": "\n3  Starting with data\n",
    "section": "\n3.3 Looking at Data",
    "text": "3.3 Looking at Data\nGreat! Now that we have our data read in the first step you should always do is to have an initial check to see what your data looks like. Normally you will have an idea already from the experiment you ran but if you are using someones data you might not, so best to check it out. There are several ways you can look at your data and these are listed in Activity 4 below. Try them all to see how the results differ.\n\n3.3.1 Activity 4: Look at your data\n\n\nOption 1: In the environment pane, click on the name of the object you want to look at. For example, click the names dat and pinfo. This will open the data to give you a spreadsheet-like view (although you can’t edit it like in Excel)\n\n\nOption 2: In the environment pane, click the small blue play button to the left of dat and pinfo. This will show you the structure of the object information including the names of all the variables in that object and what type they are (also see str(pinfo))\n\nOption 3: In the console window, type and run str(pinfo) and then str(dat)\n\n\nOption 4: Repeat option 3 but this time use the summary() function - e.g. summary(dat)\n\n\nOption 5: Repeat option 3 but this time use the head() function\n\nOption 6: Type the name of the object you want to view in the console window and run it, e.g., type dat in the console window and run it.\n\nAs you can see there are various different ways to get an idea of what your data looks like. Each tells you similar but also different info. We will explore more as we get further into the book but for now just be aware that you can use all of these approaches to see your data. More often than not Option 1 and Option 2 give you the info you need, the quickest."
  },
  {
    "objectID": "03-loading-data.html#joining-data",
    "href": "03-loading-data.html#joining-data",
    "title": "\n3  Starting with data\n",
    "section": "\n3.4 Joining Data",
    "text": "3.4 Joining Data\nSo far so awesome! We have our data and we know what it looks like, so let’s start trying to do things with our data! The first thing we will do is combine datafiles! We have two files, dat and info but what we really want is a single file that has both the data and the demographic information about the participants as it makes it easier to work with the data when it is all combined together. To do this we are going to use the function inner_join() which comes from the dplyr package - one of the packages loaded in as part of the tidyverse. But don’t worry to much about deliberately trying to remember all the different packages and functions as it will come naturally with the practice we give you.\n\n\nTop tip: Remember to use the help function ?inner_join if you want more information about how to use a function and to use tab auto-complete to help you write your code.\n\n\n3.4.1 Activity 5: Join the files together\nThe below code will create a new object, called all_dat, that combines the data from both dat and pinfo using the information in the columns id and intervention to match the participants’ data across the two sets of data. This is going to be an inner join approach - data will only be kept for a participant if they exist in both datafiles. There are lots of different joins but we will see them as we go further into the book.\n\nType and run the below code in a new code chunk to inner join the two sets of data.\nLet’s see if we can make sense of what is happening\n\n\nall_dat is the new object that has the data combined\n\nx is the first argument and it should be the first data/object you want to combine\n\ny is the second argument and it should be the second data/object you want to combine\n\nby is the third argument and it lists the names of the columns you want to combine the data by. It uses an additional function c() to say that there is more than one column to combine by.\n\n\n\n\nall_dat &lt;- inner_join(x = dat, \n                      y = pinfo, \n                      by = c(\"id\", \"intervention\"))\n\nOnce you have run this code you should now see the all_dat in the environment pane. View the new dataset using one of the methods from Activity 4. In fact, try to remember that you should always view any new object or data that you create. Code often can run but that doesn’t necessarily mean it is correct. The programme only ever knows what the code says not what you thought you said. Get into the habit of always checking output!"
  },
  {
    "objectID": "03-loading-data.html#selecting-data",
    "href": "03-loading-data.html#selecting-data",
    "title": "\n3  Starting with data\n",
    "section": "\n3.5 Selecting Data",
    "text": "3.5 Selecting Data\nExcellent! We have now combined our data into one big object! However, Very frequently, datasets will have more variables, information, and data than you actually want to use and it can make life easier to create a new object with just the data you need. So, our final step today is to select just some variables of interest! In our case, the all_dat contains the responses to each individual question on both the AHI scale and the CESD scale, as well as the total score (i.e., the sum of all the individual responses). Let’s say for our analysis all we care about is the total scores and the demographic information about participants. We are going to use a new function called the select() function, again from the dplyr package, to select only the columns we are interested in and store them in (i.e. assign them to) a new object called summarydata\n\n3.5.1 Activity 6: Pull out variables of interest\n\nType and run the below code in a new code chunk. Let’s also have a quick look at the code.\n\nsummarydata is the new object we are creating using the select() function\n\n.data is the first argument and it wants to know what object are we going to select columns from. In this instance all_dat.\nnext we have a list of columns that we want to keep. Every column must be spelt correctly and must exist in the object you are selecting it from. Makes sense really; otherwise the function wouldn’t know what you wanted!\n\n\n\n\nsummarydata &lt;- select(.data = all_dat, \n                      ahiTotal, \n                      cesdTotal, \n                      sex, \n                      age, \n                      educ, \n                      income, \n                      occasion,\n                      elapsed.days)\n\nIf that has worked correctly you should see summarydata in the environment pane and can run head(summarydata) now in the console window to get a view of the output. If you see any red text in the console window it would be worth checking the spelling of the objects and columns you wanted to select. If everything has gone to plan the output should look something like this:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nahiTotal\ncesdTotal\nsex\nage\neduc\nincome\noccasion\nelapsed.days\n\n\n\n32\n50\n1\n46\n4\n3\n5\n182.03\n\n\n34\n49\n1\n37\n3\n2\n2\n14.19\n\n\n34\n47\n1\n37\n3\n2\n3\n33.03\n\n\n35\n41\n1\n19\n2\n1\n0\n0.00\n\n\n36\n36\n1\n40\n5\n2\n5\n202.10\n\n\n37\n35\n1\n49\n4\n1\n0\n0.00"
  },
  {
    "objectID": "03-loading-data.html#knitting-our-reproducible-code",
    "href": "03-loading-data.html#knitting-our-reproducible-code",
    "title": "\n3  Starting with data\n",
    "section": "\n3.6 Knitting our Reproducible code",
    "text": "3.6 Knitting our Reproducible code\nAs we saw in Activity 8 in Chapter 2 our final step to making a reproducible document is to knit it to HTML! Try knitting your file to HTML now! If all the code is working correctly then you should get an html document showing all your code! If you don’t get the output there could be a few issues either relating to your code or to your installation. You can use the below debugging tips to ask yourself some questions about your code. If all the code looks correct be sure to speak to one of the TEAM to see what might be wrong.\n\n3.6.1 Debugging tips\n\nWhen you downloaded the files did you save the file names exactly as they were originally? If you download the file more than once you will find your computer may automatically add a number to the end of the file name. data.csv is not the same as data(1).csv. Pay close attention to names!\nHave you used the exact same object names as we did in each activity? Remember, name is different to Name. In order to make sure you can follow along with this book, pay special attention to ensuring you use the same object names as we do.\n\nHave you used quotation marks where needed?\n\nHave you accidentally deleted any back ticks (```) from the beginning or end of code chunks?"
  },
  {
    "objectID": "03-loading-data.html#code-layout",
    "href": "03-loading-data.html#code-layout",
    "title": "\n3  Starting with data\n",
    "section": "\n3.7 Code Layout",
    "text": "3.7 Code Layout\nAnd one very quick point before we end for the day. You may have noticed we wrote code as such:\n\nall_dat &lt;- inner_join(x = dat, \n                      y = pinfo, \n                      by = c(\"id\", \"intervention\"))\n\nBut we could also have written it as:\n\nall_dat &lt;- inner_join(x = dat, y = pinfo, by = c(\"id\", \"intervention\"))\n\nBoth do exactly the same! In a code chunk you can take a new line after a comma (,) and the code nicely idents for you. It can make it easier to read and to debug if the code is nicely presented but it isn’t essential!"
  },
  {
    "objectID": "03-loading-data.html#ld-fin",
    "href": "03-loading-data.html#ld-fin",
    "title": "\n3  Starting with data\n",
    "section": "\n3.8 Finished!",
    "text": "3.8 Finished!\nAnd that’s it, well done! Remember to save your work in your chapter folder and make a note of any mistakes you made and how you fixed them. You have started on your journey to become a confident and competent member of the open scientific community!\nNow would be a good time to get comfortable with what we’ve covered already and revise the activities and support materials presented so far if needed. If you’re feeling comfortable with you can work your way through this book at your own pace or push yourself by using the additional resources highlighted in Programming Basics. And don’t forget to try out the tasks below to check your understanding and knowledge of the skills you are learning!\nFinally, if you’re using the R server, we strongly recommend that you download a copy of any files you have been working on and save them on your machine so that you have a local back-up."
  },
  {
    "objectID": "03-loading-data.html#ld-test",
    "href": "03-loading-data.html#ld-test",
    "title": "\n3  Starting with data\n",
    "section": "\n3.9 Test yourself",
    "text": "3.9 Test yourself\n\n3.9.1 Knowledge Questions\n\nWhen loading in a .csv file, which function should you use?\n\nread_csv()read.csv()select()library()\n\n\n\n\n\nExplain this answer\n\n\nRemember, in this course we use read_csv() and it is important that you use this function otherwise you may find that the data does not work as expected.\n\n\n\nThe function inner_join() takes the arguments x, y, by. What does by do?\n\nSpecifies the first object to joinSpecifies the second object to joinSpecifies the column to join by that both objects have in common\n\n\n\n\n\nExplain this answer\n\n\nRemember, functions have arguments and the arguments all do something slightly different. In the inner_join() the by argument says which columns to join by. If you want to join by more than one column you need to put both columns inside the c() function.\n\n\n\nWhat does the function select() do?\n\nKeeps only the observations you specifyKeeps only the columns you specifyKeeps only the objects you specify\n\n\n\n\n\nExplain this answer\n\n\nThe select() function comes from one of the tidyverse packages - dplyr to be precise. It is the main function we use to keep and remove columns we want or don’t want. You will start to remember functions you need as you work more with them. Remember the best approach is to think back to what you did!\n\n\n\n3.9.2 Debugging exercises\nOne key skill is learning how to fix errors in your code. These exercises below are specifically design to create errors. Ruun each exercise and try to solve the errors yourself before moving on to the next one. Make a note of what the error message was and how you solved it - you might find it helpful to create a new file just for error solving notes. You will find that you often make the same errors in over and over again when running analyses; experts also make tonnes of errors. The difference between a novice and an expert is that when you are first learning, an error might slow you down, but you will greatly speed you up with practice. Don’t be put off by errors!\n\nRestart the R session (Session &gt;&gt; Restart R). Make sure that the working directory is set to the right folder and then run the below code:\n\n\ndat &lt;- read_csv(\"ahi-cesd.csv\")\n\nThis will produce the error:\n`could not find function \"read_csv\"`\nOnce you figure out how to fix this error, make a note of it.\n\n\nSolution\n\n\nWhen you restarted the session you unloaded all the packages you previously had loaded - i.e. the tidyverse. The function read_csv() is part of the tidyverse package which means that in order for the code to run you need to run library(tidyverse) to reload the package so that you can use the function. Remember that we always need to load packages into our library but we only install them once. Again, think about apps on your phone!\n\n\n\nRestart the R session (Session &gt;&gt; Restart R). Make sure that the working directory is set to the right folder and then run the below code:\n\n\nlibrary(tidyverse)\ndat &lt;- read_csv(\"ahi-cesd\")\n\nThis will produce the error:\n`Error: 'ahi-cesd' does not exist in current working directory`.\nOnce you figure out how to fix this error, make a note of it.\n\n\nSolution\n\n\nWhen loading data you need to provide the full file name including the file extension. In this case the error was caused by writing ahi-cesd instead of ahi-cesd.csv. As far as coding goes, these are two completely different files and only one of them exists in the working directory.\n\n\n\nRestart the R session (Session &gt;&gt; Restart R). Make sure that the working directory is set to the right folder and then run the below code:\n\n\nlibrary(tidyverse)\ndat &lt;- read_csv (\"ahi-cesd.csv\")\npinfo &lt;- read_csv(\"participant-info.csv\")\nall_dat &lt;- inner_join(x = dat, \n                      y = pinfo, \n                      by = \"id\", \"intervention\") \nsummary(all_dat)\n\nLook at the summary for all_dat. You will see that R has duplicated the intervention variable, so that there is now an intervention.x and an intervention.y that contain the same data. Once you figure out how to fix this error, make a note of it.\n\n\nSolution\n\n\nIf you want to join two objects that have mulitple columns in common you need to use the c() command to list all of the columns. The code above hasn’t done this, it’s just listed id and intervention without enclosing them with c() so it defaults to using just the first one and ignores the other column. When it does this both objects had an intervention column so it keeps both. The rule is, when joining objects, join them by all common columns!."
  },
  {
    "objectID": "03-loading-data.html#words-from-this-chapter",
    "href": "03-loading-data.html#words-from-this-chapter",
    "title": "\n3  Starting with data\n",
    "section": "\n3.10 Words from this Chapter",
    "text": "3.10 Words from this Chapter\nBelow you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the PsyTeachR Glossary. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter.\n\n\n\n\nterm\ndefinition\n\n\n\nassignment operator\n\n\n\nconsole\n\n\n\nCSV\n\n\n\ndata wrangling\n\n\n\ndescriptive\n\n\n\nEnvironment\n\n\n\ninner-join\n\n\n\nobject\n\n\n\npackage\n\n\n\nreplicability\n\n\n\nReproducible Research\n\n\n\ntidyverse\n\n\n\n\n\n\nEnd of Chapter\nThat is end of this chapter. Be sure to look again at anything you were unsure about and make some notes to help develop your own knowledge and skills. It would be good to write yourself some questions about what you are unsure of and see if you can answer them later or speak to someone about them. Good work today!"
  },
  {
    "objectID": "06-wrangling-3.html#tidy-data",
    "href": "06-wrangling-3.html#tidy-data",
    "title": "6  Data Wrangling 3: Pipes and Pivots",
    "section": "\n6.1 Tidy data",
    "text": "6.1 Tidy data\nBut first a little more on data structure and organisation.For most of this book, we will use a type of data organisation known as tidy data. Any data in this format is easily processed through the tidyverse package. However, the data you work with will not always start formatted in the most efficient way possible. If that happens then our first step is to put it into Tidy Data format. There are two fundamental principles defining Tidy Data:\n\nEach variable must have its own column.\nEach observation must have its own row.\n\nTidy Data (Wickham, 2014) adds the following principle:\n\nEach type of observation unit forms a table.\n\nAnd Grolemund and Wickham (2017) restate this third principle as:\n\nEach value must have its own cell (i.e. no grouping two variables together, e.g. time/date in one cell).\n\nWhere a cell is where any specific row and column meet; a single data point in a tibble is a cell for example. The Grolemund and Wickham (2017) book is a very useful read and it is free, but browsing the chapter on Tidy Data will help you visualise how you want to arrange data. Try to keep the principles in mind whilst doing so.\n\n\n\nIf you’ve worked with any kind of data before, particularly if you’ve used Excel, it’s very likely that you will have used wide format or long format data. In wide format, each participant’s data is all in one row with multiple columns for different data points. This means that the data set tends to be very wide and you will have as many rows as you have participants.\n\n\nLong format is where each row is a single observation, typically a single trial in an experiment or a response to a single item on a questionnaire. When you have multiple trials per participant, you will have multiple rows for the same participant. To identify participants, you would need a variable with some kind of participant id, which can be as simple as a distinct integer value for each participant. In addition to the participant identifier, you would have any measurements taken during each observation (e.g., response time) and what experimental condition the observation was taken under.\n\n\nIn wide format data, each row corresponds to a single participant, with multiple observations for that participant spread across columns. So for instance, with survey data, you would have a separate column for each survey question.\n\n\nTidy is a mix of both of these approachs and most functions in the tidyverse assume the tidy format, so typically the first thing you need to do when you get data, particularly wide-format data, is to reshape it through wrangling. Which is why we teach these really important skills.\n\n\nThere is more information about tidy data available here."
  },
  {
    "objectID": "06-wrangling-3.html#analysing-the-autism-spectrum-quotient-aq",
    "href": "06-wrangling-3.html#analysing-the-autism-spectrum-quotient-aq",
    "title": "6  Data Wrangling 3: Pipes and Pivots",
    "section": "\n6.2 Analysing the Autism Spectrum Quotient (AQ)",
    "text": "6.2 Analysing the Autism Spectrum Quotient (AQ)\nTo continue building your data wrangling skills in this chapter you will tidy data from the Autism Spectrum Quotient (AQ) questionnaire. The AQ10 is a non-diagnostic short form of the AQ with only 10 questions per participant. It is a discrete scale and the higher a participant scores on the AQ10 the more autistic-like traits they are said to display. Any person scoring 6 or above is recommended for further diagnosis. You can see an example of the AQ10 through this link: AQ10 Example.\nToday’s Goal\nToday we will be working with data from 66 participants and your goal in this chapter is to find an AQ score for each of them through your data-wrangling skills.\nThere are four data files to work with that you should download into your chapter folder. You can either right click and save each file separately below, or click here to download all the files in a zip file for you to unzip:\n\n\nresponses.csv containing the AQ survey responses to each of the 10 questions for the 66 participants\n\nqformats.csv containing information on how a question should be coded - i.e. forward or reverse coding\n\nscoring.csv containing information on how many points a specific response should get; depending on whether it is forward or reverse coded\n\npinfo.csv containing participant information such as Age, Sex and importantly ID number.\n\n\n\n\n\nWhy do we use .csv\n\n\ncsv stands for ‘comma separated variable’, and is a very basic way of storing and transferring data. It really just stores numbers and text and nothing else. The great thing about being this basic is that it can be read by many different machines and does not need expensive licenses to open it.\n\n\n\nAnd now over a series of eight activities we will build on our data wrangling skills. Remember to try things out,and to ask questions, but that the solutions are at the bottom of the chapter if you are stuck."
  },
  {
    "objectID": "06-wrangling-3.html#getting-set-up",
    "href": "06-wrangling-3.html#getting-set-up",
    "title": "6  Data Wrangling 3: Pipes and Pivots",
    "section": "\n6.3 Getting Set-Up",
    "text": "6.3 Getting Set-Up\nThis first activity is about getting ourselves ready to analyse the data so try out the steps and if you need help, consult the earlier chapters.\n\n6.3.1 Activity 1: Set-up Data Wrangling 3\n\nOpen RStudio and set the working directory to your chapter folder. Ensure the environment is clear.\n\nIf you’re using the Rserver, avoid a number of issues by restarting the session - click Session - Restart R\n\n\n\nOpen a new R Markdown document and save it in your working directory. Call the file “DataWrangling3”.\n\nMake sure that you have downloaded the four .csv files above and saved them in your chapter folder. Remember not to change the file names at all and that data.csv is not the same as data (1).csv.\nDelete the default R Markdown welcome text and insert a new code chunk that loads the package tidyverse using the library() function. Remember the solutions if needed."
  },
  {
    "objectID": "06-wrangling-3.html#loading-in-data",
    "href": "06-wrangling-3.html#loading-in-data",
    "title": "6  Data Wrangling 3: Pipes and Pivots",
    "section": "\n6.4 Loading in Data",
    "text": "6.4 Loading in Data\nNow you need to load in the .csv data files using the read_csv() function and save them as tibbles in the environment. For example, to load in the responses.csv file and save it as the object responses, we would type:\n\nresponses &lt;- read_csv(\"responses.csv\") \n\n\n6.4.1 Activity 2: Load in the data\n\nAdd the following lines of code to your RMarkdown in a new code chunk and complete them to load in all four .csv data files. Use the above code as an example and name each object the same as its original file name (minus the .csv part), again as above, e.g. responses.csv gets saved as responses. Remember to run the lines so that the data loaded in and is stored in your environment.\n\n\nresponses &lt;-  read_csv()    # load in survey responses\nqformats &lt;-                 # load in question formats\nscoring &lt;-                  # load in scoring info\npinfo &lt;-                    # load in participant information"
  },
  {
    "objectID": "06-wrangling-3.html#looking-at-data",
    "href": "06-wrangling-3.html#looking-at-data",
    "title": "6  Data Wrangling 3: Pipes and Pivots",
    "section": "\n6.5 Looking at Data",
    "text": "6.5 Looking at Data\nNow that we have the data loaded in it is always best to have a look at it to get an idea of its layout. We showed you a number ways of doing this before such as the glimpse() or View() functions. Remember you put these in your Console window and put the name of the data between the brackets to see how it is arranged. Don’t add these to your Markdown file, these are just for trying things out in the Console window\n\n6.5.1 Activity 3: Look at your data\nHave a look at the data in responses to see if you think it is Tidy or not and answer the following question:\n\nThe data in responses is in what format?\n\nTidyLongWide\n\n\n\n\n\nExplain this answer\n\n\nThe reponses tibble is far from being tidy; each row represents multiple observations from the same participant, i.e. each row shows responses to multiple questions and there are the same number of rows as there are participants (66)- wide format. Remember we want the data in tidy format as described above.\nEh, remind what’s a tibble?\nRemember, a tibble is simply a dataframe - or a table of data with columns and rows - that is really handy for working with when using the tidyverse package. When we say tibble, you can think of a dataframe with rows and columns of information and numbers stored in them - like responses, it is a tibble. For more info, see here: Tibbles."
  },
  {
    "objectID": "06-wrangling-3.html#gathering-your-data",
    "href": "06-wrangling-3.html#gathering-your-data",
    "title": "6  Data Wrangling 3: Pipes and Pivots",
    "section": "\n6.6 Gathering Your Data",
    "text": "6.6 Gathering Your Data\nWe now have all the data we need loaded in, but in order to make it easier for us to get the AQ score for each participant, we need to change the layout of the responses tibble to Tidy Data.\n\n6.6.1 Activity 4: Gathering with pivot_longer()\nThe first step is to use the function pivot_longer() to transform the data. The pivot functions can be easier to show than tell - you may find it a useful exercise to run the below code and compare the tibble in the newly created object rlong with the tibble in the original object, respones, before reading on.\n\nrlong &lt;- pivot_longer(data = responses,\n                      cols = Q1:Q10,\n                      names_to = \"Question\", \n                      values_to = \"Response\")\n\nTo break this code down a little to help you understand it more:\n\nAs with the other tidyverse functions, the first argument specifies the dataset to use as the base, in this case responses.\n\nAnd remember the more experienced and confident you get you do not have to write the argument names, e.g. data =.\n\n\nThe second argument, cols specifies all the columns you want to transform. The easiest way to visualise this is to think about which columns would be the same in the new long-form dataset and which will change. In this case, we only have a single column Id that will remain constant and we will transform all the the other columns that contain participant’s responses to each question.\n\nThe colon notation first_column:last_column is used to select all variables from the first column specified to the second column specified. So in our code, cols specifies that the columns we want to transform are Q1 to Q10.\nNote that “Gathering” of columns is based on position in the tibble. If the order of columns in the tibble was Q1 then Q10, the above code would only gather those two columns. As it is, in our tibble, the order, is Q1, Q2, Q3, … Q10, and therefore the code gathers all the columns between Q1 and Q10.\n\n\nThe third and fourth arguments are the names of the new columns we are creating.\n\n\nnames_to specifies the names of the new columns that will be created.\nFinally, values_to names the new column that will contain the measurements, in this case we’ll call it Response.\nThese new column names are put in quotes because they do not already exist in the tibble. This is not always the case but is the case for this function.\nNote also that these names could have been anything but by using these names the code makes more sense.\nLastly, you do need to write names_to = … and values_to = … otherwise the columns won’t be created correctly.\n\n\n\nAnd now that we have run the code and explained it a bit, you may find it helpful to go back and compare rlong and responses again to see how each argument matches up with the output of the table."
  },
  {
    "objectID": "06-wrangling-3.html#joining-your-data",
    "href": "06-wrangling-3.html#joining-your-data",
    "title": "6  Data Wrangling 3: Pipes and Pivots",
    "section": "\n6.7 Joining Your Data",
    "text": "6.7 Joining Your Data\nNow the responses data is in tidy format, you are closer to being able to calculate an AQ score for each person. However, you still need some extra information:\n\nWere the questions reverse or forward scored (i.e., is strongly agree a positive or negative response)? This information is found in qformats\n\nHow many points are given to a specific response? This information is found in scoring.\n\nThis is a typical analysis situation where different information is in different tables and you need to join them altogether. Both these pieces of information are contained in qformats and scoring respectively, but we want to join them to responses to create one informative tidy table with all the information we need. We can do this type of join through the function inner_join(); a function to combine information in two tibbles using a column common to both tibbles.\n\n6.7.1 Activity 5: Combining data\nA wee bit different of an approach here in this activity but try it out and see how you get on. Remember that the solutions are at the end of the chapter.\n\nCopy the code below into a new code chunk.\nNext, replace the NULL values in the below code with the necessary variable names to join rlong and qformats by Question. If you need extra help, revisit Starting with Data chapter as you used the same function then! Make sure you try yourself first.\n\n\nHint: join two tibbles (x and y) by “a common column”.\n\n\n\n\nrlong2 &lt;- inner_join(x = NULL, \n                     y = NULL, \n                     by = \"NULL\")\n\n\nNow have a look at the tibble in rlong2. As you can see we have matched each question with its scoring format, forward or reverse.\n\n\n\n\nWhat is forward and reverse scoring\n\n\nA lot of questionnaires have some questions that are Forward scored and some questions that are Reverse scored. What does this mean? Imagine a situation where your options in replying to a question are: 1 - extremely agree, 2 - agree, 3 - neutral, 4 - disagree, 5 - extremely disagree. In a forward-scoring question you would get 1 point for extremely agree, 2 for agree, 3 for neutral, etc. In a reverse scoring question you would get 5 for extremely agree, 4 for agree, 3 for neutral, etc.\n\n\nThe reasoning behind this shift is that sometimes agreeing or disagreeing might be more favorable depending on how the question is worded. Secondly, sometimes these questions are used just to catch people out - imagine if you had two similar questions where one has the reverse meaning of the other. In this scenario, people should respond opposites. If they respond the same then they might not be paying attention.\n\n\n\nSo far so good but there is more information we want to bring into the tibble. We now need to combine the information in our new tibble, rlong2, with the scoring tibble so you know how many points to attribute each question based on the answer the participant gave, and whether the question was forward or reverse coded. Again, you can use the inner_join() function, but this time the common columns found in rlong2 and scoring are QFormat and Response - i.e. there are two common columns.\n\n6.7.2 Activity 6: Combining more data\nHere, in the code below, we are going to show you how to combine data with two common columns. Really this is about combining tibbles were there is corresponding information in the two tibbles - participants appear in both tibbles but there is different info in each tibble and you want it all in the one tibble. This is called an inner-join But first some information on this task.\n\nYou can only ever join two tables with inner_join() at once. If you have multiple tibbles to join like we do, you need to do multiple calls to inner_join().\nWhen there is more than one common column between two tibbles you are joining, it is best to combine by all the columns to avoid repeated columns names in the new tibble. For example, if you run a join and it produces columns named variable.x and variable.y it means that there was another column that was the same in both datasets that you didn’t add to by =.\nYou have to be very careful to use c() if you have multiple variables for by. This is a common error and results in the variable.x/variable.y issue above. If you forget to use the c() and just state different columns, the code will only look at the first column and ignore the rest.\n\nNow type the below line into a new code chunk in your RMarkdown file, run it, and then view the new object. What this code does is it combines rlong2 and scoring based on the matching data in QFormat and Response\n\nrscores &lt;- inner_join(rlong2, \n                      scoring, \n                      c(\"QFormat\", \"Response\"))\n\nYou have now created rscores which has information on how each participant responded to each question and how each question should be coded and scored, all within the one tibble. All you need now is to sum the scores for each participant to get their AQ score.\n\n6.7.3 Activity 7: Calculating the AQ scores\n\nFirst, based on your knowledge from the last chapter, type the below line into your code and replace the NULLs to obtain individual aq_scores for each participant.\n\n\nhint: group_by() - how will you group individual participants?\n\nhint: summarise() - which column will you sum to obtain AQ scores?\n\n\nThen, save your Markdown and knit it to make sure all your code works.\n\n\naq_scores &lt;- rscores %&gt;% \n             group_by(NULL) %&gt;%\n             summarise(AQ = sum(NULL))\n\n\n\nAdditional Hints\n\n\nEach participant could be grouped by their Id.\nIf we summed up the value for each Score we might get a full AQ Score for each particpipant.\n\n\nExcellent. Have a look at aq_scores and see that you have all the individual AQ scores for each participant!"
  },
  {
    "objectID": "06-wrangling-3.html#pipes-again",
    "href": "06-wrangling-3.html#pipes-again",
    "title": "6  Data Wrangling 3: Pipes and Pivots",
    "section": "\n6.8 Pipes Again!",
    "text": "6.8 Pipes Again!\nYou now have a complete code to load in your data, convert it to Tidy, combine the tables and calculate an AQ score for each participant. But, if you look at it, some of your code could be more efficient by using pipes. Let’s see how well we understand pipes now!\n\n6.8.1 Activity 8: One last thing on pipes\n\nGo back through your code and try to rewrite it using pipes %&gt;% so that it is as efficient as possible.\n\n\nhint: At any point where the first argument of your function is the name of an object created before that line, there is a good chance you could have used a pipe!\n\n\n\n\n\nAdditional Hints\n\nHere are all the bits of this code that could be piped together into one chain:\n\n`rlong &lt;- pivot_longer(responses, names_to = \"Question\", values_to = \"Response\", Q1:Q10)`\n\n`rlong2 &lt;- inner_join(rlong, qformats, \\\"Question\\\")`\n\n`rscores &lt;- inner_join(rlong2, scoring, c(\\\"QFormat\\\", \\\"Response\\\"))`\n\n`aq_scores &lt;- rscores %&gt;% group_by(Id) %&gt;% summarise(AQ = sum(Score))`"
  },
  {
    "objectID": "06-wrangling-3.html#finished",
    "href": "06-wrangling-3.html#finished",
    "title": "6  Data Wrangling 3: Pipes and Pivots",
    "section": "\n6.9 Finished",
    "text": "6.9 Finished\nBrilliant work again today! You have now recapped one-table verbs and started to expand your knowledge of two-table verbs. These are great to know as for example, as seen above, it actually only took a handful of reproducible steps to get from messy data to tidy data; could you imagine doing this by hand in Excel through cutting and pasting? Not to mention the mistakes you could make! Excellent work! You are a DataWrangling expert! Before finishing, remember to go over anything you are unsure of, and if you have any questions, please post them on Teams. There are some additional questions below to help you check your understanding."
  },
  {
    "objectID": "06-wrangling-3.html#dw3-test",
    "href": "06-wrangling-3.html#dw3-test",
    "title": "6  Data Wrangling 3: Pipes and Pivots",
    "section": "\n6.10 Test yourself",
    "text": "6.10 Test yourself\n\n\nComplete the sentence, the higher the AQ score…\n\nthe less autistic-like traits displayedhas no relation to autistic-like traitsthe more autistic-like traits displayed\n\n\n\nAssuming that your code all worked, what was the AQ score (just the number) of Participant ID No. 87:\n\n2356\n\n\nType in the box how many participants had an AQ score of 3 (again just the number): \n\nThe cut-off for the AQ10 is usually said to be around 6 meaning that anyone with a score of more than 6 should be referred for diagnostic assessment. Based on this data, how many participants might be referred for further assessment?\n\n2468\n\n\n\n\n\nExplain these answers\n\n\n\nAs mentioned, the higher the score on the AQ10 the more autistic-like traits a participant is said to show.\nYou could do this by code with filter(aq_scores, Id == 87), which would give you a tibble of 1x2 showing the ID number and score. If you just wanted the score you could use pull() but we haven’t shown you that yet: filter(aq_scores, Id == 87) %&gt;% pull(AQ). The answer is an AQ score of 2.\nSame as above but changing the argument of the filter. filter(aq_scores, AQ == 3) %&gt;% count(). The answer is 13. Remember you can do this by counting but the code makes it reproducible and accurate every time. You might make mistakes.\nfilter(aq_scores, AQ &gt; 6) %&gt;% count() or filter(aq_scores, AQ &gt;= 7) %&gt;% count(). The answer is 6.\n\n\n\nRecap on Wickham Verbs!\nWhich function(s) would you use to approach each of the following problems?\n\nWe have a dataset of 400 adults, but we want to remove anyone with an age of 50 years or more. To do this, we could use the \nsummarise()\nmutate()\ngroup_by()\narrange()\nfilter()\nselect() function.\nWe are interested in overall summary statistics for our data, such as the overall average and total number of observations. To do this, we could use the \ngroup_by()\nmutate()\narrange()\nsummarise()\nselect()\nfilter() function.\nOur dataset has a column with the number of cats a person has, and a column with the number of dogs. We want to calculate a new column which contains the total number of pets each participant has. To do this, we could use the \nselect()\narrange()\nfilter()\nsummarise()\nmutate()\ngroup_by() function.\nWe want to calculate the average for each participant in our dataset. To do this we could use the \narrange() and mutate()\ngroup_by() and arrange()\ngroup_by() and summarise()\nfilter() and select() functions.\nWe want to order a dataframe of participants by the number of cats that they own, but want our new dataframe to only contain some of our columns. To do this we could use the \ngroup_by() and mutate()\nfilter() and select()\nselect() and summarise()\narrange() and select() functions.\n\n\n\nExplain these Answers\n\n\n\n\nfilter() helps us keep and remove rows!\n\nsummarise() is the main function for creating means, medians, modes, etc.\n\nmutate() can be used to add columns to help add more information.\nWhen you want summary statistics for individual groups or participants you have to first group_by() and then summarise().\nYou would need to filter() first to reduce the people based on their number of cats and then just select() the columns you want to keep."
  },
  {
    "objectID": "06-wrangling-3.html#dw3-sols",
    "href": "06-wrangling-3.html#dw3-sols",
    "title": "6  Data Wrangling 3: Pipes and Pivots",
    "section": "\n6.11 Activity solutions",
    "text": "6.11 Activity solutions\nBelow you will find the solutions to the above questions. Only look at them after giving the questions a good try and trying to find help on Google or Teams about any issues.\n\n6.11.1 Activity 1\n\nTo load the tidyverse into the library we would do the following:\n\n\nlibrary(tidyverse)\n\n\n6.11.2 Activity 2\n\nRemember that you should always use read_csv() when working with this book.\nYou read the data into the objects as follows.\n\n\nresponses &lt;- read_csv(\"responses.csv\")                  \nqformats &lt;- read_csv(\"qformats.csv\")                 \nscoring &lt;- read_csv(\"scoring.csv\")                  \npinfo &lt;- read_csv(\"pinfo.csv\")\n\n\n6.11.3 Activity 5\n\nIn this inner_join() the first tibble is in rlong, the second tibble is in qformats and the common column is Question.\n\n\nrlong2 &lt;- inner_join(x = rlong, \n                     y = qformats, \n                     by = \"Question\")\n\n\n6.11.4 Activity 7\n\nTo create the AQ score we would first group_by the Id column so that we have each individual participants data, and then we would sum the Score column to obtain their AQ score.\n\n\naq_scores &lt;- rscores %&gt;% \n             group_by(Id) %&gt;% # group by the ID number in column Id\n             summarise(AQ = sum(Score)) # sum column Score to obtain AQ scores.\n\n\n6.11.5 Activity 8\nThis was a tricky one but here is how you might read out the below code. Remember that %&gt;% can be read as and then...\n\nFirst, take the data in responses and then\ntake columns Q1 to Q10, put the column names in Question and the scores in Response and then\njoin with qformats and match the data by the column Question and then\njoin with scoring and match the data by the columns Qformat and Response and then\ngroup by participant ID and then\ncalculate the total AQ score\n\n\naq_scores2 &lt;- responses %&gt;% \n  pivot_longer(cols = Q1:Q10,\n               names_to = \"Question\", \n               values_to = \"Response\") %&gt;%  \n  inner_join(qformats, \"Question\") %&gt;% \n  inner_join(scoring, c(\"QFormat\", \"Response\")) %&gt;% \n  group_by(Id) %&gt;% \n  summarise(AQ = sum(Score))"
  },
  {
    "objectID": "06-wrangling-3.html#words-from-this-chapter",
    "href": "06-wrangling-3.html#words-from-this-chapter",
    "title": "6  Data Wrangling 3: Pivots and Pipes",
    "section": "\n6.6 Words from this Chapter",
    "text": "6.6 Words from this Chapter\nBelow you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the PsyTeachR Glossary. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter.\n\n\n\n\nterm\ndefinition\n\n\n\npipe\nA way to order your code in a more readable format using the symbol %&gt;%\n\n\npivot_longer()\nGather data by increasing the number of rows and decreasing the number of columns.\n\n\npivot_wider()\nSpread data by decreasing the number of rows and increasing the number of columns.\n\n\nreverse-code\nHaving two similar questions, one expressed in a positive way, and another expressed in a negative way.\n\n\ntidy-data\nA format for data that maps the meaning onto the structure."
  },
  {
    "objectID": "07-data-viz.html#data-visualisation",
    "href": "07-data-viz.html#data-visualisation",
    "title": "\n7  Intro to Data Visualisation\n",
    "section": "\n7.1 Data visualisation",
    "text": "7.1 Data visualisation\nData Visualisation. Being able to visualise our data, and relationships between our variables, is an incredibly useful and important skill. Before we do any statistical analyses or present any summary statistics, we should visualise our data as it is:\n\nA quick and easy way to check our data make sense, and to identify any unusual trends.\nA way to honestly present the features of our data to anyone who reads our research.\nA means of checking that our data fits with the assumptions of our descriptive and inferential tests and of the statistical analyses that we intend to use.\n\nAs Grolemund and Wickham tell us in R for Data Science:\n\nVisualisation is a fundamentally human activity. A good visualisation will show you things that you did not expect, or raise new questions about the data. A good visualisation might also hint that you’re asking the wrong question, or you need to collect different data. Visualisations can surprise you, but don’t scale particularly well because they require a human to interpret them.\n\nThe main package we use for visualisation within the tidyverse umbrella is called ggplot2 and the main starting function of all visualisations is ggplot(). The reason we say the “main starting function” is that ggplot() builds plots by combining layers (see, for example, Figure @ref(fig:img-layers) from (nordmann2021?)) - i.e. one function creates the first layer, the basic plot area, and you add functions and arguments to add additional layers such as the data, the labels, the colors, etc. If you’re used to making plots in other software this might seem a bit odd at first, however, it means that you can customise each layer separately in order to make very complex and beautiful figures with relative ease. You can get a sense of what is possible from (this website but we will start off slow and build as we go!\n\n\n\n\nBuilding a figure using the ggplot2 layers system as shown in Nordmann et al. (2021)"
  },
  {
    "objectID": "07-data-viz.html#setting-up-to-visaulise",
    "href": "07-data-viz.html#setting-up-to-visaulise",
    "title": "\n7  Intro to Data Visualisation\n",
    "section": "\n7.2 Setting up to Visaulise",
    "text": "7.2 Setting up to Visaulise\nWe will use the same data files as in Chapter 2, Starting with Data, as we already know what the data contains so we can focus just on visualising it.\n\n7.2.0.1 Activity 1: Set-up\nThis data contains happiness and depression scores:\n\nDownload ahi-cesd.csv and participant-info.csv into the folder on your computer for this chapter!\n\nMake sure that you have downloaded both .csv files above and saved them in your chapter folder. Remember not to change the file names at all and that data.csv is not the same as data (1).csv.\n\n\nOpen RStudio and set the working directory to your chapter folder. Ensure the environment is clear.\n\nIf you’re on the server, avoid a number of issues by restarting the session - click Session - Restart R\n\n\n\nOpen a new R Markdown document and save it in your working directory. Call the file “DataVisualisation1”.\n\nDelete the default R Markdown welcome text and insert a new code chunk.\nType and run the below code to load the tidyverse package and to load in the data files.\n\n\nlibrary(tidyverse) \n\ndat &lt;- read_csv(\"ahi-cesd.csv\")\npinfo &lt;- read_csv(\"participant-info.csv\")\n\nall_dat &lt;- inner_join(dat, \n                      pinfo, \n                      by= c(\"id\", \"intervention\"))\nsummarydata &lt;- select(.data = all_dat, \n                      ahiTotal, \n                      cesdTotal, \n                      sex, \n                      age, \n                      educ, \n                      income, \n                      occasion, \n                      elapsed.days) \n\nYou should have a good idea about what this code is doing but if not here is a brief summary:\n\nIt loads in the tidyverse\nIt reads both datafiles as tibbles into separate objects, dat and pinfo.\nJoins the data together into one larger tibble and stores it in the object called all_dat\n\nSelect a number of columns to keep in our data and discards others."
  },
  {
    "objectID": "07-data-viz.html#dealing-with-factors-and-categories",
    "href": "07-data-viz.html#dealing-with-factors-and-categories",
    "title": "\n7  Intro to Data Visualisation\n",
    "section": "\n7.3 Dealing with Factors and Categories",
    "text": "7.3 Dealing with Factors and Categories\nBefore we go any further we need to perform an additional step of data processing that we have glossed over up until this point. First, run the below code to look at the structure of the dataset:\n\nglimpse(summarydata)\n\nRows: 992\nColumns: 8\n$ ahiTotal     &lt;dbl&gt; 32, 34, 34, 35, 36, 37, 38, 38, 38, 38, 39, 40, 41, 41, 4…\n$ cesdTotal    &lt;dbl&gt; 50, 49, 47, 41, 36, 35, 50, 55, 47, 39, 45, 47, 33, 27, 3…\n$ sex          &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, …\n$ age          &lt;dbl&gt; 46, 37, 37, 19, 40, 49, 42, 57, 41, 41, 52, 41, 52, 58, 5…\n$ educ         &lt;dbl&gt; 4, 3, 3, 2, 5, 4, 4, 4, 4, 4, 5, 4, 5, 5, 5, 4, 3, 4, 3, …\n$ income       &lt;dbl&gt; 3, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 3, 2, 2, 3, 2, 2, 2, …\n$ occasion     &lt;dbl&gt; 5, 2, 3, 0, 5, 0, 2, 2, 2, 4, 4, 0, 4, 0, 1, 4, 0, 5, 4, …\n$ elapsed.days &lt;dbl&gt; 182.025139, 14.191806, 33.033831, 0.000000, 202.096887, 0…\n\n\nYou can see that all the variables are automatically considered as numeric (in this case double represented by &lt;dbl&gt;). This is going to be a problem because whilst the different categories within sex, educ, and income are represented by numbers, we don’t want to treat them as such because they are categories, or what we call factors. So to get around this, we need to convert these variables into factor data type. Fortunately we already know a good function for this! We can use mutate() to do this by overriding the original variable with the same data but classified as a factor.\n\n7.3.1 Activity 2: Factors\n\nType and run the below code to change the categories to factors.\n\nYou can read each line of the mutate as “overwrite the data that is in that column with the same values now considered factors and not doubles”\nSo for example, the 1s in sex change to categorical factors instead of numerical 1s.\nRemember if you mutate a new column with the same name as the old one, it will overwrite the column.\n\n\n\n\nsummarydata &lt;- summarydata %&gt;%\n  mutate(sex = as.factor(sex),\n         educ = as.factor(educ),\n         income = as.factor(income))\n\nThis is a very important step to remember if, when you look at your data, some of your categories are represented as numbers and not factors. If you do not do this then you might end up with some really confused looking figures!"
  },
  {
    "objectID": "07-data-viz.html#barplots",
    "href": "07-data-viz.html#barplots",
    "title": "\n7  Intro to Data Visualisation\n",
    "section": "\n7.4 Barplots",
    "text": "7.4 Barplots\nOk great, we are now ready to do some visualising and some plotting. For our first example we will create a barplot of our data showing the number of male and female participants within our data. A barplot is a plot that shows counts of categorical data, or factors, where the height of each bar represents the count of that particular variable.\n\n7.4.0.1 Activity 3: Bar plot\nRead through the following section and try the different code chunks. Following this, and changing parts of the code to see what happens, will help you to see how the layers build up.\nThe first layer\n\nThe first line (or layer) sets up the base of the graph: the data to use and the aesthetics (what will go on the x and y axis, how the plot will be grouped).\n\n\naes() can take both an x and y argument, however, with a bar plot you are just asking R to count the number of data points in each group so you don’t need to specify this.\n\n\nggplot(summarydata, aes(x = sex))\n\n\n\nFirst ggplot() layer sets the axes\n\n\n\n\nThe next layer adds a geom or a shape, in this case we use geom_bar() as we want to draw a bar plot.\n\nNote that we are adding layers, using a + between layers. This is a very important difference between pipes and visualisation. We will mention this again later but we add layers (+), we do not pipe them!\n\n\n\n\nggplot(summarydata, aes(x = sex)) +\n  geom_bar()\n\n\n\nBasic barplot with geom_bar() added\n\n\n\n\nAdding fill to the first layer will separate the data into each level of the grouping variable and give it a different colour. In this case, there is a different coloured bar for each level of sex.\n\n\nggplot(summarydata, aes(x = sex, fill = sex)) +\n  geom_bar()\n\n\n\nBarplot with colour\n\n\n\n\nAs you can see, adding the fill() has also produced a plot legend to the right of the graph. When you have multiple grouping variables you want legends to know which groups each color or part of the plot is referring to, but in this case it is redundant because it doesn’t tell us anything that the axes labels don’t already. We can get rid of it by adding show.legend = FALSE to the geom_bar() code.\n\n\nggplot(summarydata, aes(x = sex, fill = sex)) +\n  geom_bar(show.legend = FALSE)\n\n\n\nBarplot without legend\n\n\n\nExcellent. So far so good! But we might want to tidy up our plot to make it look a bit nicer. First we can edit the axis labels to be more informative. The most common functions you will use are:\n\n\nscale_x_continuous() for adjusting the x-axis for a continuous variable\n\nscale_y_continuous() for adjusting the y-axis for a continuous variable\n\nscale_x_discrete() for adjusting the x-axis for a discrete/categorical variable\n\nscale_y_discrete() for adjusting the y-axis for a discrete/categorical variable\n\nAnd in those functions the two most common arguments you will use are:\n\n\nname which controls the name of each axis - i.e. what is the overall variable called for example (e.g. Groups)\n\nlabels which controls the names of the break points on the axis - i.e. what are the conditions within a variable called for example (e.g. dogs and cats)\n\nThere are lots more ways you can customise your axes but we will stick with these for now.\n\nType out and and run the below code to change the axes labels and change the numeric sex codes (the 1s and 2s) into words (Female and Male).\n\n\nNote: We are using scale_x_discrete() because our x-axis is a discrete variable in this data (Female or Male), and we are using scale_y_continuous() because our y-axis is continuous in this data (a count of how many people there are)\n\nNote: The labels arguments must be written in the correct order of your data. Here it will make the 1’s Female and the 2’s Male, but if you flipped the order of Male and Female, it would make the 1’s Male and the 2’s Female. Remember the code does what you tell it to do so always check your output!\n\n\n\n\nggplot(summarydata, aes(x = sex, fill = sex)) +\n  geom_bar(show.legend = FALSE) +\n  scale_x_discrete(name = \"Participant Sex\", \n                   labels = c(\"Female\", \n                              \"Male\")) +\n  scale_y_continuous(name = \"Number of participants\")\n\n\n\nBarplot with axis labels\n\n\n\nNow the default colors are ok but you might want to adjust the colours and the visual style of the plot. ggplot2 comes built a number of different built-in themes as they are called.\n\nType the code below into a new code chunk and run it.\n\nHere we use theme_minimal() but try changing it to others and see what happens. You start by typing theme_ into the code chunk, instead of theme_minimal(), and trying the options that come up on auto-complete. Examples include, theme_bw(), theme_classic(), theme_light(), etc.\n\n\n\n\nggplot(summarydata, aes(x = sex, fill = sex)) +\n  geom_bar(show.legend = FALSE) +\n  scale_x_discrete(name = \"Participant Sex\", \n                   labels = c(\"Female\", \n                              \"Male\")) +\n  scale_y_continuous(name = \"Number of participants\") +\n  theme_minimal()\n\n\n\nBarplot with minimal theme\n\n\n\nOk but what about the color of the individual bars of the plot? Well, there are various options to adjust the colours but a good way to be inclusive is to use a colour-blind friendly palette that can also be read if printed in black-and-white. To do this, we can add on the function scale_fill_viridis_d(). This function has 5 colour options, A, B, C, D, and E. We like option = \"E\" but you can play around with them and choose the one you prefer.\n\nType and run the below code into a new code chunk. Try changing the option to either A, B, C or D and see which one you like!\n\n\nggplot(summarydata, aes(x = sex, fill = sex)) +\n  geom_bar(show.legend = FALSE) +\n  scale_x_discrete(name = \"Participant Sex\", \n                   labels = c(\"Female\", \n                              \"Male\")) +\n  scale_y_continuous(name = \"Number of participants\") +\n  theme_minimal() +\n  scale_fill_viridis_d(option = \"E\")\n\n\n\nBarplot with colour-blind friendly colour scheme\n\n\n\nFinally, you can also adjust the transparency of the bars by adding alpha to geom_bar(). Play around with the value and see what value you prefer.\n\nggplot(summarydata, aes(x = sex, fill = sex)) +\n  geom_bar(show.legend = FALSE, \n           alpha = .8) +\n  scale_x_discrete(name = \"Participant Sex\", \n                   labels = c(\"Female\", \n                              \"Male\")) +\n  scale_y_continuous(name = \"Number of participants\") +\n  theme_minimal() +\n  scale_fill_viridis_d(option = \"E\")\n\n\n\nBarplot with adjusted alpha\n\n\n\nSo as you can see, with just a few lines of code you can create a very effective figure. The top tip we have is to remember a figure is a series of layers, so write the code like that. Avoid trying to write the whole figure from a blank code chunk. Instead, create the first code chunk, run it, add the next layer, run it, add the next layer, run it, etc., etc. That will make it much easier for you to follow what your code is doing and to debug any issues.\n\n\n\nWe add layers, we don’t pipe them\n\n\nWe just wanted to remind you of a key point here - that you add layers through + and you do not pipe layers with %&gt;%. If you try to pip on a layer you will probably see an error that looks something like this:\n\n\nError: mapping must be created by aes(). Did you use %&gt;% instead of +?\n\n\nDo watch out for that as it is a very common errore we see when people are first starting to learn to visualise through ggplot2"
  },
  {
    "objectID": "07-data-viz.html#the-violin-boxplot",
    "href": "07-data-viz.html#the-violin-boxplot",
    "title": "\n7  Intro to Data Visualisation\n",
    "section": "\n7.5 The Violin-boxplot",
    "text": "7.5 The Violin-boxplot\nThere are numerous different styles of visualisations and figures that you can create. They all start with the format of ggplot(data, aes(x, y)) + geom_... and will learn more as you get deeper into the book or you can look at the cheatsheets in the help menus: top menu - Help &gt;&gt; Cheat Sheets &gt;&gt; Data Visualisation with ggplot2. For instance, geom_point() for scatterplots, geom_histogram() for histograms, and geom_line() for lineplots. But we want to show you a type of figure that is becoming a lot more common in the field due to the quality of information if tells you about your data - the violin-boxplot.\n\n7.5.0.1 Activity 4: Violin-boxplot\nThe violin boxplot is actually a merge of a violin and a boxplot. The violin-boxplot is just the boxplot laid over the top of the violin plot - to give additional information. As part of our final activities today we will create a violin-boxplot, hopefully now you will be able to see how similar it is in structure to the bar chart code. In fact, there are only three differences:\n\nWe have added a y argument to the first layer because we wanted to represent two variables, not just a count.\n\ngeom_violin() has an additional argument trim.\n\ngeom_boxplot() has an additional argument width. Try adjusting the value of this and see what happens.\n\n\nType and run the below code in a new code chunk and see what it produces.\n\nTry setting the trim argument in geom_violin() to TRUE and seeing what happens.\nTry adjusting the value of the width argument within geom_boxplot() and seeing what happens.\n\n\n\n\nggplot(summarydata, aes(x = income, \n                        y = ahiTotal, \n                        fill = income)) +\n  geom_violin(trim = FALSE, \n              show.legend = FALSE, \n              alpha = .4) +\n  geom_boxplot(width = .2, \n               show.legend = FALSE, \n               alpha = .7)+\n  scale_x_discrete(name = \"Income\",\n                   labels = c(\"Below Average\", \n                              \"Average\", \n                              \"Above Average\")) +\n  scale_y_continuous(name = \"Authentic Happiness Inventory Score\")+\n  theme_minimal() +\n  scale_fill_viridis_d()\n\n\n\nViolin-boxplot"
  },
  {
    "objectID": "07-data-viz.html#layer-order",
    "href": "07-data-viz.html#layer-order",
    "title": "\n7  Intro to Data Visualisation\n",
    "section": "\n7.6 Layer order",
    "text": "7.6 Layer order\nAs we said above, one key thing to note about ggplot2 is the use of layers. Whilst we have built layers up step-by-step in this chapter, they are independent and you could remove any of them except for the first layer. Additionally, although they are independent, the order you put them in does matter as we will show you now.\n\n7.6.0.1 Activity 5: Layers part 2\n\nType and run this code into a new code chunk and look at the output.\n\n\nggplot(summarydata, aes(x = income, y = ahiTotal)) +\n  geom_violin() +\n  geom_boxplot()\n\n\nNow type and run this code into a new code chunk and compare the output to the output of the code above. Do you see the difference?\n\n\nggplot(summarydata, aes(x = income, y = ahiTotal)) +\n  geom_boxplot() +\n  geom_violin()\n\nIf you compare the two figures, shown here below for ease, the first puts the boxplots on top of the violins whereas the second puts the violins on top of the boxplots. It does that because each plot is a different layer that it literally puts on top of what is already there. Again a great reason to always look at your output and not just run code blindly as you don’t always get what you think you are doing!\n\n\n\n\nShowing the impact of changing the order of layers. Figure A shows the boxplots on top of the violin plots. Figure B shows the violins on top of the boxplots. The codes are the same but the order of the geoms is different."
  },
  {
    "objectID": "07-data-viz.html#saving-your-figures",
    "href": "07-data-viz.html#saving-your-figures",
    "title": "\n7  Intro to Data Visualisation\n",
    "section": "\n7.7 Saving your Figures",
    "text": "7.7 Saving your Figures\nGreat work today! We just want to show you one last very helpful function on how to save and export your figures. Much like your favourite jumper, there is no point having it if nobody gets to see it! It is so useful to be able to save a copy of your plots as an image file so that you can use them in a presentation or report. One approach we can use is the function ggsave().\n\n7.7.0.1 Activity 6: Saving plots\nThere are two ways you can use ggsave(). If you don’t tell ggsave() which plot you want to save, by default it will save the last plot you created. To demonstrate this let’s run the code from Activity 5 again to produce the nice violin-boxplot:\n\nggplot(summarydata, aes(x = income, \n                        y = ahiTotal, \n                        fill = income)) +\n  geom_violin(trim = FALSE, \n              show.legend = FALSE, \n              alpha = .4) +\n  geom_boxplot(width = .2, \n               show.legend = FALSE, \n               alpha = .7)+\n  scale_x_discrete(name = \"Income\",\n                   labels = c(\"Below Average\", \n                              \"Average\", \n                              \"Above Average\")) +\n  scale_y_continuous(name = \"Authentic Happiness Inventory Score\")+\n  theme_minimal() +\n  scale_fill_viridis_d()\n\n\n\nViolin-boxplot2\n\n\n\nNow that we’ve got the plot we want to save as our last produced plot, all that ggsave() requires is for you to tell it what file name it should save the plot to and the type of image file you want to create (the below example uses .png but you could also use e.g., .jpeg and other image types).\n\nType and run the below code into a new code chunk and then check your chapter folder. If you have performed this correctly then you see the saved image file.\n\n\nggsave(\"violin-boxplot.png\")\n\nNote that the image tends to save at a default size, or the size that the image is displayed in your viewer, but you can change this manually if you think that the dimensions of the plot are not correct or if you need a particular size or file type.\n\nType and run the below code to overwrite the image file with new dimensions.\n\ntry different dimensions and units to see the difference. You might want to create violin-boxplot-v1, …-v2, …-v3, and compare them. Remeber you can use ?ggsave() in the console window to bring up the help on this function.\n\n\n\n\nggsave(\"violin-boxplot.png\", \n       width = 10, \n       height = 8, \n       units = \"in\")\n\nAlternatively, the second way of using ggsave() is to save your plot as an object, just like we have done with tibbles, and then tell ggsave() which object you want to save.\n\nType and run the below code and then check your folder for the image file. Resize the plot if you think it needs it.\n\nThe below code saves the plot from Activity 5 into an object named viobox and then saves it to an image file “violin-boxplot-stored.png”.\n\nNote: We do not add on ggsave(). Instead it is a separate line of code and we tell it which object to save. So, do not do + ggsave()\n\n\n\n\n\nviobox &lt;- summarydata %&gt;%\n  ggplot(aes(x = income,\n             y = ahiTotal,\n             fill = income)) +\n  geom_violin(trim = FALSE, \n              show.legend = FALSE, \n              alpha = .4) +\n  geom_boxplot(width = .2, \n               show.legend = FALSE, \n               alpha = .7)+\n  scale_x_discrete(name = \"Income\",\n                   labels = c(\"Below Average\", \n                              \"Average\", \n                              \"Above Average\")) +\n  scale_y_continuous(name = \"Authentic Happiness Inventory Score\")+\n  theme_minimal() +\n  scale_fill_viridis_d()\n\n\nggsave(\"violin-boxplot-stored.png\", plot = viobox)\n\nFinall, note that when you save a plot to an object, you will not see the plot displayed anywhere. To get the figure to display you need to type the object name in the console (i.e., viobox). The benefit of saving figures this way is that if you are making lots of plots, you can’t accidentally save the wrong one because you are explicitly specifying which plot to save rather than just saving the last one."
  },
  {
    "objectID": "07-data-viz.html#introviz-fin",
    "href": "07-data-viz.html#introviz-fin",
    "title": "\n7  Intro to Data Visualisation\n",
    "section": "\n7.8 Finished!",
    "text": "7.8 Finished!\nWell done! ggplot can be a bit difficult to get your head around at first, particularly if you’ve been used to making graphs a different way. But once it clicks, you’ll be able to make informative and professional visualisations with ease, which, amongst other things, will make any report you write look more professional!"
  },
  {
    "objectID": "07-data-viz.html#test-yourself",
    "href": "07-data-viz.html#test-yourself",
    "title": "\n7  Intro to Data Visualisation\n",
    "section": "\n7.9 Test Yourself",
    "text": "7.9 Test Yourself\n\nWhich of these is the appropriate order of functions to create a boxplot?\n\nggplot() %&gt;% geom_boxplot()geom_boxplot() + ggplot()ggplot() + geom_boxplot()geom_plot() + geom_boxplot()\n\n\nWould this line of code run, assuming all data and libraries had been loaded in and the data and column names were spelt correctly?\n\n\nggplot(summarydata, aes(x = sex, fill = sex)) %&gt;%\n  geom_bar()\n\n\nYes, as the code looks perfectly acceptable and no errors are visibleNo, because you have piped the geom_bar() instead of adding it\n\n\nWhy would this line of code not create a barplot, assuming all data and libraries had been loaded in and the data and column names were spelt correctly?\n\n\nggplot(summarydata, aes(x = sex, fill = sex)) +\n  geom_barplot()\n\n\nbecause this would create a boxplotbecause you have piped the barplot and not added itbecause you have not included a y axisbecause there is no geom_barplot() and it should be geom_bar()\n\n\nIf I wanted a boxplot on top of a violin plot, what order of functions would I write?\n\nggplot() %&gt;% geom_violin() %&gt;% geom_boxplot()ggplot() + geom_boxplot() + geom_violin()ggplot() %&gt;% geom_boxplot() %&gt;% geom_violin()ggplot() + geom_violin() + geom_boxplot()\n\n\n\n\n\nExplain these answers\n\n\nr unhide()\n\n\nggplot() + geom_boxplot() would be the correct answer as the rest either use pipes, have the wrong order, or have the wrong functions.\nThe line of code would not run because it uses pipes instead of adding a layer\nThe line of code would not run because there is no geom_barplot() function and it should be geom_bar()\n\nThe correct order would be ggplot() + geom_violin() + geom_boxplot() as the others either use pipes, have the wrong order, or have the wrong functions."
  },
  {
    "objectID": "07-data-viz.html#words-from-this-chapter",
    "href": "07-data-viz.html#words-from-this-chapter",
    "title": "\n7  Intro to Data Visualisation\n",
    "section": "\n7.10 Words from this Chapter",
    "text": "7.10 Words from this Chapter\nBelow you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the PsyTeachR Glossary. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter.\n\n\n\n\nterm\ndefinition\n\n\n\nbarplot\n\n\n\nboxplot\n\n\n\nData Visualisation\n\n\n\ndescriptive\n\n\n\ndouble\n\n\n\nfactor data type\n\n\n\ninferential\n\n\n\nnumeric\n\n\n\nviolin\n\n\n\n\n\n\nEnd of Chapter\nThat is end of this chapter. Be sure to look again at anything you were unsure about and make some notes to help develop your own knowledge and skills. It would be good to write yourself some questions about what you are unsure of and see if you can answer them later or speak to someone about them. Good work today!"
  },
  {
    "objectID": "08-probability.html#introduction-to-probability",
    "href": "08-probability.html#introduction-to-probability",
    "title": "\n8  Probability\n",
    "section": "\n8.1 Introduction to probability?",
    "text": "8.1 Introduction to probability?\nProbability (p) is the extent to which an event is likely to occur and is represented by a number between 0 and 1. For example, the probability of flipping a coin and it landing on ‘heads’ would be estimated at p = .5, i.e., there is a 50% chance of getting a head when you flip a coin.\nIn fact, calculating the probability of any individual event occurring can be formulated as:\n\\[p = \\frac{number \\  of  \\ ways \\ the \\ event \\ could \\  arise}{number \\ of \\ possible \\ outcomes}\\] For example, what is the probability of randomly drawing your name out of a hat of 12 names where one name is definitely yours? Well, if there are 12 possible outcomes, and only 1 way for your name to arise, then it the above formula becomes:\n\\[p = \\frac{1}{12} = 0.0833333\\]\nMeaning that the probability is 0.0833333. Or, if you wanted to write that as a percentage then it would be 8.3333333%, meaning that out of every 100 draws from the hat you would expect your name to come out about 8.3 times. And if there had been four names in the hat and one was yours then it would be:\n\\[p = \\frac{1}{4} = 0.25\\]\nAnd if it had been 24 names in the hat and one was yours then it would have been:\n\\[p = \\frac{1}{24} = 0.0416667\\]\nSo you can see that the probability of an event occurring changes with the number of possible outcomes. Makes sense really! The more possible outcomes, the less likely any specific one outcome is going to happen. So far so good!\n\n8.1.0.1 Activity 1: Probability\nTry to answer these questions below to check your understanding.\n\nWhat would be the probability of selecting your name from a hat when there are ten names in the hat and your name is one of them? \n0.0833333333333333\n0.25\n0.0416666666666667\n0.1\n\nWhat would be the probability of selecting your name from a hat when there are 100 names in the hat and your name is not one of them? Be careful on this one! \n0.1\n0.01\n0\n0.1"
  },
  {
    "objectID": "08-probability.html#types-of-data",
    "href": "08-probability.html#types-of-data",
    "title": "\n8  Probability\n",
    "section": "\n8.2 Types of data",
    "text": "8.2 Types of data\nHow you tackle probability also depends on the type of data/variables you are working with (i.e. discrete or continuous). This is also referred to as Level of Measurements and here we will recap on those different types of data.\nDiscrete data can only take integer values (whole numbers). For example, the number of participants in an experiment would be discrete - we can’t have half a participant! Discrete variables can also be further broken down into nominal and ordinal variables.\n\n\nOrdinal data is a set of ordered categories; you know which is the top/best and which is the worst/lowest, but not the difference between categories. For example, you could ask participants to rate the attractiveness of different faces based on a 5-item Likert scale (very unattractive, unattractive, neutral, attractive, very attractive). You know that very attractive is better than attractive but we can’t say for certain that the difference between neutral and attractive is the same size as the distance between very unattractive and unattractive.\n\nNominal data is also based on a set of categories but the ordering doesn’t matter (e.g. left or right handed). Nominal is sometimes simply referred to as categorical data.\n\nContinuous data on the other hand can take any value. For example, we can measure age on a continuous scale (e.g. we can have an age of 26.55 years), other examples include reaction time or the distance you travel to university every day. Continuous data can be broken down into Interval or Ratio data.\n\n\nInterval data is data which comes in the form of a numerical value where the difference between points is standardised and meaningful. For example temperature, the difference in temperature between 10-20 degrees is the same as the difference in temperature between 20-30 degrees.\n\nRatio data is very like interval but has a true zero point. With our interval temperature example above, we have been experiencing negative temperatures (-1,-2 degrees) in Glasgow but with ratio data you don’t see negative values such as these i.e. you can’t be -10 cm tall.\n\n\n8.2.0.1 Activity 2: Types of data\nTry to answer these questions below to check your understanding. What types of data are the below measurements?\n\nTime taken to run a marathon (in seconds): \ninterval\ncategorical\nratio\nordinal\n\nFinishing position in marathon (e.g. 1st, 2nd, 3rd): \ncategorical\nratio\nordinal\ninterval\n\nWhich Sesame Street character a runner was dressed as: \ncategorical\nordinal\ninterval\nratio\n\nTemperature of a runner dressed in a cookie monster outfit (in degrees Celsius): \nordinal\nratio\ncategorical\ninterval"
  },
  {
    "objectID": "08-probability.html#probability-distributions",
    "href": "08-probability.html#probability-distributions",
    "title": "\n8  Probability\n",
    "section": "\n8.3 Probability distributions",
    "text": "8.3 Probability distributions\nOK great. So we know a bit more about probability and a bit more about data types. Next thing we need to think about are probability distributions! A probability distribution is the theoretical counterpart to the observed frequency distribution. A frequency distribution simply shows how many times a certain event actually occurred. A probability distribution says how many times it should have occurred. Say for example you run a test on how many times different flips of a coin produce either heads or tails. What you count yourself is the frequency distribution. What was expected, based on simulationsGenerating data, as opposed to collecting data, from summary parameters such as the mean and standard deviation by mathematicians, is the probability distribution. Mathematicians have actually simulated a number of different probability distributions, and we know that different types of data will tend to naturally fall into a known distribution. From this, we can use these distributions to help us calculate the probability of an event without having to run it ourselves. To say that in another way, we can determine the probability of an event by running a test many many times ourselves, or we can use one of these simulated probability distributions which would save us a lot of time and effort. And that is what we are going to show you here.\nThe three distributions we will look at, to help us understand probability, are:\n\nThe uniform distribution\n\nThe binomial distribution\n\nThe normal distribution"
  },
  {
    "objectID": "08-probability.html#the-uniform-distribution",
    "href": "08-probability.html#the-uniform-distribution",
    "title": "\n8  Probability\n",
    "section": "\n8.4 The uniform distribution",
    "text": "8.4 The uniform distribution\nThe uniform distribution is when each possible outcome has an equal chance of occurring. Let’s take the example from above, pulling your name out of a hat of 12 names. Each individual name has an equal chance of being drawn (p = .08). If we visualised this distribution, it would look like this distribution below - each outcome, in this case each name, has the same chance of occurring:\n\n\n\n\nThe Uniform distribution, where every outcome has an equal probability of occurring.\n\n\n\nThe uniform distribution does not feature that regularly in Psychology, except perhaps in experiments where you are randomising which block people get first or when performing a chi-square test, but it helps us start to understand that each outcome has a probability in a distribution."
  },
  {
    "objectID": "08-probability.html#the-binomial-distribution",
    "href": "08-probability.html#the-binomial-distribution",
    "title": "\n8  Probability\n",
    "section": "\n8.5 The binomial distribution",
    "text": "8.5 The binomial distribution\nThe next distribution we want to look at is the binomial distribution. The binomial (bi = two, nominal = categories) distribution, is used for discrete data, and is a probability distribution which calculates probabilities of success for situations where there are two possible outcomes e.g., flipping a coin; your outcomes are either heads or tails! A binomial distribution models the probability of any number of successes being observed (e.g. was it a heads when you wanted heads), given the probability of a success and the number of observations (e.g. how many times did you get heads (a success) over ten coin flips (the observations)). It is probably worth pointing out that you as the researcher determine what is the success (heads or tails) but for ease here we will try to stick to heads.\nLet’s say we flip a coin 10 times. Assuming the coin is fair (probability of heads = .5), how many heads should we expect to get? The below figure shows the results of a simulation for 10,000 coin flips (if you’d like to do this simulation yourself, you can see the code by clicking “Show the code”). However, what this distribution means is that we can use what we know about our data and the binomial distribution to work out the probability of different outcomes. For example, instead of running a whole bunch of tests, we could use the distribution to answer the question of what is the probability of getting at least 3 heads if you flip a coin 10 times?.\n\n\n\n\nProbability of no. of heads from 10 coin tosses\n\n\n\n\n\nShow the code\n\nNote that you are not expected to understand this code right now\n\nheads10000 &lt;- replicate(n = 10000, \n                        expr = sample(0:1, \n                                      10, \n                                      TRUE) %&gt;%\n                          sum())\n\ndata10000 &lt;- tibble(heads = heads10000) %&gt;%\n                group_by(heads) %&gt;%     \n                summarise(n = n(),\n                          p=n/10000)\n\nggplot(data10000, aes(x = heads,y = p)) + \n  geom_bar(stat = \"identity\") + \n  labs(x = \"Number of Heads\", \n       y = \"Probability of Heads in 10 flips (p)\") +\n  theme_bw() +\n  scale_x_continuous(breaks = c(0,1,2,3,4,5,6,7,8,9,10))\n\n\nAgain, the binomial distribution is not hugely common in Psychology but we are really starting to see how we can ask questions about outcomes based on probability distributions as opposed to running tests ourselves. Let’s then look at this in a distribution that is very common in psychology - the normal distribution"
  },
  {
    "objectID": "08-probability.html#the-normal-distribution",
    "href": "08-probability.html#the-normal-distribution",
    "title": "\n8  Probability\n",
    "section": "\n8.6 The normal distribution",
    "text": "8.6 The normal distribution\nThe normal distribution, reflects the probability of any value occurring for a continuous variable. Examples of continuous variables include height or age, where a single person can score anywhere along a continuum. For example, a person could be 21.5 years old and 176 cm tall.\nThe normal distribution looks like this:\n\n\n\n\nNormal Distribution of height. \\(\\mu\\) = the mean (average), \\(\\sigma\\) = standard deviation\n\n\n\nSomething to note is that the normal distribution is symmetrical, meaning there is an equal probability of observations above and below the mean occurring. This means that, if the mean in the above plot of heights is 170 cm, we could expect the number of people who have a height of 160 cm to be the same as the number of people who have a height of 180 cm. A second thing to note is that as the distribution is symmetrical, the mean, median, and mode of the distribution are all equal and in the middle of the distribution and have the highest probability of occurring. As you move away from the middle of the distribution, the probability of those outcomes occurring starts to reduce. This plays an important role in analyses as we will come on to see in later chapters.\nNow, however, in the same way that we could with the coin flips, we can then use what we know about our data and the normal distribution to estimate the probability of certain outcomes, such as what’s the probability that someone would be taller than 190cm?\nAs with any probabilities, real-world data will come close to the normal distribution, but will (almost certainly) never match it exactly. As we collect more observations from data that we might expect to be normally distributed, our data will get increasingly closer to a normal distribution. As an example, here’s a simulation of an experiment in which we collect heights from 5000 participants. As you can see, as we add more observations, our data starts to look more and more like the normal distribution in the previous figure.\n\n\n\n\nA simulation of an experiment collecting height data from 2000 participants\n\n\n\n\n8.6.0.1 Activity 3: Normal distribution\nComplete the sentences to make sure that you are understanding the above.\n\nIn a normal distribution, the mean, median, and mode \nsum to zero\nare always different\nare all equal.\nIn a normal distribution, the further away from the mean an observation is \nthe lower its probability of occuring\nthe higher its probability of occuring.\nWhereas the binomial distribution is based on situations in which there are two possible outcomes, the normal distribution is based on situations in which the data \nis a continuous variable\nhas three possible values\nis a categorical variable.\n\n8.6.0.2 Activity 4: Distribution test\nWhich distribution is likely to be associated with the following?\n\nScores on an IQ test \nUniform distribution\nBinomial distribution\nNormal distribution\n\nWhether a country has won or lost the Eurovision song contest \nUniform distribution\nBinomial distribution\nNormal distribution\n\nPicking a spade card out of a normal pack of playing cards\nUniform distribution\nBinomial distribution\nNormal distribution"
  },
  {
    "objectID": "08-probability.html#using-the-binomial-distribution",
    "href": "08-probability.html#using-the-binomial-distribution",
    "title": "\n8  Probability\n",
    "section": "\n8.7 Using the binomial distribution",
    "text": "8.7 Using the binomial distribution\nNow, we’re going to calculate probabilities based on the binomial distribution. In this chapter, for the first time we don’t need to load the tidyverse. All of the functions we need are contained in Base R. If you want a refresher on the difference between Base R and packages, see Programming Basics.\n\n8.7.0.1 Activity 5: Getting Set-Up\n\nOpen a new R Markdown document, call it “Probability” and save it in the relevant chapter folder, remembering to delete the default text which we do not need.\n\nWe’re going to use three Base R functions to work with the binomial distribution:\n\n\ndbinom() - the density function: gives you the probability of x successes given the number of trials and the probability of success on a single trial (e.g., what’s the probability of flipping 8/10 heads with a fair coin?).\n\npbinom() - the probability distribution function: gives you the cumulative probability of getting a number of successes below a certain cut-off point (e.g. probability of getting 0 to 5 heads out of 10 flips), given the size and the probability. This is known as the cumulative probability distribution function or the cumulative density function.\n\nqbinom() - the quantile function: is the opposite of pbinom() in that it gives you the x axis value for a given probability p, plus given the size and prob, that is if the probability of flipping a head is .5, how many heads would you expect to get with 10 flips?\n\nSo let’s try these functions out to answer two questions:\n\nWhat is the probability of getting exactly 5 heads on 10 flips?\nWhat is the probability of getting at most 2 heads on 10 flips?\n\n8.7.0.2 Activity 6: dbinom()\n\nLet’s start with question 1, what is the probability of getting exactly 5 heads on 10 flips?\nWe want to predict the probability of getting 5 heads in 10 trials (coin flips) where the probability of success on each flip is 0.5 (it’ll either be heads or tails so you have a 50/50 chance which we write as 0.5). We will use dbinom() to work this out:\nThe dbinom() (density) function has three arguments:\n\n\nx: the number of ‘heads’ we want to know the probability of. Either a single value, 3, or a series of values, 0:10. In this case we want to know about 5 heads, so we write 5.\n\nsize: the number of trials (flips) we are simulating; in this case, 10 flips.\n\nprob: the probability of ‘heads’ on one trial. Here chance is 50-50 which as a probability we state as 0.5 or .5\n\nType and run the below code in a new code chunk:\n\ndbinom(x = 5, size = 10, prob = 0.5)\n\nLooking at the outcome, answer the following questions:\n\nTo two decimal places, what is the probability of getting 5 heads out of 10 coin flips? \n\nWhat is this probability expressed in percent? \n0.25%\n2.5%\n25%\n\n\n8.7.0.3 Activity 7: pbinom()\n\nOK, question 2. What is the probability of getting at most 2 heads on 10 flips?\nThis time we use pbinom() as we want to know the cumulative probability of getting a maximum of 2 heads from 10 coin flips. So we have set a cut-off point of 2 but we still have a probability of getting a heads of 0.5.\n\n\nNote: pbinom() takes the arguments size and prob argument just like dbinom(). However, the first input argument is q rather than x. This is because in dbinom x is a fixed number, whereas q is all the possibilities up to and including a given number (e.g. 0, 1, 2).\n\nType and run the below code in a new code chunk:\n\npbinom(q = 2, size = 10, prob = 0.5)\n\nLooking at the outcome, answer the following question:\n\nWhat is the probability of getting a maximum of 2 heads on 10 coin flips to 2 decimal places? \n\nWhat is this probability expressed in percent? \n0.05%\n0.5%\n5%\n\n\n8.7.0.4 Activity 8: pbinom() 2\nLet’s try one more scenario with a cut-off point to make sure you have understood this. What is the probability of getting 7 or more heads on 10 flips?\nWe can use the same function as in the previous example, however, there’s an extra argument if we want to get the correct answer. Let’s try running the code we used above first but change q = 2 to q = 7 to see what we get.\n\npbinom(q = 7, size = 10, prob = .5) \n\n[1] 0.9453125\n\n\nThis tells us that the probability is .95 or 95% - that doesn’t seem right does it? It seems very high for getting 7 or more heads out of 10 coin flips! Why is that? Well, the default behaviour for pbinom() is to calculate the cumulative probability for the lower tail of the curve, i.e., if you specify q = 2 it calculates the probability of all outcomes up to and including 2. We specified q = 7 which means that we have calculated the probability of getting an outcome of 0, 1, 2, 3, 4, 5, 6, or 7 - shown here in the blue area in the below figure - which is obviously very high.\n\n\n\n\nLower and upper tails\n\n\n\nTo get the right answer, we have to add lower.tail = FALSE to our code as we are interested in the upper tail of the distribution. Because we want the cumulative probability to include 7, and because we know q words as up to and including, in order to get 7 or more, we set q = 6. This will now calculate the cumulative probability of getting 7, 8, 9, or 10 heads out of 10 coin flips. Remember, if we set q = 7 that would be up to including 7, and looking at the upper tail of the distribution would only give us 8, 9 and 10. We want 7, 8, 9 and 10, so we have to set up to and including 6, which leaves us 7 and more.\nTry and run the below code in a new code chunk:\n\npbinom(q = 6, size = 10, prob = .5, lower.tail = FALSE) \n\nLooking at the outcome, answer the following question:\n\nWhat is the probability of getting between 7 and 10 heads from 10 coin flips to 2 decimal places? \n\nWhat is this probability expressed in percent? \n0.017%\n0.17\n17%\n\n\n8.7.0.5 Activity 9: qbinom()\n\nOK great! You are doing excellent as this is tricky stuff. Remember though the whole point is to show you that using probability distributions you can ask all sorts of questions about the probability of any outcome or series of outcomes.\nNow let’s consider a scenario in which you’d use the quantile function qbinom. Imagine that you’ve been accosted by a street magician and they want to bet you that they can predict whether the coin will land on heads or tails. You suspect that they’ve done something to the coin so that it’s not fair and that the probability of the coin landing on a head is no longer .5 or 50/50 - you suspect the coin is now very much more likely to land on tails. Your null hypothesis is that the coin is not a trick coin and that the probability of heads or tails should be even. You are going to run a single experiment to test your hypothesis, with 10 trials. What is the minimum number of heads that is acceptable if p really does equal .5?\nYou have used the argument prob in the previous two functions, dbinom and pbinom, and it represents the probability of success on a single trial (here it is the probability of ‘heads’ in one coin flip, .5). For qbinom, prob still represents the probability of success in one trial, whereas p represents the overall probability of success across all trials. When you run pbinom, it calculates the number of heads that would give that probability.\nWe know from looking at the binomial distribution above that sometimes even when the coin is fair, we won’t get exactly 5/10 heads. Instead, we want to set a cut-off, a probability that below which we’ll say that it’s so unlikely we’d get that result if the coin was fair and in this example we will use the default cut-off for statistical significance in psychology, .05, or 5%.\nIn other words, you ask for the minimum number of successes (e.g. heads) to maintain an overall probability of .05, in 10 flips, when the probability of a success on any one flip is .5. To do that we use the below code:\n\nqbinom(p = .05, size = 10, prob = .5)\n\n[1] 2\n\n\nFrom the code we see that the answer is 2. That means that if the magician flipped fewer than two heads out of ten, you could conclude that there is a less than 5% probability that would happened if the coin was fair. You would reject the null hypothesis that the coin was unbiased against heads and very very politely ask the kind magician for your money back!\nHowever, ten trials is probably far too few if you want to accuse the magician of being a bit dodge. Run the below code and then answer the following questions:\n\nqbinom(p = .05, size = c(100, 1000, 10000), prob = .5)\n\n\nWhat would your cut-off be if you ran 100 trials? \n\nWhat would your cut-off be if you ran 1000 trials? \n\nWhat would your cut-off be if you ran 10,000 trials? \n\n\nNotice that the more trials you run, the more precise the estimates become, that is, the closer they are to the probability of success on a single flip (.5). Again this is a simplification, but think about how this relates to sample size in research studies, the more participants you have, the more precise your estimate will be.\nWe should also mention that qbinom also uses the lower.tail argument and it works in a similar fashion to pbinom. We won’t try that out here but it is good to know in case you ever need it.\n\nVisualise it!\nHave a go at playing around with different numbers of coin flips and probabilities in our dbinom() and pbinom() app!"
  },
  {
    "objectID": "08-probability.html#using-the-normal-distribution",
    "href": "08-probability.html#using-the-normal-distribution",
    "title": "\n8  Probability\n",
    "section": "\n8.8 Using the normal distribution",
    "text": "8.8 Using the normal distribution\nA similar set of functions exist to help us work with other distributions, including the normal distribution and we’re going to use three of these:\n\n\ndnorm()- the density function, for calculating the probability of a specific value\n\npnorm()- the probability or distribution function, for calculating the probability of getting at least or at most a specific value\n\nqnorm()- the quantile function, for calculating the specific value associated with a given probability\n\nAs you can probably see, these functions are very similar to the functions that are used to work with the binomial distribution. We will use data about height in Scottish people to show you how the above functions work in the normal distribution\n\n8.8.1 Probability of heights\nData from the Scottish Health Survey (2008) shows that:\n\nThe average height of a 16-24 year old Scottish man is 176.2 centimetres, with a standard deviation of 6.748.\nThe average height of a 16-24 year old Scottish woman is 163.8 cm, with a standard deviation of 6.931.\nAt the time of writing, there is currently no data on Scottish trans and non-binary people.\n\nThe below figure is a simulation of this information - again, you can see the code used to run this simulation by clicking the “Show me the code” button but note that you are not asked to understand this right now.\n\n\nShow me the code\n\n\nmen &lt;- rnorm(n = 100000, mean = 176.2, sd = 6.748)\nwomen &lt;- rnorm(n = 100000, mean = 163.8, sd = 6.931)\n\nheights &lt;- tibble(men, women) %&gt;%\n  pivot_longer(names_to = \"sex\", values_to = \"height\", men:women)\n\nggplot(heights, aes(x = height, fill = sex)) +\n  geom_density(alpha = .6) +\n  scale_fill_viridis_d(option = \"E\") +\n  theme_minimal()\n\n\n\n\n\n\nSimulation of Scottish height data\n\n\n\nSo to test the normal distribution, and to round off this chapter, we will use the above information to calculate the probability of observing at least or at most a specific height with pnorm(), and the heights that are associated with specific probabilities with qnorm().\n\n8.8.1.1 Activity 10:pnorm()\n\npnorm() requires three arguments:\n\n\nq is the value that you want to calculate the probability of. Note however you set this as exactly the number you want and not 1 less than the number you want. This is because the data is continuous and not discrete as in the binomial distribution.\n\nmean is the mean of the data\n\nsd is the standard deviation of the data\n\nlower.tail works as above and depends on whether you are interested in the upper or lower tail,\n\nType the code below into a code chunk and replace the NULLs to calculate the probability of meeting a 16-24 y.o. Scottish woman who is as tall or taller than the average 16-24 y.o. Scottish man.\n\n\nhint: You are asking about the female distribution so use that mean and sd\n\nhint: the average male is 176.2\n\nhint: tall or taller is upper.\n\nhint: the solution is at the end of the chapter if you are stuck.\n\n\npnorm(q = NULL, mean = NULL, sd = NULL, lower.tail = NULL)\n\nLooking at your outcome, answer the following questions.\n\nWhat is the probability of meeting a 16-24 y.o. Scottish woman who is taller than the average 16-24 y.o. Scottish man? \n\nWhat is this probability expressed in percent? \n0.04%\n0.4%\n4%\n\n\n8.8.1.2 Activity 11: pnorm 2\nFiona is a very tall Scottish woman (181.12 cm) in the 16-24 y.o. range who will only date men who are taller than her.\n\nUsing pnorm() again, what is the proportion of Scottish men Fiona would be willing to date to 2 decimal places? \n\nhint: you want to know about the male population\n\nhint: Fiona is 181.12 cm tall and you want taller than her.\n\n\nWhat is this probability expressed in percent? \n0.23%\n2.3%\n23%\n\n\n8.8.1.3 Activity 12: pnorm 3\nOn the other hand, Fiona is bisexual and will only date women who are shorter than her.\n\nWhat is the proportion of Scottish women would Fiona be willing to date to 2 decimal places? \n\nhint: female distribution, lower than Fiona.\n\n\nWhat is this probability expressed in percent? \n0.99%\n9.9%\n99%\n\n\n8.8.1.4 Activity 13: qnorm()\n\nFinally, in the previous examples we calculated the probability of a particular outcome. Now we want to calculate what outcome would be associated with a particular probability and we can use qnorm() to do this.\nqnorm() is very similar to pnorm() with one exception, rather than specifying q our known observation or quantile, instead we have to specify p, our known probability.\n\nqnorm(p = NULL, mean = NULL, sd = NULL, lower.tail = NULL)\n\nReplace the NULLs in the above code to calculate how tall a 16-24 y.o. Scottish man would have to be in order to be in the top 5% (i.e., p = .05) of the height distribution for Scottish men in his age group. Remember the solutions are at the end of the chapter. You can confirm if you are right or not by answering this question:\nThe answer to this last question was:\n\n193.581696140348176.2187.299472274669175.352037231422\n\n\nVisualise it!\nHave a go at playing around with different distributions in our dnorm() and pnorm() app - access it here"
  },
  {
    "objectID": "08-probability.html#finished",
    "href": "08-probability.html#finished",
    "title": "\n8  Probability\n",
    "section": "\n8.9 Finished",
    "text": "8.9 Finished\nAnd that’s it! The key concepts to take away from this chapter are that different types of data tend to follow known distributions, and that we can use these distributions to calculate the probability of particular outcomes. This is the foundation of many of the statistical tests that you will learn about in this course. For example, if you want to compare whether the scores from two groups are different, that is, whether they come from different distributions, you can calculate the probability that the scores from group 2 would be in the same distribution as group 1. If this probability is less than 5% (p = .05), you might conclude that the scores were significantly different. That’s an oversimplification obviously, but if you can develop a good understanding of probability distributions it will stand you in good stead for the rest of the statistics content.\nThis was a long read so there is no test yourself today but be sure to make notes and to check your understanding of different concepts. Please also remember to ask any questions you are unsure of."
  },
  {
    "objectID": "08-probability.html#prob-sols",
    "href": "08-probability.html#prob-sols",
    "title": "\n8  Probability\n",
    "section": "\n8.10 Activity solutions",
    "text": "8.10 Activity solutions\n\n8.10.0.1 Activity 6\n\nTo two decimal places, what is the probability of getting 5 heads out of 10 coin flips?\n\n\n.25\n\n\n8.10.0.2 Activity 7\n\nWhat is the probability of getting a maximum of 2 heads on 10 coin flips to 2 decimal places?\n\n\n.06\n\n\n8.10.0.3 Activity 8\n\nWhat is the probability of getting between 7 and 10 heads from 10 coin flips to 2 decimal places?\n\n\n.17\n\n\n8.10.0.4 Activity 10\n\nWhat is the probability of meeting a 16-24 y.o. Scottish woman who is taller than the average 16-24 y.o. Scottish man?\n\n\npnorm(q = 176.2, mean = 163.8, sd = 6.931, lower.tail = FALSE)\n\n\n8.10.0.5 Activity 11\n\nUsing pnorm() again, what is the proportion of Scottish men Fiona would be willing to date to 2 decimal places?\n\n\npnorm(q = 181.12, mean = 176.2, sd = 6.748, lower.tail = FALSE)\n\n\n8.10.0.6 Activity 12\n\nWhat is the proportion of Scottish women would Fiona be willing to date to 2 decimal places?\n\n\npnorm(q = 181.12, mean = 163.8, sd = 6.931, lower.tail = TRUE)\n\n\n8.10.0.7 Activity 13\nThe answer to this last question was:\n\nqnorm(p = .05, mean = 176.2, sd = 6.748, lower.tail = FALSE)"
  },
  {
    "objectID": "08-probability.html#words-from-this-chapter",
    "href": "08-probability.html#words-from-this-chapter",
    "title": "\n8  Probability\n",
    "section": "\n8.11 Words from this Chapter",
    "text": "8.11 Words from this Chapter\nBelow you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the PsyTeachR Glossary. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter.\n\n\n\n\nterm\ndefinition\n\n\n\nbinomial distribution\n\n\n\nchi-square\n\n\n\ncontinuous\n\n\n\ndiscrete\n\n\n\ndistribution\n\n\n\ninferential\n\n\n\ninteger\n\n\n\nInterval\n\n\n\nLikert\n\n\n\nnominal\n\n\n\nnormal distribution\n\n\n\nordinal\n\n\n\npopulation\n\n\n\nprobability\n\n\n\nRatio\n\n\n\nsample\n\n\n\nsimulation\nGenerating data, as opposed to collecting data, from summary parameters such as the mean and standard deviation\n\n\nuniform distribution\n\n\n\n\n\n\nThat is end of this chapter. Be sure to look again at anything you were unsure about and make some notes to help develop your own knowledge and skills. It would be good to write yourself some questions about what you are unsure of and see if you can answer them later or speak to someone about them. Good work today!"
  },
  {
    "objectID": "09-correlation.html#set-up-the-data",
    "href": "09-correlation.html#set-up-the-data",
    "title": "\n8  Correlations\n",
    "section": "\n8.1 Set-up the Data",
    "text": "8.1 Set-up the Data\nAs always, the first activity is about getting ourselves ready to analyse the data so try out the steps and if you need help, consult the earlier chapters.\n\n8.1.0.1 Activity 1: Set-up\n\nOpen RStudio and set the working directory to your chapter folder. Ensure the environment is clear.\n\nIf you’re using the Rserver, avoid a number of issues by restarting the session - click Session - Restart R\n\n\n\nOpen a new R Markdown document and save it in your working directory. Call the file “Correlations”.\n\nDownload MillerHadenData.csv and save it in your folder. Make sure that you do not change the file name at all.\n\nIf you prefer you can download the data in a zip folder by clicking here\n\nRemember not to change the file names at all and that data.csv is not the same as data (1).csv.\n\n\nDelete the default R Markdown welcome text and insert a new code chunk that loads the following packages, in this specific order, using the library() function. Remember the solutions if needed.\n\nLoad the packages in this order, car,correlation, report, psych, and tidyverse\n\nwe have not used four of these packages before so you will likely need to install them using install.packages(). Remember though that you should only do this on your own machine and only in the console window. If you are using the RServer you will not need to install them.\n\n\nFinally, load the data into an object named mh using read_csv().\n\n\n\nAdditional Hints\n\n\n\nEach package requires using the library() function each time. For example, library(car), libary(correlation), etc, etc.\nmh &lt;- read_csv(“What_is_your_datafile_called.csv”)\n\n\n\n\n8.1.0.2 Activity 2: Look at your data\nExcellent! If you have loaded in the data correctly then you should be able to have a look at it through one of the various methods we have looked at already.\n\nLook at your data using the head() function and you should see the following:\n\n\n\n\n\n\nParticipant\nAbil\nIQ\nHome\nTV\n\n\n\n1\n61\n107\n144\n487\n\n\n2\n56\n109\n123\n608\n\n\n3\n45\n81\n108\n640\n\n\n4\n66\n100\n155\n493\n\n\n5\n49\n92\n103\n636\n\n\n6\n62\n105\n161\n407\n\n\n\n\n\n\nAs you can see, we have five columns and they are:\n\nthe participant number (Participant),\nReading Ability score (Abil),\nIntelligence score (IQ),\nthe number of minutes spent reading at Home per week (Home),\nand the number of minutes spent watching TV per week (TV).\n\nHere we will we will focus on Reading Ability and IQ but for further practice you can look at other relationships in your free time.\nA probable hypothesis for today could be that as Reading Ability increases so does Intelligence (remember there is no causality here). Or phrasing the alternative hypothesis (\\(H_1\\)) more formally, we hypothesise that the reading ability of school children, as measured through a standardized test, and intelligence, again measured through a standardized test, show a positive relationship. This is the hypothesis we will test today but remember that we could always state the null hypothesis (\\(H_0\\)) that there is no relationship between reading ability and IQ."
  },
  {
    "objectID": "09-correlation.html#assumptions-of-the-test",
    "href": "09-correlation.html#assumptions-of-the-test",
    "title": "\n8  Correlations\n",
    "section": "\n8.2 Assumptions of the test",
    "text": "8.2 Assumptions of the test\nNow before running an analysis we should check the assumptions of the test, where the assumptions are checks that the data must pass before we can use certain tests. The assumptions change on the test and you should only use a given test based on how well the data meets the assumptions of the test. In short, the Pearson correlation and the Spearman correlation have different assumptions and we need to check our data to see which test to use.\n\n8.2.0.1 Activity 3: Assumptions\nFor correlations, the main assumptions we need to check are:\n\nIs the data interval, ratio, or ordinal?\nIs there a data point for each participant on both variables?\nIs the data normally distributed in both variables?\nDoes the relationship between variables appear linear?\nDoes the spread have homoscedasticity?\n\nWe will look at each of these assumptions in turn to see which correlation we should use.\nAssumption 1: Level of Measurement\nIf we want to run a Pearson correlation then we need interval or ratio data; Spearman correlations can run with ordinal, interval or ratio data. What type of data do we have?\n\nThe type of data in this analysis is most probably \nratio\ninterval\nordinal\nnominal as the data is \ncontinuous\ndiscrete and there is unlikely to be a true zero\n\n\n\nHints on data type\n\n\n\nAre the variables continuous?\nIs the difference between 1 and 2 on the scale equal to the difference between 2 and 3?\n\n\n\nAssumption 2: Pairs of Data\nGreat! So the data looks at least interval and continuous. Next, all correlations must have a data point for each participant in the two variables being correlated. This should make sense as to why - you can’t correlate against an empty cell! So now go check that you have a data point in both columns for each participant.\nNote: You can check for missing data by visual inspection - literally using your eyes. A missing data point will show as a NA, which is short for not applicable, not available, or no answer. An alternative would be to use the is.na() function. This can be really handy when you have lots of data and visual inspection would just take too long. If for example you ran the following code:\n\nis.na(mh)\n\nIf you look at the output from that function, each FALSE tells you that there is a data-point in that cell. That is because is.na() asks is that cell a NA; is it empty. If the cell was empty then it would come back as TRUE. As all cells have data in them, they are all showing as FALSE. If you wanted to ask the opposite question, is their data in this cell, then you would write !is.na() which is read as “is not NA”. Remember, the exclamation mark ! turns the question into the opposite.\nHowever you have looked at the data, it looks like that everyone has data in all the columns but let’s test our skills a little whilst we are here. Answer the following questions:\n\nHow is missing data represented in a tibble? \nan empty cell\nNA\na large number\ndon’t know\n\nWhich code would leave you with just the participants who were missing Reading Ability data in mh: \nfilter(mh, is.na(Ability)\nfilter(mh, is.na(Abil)\nfilter(mh, !is.na(Ability)\nfilter(mh, !is.na(Abil)\n\nWhich code would leave you with just the participants who were not missing Reading Ability data in mh: \nfilter(mh, is.na(Ability)\nfilter(mh, is.na(Abil)\nfilter(mh, !is.na(Ability)\nfilter(mh, !is.na(Abil)\n\n\n\n\nHints on removing missing data points\n\n\n\n\nfilter(dat, is.na(variable)) versus filter(dat, !is.na(variable))\n\n\n\n\nAssumption 3-5: Normality, linearity, homoscedasticity\nBrilliant! We know our data type and we know we have no missing data. The remaining assumptions are all best checked through visualisations. You can use histograms and QQ-plots to check that the data (Abil and IQ) are both normally distributed, and you can use a scatterplot of IQ as a function of Abil to check whether the relationship is linear, with homoscedasticity, and without outliers. An alternative would be to use z-scores to check for outliers with the cut-off usually being set at around \\(\\pm2.5SD\\) or \\(\\pm3SD\\). You could do this using the mutate function (e.g. mutate(z = (X - mean(X))/SD(X))), but today we will just use visual checks.\nWe will now ask you to create a few figures and then we will look at them together, as a whole, to answer some questions about these last assumptions.\nHistograms for Normality\n\nType the below code in a new code chunk and run it to create a histogram for Abil.\n\n\nggplot(data = mh, aes(x = Abil)) +\n  geom_histogram()\n\nThis code should look very similar to the code you used to create a bar plot in Chapter 7. We have specified that we want to display Abil on the x-axis and that the shape we want to produce is a histogram, hence geom_histogram(). Just like geom_bar(), you do not need to specify the y-axis because if it’s a histogram, it’s always a count. The figure should look as shown here.\n\n\n\n\nHistogram of Abil\n\n\n\n\nNow, in a new code chunk, write and run code to produce a histogram for the variable IQ. Remember the solutions are at the end of the chapter.\n\nQ-Q Plots for Normality\nAs we said we will look at the figures in a minute but first we need a few more plots. One being the Q-Q plot which allows us to check normality. The Q-Q plot require us to use the package car rather than ggplot2. You can make Q-Q plots in ggplot2 but they aren’t as useful, however, the code is still very simple.\n\nIn a new code chunk, type and run the below code to create a Q-Q plot for Abil.\n\n\nqqPlot(x = mh$Abil)\n\nThis code looks a little different to code you’ve used up until this point as it comes from Base R. It uses the notation object$variable so our x variable could be read as “use the variable Abil from the object mh. And the figure will look like this:\n\n\n\n\nQ-Q plot for Abil\n\n\n\n[1] 15  4\n\n\nThe Q-Q plot includes a confidence envelope (the blue dotted lines) around the data with the understanding that if your data points fall within these dotted lines then you can assume normality. The ggplot2 version of Q-Q plots make it more difficult to add on this confidence envelope, which is why we’re using a different package. qqPlot() will also print the IDs of the most extreme data points. In this case, the 4th and 15th data point in Abil are flagged, although because they fall within the confidence envelope, they don’t appear problematic. This also explains why you might see a message stating ## [1] 15 4. The 15th and 4th value are worth considering!\n\nNow, in a new code chunk, write and run code to create a Q-Q plot for IQ.\n\nInformation: Normality of the residuals\nOne thing to note before we move on is that, in terms of normality, it is in fact the normality of the residuals that matters, where the residuals are the difference between the individual data points and the line of best fit. However, to fully understand this we need to cover more information first as introducing that concept at this stage would be confusing. One approach the field can use however is that if the data is normally distributed then it is highly likely that the residuals will also be normally distributed. We will look at residuals in the next chapter, but here we will instead use the normality of the raw data as a proxy for the normality of the residuals.\nScatterplots for linearity and homoscedasticity\nFinally, in order to assess linearity and homoscedasticity, we can create a scatterplot using ggplot2.\n\nIn a new code chunk, copy and run the below code to create a scatterplot of the relationship between IQ and Ability.\n\n\nggplot(data = mh, aes(x = Abil, y = IQ)) +\n  geom_point()+\n  geom_smooth(method = lm)\n\nThe ggplot2 code is very similar to what you have already encountered with the bar chart and violin-boxplot.\n\nThe first line of data sets up the base of the plot and we specify that we wish to display Abil on the x-axis, IQ on the y-axis, and use the dataset mh.\nThe first geom, geom_point(), adds in the data points,\nthe second geom, geom_smooth, adds in the line of best fit. The shaded area around the line is a confidence interval around the data. This can be turned off by setting se = FALSE as an additional argument.\n\nThe figure should look as follows:\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\nScatterplot of scores\n\n\n\nNote: Do not worry if you see a message stating ## geom_smooth() using formula 'y ~ x'. This is just letting you know how it is plotting the line of best fit (the blue line)\n\nNow, remembering that ggplot2 works on layers and that you can customise each layer, edit the above code to add in a layer of scale_x_continuous() that changes the label Abil to Reading Ability.\n\nChecking the assumptions\nNow that we have all the figures we need we should be able to check the assumptions. Try to answer the following questions, based on the above visualisations:\n\nIs the assumption of normality met for both variables? \nYes\nNo\n\nIs the assumption of linearity met? \nYes\nNo\n\nIs the assumption of homoscedasticity met? \nYes\nNo\n\nBased on the above, which correlation method would you use? \nPearson\nSpearman\n\n\n\n\nExplain these answers\n\n\nWhen assessing assumptions through the use of visualisations your decision will always be a judgement call. In this dataset, we only have data from 25 participants therefore it is very unlikely we would ever observe perfect normality and linearity in this dataset. It is likely that a researcher would assume that this data is approximately normal, that there is no evidence of a non-linear relationship, and that the spread of data points around the line is relatively even. Many students become fixated with needing a ‘perfect’ dataset that follows an exactly normal distribution. This is unlikely to ever happen with real data - learn to trust your instincts!\nFinally, as the data is interval, continuous, normally distributed, and the relationship is linear and the assumption of homoscedasticity has been met, we would use a Pearson correlation."
  },
  {
    "objectID": "09-correlation.html#descriptives-of-the-correlation",
    "href": "09-correlation.html#descriptives-of-the-correlation",
    "title": "\n8  Correlations\n",
    "section": "\n8.3 Descriptives of the Correlation",
    "text": "8.3 Descriptives of the Correlation\nNow that we have checked our assumptions and have confirmed we will use the Pearson correlation, the next step is descriptives. A key thing to keep in mind is that the scatterplot is actually the descriptive of the correlation. Meaning that in an article, or in a report, you would not only use the scatterplot to determine which type of correlation to use but also to describe the potential relationship in regards to your hypothesis. So you would always expect to see a scatterplot in the write-up of this type of analysis.\n\n8.3.0.1 Activity 4: Descriptive statistics\n\nLooking at the scatterplot, spend a couple of minutes thinking about and describing the relationship between Ability and IQ in terms of your hypothesis. Remember this is a descriptive analysis at this stage, so nothing is confirmed. Does the relationship appear to be as we predicted in our hypothesis? A discussion is in the solutions at the end of the chapter.\n\n\n\nHints on discussing descriptives\n\n\n\nHint 1: We hypothesised that reading ability and intelligence were positively correlated. Is that what you see in the scatterplot?\nHint 2: Keep in mind it is subjective at this stage.\nHint 3: Remember to only talk about a relationship and not a prediction. This is correlational work, not regression.\nHint 4: Can you say something about both the strength (weak, medium, strong) and the direction (positive, negative)?\n\n\n\nIn addition to the scatterplot, it can sometimes be relevant to include means and standard deviations of scales in a correlation. It is not always relevant but, as an example, if you were measuring something like anxiety, or stress, or IQ, it can be informative to include this information to help demonstrate how your sample compares to population norms. As such we will calculate some descriptives here as it is also good practice of our data-wrangling skills.\n\nIn a new code chunk, write and run code to calculate the mean score and standard deviation for Abil and IQ using summarise() and store the output of this function in an object called descriptives\n\nName the output of the calculations Abil_mean, Abil_SD, IQ_mean, and IQ_SD. Make sure to use these exact spellings otherwise later activities won’t work.\n\nhint: We have already seen how to calculate the mean(), the median(), the number of people (with n()), and the sum() within the summarise() function. Other descriptives such as the sd(), the min() and the max() can also be calculated in a similar way to using mean() and median().\n\n\n\nIf you have performed this correctly, when you view descriptives should look similar to this:\n\n\n\n\nAbil_mean\nAbil_SD\nIQ_mean\nIQ_SD\n\n\n55.12\n6.08\n100.04\n9.04\n\n\n\n\nAnswer the following questions to confirm your understanding of the output:\n\nWhat is the mean of Reading Ability? \n54.12\n56.12\n55.12\n\nWhat is the mean of IQ? \n99.04\n100.04\n101.04\n\nIf the population norm mean of IQ is 100, how comparable is your sample to the population? \nthe same\nvery different"
  },
  {
    "objectID": "09-correlation.html#inferentials-of-the-correlation",
    "href": "09-correlation.html#inferentials-of-the-correlation",
    "title": "\n8  Correlations\n",
    "section": "\n8.4 Inferentials of the correlation",
    "text": "8.4 Inferentials of the correlation\nExcellent! So we have checked our assumptions and our descriptives. Our data looks consistent with population norms and the scatterplot would suggest a positive relationship between the two variables. Finally we will run the correlation!\nThere are often many different functions that can be used to achieve the same thing and we’re actually going to show you two ways of running a correlation as some people prefer one approach over the other because of the data type the results come in and how easy it is to work with that output.\n\n8.4.0.1 Activity 5: Run the correlation\nFirst, we’ll use the correlation() function from the correlation package. Remember that for help on any function you can type e.g., ?correlation in the console window. The correlation() function requires:\n\nThe name of the data set you are using\nThe name of the first variable you want to select for the correlation\nThe name of the second variable you want to select for the correlation\nThe type of correlation you want to run: e.g. pearson, spearman\n\nThe type of NHST tail you want to run: e.g. \"less\",\"greater\", \"two.sided\"\n\n\nFor example, if your data is stored in dat and you want to do a two-sided pearson correlation of the variables (columns) X and Y, then you would do:\n\ncorrelation(data = dat, \n            select = \"X\", \n            select2 = \"Y\",  \n            method = \"pearson\", \n            alternative = \"two.sided\")\n\nHere we are wanting to run a Pearson correlation with a two-sided alternative.\n\nIn a new code chunk, using the information about correlation() above, type and run a Pearson correlation between IQ and Ability and store the output in an object called results.\nView the output by typing View(results) in the console window\n\nThe second method is to use cor.test() which is a Base R function and uses similar code as correlation() except for how the variables are specified. cor.test() use the same object$variable syntax we saw in qqPlot():\n\nIn a new code chunk, type and run the below code and then view the output by typing results2 in the console.\n\nnot that we have specified x = mh$IQ meaning that the first variable, x, is the column IQ in the object mh.\n\n\n\n\nresults2 &lt;-  cor.test(x = mh$IQ, \n                      y = mh$Abil, \n                      method = \"pearson\", \n                      alternative = \"two.sided\")\n\nLook at how the output differs from results. We’ll come back to why we’ve shown you two ways shortly."
  },
  {
    "objectID": "09-correlation.html#interpreting-output-and-writing-up",
    "href": "09-correlation.html#interpreting-output-and-writing-up",
    "title": "\n8  Correlations\n",
    "section": "\n8.5 Interpreting output and writing up",
    "text": "8.5 Interpreting output and writing up\nExcellent work. As you can see, running the correlation is actually really quick, and the hard work was checking the assumptions and some data-wrangling. You should now have a tibble called results that gives you the output of the correlation between Reading Ability and IQ for the school children measured in Miller and Haden (2013) Chapter 11. All that is left to do now is interpret the output and write it up.\n\n8.5.0.1 Activity 6: Interpreting the correlation\nLook at results and then answer the following questions:\n\nWhat is the value of Pearson’s r to 2 decimal places? \n\nThe direction of the relationship between Ability and IQ is: \npositive\nnegative\nno relationship\n\nThe strength of the relationship between Ability and IQ is: \nstrong\nmedium\nweak\n\nAssuming \\(\\alpha = .05\\) the relationship between Ability and IQ is: \nsignificant\nnot significant\n\nThe alternative hypothesis was that the reading ability of school children, as measured through a standardized test, and intelligence, again through a standardized test, are positively correlated. Based on the results we can say that the alternative hypothesis: \nis accepted\nis rejected\nis proven\nis not proven\n\n\n\n\nExplain these answers\n\n\n\nThe test statistic, in this case the r value, is usually labelled as the estimate.\nIf Y increases as X increases then the relationship is positive. If Y increases as X decreases then the relationship is negative. If there is no change in Y as X changes then there is no relationship\nDepending on the field most correlation values greater than .5 would be strong; .3 to .5 as medium, and .1 to .3 as small.\nThe field standard says less than .05 is significant and our p-value is less than .05.\nThe alternative hypothesis can only be accepted or rejected, never proven. In this case, our results matched our alternative hypothesis and therefore it is accepted. Remember that the null hypothesis on the other hand can only be rejected or retained.\n\n\n\n\n8.5.0.2 Activity 7: Write-up\nNow we have interpreted the output we would want to write it up. Copy and paste the below exactly into white space in your R Markdown document and then knit the file.\n\nAs shown in Figure 7.5, there appeared to be a positive relationship between Reading Ability (M = `r round(pluck(descriptives$Abil_mean),2)`, SD = `r round(pluck(descriptives$Abil_SD),2)`) and IQ (M = `r round(pluck(descriptives$IQ_mean),2)`, SD = `r round(pluck(descriptives$IQ_SD),2)`), in line with the alternative hypothesis. A Pearson correlation found a significant, medium positive correlation between the two variables (r (`r results$df_error`) = `r round(results$r, 2)`, *p* = `r round(results$p, 3)`) and the alternative hypothesis is therefore accepted. \n\nWhen you knit the code, assuming you have done all of the above tasks correctly, the code you pasted will transform into a readable passage as follows:\nAs shown in Figure 7.5, there appeared to be a positive relationship between Reading Ability (M = 55.12, SD = 6.08) and IQ (M = 100.04, SD = 9.04), in line with the alternative hypothesis. A Pearson correlation found a significant, medium positive correlation between the two variables (r (23) = 0.45, p = 0.024) and the alternative hypothesis is therefore accepted.\nSo you get a fairly ok start of a write-up. It isn’t perfect but it is a good start. For instance, the r-value should not have the first 0 and just be r = .xx. Likewise, the p-value should not have the first 0 either. So you will always have to do a bit of tidying up.\nNote: Remember that a relationship is said to be significant if the p-value of the relationship is lower than the accepted level (normally called alphaThe threshold chosen in Neyman-Pearson hypothesis testing to distinguish test results that lead to the decision to reject the null hypothesis, or not, based on the desired upper bound of the Type 1 error rate. An alpha level of 5% it most commonly used, but other alpha levels can be used as long as they are determined and preregistered by the researcher before the data is analyzed. and set at \\(\\alpha = .05\\)). Alternatively, a relationship that has a p-value higher than the accepted level is said to be non significant\nBut why two approaches\nThe reason that we have shown you two methods of performing correlations is because of the way each outputs the results. correlation() produces a tibble which means it is very easy to work with and pull out values or join to another table as needed because it is already in tidyverse format. cor.test() on the other hand produces a list type object, which is a harder to work with. However, the output of cor.test() also happens to work with functions from the report package, report() and report_table() that give you an automatic report of the analyses. For example, report() presents a fixed write-up of the correlation with all the available information. For correlations, this is perhaps less than useful, however, for more complex statistics this reporting function can really help when learning about data and output, and so we’re introducing it now. report() doesn’t currently work with the output of correlation() which is why we showed you both ways. Run the below in your console window and you will see what we mean - you will probably get an error.\n\nreport(results2)\n\nNote: The write-up that comes out of report should not be considered as something to copy and paste into a report. It is a means of just obtaining an overview quickly to help you confirm your own thinking. There are issues again with the presentation of numbers and writing, and additional info that isn’t needed. Basically, use these functions and approaches to start you off in your writing, but not as your write-up."
  },
  {
    "objectID": "09-correlation.html#multiple-correlations",
    "href": "09-correlation.html#multiple-correlations",
    "title": "\n8  Correlations\n",
    "section": "\n8.6 Multiple Correlations",
    "text": "8.6 Multiple Correlations\nFinally, to round off this chapter, we want to briefly show you about running multiple correlations at one. Above we ran one correlation. However, when you have lots of variables in a dataset, to get a quick overview of patterns, you might want to run all the correlations at the same time or create a matrix of scatterplots at the one time. You can do this with functions from the psych and correlation packages (cor.test() only works for one correlation at a time). We will use the Miller and Haden data here again which you should still have in a tibble called mh.\n\n8.6.0.1 Activity 8: Scatterplot matrix\n\nIn a new code chunk, type and run the following code. The pairs.panels()) function comes from the psych library and creates a matrix of scatterplots, with the histograms, and correlation coefficients which you can then use to give you an overview of all the relationships at the one time. So it is useful for checking assumptions in one place.\n\n\npairs.panels(mh)\n\n\n\nScatterplot matrix\n\n\n\nNotice something wrong? pairs.panels() will create plots for all variables in your data (as will correlation() below). This means that it has correlated the Participant ID number as well, which is totally meaningless.\nInstead, we can use pipes to help us out here. The code below:\n\nTakes the dataset mh and then;\nUses select() to get rid of the Participant column and then;\nPipes the remaining data into the pairs.panels() function\nThe additional arguments:\n\n\nellipses = FALSE turns off the correlation ellipses,\n\nlm = TRUE use a linear line of best fit,\n`method = “pearson”, specifies a Pearson correlation.\n\n\n\nThere are additional arguments to adjust the plot pairs.panel creates that you can look up in the help documentation if you are interested.\n\nmh %&gt;%\n  select(-Participant) %&gt;%\n  pairs.panels(ellipses = FALSE, \n               lm = TRUE, \n               method = \"pearson\")\n\nWhich produces:\n\n\n\n\nAdjusted scatterplot matrix\n\n\n\n\n8.6.0.2 Activity 9: Running multiple correlations\nTo perform multiple correlations in one go, we will again use the correlation() function. package. Rather than specifying two variables to correlation, you can also provide a data frame that has multiple variables and it will run all possible correlations between the variables. Similar to above, we want to remove the Participant column before we do this.\n\nmethod controls which correlation is computed, the default is pearson but if you needed to run the non-parametric version you could change this to spearman.\n\np_adjust is the reason we are using the correlation package. In the lectures we discussed the problem of multiple comparisons - the idea that if you run lots and lots of tests your false positive rate will increase and the probability of finding a significant result increase.\n\nThis argument applies a correction to the p-value that adjusts for the number of correlations you have performed. There are several different methods which you can look up in the help documentation, but here we are setting bonferroni. The default setting is actually the less conservative analysis Holm-Bonferroni and you can read about why some might chose that instead in the help function by typing ?correlation in the console window.\n\n\nNote: Because you’re running multiple correlations and some may be positive and some may be negative, there is no option to specify a one or two-tailed test.\nRun the below code to calculate then view the correlation results\n\n\ncorr_results &lt;- mh %&gt;%\n  select(-Participant) %&gt;%\n  correlation(method = \"pearson\", \n              p_adjust = \"bonferroni\")\n\ncorr_results\n\nWhich produces the following output:\n\nknitr::kable(corr_results)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\nCI\nCI_low\nCI_high\nt\ndf_error\np\nMethod\nn_Obs\n\n\n\nAbil\nIQ\n0.4511699\n0.95\n0.0681965\n0.7182564\n2.4245212\n23\n0.1415557\nPearson correlation\n25\n\n\nAbil\nHome\n0.7443192\n0.95\n0.4946735\n0.8804938\n5.3451643\n23\n0.0001194\nPearson correlation\n25\n\n\nAbil\nTV\n-0.2881974\n0.95\n-0.6134691\n0.1206755\n-1.4433874\n23\n0.9743671\nPearson correlation\n25\n\n\nIQ\nHome\n0.2016786\n0.95\n-0.2102033\n0.5527604\n0.9875083\n23\n1.0000000\nPearson correlation\n25\n\n\nIQ\nTV\n0.2455425\n0.95\n-0.1656610\n0.5840118\n1.2147699\n23\n1.0000000\nPearson correlation\n25\n\n\nHome\nTV\n-0.6476572\n0.95\n-0.8303052\n-0.3393758\n-4.0765523\n23\n0.0027905\nPearson correlation\n25\n\n\n\n\n\ncorr_results is a tibble that lists the results of each correlation with its corresponding statistics. Look through the table and then answer the following questions:\n\nIs the correlation between Abil and Home positive or negative? \nPositive\nNegative\n\nThis means that as Abil scores increase, Home scores will \nIncrease\nDecrease\n\nWhat is the strongest positive correlation? \nAbil * IQ\nAbil * Home\nAbil * TV\n\nWhat is the strongest negative correlation? \nAbil * TV\nIQ * TV\nHome * TV\n\nIs the correlation between Abil and IQ significant? \nYes\nNo\n\nIs the correlation between Abil and Home significant? \nYes\nNo\n\nHow would you describe the strength of the correlation between Home and TV? \nWeak\nMedium\nStrong\n\nThink back to the lecture. Why are we not calculating an effect size?\n\n\n\nExplain these answers\n\n\n\nNegative correlations are denoted by a negative r value.\n\nPositive correlations mean that as one score goes up so does the other, negative correlations mean that as one score goes up the other goes down.\n3 & 4. Remember that correlations take values from -1 - 1 and that the nearer to one in either direction the stronger the correlation (i.e., an r value of 0 would demonstrate a lack of any relationship.\n5 & 6. The traditional cut-off for significance is .05. Anything below .05 is considered significant. Be careful to pay attention to decimal places.\n\nCohen’s guidelines recommend weak = 1. - .3, medium = .3 - .5, strong &gt; .5.\n\nBecause r is an effect size.\n\n\n\n\n\nNice work! So it can be really easy to run a lot of correlations at once. However, you need to remember about what is appropriate in research. You should not just wildly run every correlation you can and then write up your favourite. PreRegistration of ideas, or Registered Reports, helps reduce Questionable Research Practices, and this is just another example of where setting out in advance, what you plan to do, will prevent bad practice!"
  },
  {
    "objectID": "09-correlation.html#corr-fin",
    "href": "09-correlation.html#corr-fin",
    "title": "\n8  Correlations\n",
    "section": "\n8.7 Finished!",
    "text": "8.7 Finished!\nExcellent work today! You can now add running, interpreting and writing up correlations to the list of knowledge and skills in your research methods toolbox. Remember that actually a lot of the work is in the preparation of the data and really running the correlation is just one more function. It might be worthwhile repeating the first few activities with two other variables to test your understanding. If you have any questions, please post them on Teams."
  },
  {
    "objectID": "09-correlation.html#test-yourself",
    "href": "09-correlation.html#test-yourself",
    "title": "\n8  Correlations\n",
    "section": "\n8.8 Test Yourself",
    "text": "8.8 Test Yourself\nLook at this code and answer the following questions:\n\nresults &lt;- correlation(data = mh, \n                       select = \"IQ\", \n                       select2 = \"Home\",  \n                       method = \"pearson\", \n                       alternative = \"two.sided\")\n\n\nWhat would this analysis show?\n\nthe relationship between IQ and the time spent watching TV at homethe effect of IQ on time spent reading at Homethe relationship between IQ and the time spent reading at homethe relationship between IQ and Reading Ability\n\n\nWhat type of correlation analysis is it?\n\ntwo-tailed spearman analysisone-tailed pearson analysistwo-tailed pearson analysisone-tailed spearman analysis\n\n\n\nNow try running the code and then answering the following questions.\n\nTo three decimal places, what is the r-value of the correlation between IQ and the time spent reading at Home?\n\n0.3340.5530.9880.202\n\n\nTo three decimal places, what is the p-value of the correlation between IQ and the time spent reading at Home?\n\n0.9880.3340.5530.202\n\n\nWhat is the degrees of freedom of the correlation between IQ and the time spent reading at Home?\n\n23250.5530.988\n\n\n\n\n\nExplain these answers\n\n\nThis analysis is a two-tailed pearson correlation looking at the relationship between IQ and the amount of time spent reading at home. You can tell this from the two variables in the code being IQ and Home, and the code stating pearson, and two-sided (another name for two-tailed). If you run the analysis you will find that the result would be r(23) = .202, p = .334."
  },
  {
    "objectID": "09-correlation.html#corr-sols",
    "href": "09-correlation.html#corr-sols",
    "title": "\n8  Correlations\n",
    "section": "\n8.9 Activity solutions",
    "text": "8.9 Activity solutions\nBelow you will find the solutions to the above questions. Only look at them after giving the questions a good try and trying to find help on Google or Teams about any issues.\n\n8.9.0.1 Activity 1\n\nlibrary(car)\nlibrary(correlation)\nlibrary(report)\nlibrary(psych)\nlibrary(tidyverse)\nmh &lt;- read_csv(\"MillerHadenData.csv\")\n\n\n8.9.0.2 Activity 3\nThe histogram of IQ\n\nggplot(data = mh, aes(x = IQ)) +\n  geom_histogram()\n\nThe qqPlot of IQ\n\nqqPlot(x = mh$IQ)\n\n\n\n\n\n\n\n[1]  3 14\n\n\nThe scatterplot\n\nggplot(data = mh, aes(x = Abil, y = IQ)) +\n  geom_point()+\n  geom_smooth(method = lm)+\n  scale_x_continuous(name = \"Reading Ability\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n8.9.0.3 Activity 4\nThe scatterplot\nBased on the scatterplot we might suggest that as reading ability scores increase, IQ scores also increase and as such it would appear that our data is inline with our hypothesis that the two variables are positively correlated. This appears to be a medium strength relationship.\nThe means and standard deviations\n\ndescriptives &lt;- summarise(mh, \n                          Abil_mean = mean(Abil),\n                          Abil_SD = sd(Abil),\n                          IQ_mean = mean(IQ),\n                          IQ_SD = sd(IQ))\n\ndescriptives\n\n\n\n\nAbil_mean\nAbil_SD\nIQ_mean\nIQ_SD\n\n\n55.12\n6.084954\n100.04\n9.043782\n\n\n\n\n\n\n8.9.0.4 Activity 5\nThe correlation using correlation()\n\nresults &lt;- correlation(data = mh, \n                       select = \"IQ\", \n                       select2 = \"Abil\",  \n                       method = \"pearson\", \n                       alternative = \"two.sided\")\n\nresults\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\nCI\nCI_low\nCI_high\nt\ndf_error\np\nMethod\nn_Obs\n\n\nIQ\nAbil\n0.4511699\n0.95\n0.0681965\n0.7182564\n2.424521\n23\n0.0235926\nPearson correlation\n25"
  },
  {
    "objectID": "09-correlation.html#words-from-this-chapter",
    "href": "09-correlation.html#words-from-this-chapter",
    "title": "\n8  Correlations\n",
    "section": "\n8.10 Words from this Chapter",
    "text": "8.10 Words from this Chapter\nBelow you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the PsyTeachR Glossary. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter.\n\n\n\n\nterm\ndefinition\n\n\n\nalpha\nThe threshold chosen in Neyman-Pearson hypothesis testing to distinguish test results that lead to the decision to reject the null hypothesis, or not, based on the desired upper bound of the Type 1 error rate. An alpha level of 5% it most commonly used, but other alpha levels can be used as long as they are determined and preregistered by the researcher before the data is analyzed.\n\n\nalternative hypothesis\n\n\n\nassumptions\n\n\n\nbonferroni\n\n\n\nconservative analysis\n\n\n\ncorrelation\n\n\n\nHolm-Bonferroni\n\n\n\nhomoscedasticity\n\n\n\nhypothesis\n\n\n\ninferential\n\n\n\nline of best fit\n\n\n\nmultiple comparisons\n\n\n\nnegative relationship\n\n\n\nnon significant\n\n\n\nnormal distribution\n\n\n\nnull hypothesis\n\n\n\nPearson\na standardised measure of the linear relationship between two variables\n\n\npositive relationship\n\n\n\nQ-Q plot\n\n\n\nresidual\n\n\n\nscatterplot\n\n\n\nsignificant\n\n\n\nSpearman\na standardised measure of the relationship between two variables that does not assume a linear relationship. Note that the relationship can be linear but it is not required.\n\n\nvariable\n\n\n\n\n\n\nThat is end of this chapter. Be sure to look again at anything you were unsure about and make some notes to help develop your own knowledge and skills. It would be good to write yourself some questions about what you are unsure of and see if you can answer them later or speak to someone about them. Good work today!"
  },
  {
    "objectID": "10-t-tests.html#between-subjects-t-tests-two-sample",
    "href": "10-t-tests.html#between-subjects-t-tests-two-sample",
    "title": "\n10  t-tests\n",
    "section": "\n10.1 Between-Subjects t-tests (two-sample)",
    "text": "10.1 Between-Subjects t-tests (two-sample)\nWe will begin by looking at the between-subjects t-test which is used for comparing the outcome in two groups of different people. Here we will be using data from Schroeder and Epley (2015) on the perception of people from their job applications. You can take a look at the Psychological Science article here, Schroeder, J. and Epley, N. (2015). The sound of intellect: Speech reveals a thoughtful mind, increasing a job candidate’s appeal. Psychological Science, 26, 277–891., if you like but it is not essential for completing the activities. The abstract from this article explains more about the different experiments conducted, and we will be specifically looking at the data set from Experiment 4, based on information from the Open Stats Lab. The abstract reads:\n\nA person’s mental capacities, such as intellect, cannot be observed directly and so are instead inferred from indirect cues. We predicted that a person’s intellect would be conveyed most strongly through a cue closely tied to actual thinking: his or her voice. Hypothetical employers (Experiments 1-3b) and professional recruiters (Experiment 4) watched, listened to, or read job candidates’ pitches about why they should be hired. These evaluators (the employers) rated a candidate as more competent, thoughtful, and intelligent when they heard a pitch rather than read it and, as a result, had a more favourable impression of the candidate and were more interested in hiring the candidate. Adding voice to written pitches, by having trained actors (Experiment 3a) or untrained adults (Experiment 3b) read them, produced the same results. Adding visual cues to audio pitches did not alter evaluations of the candidates. For conveying one’s intellect, it is important that one’s voice, quite literally, be heard.\n\nTo summarise, 39 professional recruiters from Fortune 500 companies evaluated job pitches of M.B.A. candidates from the University of Chicago Booth School of Business. The methods and results appear on pages 887-889 of the article if you want to look at them specifically for more details and the original data, in wide format, can be found at the Open Stats Lab website for later self-directed learning. Today however, we will be working with a modified version in “tidy” format which can be downloaded below and what we plan to do is reproduce the results from the article on Pg 887.\n\n10.1.1 Data and Descriptives\nAs always, the first activity is about getting ourselves ready to analyse the data so try out the steps and if you need help, consult the earlier chapters.\n\n10.1.1.1 Activity 1: Set-up\n\nOpen RStudio and set the working directory to your chapter folder. Ensure the environment is clear.\n\nIf you’re using the Rserver, avoid a number of issues by restarting the session - click Session - Restart R\n\n\n\nOpen a new R Markdown document and save it in your working directory. Call the file “ttests”.\n\nDownload evaluators.csv and ratings.csv and save them in your t-test folder. Make sure that you do not change the file names at all.\n\nIf you prefer you can download the data in a zip folder by clicking here\n\nRemember not to change the file names at all and that data.csv is not the same as data (1).csv.\n\n\nDelete the default R Markdown welcome text and insert a new code chunk that loads the following packages, in this specific order, using the library() function. Remember the solutions if needed.\n\nLoad the packages in this order, Hmisc, broom, car,effectsize, report, and tidyverse\n\nagain we have not used some of these packages so you will likely need to install some of them using install.packages(). Remember though that you should only do this on your own machine and only in the console window. If you are using the RServer you will not need to install them.\n\n\nFinally, load the data held in evaluators.csv as a tibble into an object named evaluators using read_csv().\n\nRemember to have a look at your data to help you understand the structure and the layout of the data. You can do this in whatever way you prefer.\nNow that we have our data, and have explored it, there is a few things we can do to make working with it a bit easier. If you look at the data, and in particular the sex column, you will see it is actually coded as numeric but we will want to treat it as categorical. Secondly, it can be tricky to work with 1s and 2s when you mean people, so we can “recode” the variables into labels that are easier to work with. That is what we will do here using a combination of mutate(), which we already know, and the recode() function from the dplyr package that is loaded in as part of the tidyverse, and the as.factor() function from base. Converting categorical data to factors will make it easier to work with in visualisations and analysis.\n\n10.1.1.2 Activity 2: Explore the dataset\nIn a new code chunk, copy the code below and see if you can follow it.\n\nFirst we use mutate() and recode() to recode sex into a new variable called sex_labels so that 1 = male and 2 = female.\n\nBe careful using recode() as there are multiple functions in different packages called with the same name so it is better to use the package::function() approach and specify dplyr::recode() to get the right one.\n\n\nThen we use mutate() and as.factor() to overwrite sex_labels and condition as factors.\n\n\nevaluators &lt;- evaluators %&gt;%\n  mutate(sex_labels = dplyr::recode(sex, \"1\" = \"male\", \"2\" = \"female\"),\n         sex_labels = as.factor(sex_labels),\n         condition = as.factor(condition))\n\nNow see if you can create a count of the different sex labels to answer the following question. One approach would be group_by() %&gt;% count() but what would you group by? Maybe store this tibble in an object called eval_counts.\n\nHow many participants were noted as being female: \n\nHow many participants were noted as being male: \n\nHow many data points are missing for sex? \n\n\n10.1.1.3 Activity 3: Ratings\nExcellent work. Our evaluator data is ready to work with and we are now going to calculate what is called an “overall intellect rating” given by each evaluator, calculated by averaging the ratings of competent, thoughtful and intelligent from each evaluator; held within ratings.csv. This overall rating will measure how intellectual the evaluators thought candidates were, depending on whether or not the evaluators read or listened to the candidates’ resume pitches. Note, however, we are not looking at ratings to individual candidates; we are looking at overall ratings for each evaluator. This is a bit confusing but makes sense if you stop to think about it a little. What we are interested in is how the medium they received the resume impacted their rating of the candidate. Once we have done that, we will then combine the overall intellect rating with the overall impression ratings and overall hire ratings for each evaluator, with the end goal of having a tibble called ratings2 - which has the following structure:\n\n\n\n\neval_id\nCategory\nRating\ncondition\nsex_labels\n\n\n\n1\nhire\n6.000\nlistened\nfemale\n\n\n1\nimpression\n7.000\nlistened\nfemale\n\n\n1\nintellect\n6.000\nlistened\nfemale\n\n\n2\nhire\n4.000\nlistened\nfemale\n\n\n2\nimpression\n4.667\nlistened\nfemale\n\n\n2\nintellect\n5.667\nlistened\nfemale\n\n\n\n\n\nThe following steps describe how to create the above tibble and it would be good practice to try this out yourself. Look at the table and think what do I need? The trick when doing data analysis and data wrangling is to first think about what you want to achieve - the end goal - and then think about what functions you need to use to get there. The solution is hidden just below the stpes of course if you want to look at it. Let’s look at the steps. Steps 1, 2 and 3 calculate the new overall intellect rating. Steps 4 and 5 combine this rating to all other information.\n\nLoad the data found in ratings.csv as a tibble into an object called ratings. (e.g. read the csv)\nfilter() only the relevant variables (thoughtful, competent, intelligent) into a new tibble stored in an objected called something useful (we will call ours iratings), and then calculate a mean Rating for each evaluator (e.g. group_by & summarise).\nAdd on a new column called Category where every entry is the word intellect. This tells us that every number in this tibble is an intellect rating. (e.g. mutate)\nNow create a new tibble called ratings2 and filter into it just the “impression” and “hire” ratings from the original ratings tibble.\nNext, bind this tibble with the tibble you created in step 3 to bring together the intellect, impression, and hire ratings, in ratings2. (e.g. bind_rows(object1, object2))\nJoin ratings2 with the evaluator tibble that we created in Task 1 (e.g. inner_join()). Keep only the necessary columns as shown above (e.g. select()) and arrange by Evaluator and Category (e.g. arrange()).\n\n\n\nOur approach to this\n\n\n# 1. load in the data\nratings &lt;- read_csv(\"book/ratings.csv\")\n\n# 2. first step: pull out the ratings associated with intellect\niratings &lt;- ratings %&gt;%\n  filter(Category %in% c(\"competent\", \"thoughtful\", \"intelligent\"))\n\n# second step: calculate means for each evaluator\nimeans &lt;- iratings %&gt;%\n  group_by(eval_id) %&gt;%\n  summarise(Rating = mean(Rating))\n\n# 3. add Category variable \n# this way we can combine with 'impression' and 'hire' into a single table, very useful!\nimeans2 &lt;- imeans %&gt;%\n  mutate(Category = \"intellect\")\n\n# 4., 5. & 6. combine into a single table\nratings2 &lt;- ratings %&gt;%\n  filter(Category %in% c(\"impression\", \"hire\")) %&gt;%\n  bind_rows(imeans2) %&gt;%\n  inner_join(evaluators, \"eval_id\") %&gt;%\n  select(-age, -sex) %&gt;%\n  arrange(eval_id, Category)\n\n\n\nFinally, calculate the n, mean and SD for each condition and category to help with reporting the descriptive statistics.\n\n\ngroup_means &lt;- ratings2 %&gt;%\n  group_by(condition, Category) %&gt;%\n  summarise(n = n(), m = mean(Rating), sd = sd(Rating))\n\n`summarise()` has grouped output by 'condition'. You can override using the\n`.groups` argument.\n\n\n\n10.1.2 Visualising two groups\nBrilliant! Now that we have our data in a workable fashion, we are going to start looking at some visualisations and making figures. You should always visualise your data before you run a statistical analysis. Visualisations serve as part of the descriptive measures and they help you interpret the results of the test but they also give you an understanding of the spread of your data as part of the test assumptions. For data with a categorical IV, we are going to look at using the violin-boxplots that we saw in the introduction to visualisation chapter. In the past people would have tended to use barplots but as Newman and Scholl (2012) point out, barplots are misleading to viewers about how the underlying data actually looks. You can read that paper if you like, for more info, but hopefully by the end of this section you will see why violin-boxplots are more informative.\n\n10.1.2.1 Activity 4: Visualisation\nWe will visualise the intellect ratings for the listened and the read conditions. The code we will use to create our figure is as follows with the explanation below. Put this code in a new code chunk and run it.\n\nratings2 %&gt;%\n  filter(Category == \"intellect\") %&gt;%\nggplot(aes(x = condition, y = Rating)) +\n  geom_violin(trim = TRUE) +\n  geom_boxplot(aes(fill = condition), width = .2, show.legend = FALSE) + \n  stat_summary(geom = \"pointrange\", fun.data = \"mean_cl_normal\")  +\n  labs(x = \"Condition\", y = \"Rating Score\") +\n  geom_jitter(height = .1, width = .2)\n\nThe first part of the code uses a pipe to filter the data to just the intellect rating:\n\n\nratings %&gt;% filter(Category == \"intellect) is the same as filter(ratings, Category == \"intellect\")\n\nthis code also reflects nicely the difference between pipes (%&gt;%) used in wrangling and the + used in the visualisations with ggplot. Notice that we switch from pipes to plus when we start adding layers to our visualisation.\n\nThe main parts of the code to create the violin-boxplot above are:\n\nggplot() which creates our base layer and sets our data and our x and y axes.\n\ngeom_violin() which creates the density plot. The reason it is called a violin plot is because if your data are normally distributed it should look something like a violin.\n\n\ngeom_boxplot() which creates the boxplot, showing the median and inter-quartile range (see here if you would like more information). The boxplot can also give you a good idea if the data are skewed - the median line should be in the middle of the box. The more the median is moved towards one of th extremities of the box, the more your data is likely to be skewed.\n\n\ngeom_jitter() can be used to show individual data points in your dataset and you can change the width and height of the jitter. Note that this uses a randomised method to display the points so you will get a different output each time you run it.\nAnd finally, we will use stat_summary() for displaying the mean and confidence intervals. Within this function, fun.data specifies the a summary function that gives us the summary of the data we want to plot, in this case, mean_cl_normal which will calculate the mean plus the upper and lower confidence interval limits. You could also specify mean_se here if you wanted standard error. Finally, geom specifies what shape or plot we want to use to display the summary, in this case we want a pointrange (literally a point (the mean) with a range (the CI)).\n\nThe figure will look like this:\n\n\n\n\nViolin-boxplot of the evaluator data\n\n\n\nAn alternative version would be this shown below. Perhaps compare the two codes and see if you can see what makes the differences:\n\nratings2 %&gt;%\n  filter(Category == \"intellect\") %&gt;%\nggplot(aes(x = condition, y = Rating)) +\n  geom_violin(trim = FALSE) +\n  geom_boxplot(aes(fill = condition), width = .2, show.legend = FALSE) + \n  stat_summary(geom = \"pointrange\", fun.data = \"mean_cl_normal\") +\n  labs(x = \"Condition\", y = \"Rating Score\")\n\n\n\nViolin-boxplot of the evaluator data\n\n\n\nTry to answer the following question:\n\nIn which condition did the evaluators give the higher ratings overall? \nlistened\nread\n\nWould the descriptives (means, sds, figure) be inline with the hypothesis that evaluators favour resumes they have listened to more than resumes they have read? \nyes\nno\n\n\nNice and informative figure huh? It gives a good representation of the data in the two conditions, clearly showing the spread and the centre points. If you compare this to Figure 7 in the original paper you see the difference. We actually get much more information with our approach. We even get a sense that maybe the data is questionable on whether it is skewed or not, but more on that below.\nThe code is really useful as well so you know it is here if you want to use it again. But maybe have a play with the code to try out things to see what happens. For instance:\n\nTry setting trim = TRUE, show.legend = FALSE, and/or altering the value of width to see what these arguments do.\nchange the Category == \"intellect\" to Category == \"hire\" or Category == \"impression\" to create visualisations of the other conditions.\n\n10.1.3 Assumptions\nGreat. We have visualised our data as well and we have been able to make some descriptive analysis about what is going on. Now we want to get ready to run the actual analysis. But one final thing we are going to decide is which t-test? But hang on you say, didn’t we decide that? We are going to run a between-subjects t-test! Right? Yes! But, and you know what we are about to say, there is more than one between-subjects t-test you can run. The two common ones are:\n\nStudent’s between-subjects t-test\nWelch’s between-subjects t-test\n\nWe are going to recommend that, at least when doing the analysis by code, you should use Welch’s between-subjects t-test for the reasons explained in this paper by Delarce et al,m (2017) Now you don’t have to read that paper but effectively, the Welch’s between-subjects t-test is better at maintaining the false positive rate of your test (\\(\\alpha\\), usually set at \\(\\alpha\\) = .05) at the requested level. So we will show you how to run a Welch’s t-test here.\nThe assumptions for a Welch’s between-subjects t-test are:\n\nThe data are continuous, i.e. interval/ratio\nThe data are independent\nThe residuals are normally distributed for each group\n\nWe know that 1 and 2 are true from the design of the experiment, the measures used, and by looking at the data. To test assumption 3, we can create a Q-Q plots of the residuals. For a between-subject t-test the residuals are the difference between the mean of each group and each data point. E.g., if the mean of group A is 10 and a participant in group A scores 12, the residual for that participant is 2.\n\nThinking back to your lectures, if you ran a Student’s t-test instead of a Welch t-test, what would the 4th assumption be? \nHomogeneity of variance\nHomoscedascity\nNominal data\n\n\n\n10.1.3.1 Activity 5: Assumptions\n\nRun the below code to calculate then plot the residuals for the “listened” condition on “intellect” ratings.\n\n\nlistened_intellect_residuals &lt;- ratings2 %&gt;%\n  filter(condition == \"listened\", Category == \"intellect\") %&gt;%\n  mutate(group_resid = Rating - mean(Rating)) %&gt;%\n  select(group_resid)\n\nqqPlot(listened_intellect_residuals$group_resid)\n\n\nRun the below code to calculate then plot the residuals for the “read” condition on “intellect” ratings.\n\n\nread_intellect_residuals &lt;- ratings2 %&gt;%\n  filter(condition == \"read\", Category == \"intellect\") %&gt;%\n  mutate(group_resid = Rating - mean(Rating)) %&gt;%\n  select(group_resid)\n\nqqPlot(read_intellect_residuals$group_resid)\n\nIf we then look at our plots we get something that looks like this for the listened condition:\n\n\n\n\nResidual plots of listened condition. Each circle represents an indivudal rater. If data is normally distributed then it should fall close to or on the diagonal line.\n\n\n\n[1] 6 8\n\n\nAnd something like this for the read condition.\n\n\n\n\nResidual plots of read intellect condition. Each circle represents an indivudal rater. If data is normally distributed then it should fall close to or on the diagonal line.\n\n\n\n[1] 11 18\n\n\nWhat you are looking for is for the data to fall close to the diagonal line. Looking at the plots, maybe we could suggest that the “listened” condition is not so great as there is some data points moving away from the line at the far ends. The “read” condition seems a bit better, at least subjectively! There will always be some deviation from the diagonal line but at perhaps most of the data in both plots is relatively close to their respective diagonal lines.\nBut in addition to the Q-Q plots we can also run a test on the residuals known as the Shapiro-Wilk test. The Shapiro-Wilk’s test has the alternative hypothesis that the data is significantly different from normal. As such, if you find a significant result using the test then the interpretation is that your data is not normal. If you find a non-significant finding then the interpretation is that your data is not significantly different from normal. One technical point is that the test doesn’t actually say your data is normal either but just that it is not significantly different from normal. Again, remember that assumptions have a degree of subjectivity to them. We use the shapiro.wilk() function from the base package to run the Shapiro-Wilk’s test.\n\nIn a new code chunk, run both lines of code below and look at their output.\n\n\nshapiro.test(x = listened_intellect_residuals$group_resid)\nshapiro.test(x = read_intellect_residuals$group_resid)\n\nTry to answer the following questions:\n\nAccording to the Shapiro-Wilk’s test, is the data normally distributed for the listened condition? \nYes\nNo\n\nAccording to the Shapiro-Wilk’s test, is the data normally distributed for the read condition? \nYes\nNo\n\n\nSo as you can see, the p-value for the listened condition is p = .174, and the p-value for the read condition is p = .445. So here we are in an interesting position that often happens. The figures for “listened” is a bit unclear, but the figure for “read” looks ok and both tests show a non-significant difference from normality. What do we do? Well we combine our knowledge of our data to make a reasoned decision. In this situation the majority of our information is pointing to the data being normal. However, there are known issues with the Shapiro-Wilks test when there are small sample sizes so we must always take results like this with some caution. It is never a good idea to run a small sample such as this and so in reality we might want to design a study that has larger sample groups. All that said, here it would not be unreasonable to take the assumption of normality as being held.\n\n\n\nFor info though, here are some options if you are convinced your data is nor normal.\n\n\n\nTransform your data to try and normalise the distribution. We won’t cover this but if you’d like to know more, this page is a good start. Not usually recommended these days but some still use it.\n\n\nUse a non-parametric test. The non-parametric equivalent of the independent t-test is the Mann-Whitney and the equivalent of the paired-samples t-test is the Wilcoxon signed-ranks test. Though more modern permutation tests are better. Again we won’t cover these here but useful to know if you read them in a paper.\n\n\nDo nothing. Delacre, Lakens & Leys, 2017 argue that with a large enough sample (&gt;30), the Welch test is robust to deviations from assumptions. With very large samples normality is even less of an issue, so design studies with large samples.\n\n\n\n\n\n10.1.4 Inferential analysis\nNow that we have checked our assumptions and our data seems to fit our Welch’s t-test we can go ahead and run the test. We are going to conduct t-tests for the Intellect, Hire and Impression ratings separately; each time comparing evaluators’ overall ratings for the listened group versus overall ratings for the read group to see if there was a significant difference between the two conditions: i.e. did the evaluators who listened to pitches give a significant higher or lower rating than evaluators that read pitches.\n\n10.1.4.1 Activity 6: Running the t-test\n\nFirst, create separate objects for the intellect, hire, and impression data using filter(). We have completed intellect object for you so you should replace the NULLs in the below code to create one for hire and impression.\n\n\nintellect &lt;- filter(ratings2, Category == \"intellect\")\nhire &lt;- NULL\nimpression &lt;- NULL \n\nAnd we are finally ready to run the t-test. It is funny right, as you may have realised by now, most of the work in analysis involves the set-up and getting the data ready, running the tests is generally just one more function. To conduct the t-test we will use t.test() function from base which takes the following format called the formula syntax:\n\nt.test(DV_column_name ~ IV_column_name, \n       paired = FALSE,\n       data = my_object)\n\n\n\n~ is called a tilde. It can be read as ‘by’ as in “analyse the DV by the IV”.\n\nThe variable on the left of the tilde is the dependent or outcome variable, DV_column_name.\nThe variable(s) on the right of the tilde is the independent or predictor variable, IV_column_name.\n\nand paired = FALSE indicates that we do not want to run a paired-samples test and that our data is from a between-subjects design.\n\nSo let’s run our first test:\n\nIn a new code chunk, type and run the below code, and thenview the output by typing intellect_t in the console.\n\n\nintellect_t &lt;- t.test(Rating ~ condition, \n                      paired = FALSE, \n                      data = intellect,\n                      alternative = \"two.sided\")\n\nSimilar to when we used cor.test() for correlations, the output of t.test() is a list type object which can make it harder to work with. This time, we are going to show you how to use the function tidy() from the broom package to convert the output to a tidyverse format.\n\nRun the below code. You can read it as “take what is in the object intellect_t and try to tidy it into a tibble”.\n\nView the object by clicking on results_intellect in the environment.\n\n\nresults_intellect &lt;- intellect_t %&gt;%\n  tidy()\n\nAs you will see, results_intellect is now in a nice tibble format that makes it easy to extract individual values. It is worth looking at the values with the below explanations:\n\n\nestimate is the difference between the two means (alphabetically entered as mean 1 minus mean 2)\n\nestimate1 is the mean of group 1\n\nestimate2 is the mean of group 2\n\n\nstatistic is the t-statistic\n\n\np.value is the p-value\n\n\nparameter is the degrees of freedom\n\n\ncon.low and conf.high are the confidence interval of the estimate\n\n\nmethod is the type of test, Welch’s, Student’s, paired, or one-sample\n\nalternative is whether the test was one or two-tailed\n\nAnd now that we know how to run the test and tidy it, try the below:\n\nComplete the code below in a new code chunk by replacing the NULLs to run the t-tests for the hire and impression ratings, don’t tidy them yet.\n\n\nhire_t &lt;- NULL\nimpression_t &lt;- NULL\n\n\nAnd now tidy the data into the respective objects - hire_t into results_hire, etc.\n\n\nresults_hire &lt;- NULL\nresults_impression &lt;- NULL\n\nBe sure to look at each of your tests and see what the outcome of each was. To make that easier, we are going join all the results of the t-tests together using bind_rows() - which we can do because all the tibbles have the same column names after we passed them through tidy().\n\nCopy and run the below code. First, it specifies all of the individual tibbles you want to join and gives them a label (hire, impression, intellect), and then you specify what the ID column should be named (test).\n\n\nresults &lt;- bind_rows(hire = results_hire, \n                     impression = results_impression, \n                     intellect = results_intellect, \n                     .id = \"test\")\n\nWhich produces the below:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntest\nestimate\nestimate1\nestimate2\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n\nhire\n1.825397\n4.714286\n2.888889\n2.639949\n0.0120842\n36.85591\n0.4241979\n3.226596\nWelch Two Sample t-test\ntwo.sided\n\n\nimpression\n1.894333\n5.968333\n4.074000\n2.817175\n0.0080329\n33.80061\n0.5275086\n3.261158\nWelch Two Sample t-test\ntwo.sided\n\n\nintellect\n1.986722\n5.635000\n3.648278\n3.478555\n0.0014210\n33.43481\n0.8253146\n3.148130\nWelch Two Sample t-test\ntwo.sided\n\n\n\n\n\nAnd looking along the line at the p-values we might have some significant differences. However, we have to remember to consider multiple comparisons.\n\n10.1.4.2 Activity 7: Correcting for multiple comparisons\nBecause we have run three t-tests, we are actually increasing our false positive rate due to what is called familywise error - essentially, instead of a false positive rate of .05, we would have a false positive rate of 1-(1-.05)^3 = 0.142625, where the “3” in the formula is the number of tests we ran. To correct for this we can apply the multiple comparison correction just like we did with correlations when we ran a lot of correlations. So, we’re going to add on a column to our results tibble that shows the adjusted p-values using p.adj() and mutate().\n\nType and run the below code in a new code chunk and have a look at the output.\n\ninside the p.adjust(), p.value says what column the p-values are in, and bonferroni says what adjustment to use.\n\n\n\n\nresults_adj &lt;- results %&gt;%\n  mutate(p.adjusted = p.adjust(p = p.value, \n                               method = \"bonferroni\"))\n\nLooking at the adjusted p-values, try to answer the following questions:\n\nListened is significantly more preferred in the hire condition after adjusting for multiple comparisons? \nTRUE\nFALSE\n\nListened is significantly more preferred in the impression condition after adjusting for multiple comparisons? \nTRUE\nFALSE\n\nListened is significantly more preferred in the intellect condition after adjusting for multiple comparisons? \nTRUE\nFALSE\n\n\n10.1.5 Effect Size\nAs you can see, even after correcting for multiple comparisons, our effects are still significant and we have maintained our false positive rate. But one more thing we can add is the effect size. Remember that some effects are significant and large, some are significant and medium, and some are significant and small. The effect size tells us the magnitude of the effect size in a way we can compare across studies - it is said to be a standardised - and the common effect size for a t-test is called Cohen’s D.\n\n10.1.5.1 Activity 8: Effect size\nWhilst Cohen’s D is relatively straightforward by hand, here we will use the function cohens_d() from the effectsize package. The code is similar to the syntax for t.test().\n\nThe code to run the Cohen’s D for intellect has been completed below.\n\nThe first argument should specify the formula, using the same syntax as t.test(), that is dv ~ iv.\n\npooled_sd should be FALSE if you ran a Welch test where the variances are not assumed to be equal and TRUE if you ran a regular Student’s t-test.\n\n\nRun and complete the code below by replacing the NULLs to calculate the effect sizes for hire and impression\n\n\nintellect_d &lt;- cohens_d(Rating ~ condition, \n                      pooled_sd = FALSE, \n                      data = intellect)\nhire_d &lt;- NULL\nimpression_d &lt;- NULL\n\n\n10.1.6 Interpretation\nGreat Work! But let’s take a second to recap on our understanding of the data.\n\n10.1.6.1 Activity 9: Interpreting the results\n\n\nWere your results for hire significant? Enter the mean estimates and t-test results (means and t-value to 2 decimal places, p-value to 3 decimal places). Use the adjusted p-values:\n\nMean estimate1 (listened condition) = \nMean estimate2 (read condition) = \nt() = , p = \n\n\n\nWere your results for impression significant? Enter the mean estimates and t-test results (means and t-value to 2 decimal places, p-value to 3 decimal places):\n\nMeanestimate1 (listened condition) = \nMean estimate2 (read condition) = \nt() = , p = \n\n\nAccording to Cohen’s (1988) guidelines, the effect sizes for all three tests are \nSmall\nMedium\nLarge\n\n10.1.7 Write-Up\nAnd then finally on the between-subjects t-test, we should look at the write up.\n\n10.1.7.1 Activity 10: Write-up\nIf you refer back to the original paper on pg 887, you can see, for example, that the authors wrote:\nIn particular, the recruiters believed that the job candidates had greater intellect—were more competent, thoughtful, and intelligent—when they listened to pitches (M = 5.63, SD = 1.61) than when they read pitches (M = 3.65, SD = 1.91), t(37) = 3.53, p &lt; .01, 95% CI of the difference = [0.85, 3.13], d = 1.16.\nIf we were to compare our findings, we would have something like the below:\nA bonferroni-corrected Welch t-test found that recruiters rated job candidates as more intellectual when they listened to resumes (M = 5.64, SD = 1.61) than when they read resumes (M = 3.65, SD = 1.91), t(33.43) = 3.48, p = 0.004, 95% CI of the difference = [0.83, 3.15], d = 1.12.\nYou can create this same paragraph, using code, by copying and pasting the below exactly into white space in your R Markdown document and then knitting the file.\n\nA bonferroni-corrected Welch t-test found that recruiters rated job candidates as more intellectual when they listened to resumes (M = `r results_intellect$estimate1%&gt;% round(2)`, SD = `r round(group_means$sd[3], 2)`) than when they read resumes (M = `r results_intellect$estimate2%&gt;% round(2)`, SD = `r round(group_means$sd[6], 2)`), t(`r round(results_intellect$parameter, 2)`) = `r round(results_adj$statistic[3],2)`, p = `r results_adj$p.adjusted[3] %&gt;% round(3)`, 95% CI of the difference = [`r round(results_intellect$conf.low, 2)`, `r round(results_intellect$conf.high, 2)`], d = `r round(intellect_d$Cohens_d,2)`. \n\nNote that we haven’t replicated the analysis exactly - the authors of this paper conducted Student’s t-test whilst we have conducted Welch tests and we’ve also applied a multiple comparison correction. But you can look at the two examples and see the difference. It would also be worthwhile trying your own write-up of the two remaining conditions before moving on to within-subjects t-tests."
  },
  {
    "objectID": "10-t-tests.html#within-subjects-paired-samples",
    "href": "10-t-tests.html#within-subjects-paired-samples",
    "title": "\n10  t-tests\n",
    "section": "\n10.2 Within-subjects (paired-samples)",
    "text": "10.2 Within-subjects (paired-samples)\nFor the final activity we will run a paired-samples t-test for a within-subject design but we will go through this one more quickly and just point out the differences to the above. For this example we will again draw from the Open Stats Lab and look at data from the data in Mehr, S. A., Song. L. A., & Spelke, E. S. (2016). For 5-month-old infants, melodies are social. Psychological Science, 27, 486-501.{target = “_blank”}.\nThe premis of the paper is that parents often sing to their children and, even as infants, children listen to and look at their parents while they are sung to. The authors sought to explore the psychological function that music has for parents and infants, by examining the research question that particular melodies may convey important social information to infants. More specifically, that common knowledge of songs and melodies convey information about social affiliation. The authors argue that melodies are shared within social groups. Whereas children growing up in one culture may be exposed to certain songs as infants (e.g., “Rock-a-bye Baby”), children growing up in other cultures (or even other groups within a culture) may be exposed to different songs. Thus, when a novel person (someone who the infant has never seen before) sings a familiar song, it may signal to the infant that this new person is a member of their social group.\nTo test this the researchers recruited 32 infants and their parents to take part in the following experiment. During their first visit to the lab, the parents were taught a new lullaby (one that neither they nor their infants had heard before). The experimenters asked the parents to sing the new lullaby to their child every day for the next 1-2 weeks. Following this 1-2 week exposure period, the parents and their infant returned to the lab to complete the experimental portion of the study. Infants were first shown a screen with side-by-side videos of two unfamiliar people, each of whom were silently smiling and looking at the infant. The researchers recorded the looking behaviour (or gaze) of the infants during this ‘baseline’ phase. Next, one by one, the two unfamiliar people on the screen sang either the lullaby that the parents learned or a different lullaby (that had the same lyrics and rhythm, but a different melody). Finally, the infants saw the same silent video used at baseline, and the researchers again recorded the looking behaviour of the infants during this ‘test’ phase. For more details on the experiment’s methods, please refer to Mehr et al. (2016) Experiment 1.\n\n10.2.1 The Data\n\n10.2.1.1 Activity 11: Getting the data ready\n\nFirst, download Mehr Song and Spelke 2016 Experiment 1.csv by clicking on the link and putting it into your working directory.\n\nagain if easier you can download the data as a zip file by clicking this link.\n\n\nNext, type and run the below code in a new code chunk. The code loads in the data and then does some wrangling to get the data into a working format:\n\nit filters so we just have the first experiment from the paper\nselects the id and the preferential looking time of babies at the baseline stage and at the test stage.\nfinally it renames the two preferential looking time columns to have names that are easier to work with using the rename() function.\n\n\n\n\ngaze &lt;- read_csv(\"Mehr Song and Spelke 2016 Experiment 1.csv\") %&gt;%\n  filter(exp1 == 1) %&gt;%\n  select(id,\n         Baseline_Proportion_Gaze_to_Singer,\n         Test_Proportion_Gaze_to_Singer) %&gt;%\n  rename(baseline = Baseline_Proportion_Gaze_to_Singer,\n         test = Test_Proportion_Gaze_to_Singer)\n\n\n10.2.2 Assumptions\nSo now that we have our data ready to work with, and be sure to look at it to get an understanding of the data, we want to consider the assumptions of the within-subjects t-test.\nThe assumptions for this t-test are a little different (although very similar) to the between-subjects t-tests above. They are\n\nThe data is continuous, i.e. interval/ratio\nAll participants should appear in both conditions/groups.\nThe residuals are normally distributed.\n\nAside from the data being paired rather than independent, i.e. it is the same participants in two conditions, rather than two groups of people in different conditions, the key difference is that for the within-subjects test, the data is actually determined as the difference between the scores in the two conditions for each participant. So for example, say participant one scores 10 in condition 1 and 7 in condition 2, then there data is actually 3, and you do that for all participants. So it isn’t looking at what they scored in either condition by itself, but what was the difference between conditions. And it is that data that must be continuous and that the residuals must be normally distributed for.\n\n10.2.2.1 Activity 12: Assumptions\n\nType and run the below code to first calculate the difference scores (diff) and then the residuals (group_resid).\nnext it plots the Q-Q plot of the residuals before carrying out a Shapiro-Wilk’s test on the residuals\n\n\ngaze_residual &lt;- gaze %&gt;%\n  mutate(diff = baseline - test) %&gt;%\n  mutate(group_resid = diff - mean(diff))\n\nqqPlot(gaze_residual$group_resid)\n\nshapiro.test(gaze_residual$group_resid)\n\nAnd if we look at the plot we see:\n\n\n\n\n\n\n\n\n[1] 22 29\n\n\nand the Shapiro-Wilk’s suggests:\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  gaze_residual$group_resid\nW = 0.97818, p-value = 0.7451\n\n\nNow as we saw above, with the Q-Q plot we want the data to fall approximately on the diagonal line, and with the Shapiro-Wilks test we are looking for a non-significant finding. Based on those two tests, we can therefor say that our data meets the assumption of normality and so we can proceed.\n\n10.2.3 Descriptives\nNow we are going to look at some descriptives. It made sense to keep the data in wide-form until this point to make it easy to calculate a column for the difference score, but now we will transform it to tidy data so that we can easily create descriptives and plot the data using tidyverse tools.\n\n10.2.3.1 Activity 13: Descriptives and visualisations\n\nType and run the below code to gather the data using pivot_longer().\nNext create a violin-boxplot of the data using your knowledge (and code) from Activity 4 above.\nFinally, create a descriptives table that contains the n, the mean, and the standard deviation of each condition.\n\nIf you prefer, you could actually work on the difference scores instead of the two different conditions. Whilst we analyse the difference, people plot either the difference or the two conditions as descriptives.\n\n\n\n\ngaze_tidy &lt;- gaze %&gt;%\n  pivot_longer(names_to = \"time\", \n               values_to = \"looking\", \n               cols = c(baseline, test))\n\nIf you have done this step correctly, you should see a plot that looks like this:\n\n\n\n\nPreferential Looking time for infants at baseline stage (left) and test stage (right).\n\n\n\nAnd the descriptives:\n\n\n\n\ntime\nn\nmean_looking\nsd_looking\n\n\n\nbaseline\n32\n0.5210967\n0.1769651\n\n\ntest\n32\n0.5934912\n0.1786884\n\n\n\n\n\nAgain you could look at the differences and if you know how you could plot the confidence interval of the difference, but it is not essential here. But looking at what you have done it would be worth spending a few minutes to try and predict the outcome of the t-test if the null hypothesis is that there is no difference in preferential looking time in babies between the baseline and test conditions.\n\n10.2.4 Inferential Analysis\nWhich brings us on to running the t-test and the effect size. The code is almost identical to the independent code with two differences:\n\nIn t.test() you should specify paired = TRUE rather than FALSE\n\nIn cohens_d() you should specify method = paired rather than pooled_sd\n\n\n\n10.2.4.1 Activity 14: Paired-samples t-test\n\nNow have a go at running the within-subjects t-test based on your knowledge. The data you need is in gaze_tidy(). Store the output of the t-test as a tibble in the object gaze_test\n\ni.e. pipe the output of the t-test into `tidy() in the one line of code.\n\n\ncalculate the Cohen’s D for the t-test and store it in gaze_d\n\n\n\ngaze_test &lt;- NULL\ngaze_d &lt;- NULL\n\nAnd if you have done that correctly, you should see in gaze_test something like this:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nestimate\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n-0.0723946\n-2.41643\n0.0217529\n31\n-0.133497\n-0.0112922\nPaired t-test\ntwo.sided\n\n\n\n\n\n10.2.5 Write-Up and Interpretation\nLooking at the output of the test, it is actually very similar to the between-subjects t-test, with one exception. Rather than providing the means of both conditions, there is a single estimate. This is the mean difference score between the two conditions and if you had calculated the descriptives on the diff we created above you would get the same answer.\n\n\nEnter the mean estimates and t-test results (means and t-value to 2 decimal places, p-value to 3 decimal places):\n\nMean estimate = \nt() = , p = \n\n\n\n\n10.2.5.1 Activity 15: Write-up\nNow have a go at summarising this finding in a sentence using the standard APA formatting. We have hidden our version just below for you to look at when you have had a go.\n\n\nShow our write-up\n\n\nAt test stage (M = .59, SD = .18), infants showed a significantly longer preferential looking time to the singer of the familiar melody than they had shown the same singer at baseline (M = .52, SD = .18), t(31) = 2.42, p = .022, d = .41.\nAlternatively:\nAt test stage, infants showed a significantly longer preferential looking time to the singer of the familiar melody than they had shown the same singer at baseline (Mean Difference = 0.07, SD = 0.17), t(31) = 2.42, p = .022, d = .41."
  },
  {
    "objectID": "10-t-tests.html#ttest-fin",
    "href": "10-t-tests.html#ttest-fin",
    "title": "\n10  t-tests\n",
    "section": "\n10.3 Finished!",
    "text": "10.3 Finished!\nThat was a long chapter but hopefully you will see that it really is true that the hardest part is the set-up and the data wrangling. As we’ve said before, you don’t need to memorise lines of code - you just need to remember where to find examples and to understand which bits of them you need to change. Play around with the examples we have given you and see what changing the values does. There is no specific Test Yourself section for this chapter but make sure you check your understanding of the different sections before moving on."
  },
  {
    "objectID": "10-t-tests.html#ttest-sols",
    "href": "10-t-tests.html#ttest-sols",
    "title": "\n10  t-tests\n",
    "section": "\n10.4 Activity solutions",
    "text": "10.4 Activity solutions\nBelow you will find the solutions to the above questions. Only look at them after giving the questions a good try and trying to find help on Google or Teams about any issues.\n\n10.4.0.1 Activity 1\n\nlibrary(broom)\nlibrary(car)\nlibrary(effectsize)\nlibrary(report)\nlibrary(tidyverse)\nevaluators &lt;- read_csv(\"evaluators.csv\")\n\n\n10.4.0.2 Activity 2\nThis was our code:\n\nevaluators &lt;- evaluators %&gt;%\n  mutate(sex_labels = dplyr::recode(sex, \"1\" = \"male\", \"2\" = \"female\"),\n         sex_labels = as.factor(sex_labels),\n         condition = as.factor(condition))\n\nand you could summarise as below to give an output:\n\neval_counts &lt;- group_by(evaluators, sex_labels) %&gt;% count()\n\n\n10.4.0.3 Activity 6\n\nintellect &lt;- filter(ratings2, Category == \"intellect\")\nhire &lt;- filter(ratings2, Category == \"hire\")\nimpression &lt;- filter(ratings2, Category == \"impression\")\n\n\n10.4.0.4 Activity 8\n\nintellect_d &lt;- cohens_d(Rating ~ condition, \n                      pooled_sd = FALSE, \n                      data = intellect)\nhire_d &lt;- cohens_d(Rating ~ condition, \n                      pooled_sd = FALSE, \n                      data = hire)\nimpression_d &lt;- cohens_d(Rating ~ condition, \n                      pooled_sd = FALSE, \n                      data = impression)\n\n\n10.4.0.5 Activity 13\nFor the plot:\n\nggplot(gaze_tidy, aes(x = time, y = looking)) +\n  geom_violin(trim = FALSE) +\n  geom_boxplot(aes(fill = time), width = .2, show.legend = FALSE) + \n  stat_summary(geom = \"pointrange\", fun.data = \"mean_cl_normal\") +\n  labs(x = \"Experimental Stage\", \n       y = \"Preferential Looking Time (Proportion)\")\n\nFor the descriptives:\n\ndesc &lt;- gaze_tidy %&gt;% \n  group_by(time) %&gt;% \n  summarise(n = n(), \n            mean_looking = mean(looking), \n            sd_looking = sd(looking))\n\n\n10.4.0.6 Activity 14\nFor the t-test:\n\ngaze_test &lt;- t.test(looking ~ time, \n                    paired = TRUE, \n                    data = gaze_tidy) %&gt;% \n  tidy()\n\nFor the Cohen’s D:\n\ngaze_d &lt;- cohens_d(looking ~ time, \n                   method = \"paired\", \n                   data = gaze_tidy)"
  },
  {
    "objectID": "10-t-tests.html#words-from-this-chapter",
    "href": "10-t-tests.html#words-from-this-chapter",
    "title": "\n10  t-tests\n",
    "section": "\n10.5 Words from this Chapter",
    "text": "10.5 Words from this Chapter\nBelow you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the PsyTeachR Glossary. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter.\n\n\n\n\nterm\ndefinition\n\n\n\nbetween subjects\n\n\n\ncategorical\n\n\n\nmixed design\n\n\n\nnumeric\n\n\n\nOne-sample\n\n\n\nwithin subjects\n\n\n\n\n\n\nThat is end of this chapter. Be sure to look again at anything you were unsure about and make some notes to help develop your own knowledge and skills. It would be good to write yourself some questions about what you are unsure of and see if you can answer them later or speak to someone about them. Good work today!"
  },
  {
    "objectID": "12-missing-data.html#the-set-up-and-the-data",
    "href": "12-missing-data.html#the-set-up-and-the-data",
    "title": "\n11  Screening Data\n",
    "section": "\n11.1 The Set-Up and the Data",
    "text": "11.1 The Set-Up and the Data\nAs always we first need to start with setting up our working environment, bringing in our data and looking at it.\n\n11.1.0.1 Activity 1: Set-up\n\nOpen RStudio and set the working directory to your chapter folder. Ensure the environment is clear.\n\nIf you’re using the Rserver, avoid a number of issues by restarting the session - click Session - Restart R\n\n\n\nOpen a new R Markdown document and save it in your working directory. Call the file “screeningdata”.\n\nDownload messy.csv and save it in your Screening Data folder. Make sure that you do not change the file name at all.\n\nIf you prefer you can download the data in a zip folder by clicking here\n\nRemember not to change the file names at all and that data.csv is not the same as data (1).csv.\n\n\nDelete the default R Markdown welcome text and insert a new code chunk that loads the following packages, in this specific order, using the library() function. Remember the solutions if needed.\n\nLoad the packages in this order, psych then tidyverse\n\nagain we have not used some of these packages so you will likely need to install some of them using install.packages(). Remember though that you should only do this on your own machine and only in the console window. If you are using the RServer you will not need to install them.\n\n\nFinally, load the data held in messy.csv as a tibble into an object named messy using read_csv(). If unsure, have a look at the solution at the end of the chapter\n\n11.1.0.2 Activity 2: Look at the data\nmessy is simulated data for an experiment looking at the effect of note-taking on test performance and whether this is affected by being first language English. Participants are first given a pre-test to judge their baseline knowledge, then they watch a lecture and take notes. Immediately after the lecture is finished they take another test. Finally, they are tested after a week’s delay. The maximum score for any test is 30. Participants lose marks for incorrect answers so minus scores are also possible. The dataset has six variables:\n\n\nid showing the participant ID number\n\nage showing the age of the participant\n\nspeakershowing if the participant are first language English or not\n\n\ngender showing if the participant is male, female, or non-binary\n\n\npre showing pre-test score before any notes were taken\n\n\npost showing post-test score immediately after the lecture\n\n\ndelay showing test score after one week delay"
  },
  {
    "objectID": "12-missing-data.html#missing-data",
    "href": "12-missing-data.html#missing-data",
    "title": "\n11  Screening Data\n",
    "section": "\n11.2 Missing data",
    "text": "11.2 Missing data\nThe first issue we will cover is missing data. There is a whole host of reasons that your data could have missing values. For example:\n\nData can be missing because your participants accidentally didn’t fill in a question.\nData can be missing because participants intentionally didn’t want to answer a question.\nData can be missing because participants didn’t turn up to a final testing session.\nData can be missing because you did something wrong whilst setting up your questionnaire/experiment and it didn’t save.\n\nIn truth, real data frequently contains missing values and it’s important that you know how to identify missing data and what you can do with it. Which is what we want to show you a little of in this chapter.\n\n11.2.0.1 Activity 3: summary() and is.na()\n\nMissing data is normally shown in your tibbles and objects as NA - usually taken to mean something like “Not Available”. We have already seen a couple of approaches to find NAs in our data and we will quickly recap them.\nThe first approach is to use a pipeline of functions we have used before including summarise(), is.na(), sum(), and pluck(). For instance:\n\nmessy_na &lt;- messy %&gt;% \n  summarise(find_nas = is.na(speaker)) %&gt;%\n  summarise(count_nas = sum(find_nas)) %&gt;%\n  pluck(\"count_nas\")\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\nWhich reads as use is.na() to find all the NAs in messy (i.e the first summarise()) and then count up all those NAs (i.e. the second summarise() - which works because NAs are either TRUE, summed as 1, or FALSE, summed as 0), and then pluck out that number (i.e. the pluck()). And if you look at messy_na you see there are 20 NAs in speaker. That code looks quite long but it could actually be written as below if you prefer and you can follow the pipe inside the summarise().\n\nmessy_na &lt;- messy %&gt;% \n  summarise(count_nas = is.na(speaker) %&gt;% sum()) %&gt;% \n  pluck(\"count_nas\")\n\nThis approach, using is.na(), is a good approach if you are only interested in one column or maybe a couple of columns, but if you want a snapshot of all your columns then we can use summary() which we have seen previously. First, however, because speaker and gender are character/text rather than numerical, in order to see how many values are missing we first need to convert these two columns into factors using the below code\n\nmessy &lt;- messy %&gt;%\n  mutate(speaker = as.factor(speaker), \n         gender = as.factor(gender))\n\nsummary(messy)\n\nIf you run the code, you can see, there are 20 data points missing (NAs) in each of speaker, gender, and delay. However, and the important part if you look at the actual data, the missing data is not in the same 20 participants and that gives us some issues about how to deal with these different participants. Fortunately, there are several different approaches to dealing with missing data and we will cover a few here."
  },
  {
    "objectID": "12-missing-data.html#listwise-deletion",
    "href": "12-missing-data.html#listwise-deletion",
    "title": "\n11  Screening Data\n",
    "section": "\n11.3 Listwise Deletion",
    "text": "11.3 Listwise Deletion\nOne method for dealing with missing data is listwise. This approach removes any participant who have a missing value (i.e. a NA) in any variable. So if there is missing data in any of the columns in the dataset, that participant will be removed and you will only be left with participants with complete datasets. For example the below participants would be removed along with all others with a similar profile:\n\n\n\n\nid\nage\nspeaker\ngender\npre\npost\ndelay\n\n\n\nS008\n48\nenglish\nNA\n12\n15\n17\n\n\nS009\n22\nNA\nmale\n5\n18\n5\n\n\nS010\n31\nNA\nfemale\n13\n35\n17\n\n\nS011\n26\nenglish\nNA\n18\n19\n16\n\n\n\n\n\nWe can achieve this using the drop_na() function from the tidyr package that comes in as part of tidyverse.\n\n11.3.0.1 Activity 4: Listwise deletion\n\nRun the below code and then view the tibble in the object called messy_listwise.\n\n\nmessy_listwise &lt;- drop_na(messy)\n\nAs you can see messy_listwise now only contains data from participants with a complete set of data - i.e. responses in each column.\nNow, however, whilst this might seem like a good thing, and sometimes it is the most appropriate option, there are a couple of important points to consider.\n\nFirst, gender might not be part of our experiment; it might just be there as demographic information. So whilst we might not include gender in any of our analyses, because of the listwise deletion approach we have deleted experimental data if the participant was missing gender which means we are removing participants we could actual use.\nRelatedly, using a listwise deletion approach may result in the loss of a lot of data. Compare messy to messy_listwise. The original dataset had 200 participants. After using drop_na() we only have 143 participants meaning that we have lost over 25% of our data with this approach which is a lot of data.\n\n\n\nNote: It is worth mentioning that if you do use a listwise approach you should check that the missing values are not coming from one particular group (i.e., non-random attrition).\n\nTo counter these issues, one option is to amend the use of drop_na() so that it doesn’t include gender, or any column for that matter that we don’t want to exclude people based on. We can do this using a similar approach to what we have seen when using select(). For example, run the below code, have a look at the output and then answer the question:\n\nmessy_listwise2 &lt;- drop_na(messy, -gender)\n\n\nHow many observations does messy_listwise2 have? \n\n\nSo that approach says “remove participants with NAs from messy based on all columns except gender”. Alternatively, you could do “remove participants with NAs from messy based on only the columns of speaker and delay” as follows:\n\nmessy_listwise3 &lt;- drop_na(messy, speaker, delay)\n\nSo you actually have a lot of control with drop_na() as long as you plan your approach in advance."
  },
  {
    "objectID": "12-missing-data.html#pairwise-deletion",
    "href": "12-missing-data.html#pairwise-deletion",
    "title": "\n11  Screening Data\n",
    "section": "\n11.4 Pairwise Deletion",
    "text": "11.4 Pairwise Deletion\nThe alternative to listwise deletion is pairwise. This is when cases are removed depending upon the analysis. For example, if we were to calculate the correlations between pre, post, and delay without first removing participants with missing data, we would basically just use different numbers of participants in each correlation depending on missing data. For example, if you compare the degrees of freedom for the following two correlations:\n\ncor.test(messy$pre, messy$post)\n\n\n    Pearson's product-moment correlation\n\ndata:  messy$pre and messy$post\nt = 7.0493, df = 198, p-value = 2.924e-11\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.3296550 0.5523276\nsample estimates:\n      cor \n0.4479101 \n\n\n\ncor.test(messy$pre, messy$delay)\n\n\n    Pearson's product-moment correlation\n\ndata:  messy$pre and messy$delay\nt = 7.9619, df = 178, p-value = 1.927e-13\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.3958642 0.6127887\nsample estimates:\n      cor \n0.5124561 \n\n\nYou can see that the correlation of pre versus post has df = 198 whereas pre versus delay has df = 178. Meaning that the correlation is by default run only on the participants who have data in both columns - pairwise deletion. The problem here is remembering to write up the output accordingly as the dfs are changing and they may be different from the number of participants you stated in your methods section. Again it is about looking at your data!"
  },
  {
    "objectID": "12-missing-data.html#summarising-data-with-missing-values",
    "href": "12-missing-data.html#summarising-data-with-missing-values",
    "title": "\n11  Screening Data\n",
    "section": "\n11.5 Summarising data with missing values",
    "text": "11.5 Summarising data with missing values\nSo when running inferential tests like correlations, the analysis will usually know when to ignore missing values. However, if you’re calculating descriptive statistics or if you want to calculate the average score of a number of different items, you need to explicitly state to ignore the missing values. We can do this through na.rm = TRUE\n\n11.5.0.1 Activity 5: na.rm = TRUE\n\n\nRun the below code to calculate the mean score for each testing condition.\n\n\nsummarise(messy, \n          pre_mean = mean(pre),\n          post_mean = mean(post),\n          delay_mean = mean(delay)\n          )\n\nThis gives a table similar to below. We have rounded all the values to two decimal places but yours might have more decimal places.\n\n\n\n\npre_mean\npost_mean\ndelay_mean\n\n\n10.02\n17.27\nNA\n\n\n\n\nAs you can see, the mean score for delay shows as NA. This is because we are trying to calculate an average of a variable that has missing data and that just isn’t doable. As such we need to calculate the mean but ignoring the missing values by adding na.rm = TRUE - which you can read this as “remove the NAs? Yes”.\n\nRun the below code and then answer the question.\n\n\nsummarise(messy, \n          pre_mean = mean(pre),\n          post_mean = mean(post),\n          delay_mean = mean(delay, na.rm = TRUE)\n          )\n\n\nWhat is the mean score for the delay condition to 2 decimal places? \n\n\n\n\n\nIt’s really important that you think about whether you want to calculate your descriptives from participants that have missing data. For example, if you are calculating the average reaction time from hundreds of trials, a few missing data points won’t affect the validity of the mean. However, if you are using a standardised questionnaire that has been validated using complete responses but your participants didn’t answer 3/10 questions, it may not be appropriate to calculate a mean score from the remaining data."
  },
  {
    "objectID": "12-missing-data.html#implausible-values",
    "href": "12-missing-data.html#implausible-values",
    "title": "\n11  Screening Data\n",
    "section": "\n11.6 Implausible values",
    "text": "11.6 Implausible values\nAlong with looking for missing values, an additional crucial step of data screening is checking for implausible values - values that should not exist in your data. What is implausible depends on the data you’ve collected!\n\n11.6.0.1 Activity 6: Implausible values\nAdditional functions we can put inside a summarise() function are min() and max().\n\nRun the below code and look at the output and answer the questions below:\n\n\nmessy %&gt;%\n  summarise(max_age = max(age, na.rm = TRUE),\n            min_age = min(age, na.rm = TRUE),\n            max_pre = max(pre, na.rm = TRUE),\n            min_pre = min(pre, na.rm = TRUE),\n            max_post = max(post, na.rm = TRUE),\n            min_post = min(post, na.rm = TRUE),\n            max_delay = max(delay, na.rm = TRUE),\n            min_delay = min(delay, na.rm = TRUE))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmax_age\nmin_age\nmax_pre\nmin_pre\nmax_post\nmin_post\nmax_delay\nmin_delay\n\n\n470\n18\n26\n-5\n40\n3\n29\n-3\n\n\n\n\n\n\nDoes the max value of age look plausible? \nYes\nNo\n\nDoes the max value of pre look plausible? \nYes\nNo\n\nDo the max value of post look plausible? \nYes\nNo\n\nDo the min value of delay look plausible? \nNo\nYes\n\n\n\n\nExplain these answers\n\n\nThe maximum value for age is 470, this is unlikely to be correct!\nThe maximum value for pre, post, and delay should be 30, as we described at the start of the chapter. However, for post, the maximum value is 40 so something is wrong. This is a very important check to do on your data, not just for the raw data but if you’ve calculated a total score.\nThe min value for delay is plausible, given the explanation at the start of the chapter. Remember that participants can be deducted points for incorrect answers, so negative values are possible.\n\n\nThat code above does look a bit long and could be written quicker as below. We won’t go into detail as to how this works but see if you can figure it out by comparing the output to the version above:\n\nmessy %&gt;% \n  summarise_at(c(\"age\",\"pre\",\"post\",\"delay\"),\n               c(max, min),\n               na.rm = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nage_fn1\npre_fn1\npost_fn1\ndelay_fn1\nage_fn2\npre_fn2\npost_fn2\ndelay_fn2\n\n\n470\n26\n40\n29\n18\n-5\n3\n-3\n\n\n\n\n\nAnd there is always summary(messy) if you prefer. But the main point is that we should always check our values to make sure they are allowed in our data. But whilst looking at the values is useful, it can be easier to visualise the data.\n\n11.6.0.2 Activity 7: Visualising implausible values\nThere are a number of different ways to visualise the data as you know and this depends on the data, and your preferences. You could produce violin-boxplots with the data points on top to check the distributions as follows:\n\nmessy %&gt;%\n  pivot_longer(cols = c(\"pre\", \"post\", \"delay\"), \n               names_to = \"test\", \n               values_to = \"score\") %&gt;%\n  ggplot(aes(x = test, y = score)) +\n  geom_violin() +\n  geom_boxplot() +\n  geom_jitter(width = .2)\n\n\n\nData screening plots\n\n\n\nAnd if it helped, you could add some max and min lines to help spot issues using geom_hline() as follows:\n\nmessy %&gt;%\n  pivot_longer(cols = c(\"pre\", \"post\", \"delay\"), \n               names_to = \"test\", \n               values_to = \"score\") %&gt;%\n  ggplot(aes(x = test, y = score)) +\n  geom_violin() +\n  geom_boxplot() +\n  geom_jitter(width = .2) +\n  geom_hline(yintercept = c(0,30), color = \"red\", linetype = 2)\n\n\n\nData screening plots\n\n\n\nAlternatively you could also use a histogram to spot an outlier:\n\nggplot(messy, aes(x = age)) +\n  geom_histogram()\n\n\n\nHistogram of age for data screening\n\n\n\nAnd we can make use of facet_wrap() which we have seen before to help split figures based on different conditions:\n\nmessy %&gt;%\n  pivot_longer(cols = c(\"pre\", \"post\", \"delay\"), \n               names_to = \"test\", \n               values_to = \"score\") %&gt;%\n  ggplot(aes(x = score)) +\n  geom_histogram(binwidth = 1) +\n  facet_wrap(~test)\n\n\n\nHistogram of the DVs for data screening\n\n\n\nWhatever method you choose, make sure that you look at your data before trying to work with it and that you know in advance what range your values should take (for example, if your Likert scale is 1-7, you shouldn’t have a score of 8, for reaction times, 50ms is unlikely to reflect a real response)."
  },
  {
    "objectID": "12-missing-data.html#dealing-with-implausible-values-or-missing-data",
    "href": "12-missing-data.html#dealing-with-implausible-values-or-missing-data",
    "title": "\n11  Screening Data\n",
    "section": "\n11.7 Dealing with implausible values or missing data",
    "text": "11.7 Dealing with implausible values or missing data\nOnce we have spotted some implausible or missing values we then need to decide what to do with them. However, there is no hard and fast rule about what to do with missing data. You should review the missing data to see if there are any patterns, for example, is all the missing data from one condition? A pattern may indicate a problem with your design. Alternatively, does a single participant have a lot of missing data and should they be removed? This might indicate they were not paying attention.\nOne way of dealing with implausible values is to use the replace() and mutate() functions to change such values to Na.\n\nFor age, we know that we have one very specific data point that is implausible, an age of 470 so we can specify just to replace this one value with NA.\nFor post, there are multiple missing values so we specify to replace any data point that is over the maximum plausible value (30) with NA.\n\n\nmessy_screen &lt;-  messy %&gt;% \n  mutate(age = replace(age, age == 470, NA),\n         post = replace(post, post &gt; 30, NA))\n\nAn alternative method for dealing with implausible data is to impute the data, i.e., to replace missing data with substituted values. There are many methods of doing this, for example, you can replace missing values with the mean value of the distribution. We won’t go into which method you should choose this in this chapter but there’s more information available online about the various options if you’re interested. The code for imputing missing data is relatively simple and uses mutate() and replace_na().\n\nYou can read the below code as “create a new variable named post_impute that replaces the values of post if they’re NA with the mean of the values in post.\n\n\nmessy_impute &lt;- messy_screen %&gt;%\n  mutate(post_impute = replace_na(post, \n                                  mean(post, na.rm = TRUE)))\n\nAnd if we look at a participant who had a NA for post we can see the change:\n\n\n\n\nid\nage\nspeaker\ngender\npre\npost\ndelay\npost_impute\n\n\nS016\n40\nenglish\nfemale\n21\nNA\n12\n16.71134\n\n\n\n\nSo you can see that they have been given the value of the mean of the distribution in this new variable and then can be used in different analyses!"
  },
  {
    "objectID": "12-missing-data.html#alternative-function-for-descriptive-statistics",
    "href": "12-missing-data.html#alternative-function-for-descriptive-statistics",
    "title": "\n11  Screening Data\n",
    "section": "\n11.8 Alternative function for descriptive statistics",
    "text": "11.8 Alternative function for descriptive statistics\nAnd before we end this chapter we wanted to just add a small section on an alternative function for calculating some useful descriptives that you can use to check your data. So far in this book, we’ve calculated descriptive statistics using summarise() from the tidyverse. There’s a good reason we’ve done this - the output of summarise() works well with ggplot() and the code is very flexible. However, it can be hard to calculate descriptives such as skew and kurtosis within summarise() and it can be useful to know of other functions that help create these descriptives. For example, the psych package contains many functions that are useful for psychology research. One of the functions of psych is describe().\n\nRun the below code and look at the output as shown below.\n\n\ndescriptives &lt;- describe(messy)\ndescriptives\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvars\nn\nmean\nsd\nmedian\ntrimmed\nmad\nmin\nmax\nrange\nskew\nkurtosis\nse\n\n\n\nid*\n1\n200\n100.500000\n57.8791845\n100.5\n100.500000\n74.1300\n1\n200\n199\n0.0000000\n-1.2180144\n4.0926764\n\n\nage\n2\n200\n36.075000\n32.3102015\n34.0\n33.931250\n13.3434\n18\n470\n452\n12.0951922\n159.6718805\n2.2846763\n\n\nspeaker*\n3\n180\n1.511111\n0.5012709\n2.0\n1.513889\n0.0000\n1\n2\n1\n-0.0440855\n-2.0091259\n0.0373625\n\n\ngender*\n4\n180\n1.688889\n0.7268889\n2.0\n1.611111\n1.4826\n1\n3\n2\n0.5452331\n-0.9643153\n0.0541791\n\n\npre\n5\n200\n10.015000\n5.0039959\n10.0\n9.987500\n4.4478\n-5\n26\n31\n0.0555773\n0.2559528\n0.3538359\n\n\npost\n6\n200\n17.270000\n6.3386110\n17.0\n16.968750\n5.9304\n3\n40\n37\n0.5802699\n0.7133158\n0.4482075\n\n\ndelay\n7\n180\n13.600000\n5.1563271\n14.0\n13.645833\n4.4478\n-3\n29\n32\n-0.0462551\n0.4985955\n0.3843299\n\n\n\n\n\nAs you can see describe() produces a full set of descriptive statistics, including skew, kurtosis and standard error for the entire dataset! Run ?describe to see a full explanation of all the statistics it calculates.\nYou may notice that id, speaker and gender all have a star next to their name. This star signifies that these variables are factors, and so it is not really appropriate to calculate these statistics, but we asked it to apply describe() to the entire dataset so it’s done what you asked. However, we could describe()with select() to remove these variables and just get the data we want:\n\ndescriptives2 &lt;- messy %&gt;%\n  select(-id, -speaker, -gender) %&gt;%\n  describe()\n\ndescriptives2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvars\nn\nmean\nsd\nmedian\ntrimmed\nmad\nmin\nmax\nrange\nskew\nkurtosis\nse\n\n\n\nage\n1\n200\n36.075\n32.310201\n34\n33.93125\n13.3434\n18\n470\n452\n12.0951922\n159.6718805\n2.2846763\n\n\npre\n2\n200\n10.015\n5.003996\n10\n9.98750\n4.4478\n-5\n26\n31\n0.0555773\n0.2559528\n0.3538359\n\n\npost\n3\n200\n17.270\n6.338611\n17\n16.96875\n5.9304\n3\n40\n37\n0.5802699\n0.7133158\n0.4482075\n\n\ndelay\n4\n180\n13.600\n5.156327\n14\n13.64583\n4.4478\n-3\n29\n32\n-0.0462551\n0.4985955\n0.3843299\n\n\n\n\n\nThe output of describe() is a little harder to work with in terms of manipulating the table and using the data in subsequent plots and analyses, so we still strongly recommend that you use summarise() and group_by() for these operations, however, for getting a comprehensive overview of your data, describe() is a good function to know about."
  },
  {
    "objectID": "12-missing-data.html#screening-fin",
    "href": "12-missing-data.html#screening-fin",
    "title": "\n11  Screening Data\n",
    "section": "\n11.9 Finished!",
    "text": "11.9 Finished!\nAnd you’re done! Excellent work today! This isn’t a comprehensive tutorial on every type of dataset you will come across and the concept of tidy data will take practice but hopefully this should give you a good starting point for when you have your own real, messy data."
  },
  {
    "objectID": "12-missing-data.html#screening-sols",
    "href": "12-missing-data.html#screening-sols",
    "title": "\n11  Screening Data\n",
    "section": "\n11.10 Activity solutions",
    "text": "11.10 Activity solutions\n\n11.10.1 Activity 1\n\nlibrary(psych)\nlibrary(tidyverse)\nmessy &lt;- read_csv(\"messy.csv\")"
  },
  {
    "objectID": "12-missing-data.html#words-from-this-chapter",
    "href": "12-missing-data.html#words-from-this-chapter",
    "title": "\n11  Screening Data\n",
    "section": "\n11.11 Words from this Chapter",
    "text": "11.11 Words from this Chapter\nBelow you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the PsyTeachR Glossary. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter.\n\n\n\n\nterm\ndefinition\n\n\n\nimpute\n\n\n\nlistwise\n\n\n\npairwise\n\n\n\n\n\n\nThat is end of this chapter. Be sure to look again at anything you were unsure about and make some notes to help develop your own knowledge and skills. It would be good to write yourself some questions about what you are unsure of and see if you can answer them later or speak to someone about them. Good work today!"
  },
  {
    "objectID": "17-multiple-regression.html#mulregression-a1",
    "href": "17-multiple-regression.html#mulregression-a1",
    "title": "\n16  Multiple regression\n",
    "section": "\n16.1 Activity 1: Set-up",
    "text": "16.1 Activity 1: Set-up\n\nOpen R Studio and set the working directory to your chapter folder. Ensure the environment is clear.\n\nOpen a new R Markdown document and save it in your working directory. Call the file “Multiple Regression”.\n\nDownload wellbeing.csv, participant_info.csv and screen_time.csv and save them in your Chapter folder. Make sure that you do not change the file names at all.\n\nIf you’re on the server, avoid a number of issues by restarting the session - click Session - Restart R\n\nDelete the default R Markdown welcome text and insert a new code chunk that loads pwr, see, performance, report, and tidyverse using the library() function.\nLoad the CSV datasets into variables called pinfo, wellbeing and screen using read_csv()."
  },
  {
    "objectID": "17-multiple-regression.html#mulregression-a2",
    "href": "17-multiple-regression.html#mulregression-a2",
    "title": "\n16  Multiple regression\n",
    "section": "\n16.2 Activity 2: Look at the data",
    "text": "16.2 Activity 2: Look at the data\nTake a look at the resulting tibbles pinfo, wellbeing, and screen. The wellbeing tibble has information from the WEMWBS questionnaire; screen has information about screen time use on weekends (variables ending with we) and weekdays (variables ending with wk) for four types of activities: using a computer (variables starting with Comph; Q10 on the survey), playing video games (variables starting with Comp; Q9 on the survey), using a smartphone (variables starting with Smart; Q11 on the survey) and watching TV (variables starting with Watch; Q8 on the survey). If you want more information about these variables, look at the items 8-11 on pages 4-5 of the the PDF version of the survey on the OSF website.\n\nThe variable corresponding to gender is located in the table named \npinfo\nwellbeing\nscreen and this variable is called .\nThe WEMWBS data is in \nlong\nwide format, and contains observations from  participants on  items.\nIndividual participants in this dataset are identified by the variable named  [be sure to type the name exactly, including capitalization]. This variable will allow us to link information across the three tables.\nRun summary() on the three data-sets. Are there any missing data points? \nYes\nNo"
  },
  {
    "objectID": "17-multiple-regression.html#mulregression-a3",
    "href": "17-multiple-regression.html#mulregression-a3",
    "title": "\n16  Multiple regression\n",
    "section": "\n16.3 Activity 3: Compute the well-being score for each respondent",
    "text": "16.3 Activity 3: Compute the well-being score for each respondent\nThe WEMWBS well-being score is simply the sum of all the items.\n\nWrite the code to create a new table called wemwbs, with two variables: Serial (the participant ID), and tot_wellbeing, the total WEMWBS score.\n\n\n\nHint\n\n\n“pivot” the table from wide to long\n\n\n\n\nAnother Hint\n\n\n\ngroup_by(); summarise(tot_wellbeing = ...)\n\n\n\nSanity check: Verify for yourself that the scores all fall in the 14-70 range. Przybylski and Weinstein reported a mean of 47.52 with a standard deviation of 9.55. Can you reproduce these values?\n\n\nHint\n\n\n\nsummarise(), min(), max()\n\n\n\n\n\nNow visualise the distribution of tot_wellbeing in a histogram using ggplot2.\n\n\n\nHint\n\n\ngeom_histogram()\n\n\n\n\nSolution\n\n\nggplot(wemwbs, aes(tot_wellbeing)) + geom_histogram() \n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nThe distribution of well-being scores is \nsymmetric\nnegatively skewed\npositively skewed."
  },
  {
    "objectID": "17-multiple-regression.html#mulregression-a4",
    "href": "17-multiple-regression.html#mulregression-a4",
    "title": "\n16  Multiple regression\n",
    "section": "\n16.4 Activity 4: Visualise the relationship",
    "text": "16.4 Activity 4: Visualise the relationship\nLet’s take a quick look at the relationship between screen time (for the four different technologies) and measures of well-being. Here is code to do this.\n\nRun the below code and try and explain in words what each line of code is doing (remember, pronounce %&gt;% as “and then”). You may find it easier to look at each of the tables that are produced.\n\n\nscreen_long &lt;- screen %&gt;%\n  pivot_longer(names_to = \"var\", values_to = \"hours\", -Serial) %&gt;%\n  separate(var, c(\"variable\", \"day\"), \"_\")\n\nscreen2 &lt;- screen_long %&gt;%\n  mutate(variable = dplyr::recode(variable,\n               \"Watch\" = \"Watching TV\",\n               \"Comp\" = \"Playing Video Games\",\n               \"Comph\" = \"Using Computers\",\n               \"Smart\" = \"Using Smartphone\"),\n     day = dplyr::recode(day,\n              \"wk\" = \"Weekday\",\n              \"we\" = \"Weekend\"))\n\ndat_means &lt;- inner_join(wemwbs, screen2, \"Serial\") %&gt;%\n  group_by(variable, day, hours) %&gt;%\n  summarise(mean_wellbeing = mean(tot_wellbeing))\n\nggplot(dat_means, aes(hours, mean_wellbeing, linetype = day)) +\n  geom_line() +\n  geom_point() +\n  facet_wrap(~variable, nrow = 2)\n\n\n\nRelationship between wellbeing and screentime usage by technology and weekday\n\n\n\nThe graph makes it evident that smartphone use of more than 1 hour per day is associated with increasingly negative well-being. Note that we have combined the tables using an inner_join(), such that we only include data for which we have observations across the wemwbs and screen2 tables.\nIn the next step, we are going to focus in on the smartphone/well-being relationship."
  },
  {
    "objectID": "17-multiple-regression.html#mulregression-a5",
    "href": "17-multiple-regression.html#mulregression-a5",
    "title": "\n16  Multiple regression\n",
    "section": "\n16.5 Activity 5: Smartphone and well-being for boys and girls",
    "text": "16.5 Activity 5: Smartphone and well-being for boys and girls\nFor this analysis, we are going to collapse weekday and weekend use for smartphones.\n\nCreate a new table, smarttot, that has the that has mean number of hours per day of smartphone use for each participant, averaged over weekends/weekdays.\nYou will need to filter the dataset to only include smartphone use and not other technologies.\nYou will also need to group the results by the participant ID (i.e., serial).\nThe final data-set should have two variables: Serial (the participant) and tothours.\nYou will need to use the data-set screen2 to do this.\n\n\n\nHint\n\n\n\nfilter() then group_by() then summarise()\n\n\n\n\nNext, create a new tibble called smart_wb that only includes (filters) participants from smarttot who used a smartphone for more than one hour per day each week, and then combine (join) this table with the information in wemwbs and pinfo.**\n\n\n\nHint\n\n\n\nfilter() then inner_join() then another inner_join()"
  },
  {
    "objectID": "17-multiple-regression.html#mulregression-a6",
    "href": "17-multiple-regression.html#mulregression-a6",
    "title": "\n16  Multiple regression\n",
    "section": "\n16.6 Activity 6: Mean-centering variables",
    "text": "16.6 Activity 6: Mean-centering variables\nAs discussed in the lecture, When you have continuous variables in a regression, it is often sensible to transform them by mean centering. You mean center a predictor X simply by subtracting the mean (X_centered = X - mean(X)). This has two useful consequences:\n\nthe model intercept reflects the prediction for \\(Y\\) at the mean value of the predictor variable, rather than at the zero value of the unscaled variable;\nif there are interactions in the model, any lower-order effects can be given the same interpretation as they receive in ANOVA (main effects, rather than simple effects).\n\nFor categorical predictors with two levels, these become coded as -.5 and .5 (because the mean of these two values is 0).\n\nUse mutate to add two new variables to smart_wb: tothours_c, calculated as a mean-centered version of the tothours predictor; and male_c, recoded as -.5 for female and .5 for male.\nTo create male_c you will need to use if_else(male == 1, .5, -.5) You can read this code as “if the variable male equals 1, recode it as .5, if not, recode it as -.5”.\nFinally, recode male and male_c as factors, so that R knows not to treat them as a real numbers."
  },
  {
    "objectID": "17-multiple-regression.html#mulregression-a7",
    "href": "17-multiple-regression.html#mulregression-a7",
    "title": "\n16  Multiple regression\n",
    "section": "\n16.7 Activity 7: Visualise the relationship",
    "text": "16.7 Activity 7: Visualise the relationship\n\nReverse-engineer the below plot. Calculate mean well-being scores for each combination of male and tothours, and then create a scatterplot plot that includes separate regression lines for each gender.\nYou may find it useful to refer to the Visualisation chapter.\n\n\n\nHint\n\n\n\ngroup_by() both variables then summarise()\n\ncolour = variable_you_want_different_colours_for\n\n\n\n\n\n\nRelationship between mean wellbeing and smartphone use by gender\n\n\n\nWrite an interpretation of the above plot in plain English.\n\n\nPossible solution\n\nGirls show lower overall well-being compared to boys. In addition, the slope for girls appears more negative than that for boys; the one for boys appears relatively flat. This suggests that the negative association between well-being and smartphone use is stronger for girls."
  },
  {
    "objectID": "17-multiple-regression.html#mulregression-a8",
    "href": "17-multiple-regression.html#mulregression-a8",
    "title": "\n16  Multiple regression\n",
    "section": "\n16.8 Activity 8: Running the regression",
    "text": "16.8 Activity 8: Running the regression\nNow we’re going to see if there is statistical support for our above interpretation of the graph.\nFor the data in smart_wb, use the lm() function to calculate the multiple regression model:\n\\(Y_i = \\beta_0 + \\beta_1 X_{1i} + \\beta_2 X_{2i} + \\beta_3 X_{3i} + e_i\\)\nwhere\n\n\n\\(Y_i\\) is the well-being score for participant \\(i\\);\n\n\\(X_{1i}\\) is the mean-centered smartphone use variable for participant \\(i\\);\n\n\\(X_{2i}\\) is gender (-.5 = female, .5 = male);\n\n\\(X_{3i}\\) is the interaction between smartphone use and gender (\\(= X_{1i} \\times X_{2i}\\))\n\nThen use summary() to view the results and store this in an object called mod_summary().\n\n\nHint\n\n\nR formulas look like this: y ~ a + b + a:b where a:b means interaction\n\n\n\nThe interaction between smartphone use and gender is shown by the variable \nthours_c\nmale_c\nthours_c:male_c, and this interaction was \nsignificant\nnonsignificant at the \\(\\alpha = .05\\) level.\nTo 2 decimal places, what proportion of the variance in well-being scores does the overall model explain? \nThe p-value for the overall model fit is &lt; 2.2e-16. Is this significant? \nYes\nNo\nWhat is the most reasonable interpretation of these results? \nsmartphone use harms girls more than boys\nsmartphone use harms boys more than girls\nthere is no evidence for gender differences in the relationship between smartphone use and well-being\nsmartphone use was more negatively associated with wellbeing for girls than for boys"
  },
  {
    "objectID": "17-multiple-regression.html#mulregression-a9",
    "href": "17-multiple-regression.html#mulregression-a9",
    "title": "\n16  Multiple regression\n",
    "section": "\n16.9 Activity 9: Assumption checking",
    "text": "16.9 Activity 9: Assumption checking\nNow it’s time to test those pesky assumptions. The assumptions for multiple regression are the same as simple regression but there is one additional assumption, that of multicollinearity, the idea that predictor variables should not be too highly correlated.\n\nThe outcome/DV is a interval/ratio level data\nThe predictor variable is interval/ratio or categorical (with two levels)\nAll values of the outcome variable are independent (i.e., each score should come from a different participant)\nThe predictors have non-zero variance\nThe relationship between outcome and predictor is linear\nThe residuals should be normally distributed\nThere should be homoscedasticity (homogeneity of variance, but for the residuals)\nMulticollinearity: predictor variables should not be too highly correlated\n\nFrom the work we’ve done so far we know that assumptions 1 - 4 are met and we can use the functions from the performance package again to check the rest, like we did with the simple linear regression chapter.\nOne difference from when we used check_model() previously is that rather than just letting it run all the tests it wants, we’re going to specify which tests, to stop it throwing an error. A word of warning - these assumptions tests will take longer than usual to run, because it’s such a big dataset. The first line of code will run the assumption tests and save it to an object, calling the object name will then display the plots.\n\nassumptions &lt;- check_model(mod, check = c(\"vif\", \"qq\", \"normality\", \"linearity\", \"homogeneity\"))\n\nassumptions\n\n\n\nAssumption plots\n\n\n\nFor assumption 5, linearity, we already know from looking at the scatterplot that the relationship is linear, but the residual plot also confirms this.\nFor assumption 6, normality of residuals, again the residuals look good in both plots and this provides an excellent example of why it’s often better to visualise than rely on statistics because if we use check_normality() which calls the Shapiro-Wilk test:\n\ncheck_normality(mod)\n\nWarning: Non-normality of residuals detected (p &lt; .001).\n\n\nIt tells us that the residuals are not normal, despite the fact that the plots look almost perfect. And that’s because with large sample sizes, any deviation from perfect normality can be flagged as non-normal.\nFor assumption 7, homoscedasticity, the plot is missing the reference line - fun fact, this took us several days of our lives and asking for help on Twitter to figure out. The reason the line isn’t there is because the dataset is so large that is creates a memory issue so we need to create the plot ourselves using code the developers of the package see provided to us on Twitter. The default code would try to draw confidence intervals around the line which is what causes the memory issue, this code removes that with se = FALSE.\nPlease note that with most datasets you wouldn’t have to do this extra step, but it’s a good example that when it comes to programming, it doesn’t matter how long you’ve been doing it, there will always be a problem you haven’t come across and that asking for help is part of the process.\n\nggplot(assumptions$HOMOGENEITY, aes(x, y)) +\n    geom_point2() +\n    stat_smooth(\n      method = \"loess\",\n      se = FALSE,\n      formula = y ~ x,\n    ) +\n    labs(\n      title = \"Homogeneity of Variance\",\n      subtitle = \"Reference line should be flat and horizontal\",\n      y = expression(sqrt(\"|Std. residuals|\")),\n      x = \"Fitted values\"\n    ) \n\n\n\nAdjusted homogeneity plot that will produce reference line\n\n\n\nAgain like normality, the plot isn’t perfect but it is pretty good and another example of why visualisation is better than running statistical tests as we see the same significant result if we run:\n\ncheck_homogeneity(mod)\n\nWarning: Variances differ between groups (Bartlett Test, p = 0.000).\n\n\nFor assumption 8, linearity, again the plot looks fine, and we could also have used the grouped scatterplots above to look at this.\nFinally, for assumption 9, multicollinearity, the plot also indicates no issues but we can also test this statistically using check_collinearity().\nEssentially, this function estimates how much the variance of a coefficient is “inflated” because of linear dependence with other predictors, i.e., that a predictor isn’t actually adding any unique variance to the model, it’s just really strongly related to other predictors. You can read more about this here. Thankfully, VIF is not affected by large samples like the other tests.\nThere are various rules of thumb, but most converge on a VIF of above 2 - 2.5 for any one predictor being problematic.\n\ncheck_collinearity(mod)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTerm\nVIF\nVIF_CI_low\nVIF_CI_high\nSE_factor\nTolerance\nTolerance_CI_low\nTolerance_CI_high\n\n\n\nthours_c\n1.721968\n1.704219\n1.740165\n1.312238\n0.5807308\n0.5746582\n0.5867789\n\n\nmale_c\n1.035552\n1.028488\n1.044369\n1.017621\n0.9656682\n0.9575159\n0.9723014\n\n\nthours_c:male_c\n1.716349\n1.698683\n1.734463\n1.310095\n0.5826319\n0.5765474\n0.5886915"
  },
  {
    "objectID": "17-multiple-regression.html#mulregression-a10",
    "href": "17-multiple-regression.html#mulregression-a10",
    "title": "\n16  Multiple regression\n",
    "section": "\n16.10 Activity 10: Power and effect size",
    "text": "16.10 Activity 10: Power and effect size\nFinally, we’ll calculate power and effect size as usual.\n\nUsing the code from Power and Effect Size calculate the minimum effect size we could reliably observe given our sample size and design but for 99% power. Report this to 2 decimal places \n\n\n\nWhat is the observed effect size for the study to 2 decimal places? \n\nIs the study sufficiently powered? \nYes\nNo"
  },
  {
    "objectID": "17-multiple-regression.html#mulregression-a11",
    "href": "17-multiple-regression.html#mulregression-a11",
    "title": "\n16  Multiple regression\n",
    "section": "\n16.11 Activity 11: Write-up",
    "text": "16.11 Activity 11: Write-up\nSame as the simple regression, we can use inline coding or the report() function to help with the write-up. First, copy and paste the below code into white-space and then knit the document. Note that the p-values are entered manually because of the APA p &lt; .001 formatting.\n\nAll continuous predictors were mean-centered and deviation coding was used for categorical predictors. The results of the regression indicated that the model significantly predicted course engagement (F(`r mod_summary$fstatistic[2]`, `r mod_summary$fstatistic[3] %&gt;% round(2)`) = `r mod_summary$fstatistic[1] %&gt;% round(2)`, p &lt; .001, Adjusted R2 = `r mod_summary$adj.r.squared %&gt;% round(2)`, f^2^ = .63), accounting for `r (mod_summary$adj.r.squared %&gt;% round(2))*100`% of the variance. Total screen time was a significant negative predictor of wellbeing scores (β = `r mod$coefficients[2] %&gt;% round(2)`, p &lt; .001, as was gender (β = `r mod$coefficients[3] %&gt;% round(2)`, p &lt; .001, with girls having lower wellbeing scores than boys. Importantly, there was a significant interaction between screentime and gender (β = `r mod$coefficients[4] %&gt;% round(2)`, p &lt; .001), smartphone use was more negatively associated with wellbeing for girls than for boys. \n\n\nAll continuous predictors were mean-centered and deviation coding was used for categorical predictors. The results of the regression indicated that the model significantly predicted course engagement (F(3, 7.1029^{4}) = 2450.89, p &lt; .001, Adjusted R2 = 0.09, f2 = .63), accounting for 9% of the variance. Total screen time was a significant negative predictor of well-being scores (β = -0.77, p &lt; .001, as was gender (β = 5.14, p &lt; .001, with girls having lower well-being scores than boys. Importantly, there was a significant interaction between screen time and gender (β = 0.45, p &lt; .001), smartphone use was more negatively associated with well-being for girls than for boys.\n\nNow, we can use report() to produce an automated summary. Again, it would need some editing but may be useful to aid interpretation and reporting.\n\nreport(mod)\n\nWe fitted a linear model (estimated using OLS) to predict tot_wellbeing with\nthours_c and male_c (formula: tot_wellbeing ~ thours_c * male_c). The model\nexplains a statistically significant and weak proportion of variance (R2 =\n0.09, F(3, 71029) = 2450.89, p &lt; .001, adj. R2 = 0.09). The model's intercept,\ncorresponding to thours_c = 0 and male_c = -0.5, is at 44.87 (95% CI [44.78,\n44.96], t(71029) = 1001.87, p &lt; .001). Within this model:\n\n  - The effect of thours c is statistically significant and negative (beta =\n-0.77, 95% CI [-0.82, -0.73], t(71029) = -32.96, p &lt; .001; Std. beta = -0.15,\n95% CI [-0.16, -0.15])\n  - The effect of male c [0.5] is statistically significant and positive (beta =\n5.14, 95% CI [5.00, 5.28], t(71029) = 72.25, p &lt; .001; Std. beta = 0.54, 95% CI\n[0.52, 0.55])\n  - The effect of thours c × male c [0.5] is statistically significant and\npositive (beta = 0.45, 95% CI [0.38, 0.52], t(71029) = 12.24, p &lt; .001; Std.\nbeta = 0.09, 95% CI [0.08, 0.11])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation."
  },
  {
    "objectID": "17-multiple-regression.html#mulregression-fin",
    "href": "17-multiple-regression.html#mulregression-fin",
    "title": "\n16  Multiple regression\n",
    "section": "\n16.12 Finished!",
    "text": "16.12 Finished!\nAnd you’re done! Not just with this week but with the R component of RM2! The progress that you have made is truly astonishing. Even if you struggled with R and haven’t quite understood every single line of code we’ve shown, what you’re capable of with data wrangling and visualisation alone makes you some of the most highly competitive psychology graduates in the world.\nRegardless of whether you continue with quantitative methods and using R, remember the more important critical skills that you have learned as part of this process. The next time you see a dataset or you see data being talked about in the news, think about all work that was put into getting the data into the final format. More importantly, think about all the decisions that the researcher needed to make along the way and how that might have affected the outcome."
  },
  {
    "objectID": "17-multiple-regression.html#mulregression-sols",
    "href": "17-multiple-regression.html#mulregression-sols",
    "title": "\n16  Multiple regression\n",
    "section": "\n16.13 Activity solutions",
    "text": "16.13 Activity solutions\n\n16.13.1 Activity 3\n\n\nSolution\n\n\nwemwbs &lt;- wellbeing %&gt;%\n  pivot_longer(names_to = \"var\", values_to = \"score\", -Serial) %&gt;%\n  group_by(Serial) %&gt;%\n  summarise(tot_wellbeing = sum(score))\n\n# sanity check values\n\nwemwbs %&gt;% summarise(mean = mean(tot_wellbeing),\n                     sd = sd(tot_wellbeing),\n                     min = min(tot_wellbeing), \n                     max = max(tot_wellbeing))\n\n\n\n16.13.2 Activity 5\n\n\nSolution\n\n\nsmarttot &lt;- screen2 %&gt;%\n  filter(variable == \"Using Smartphone\") %&gt;%\n  group_by(Serial) %&gt;%\n  summarise(tothours = mean(hours))\n\nsmart_wb &lt;- smarttot %&gt;%\n  filter(tothours &gt; 1) %&gt;%\n  inner_join(wemwbs, \"Serial\") %&gt;%\n  inner_join(pinfo, \"Serial\") \n\n\n\n16.13.3 Activity 6\n\n\nSolution\n\n\nsmart_wb &lt;- smarttot %&gt;%\n  filter(tothours &gt; 1) %&gt;%\n  inner_join(wemwbs, \"Serial\") %&gt;%\n  inner_join(pinfo, \"Serial\") %&gt;%\n  mutate(thours_c = tothours - mean(tothours),\n         male_c = ifelse(male == 1, .5, -.5),\n         male_c = as.factor(male_c),\n         male = as.factor(male))\n\n\n\n16.13.4 Activity 7\n\n\nSolution\n\n\nsmart_wb_gen &lt;- smart_wb %&gt;%\n  group_by(tothours, male) %&gt;%\n  summarise(mean_wellbeing = mean(tot_wellbeing))\n\nggplot(smart_wb_gen, aes(tothours, mean_wellbeing, color = male)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  scale_color_discrete(name = \"Gender\", labels = c(\"Female\", \"Male\"))+\n  scale_x_continuous(name = \"Total hours smartphone use\") +\n  scale_y_continuous(name = \"Mean well-being score\")\n\n\n\n16.13.5 Activity 8\n\n\nSolution\n\n\nmod &lt;- lm(tot_wellbeing ~ thours_c * male_c, smart_wb)\n# alternatively: \n# mod &lt;- lm(tot_wellbeing ~ thours_c + male_c + thours_c:male_c, smart_wb)\n\nmod_summary &lt;- summary(mod)\n\n\n\n16.13.6 Activity 9\n\n\nSolution\n\n\nqqPlot(mod$residuals)\n\n\n\n16.13.7 Activity 10\n\n\nSolution\n\n\npwr.f2.test(u = 3, v = 71029, f2 = NULL, sig.level = .05, power = .99)\nf2 &lt;- mod_summary$adj.r.squared/(1 - mod_summary$adj.r.squared)"
  },
  {
    "objectID": "11-power.html#designing-studies",
    "href": "11-power.html#designing-studies",
    "title": "\n10  Power and Effect Sizes\n",
    "section": "\n10.1 Designing Studies",
    "text": "10.1 Designing Studies\nTo reiterate, power is defined as the probability of correctly rejecting the null hypothesis for a fixed effect size and fixed sample size. As such, power is a key decision when you design your study, under the premis that the higher the power of your planned study, the better.\nTwo relationships you will learn in this chapter are that:\n\nfor a given sample size and \\(\\alpha\\), the power of your study is higher if the effect you are looking for is assumed to be a large effect as opposed to a small effect; large effects are easier to detect.\nand, for a given effect size and \\(\\alpha\\), the power of your study is higher when you increase your sample size.\n\nFrom these relationships we see that, because you have little control over the size of the effect you are trying to detect (it lives in the real world which you don’t control), you can instead increase the power of your study by increasing the size of your sample (and also reducing sources of noise and measurement error in your study). As such, when planning a study, any good researcher will consider the following four key elements - and we thank Dr Ian Walker (University of Bath) for the excellent acronym - the APES:\n\n\nalpha - most commonly thought of as the significance level (i.e., your p-value); usually set at \\(\\alpha = .05\\)\n\n\npower - the probability of correctly rejecting the null hypothesis for a given effect size and sample size, typically set at \\(power = .8\\).\n\neffect size - size of the relationship/difference between two variables\n\nsample size - the number of observations (usually, participants, but sometimes also stimuli) in your study.\n\nAnd the beautiful thing is that if you know three of these elements then you can calculate the fourth. The two most common calculations prior to a study would be:\n\nto determine the appropriate sample size required to obtain the effect size that you are interested in. That is, prior to the experiment you decide you would be interested in testing for a small, medium, or large effect sizes, so you know everything except the sample size - how many people you need to run in your study. Generally, the smaller the effect size, the more participants you will need, assuming power and alpha are held constant at .8 and .05 respectively.\n\n\nHere you know alpha, the power, and the effect size and you want to know the sample size.\n\n\nto determine the smallest effect size you can reliably detect given your sample size. For example, you know everything except the effect size. For example, say you are taking a secondary datadata that has been collected already and made available to you to ask research questions of. approach and using an open dataset, and you know they have run 100 participants, you can’t add any more participants, but you want to know what is the minimum effect size you could reliably detect in this dataset.\n\n\nHere you know alpha, the power, and the sample size and you want to know the smallest effect size you can determine.\n\nHopefully that gives you an idea of how we use power to determine sample sizes for studies - and that the sample size should not just be pulled out of thin air. Both of these approaches described above a priori power analyses as you are stating the power level you want before (a priori means before) the study - though the second approach of determining the smallest effect size you can determine based on a known sample size is also referred to as a sensitivity power analysis. However, you may now be thinking though, if everything is connected, then can we use the effect size from our study and the sample size to determine the power of the study after we have run it? No! Well, you can but it would be wrong to do so. This is actually called Observed or Post-Hoc power and most papers would discourage you from calculating it on the grounds that the effect size you are using is not the true effect size of the population you are interested in; it is just the effect size of your sample. As such any indication of power from this analysis is misleading. Avoid doing this. You can read more about why, here, in your own time if you like: Lakens (2014) Observed Power, and what to do if your editor asks for post-hoc power analyses. In brief, Observed Power conflates the effect size of the sample with the effect size within the population and those two are not the same. Stick to using only a priori power analyses approaches and use them to determine your required sample size or achievable reliable effect size.\nSo let’s jump into this a bit now and start running some analyses to help further our understanding of alpha, power, effect sizes and sample size! We will start by looking at effect sizes, before moving on to calculating power."
  },
  {
    "objectID": "11-power.html#effect-size-by-hand",
    "href": "11-power.html#effect-size-by-hand",
    "title": "\n10  Power and Effect Sizes\n",
    "section": "\n10.2 Effect Size By Hand",
    "text": "10.2 Effect Size By Hand\nThere are a number of different “effect sizes” that you can choose to calculate but a common one for t-tests, as we have seen previously, is Cohen’s d: the standardised difference between two means (in units of SD) and is written as d = effect-size-value. The key point is that Cohen’s d is a standardised difference, meaning that it can be used to compare against other studies regardless of how the measurement was made. Take for example height differences in men and women which is estimated at about 5 inches (12.7 cm). That in itself is an effect size, but it is an unstandardised effect size in that for every sample that you test, that difference is dependent on the measurement tools, the measurement scale, and the errors contained within them (Note: ask Helena about the time she photocopied some rulers). As such using a standardised effect size allows you to make comparisons across studies regardless of measurement error. In standardised terms, the height difference above is considered a medium effect size (d = 0.5) which Cohen (1988, as cited by Schafer and Schwarz (2019)) defined as representing “an effect likely to be visible to the naked eye of a careful observer”. Cohen (1988) in fact stated three sizes of Cohen’s d that people could use as a guide:\n\n\n\nEffect size\nCohen’s d value\n\n\n\nsmall to medium\n.2 to .5\n\n\nmedium to large\n.5 to .8\n\n\nlarge\n&gt; .8\n\n\n\n\nYou may wish to read this paper later about different effect sizes in psychology - Schafer and Schwarz (2019) The Meaningfulness of Effect Sizes in Psychological Research: Differences Between Sub-Disciplines and the Impact of Potential Biases.\nThe thing to note is that the formula is slightly different depending on the type of t-test used and it can sometimes change depending on who you read. For this worksheet, let’s go with the following formulas:\n\nOne-sample t-test & paired-sample t-test:\n\n\\[d = \\frac{t}{\\sqrt{N}}\\]\n\nIndependent t-test:\n\n\\[d = \\frac{2 \\times t}{\\sqrt{df}}\\]\nLet’s now try out some calculations. We will start with just looking at effect sizes from t-tests before calculating power in later tasks.\n\n10.2.0.1 Activity 1: Set-up\n\nOpen RStudio and set the working directory to your chapter folder. Ensure the environment is clear.\n\nIf you’re using the Rserver, avoid a number of issues by restarting the session - click Session - Restart R\n\n\n\nOpen a new R Markdown document and save it in your working directory. Call the file “APES”.\nDelete the default R Markdown welcome text and insert a new code chunk that loads the following packages, in this specific order, using the library() function. Remember the solutions if needed.\n\nLoad the packages in this order, pwr, and tidyverse\n\nwe have not used the pwr package before so you will likely need to install them using install.packages(). Remember though that you should only do this on your own machine and only in the console window. If you are using the RServer you will not need to install them.\n\n\n\n10.2.0.2 Activity 2: Effect size from a one-sample t-test\n\nYou run a one-sample t-test and discover a significant effect, t(25) = 3.24, p &lt; .05. Using the above formulas, calculate d and determine whether the effect size is small, medium or large.\n\n\n\nHelpful hint\n\n\n\nUse the appropriate formula from above for the one-sample t-tests.\nYou have been given a t-value and df (degrees of freedom), you still need to determine n before you calculate d.\nAccording to Cohen (1988), the effect size is small (.2 to .5), medium (.5 to .8) or large (&gt; .8).\n\n\n\nAnswering the following questions to check your answers. The solutions are at the bottom if you need them:\n\nEnter, in digits, how many people were run in this study: \n\nWhich of these codes is the appropriate calculation of d in this instance:\nd = t/sqrt(N)\nd = 2t/sqrt(df)\n\nEnter the correct value of d for this analysis rounded to 2 decimal places: \n\nAccording to Cohen (1988), the effect size for this t-test would probably be considered: \nsmall to medium\nmedium to large\nlarge\n\n\n10.2.0.3 Activity 3: Effect size from between-subjects t-test\n\nYou run a between-subjects t-test and discover a significant effect, t(30) = 2.9, p &lt; .05. Calculate d and determine whether the effect size is small, medium or large.\n\n\n\nHelpful hint\n\n\n\nUse the appropriate formula above for between-subjects t-tests.\nAccording to Cohen (1988), the effect size is small (.2 to .5), medium (.5 to .8) or large (&gt; .8).\n\n\n\nAnswer the following questions to check your answers. The solutions are at the bottom if you need them:\n\nEnter, in digits, how many people were run in this study: \n\nWhich of these codes is the appropriate calculation of d in this instance:\nd = t/sqrt(N)\nd = 2t/sqrt(df)\n\nEnter the correct value of d for this analysis rounded to 2 decimal places: \n\nAccording to Cohen (1988), the effect size for this t-test would probably be considered: \nsmall to medium\nmedium to large\nlarge\n\n\n10.2.0.4 Activity 4: t-value and effect size for a between-subjects Experiment\n\nYou run a between-subjects design study and the descriptives tell you: Group 1, M = 10, SD = 1.3, n = 30; Group 2, M = 11, SD = 1.7, n = 30. Calculate t and d for this between-subjects experiment.\nNote: the hint contains the appropriate t-test formula if you are unsure.\n\n\n\nHelpful hint\n\n\n\nBefore you can calculate d (using the appropriate formula for a between-subjects experiment), you need to first calculate t using the formula:\n\nt = (Mean1 - Mean2)/sqrt((var1/n1) + (var2/n2))\n\n\nvar stands for variance in the above formula. Variance is not the same as the standard deviation, right? Variance is measured in squared units. So for this equation, if you require variance to calculate t and you have the standard deviation, then you need to remember that var = SD^2.\nNow you have your t-value, but for calculating d you also need degrees of freedom. Think about how you would calculate df for a between-subjects experiment, taking n for both Group 1 and Group 2 into account.\nRemember that convention is that people report the t and d values as positive.\n\n\n\nAnswer the following questions to check your answers. The solutions are at the bottom if you need them:\n\nEnter the correct t-value for this test, rounded to two decimal places: \nWhich of these codes is the appropriate calculation of d in this instance:\nd = t/sqrt(N)\nd = 2t/sqrt(df)\nBased on the above t-value above, enter the correct value of d for this analysis rounded to 2 decimal places: \nAccording to Cohen (1988), the effect size for this t-test would probably be described as: \nsmall to medium\nmedium to large\nlarge\n\nExcellent! Now that you are comfortable with calculating effect sizes, we will look at using them to establish the sample size for a required power. One thing you will realise as we progress is that the true effect size in a population is something we do not know, but we need to justify one for our design. A clever approach is laid out by Daniel Lakens in the blog on the Smallest Effect Size of Interest (SESOI) - you set the smallest effect that you as a researcher would be interested in! This can be determined through theoretical analysis, through previous studies, through pilot studies, or through rules of thumb like Cohen (1988). However, also keep in mind that the lower the effect size, the larger the sample size you will need. Everything is a trade-off."
  },
  {
    "objectID": "11-power.html#power-calculations",
    "href": "11-power.html#power-calculations",
    "title": "\n10  Power and Effect Sizes\n",
    "section": "\n10.3 Power Calculations",
    "text": "10.3 Power Calculations\nToday we will use the functions pwr.t.test(), pwr.r.test() and pwr.chisq.test from the package pwr to run power calculations for t-tests, correlations and chi-square.\n\n10.3.1 t-tests\nRemember that for more information on a function, for example pwr.t.test(), simply do ?pwr.t.test in the console. Or you can have a look at these webpages later to get an idea (or bad ideas if you spot where they erroneously calculate post-hoc power!):\n\nA quick-R summary of the pwr package - https://www.statmethods.net/stats/power.html\n\nthe pwr package vignette -  https://cran.r-project.org/web/packages/pwr/vignettes/pwr-vignette.html\n\n\nFrom these you will see that pwr.t.test() takes a series of inputs:\n\n\nn - Number of observations/participants, per group for the independent samples version, or the number of subjects or matched pairs for the paired and one-sample designs.\n\nd - the effect size of interest (Cohen’s d) - difference between the means divided by the pooled standard deviation\n\nsig.level - the significance level (False Positive Rate) or \\(\\alpha\\)\n\n\npower - the power of test (1 minus False Negative Rate) or \\(1-\\beta\\)\n\n\ntype - the type of t test : one.sample, two.sample, or paired\n\n\nalternative - the type of hypothesis; \"two.sided\", \"greater\", \"less\"\n\n\nAnd the function works on a leave one out principle. You give it all the information you have and it returns the element you are missing. So, for example, say you needed to know how many people per group (n) you would need to detect an effect size of d = 0.4 with power = .8, alpha = .05 in a two.sample (between-subjects) t-test on a two.sided hypothesis test.\n\n10.3.1.1 Activity 5: pwr.t.test()\n\n\nRun the below code:\n\n\npwr.t.test(d = .4,\n           power = .8,\n           sig.level = .05,\n           alternative = \"two.sided\",\n           type = \"two.sample\")\n\nThe output tells you that you would need 99.0803248 people per condition. But you only get whole people and we like to be conservative on our estimates so we would actually run 100 per condition. That is a lot of people!!!\nTo make the output of pwr.t.test() easier to work with, we’re going to amend the code to just give us exactly the number that we want.\n\n\npluck() will pull out the value from the analysis that we want. e.g. pluck(\"n\") will give us the sample size and pluck(\"d\") will give us the effect size.\n\nceiling() rounds up to give us the next highest whole number\n\n\npwr.t.test(d = .4,\n           power = .8,\n           sig.level = .05,\n           alternative = \"two.sided\",\n           type = \"two.sample\") %&gt;% \n  pluck(\"n\") %&gt;%\n  ceiling()\n\nNote: ceiling() is better to use than round() when dealing with people as it always rounds up. For example, ceiling(1.1) gives you 2. round() on the other hand is useful for rounding an effect size, for example, to two decimal places - e.g. d = round(.4356, 2) would give you d = 0.44. So use ceiling() for sample sizes and round() for effect sizes.\n\n10.3.1.2 Activity 6: Sample size for standard power one-sample t-test\n\nAssuming you are interested in detecting a minimum Cohen’s d of d = 0.23, what would be the minimum number of participants you would need in a one-sample t-test, assuming power = .8, \\(\\alpha\\) = .05, on a two-sided hypothesis?\n\nUsing a pipeline, store the answer as a single, rounded value called sample_size_t (i.e. use pluck() %&gt;% ceiling()).\n\n\nHelpful hint\n\n\n\nUse the list of inputs above as a kind of check-list to clearly determine which inputs are known or unknown. This can help you enter the appropriate values to your code.\nThe structure of the pwr.t.test() would be very similar to the one shown above except two.sample would become one.sample\nYou will also need to use pluck(\"n\") to help you obtain the sample size and %&gt;% ceiling() to round up to the nearest whole participant.\n\n\n\nAnswer the following question to check your answers. The solutions are at the bottom if you need them:\n\nEnter the minimum number of participants you would need in this one-sample t-test: \n\n\n10.3.1.3 Activity 7: Effect size from a high power between-subjects t-test\n\nAssuming you run a between-subjects t-test with 50 participants per group and want a power of .9, what would be the minimum effect size you can reliably detect? Assume standard \\(\\alpha\\) and alternative hypothesis settings.\n\nAnswer the following questions to check your answers. The solutions are at the bottom if you need them:\n\nBased on the information given, what will you set type as in the function?\n\none.sampletwo.sample\n\n\nBased on the output, enter the minimum effect size you can reliably detect in this test, rounded to two decimal places: \n\nAccording to Cohen (1988), the effect size for this t-test is\n\nsmall to mediummedium to largelarge\n\n\nSay you run the study and find that the effect size determined is d = 0.50. Given what you know about power, select the statement that is true:\n\nthe study is sufficiently powered as the analysis indicates you can detect only effect sizes smaller than d = 0.65the study is underpowered as the analysis indicates you can detect only effect sizes larger than d = 0.65\n\n\n\n10.3.1.4 Uneven groups\nThere is an additional function that is very worthwhile knowing about called pwr.t2n.test() that allows you to run power analyses for t-tests where there are uneven sample sizes in the two groups. For instance, say you wanted to know the minimum effect size you could determine in a between-subjects t-test where you have 25 participants in one group and 30 participants in the second group. The additional aspect of this function is that instead of n =, you would do:\n\n\nn1 = ... for the number of people in group 1\n\nn2 = ... for the number of people in group 2\nnote that there is no type argument in this function because it has to be two samples.\n\nAssuming \\(\\alpha = .05\\), Power = .8, and it is a two-tailed test, you would do:\n\npwr.t2n.test(n1 = 25,\n             n2 = 30,\n             power = .8,\n             sig.level = .05,\n             alternative = \"two.sided\") %&gt;%\n  pluck(\"d\") %&gt;%\n  round(3)\n\n[1] 0.773\n\n\nMeaning that the minimum effect size you could determine would be d = 0.773.\n\n10.3.2 Correlations\nNow, we’re going to do the same thing but for a correlation analysis using pwr.r.test. The structure of this function is very similar to pwr.t.test() and works on the same leave-one-out principle:\n\n\nn - Number of observations\n\nr - Correlation coefficient\n\nsig.level - Significance level (Type I error probability)\n\npower - Power of test (1 minus Type II error probability)\n\nalternative - a character string specifying the alternative hypothesis, must be one of two.sided (default), greater (a positive correlation) or less (a negative correlation).\n\n\n10.3.2.1 Activity 8: Sample size for a correlation\n\nAssuming you are interested in detecting a minimum correlation of r = .4 (in either direction), what would be the minimum number of participants you would need for a correlation analysis, assuming power = .8, \\(\\alpha\\) = .05?\n\nUsing a pipeline, store the answer as a single, rounded value called sample_size_r (i.e. use pluck() %&gt;% ceiling()).\n\nEnter the minimum number of participants you would need in this correlation: \n\n\n10.3.2.2 Activity 9: Effect size for a correlation analysis\n\nYou run a correlation analysis with 50 participants and the standard power and alpha levels and you have hypothesised a positive correlation, what would be the minimum effect size you can reliably detect? Answer the following questions to check your answers. The solutions are at the bottom if you need them:\nBased on the information given, what will you set alternative as in the function? \ntwo.sided\ngreater\nless\nBased on the output, enter the minimum effect size you can reliably detect in this test, rounded to two decimal places: \nAccording to Cohen (1988), the effect size for this correlation is \nsmall to medium\nmedium to large\nlarge\n\nSay you run the study and find that the effect size determined is d = 0.24. Given what you know about power, select the statement that is true:\n\nthe study is sufficiently powered as the analysis indicates you can detect only effect sizes smaller than d = 0.24the study is underpowered as the analysis indicates you can detect only effect sizes larger than d = 0.34\n\n\n\n10.3.3 Effect Sizes in Published Research\n\n10.3.3.1 Activity 10: Power of published research\nThus far we have used hypothetical situations - now go look at the paper on the Open Stats Lab website called Does Music Convey Social Information to Infants? (we have used this dataset in the t-test chapter). You can download the pdf and look at it, but here we will determine the power of the significant t-tests reported in Experiment 1 under the Results section on Pg489. There is a one-sample t-test and a paired-samples t-test to consider, summarised below. Assume testing was at power = .8, alpha = .05. Based on your calculations are either of the stated effects underpowered?\n\none-sample: t(31) = 2.96, p = .006, d = 0.52\npaired t-test: t(31) = 2.42, p = .022, d= 0.43\n\n\n\nHelpful hint\n\n\n\nTo calculate n: n = df + 1.\n\n\n\nWhich of the t-tests do you believe to be underpowered? Why do you think this may be? Additional information about this can be found in the solution to task 8 at the end of this activity.\nOne caveat to Task 10: We have to keep in mind that here we are looking at single studies using one sample from a potentially huge number of samples within a population. As such there will be a degree of variance in the true effect size within the population regardless of the effect size of one given sample. What that means is we have to be a little bit cautious when making claims about a study. Ultimately the higher the power the better as you can detect smaller effect sizes!"
  },
  {
    "objectID": "11-power.html#power-fin",
    "href": "11-power.html#power-fin",
    "title": "\n10  Power and Effect Sizes\n",
    "section": "\n10.4 Finished!",
    "text": "10.4 Finished!\nGreat! Hopefully you are now starting to see the interaction between alpha, power, effect sizes, and sample size. We should always want really high powered studies and depending on the size of the effect we are interested in (small to large), and our \\(\\alpha\\) level, this will mean we will need to run more or less participants to make sure our study is well powered. Points to note:\n\nLowering the \\(\\alpha\\) level (e.g. .05 to .01) will reduce the power.\nLowering the effect size (e.g. .8 to .2) will reduce the power.\nIncreasing power (.8 to .9) will require more participants.\n\nA high-powered study looking to detect a small effect size at a low alpha will require a large number of participants!\nThere are additional functions in the pwr package for other types of statistical analyses. We will include these calculates as part of the ANOVA and regression chapters.\nIf you want more examples of power to reinforce your understanding, go back and calculate the power of the t-tests, correlations, and chi-squares from earlier chapters."
  },
  {
    "objectID": "11-power.html#test-yourself",
    "href": "11-power.html#test-yourself",
    "title": "\n10  Power and Effect Sizes\n",
    "section": "\n10.5 Test Yourself",
    "text": "10.5 Test Yourself\n\nAssuming you were running a between-subjects t-test on secondary data (\\(\\alpha = .05\\), Power = .8, alternative = two-tailed) and that this secondary data has 100 participants in both groups. The smallest effect size, to three decimal places, you could determine with this data is:\n\nd = 0.280d = 0.281d = 0.398d = 0.399\n\n\n\n\n\nSolution\n\nThe code for this test would be:\n\npwr.t.test(n = 100, \n           sig.level = .05, \n           power = .8,\n           type = \"two.sample\",\n           alternative = \"two.sided\") %&gt;% \n  pluck(\"d\") %&gt;% \n  round(3)\n\n\nMeaning that the smallest effect size would be d = 0.39\n\n\n\nAssuming you were running a between-subjects t-test on secondary data (\\(\\alpha = .05\\), Power = .8, alternative = two-tailed) and that this secondary data has 60 participants in Group 1 and 40 participants in Group 2. The smallest effect size, to three decimal places, you could determine with this data is:\n\nr = .577d = 0.577d = 0.578r = .578\n\n\n\n\n\nSolution\n\nThe code for this test would be:\n\npwr.t2n.test(n1 = 60,\n           n2 = 40,\n           sig.level = .05, \n           power = .8,\n           alternative = \"two.sided\") %&gt;% \n  pluck(\"d\") %&gt;% \n  round(3)\n\n\nMeaning that the smallest effect size would be d = 0.578\n\n\n\nAssuming you ran a correlation on secondary data (\\(\\alpha = .05\\), Power = .8, alternative = two-tailed) and that this secondary data has 50 observations. The smallest effect size, to three decimal places, you could determine with this data is:\n\nr = .276r = .385r = .384r = .275\n\n\n\n\n\nSolution\n\nThe code for this test would be:\n\npwr.r.test(n = 50,\n           sig.level = .05, \n           power = .8,\n           alternative = \"two.sided\") %&gt;% \n  pluck(\"r\") %&gt;% \n  round(3)\n\n\nMeaning that the smallest effect size would be r = .384"
  },
  {
    "objectID": "11-power.html#power-sols",
    "href": "11-power.html#power-sols",
    "title": "\n10  Power and Effect Sizes\n",
    "section": "\n10.6 Activity solutions",
    "text": "10.6 Activity solutions\nBelow you will find the solutions to the above questions. Only look at them after giving the questions a good try and trying to find help on Google or Teams about any issues.\n\n10.6.0.1 Activity 1\n\nlibrary(pwr)\nlibrary(broom)\nlibrary(tidyverse)\n\n\n10.6.0.2 Activity 2\n\nd &lt;- 3.24 / sqrt(25 +1)\n\n# effect is medium to large; d = .64\n\n\n10.6.0.3 Activity 3\n\nd &lt;- (2*2.9) / sqrt(30)\n\n# effect is large; d = 1.06\n\n\n10.6.0.4 Activity 4\n\nt = (10 - 11)/sqrt((1.3^2/30) + (1.7^2/30))\n\nd = (2*t)/sqrt((30-1) + (30-1))\n\n# t = 2.56\n# d = .67\n\n# Remember that convention is that people report the t and d as positive.\n\n\n10.6.0.5 Activity 6\n\nsample_size_t &lt;- pwr.t.test(d = .23,\n                            power = .8, \n                            sig.level = .05, \n                            alternative = \"two.sided\", \n                            type = \"one.sample\") %&gt;% pluck(\"n\") %&gt;% ceiling()\n\nsample_size_t\n[1] 151\n\n\n10.6.0.6 Activity 7\n\npwr.t.test(n = 50,\n           power = .9, \n           sig.level = .05, \n           alternative = \"two.sided\", \n           type = \"two.sample\") %&gt;%\n  pluck(\"d\") %&gt;%\n  round(2)\n[1] 0.65\n\n\n10.6.0.7 Activity 8\n\nsample_size_r &lt;- pwr.r.test(r = .4, \n                            sig.level = .05, \n                            power = .8, \n                            alternative = \"two.sided\") %&gt;%\n  pluck(\"n\") %&gt;% \n  ceiling()\n\n\n10.6.0.8 Activity 9\n\npwr.r.test(n = 50,\n           sig.level = .05, \n           power = .8, \n           alternative = \"greater\") %&gt;%\n  pluck(\"r\") %&gt;%\n  round(3)\n[1] 0.344\n\n\n10.6.0.9 Activity 10\nAchievable Cohen d for Example 1\n\npwr.t.test(power = .8, \n           n = 32, \n           type = \"one.sample\", \n           alternative = \"two.sided\", \n           sig.level = .05) %&gt;%\n  pluck(\"d\") %&gt;%\n  round(2)\n[1] 0.51\n\n\nGiving an achievable effect size of 0.51 and they found an effect size of 0.52.\n\nThis study seems ok as the authors could achieve an effect size as low as .51 and found an effect size at .52\nAchievable Cohen d for Example 2\n\npwr.t.test(power = .8, \n           n = 32, \n           type = \"paired\", \n           alternative = \"two.sided\", \n           sig.level = .05) %&gt;%\n  pluck(\"d\") %&gt;%\n  round(2)\n[1] 0.51\n\n\nGiving an achievable effect size of 0.51 and they found an effect size of 0.43.\n\nThis effect might not be reliable given that the effect size found was much lower than the achievable effect size. The issue here is that the researchers established their sample size based on a previous effect size and not on the minimum effect size that they would find important. If an effect size as small as .4 was important then they should have powered all studies to that level and ran the appropriate n ~52 babies (see below). Flipside of course is that obtaining 52 babies isnt easy; hence why some people consider the Many Labs approach a good way ahead.\nONE CAVEAT to the above is that before making the assumption that this study is therefore flawed, we have to keep in mind that this is one study using one sample from a potentially huge number of samples within a population. As such there will be a degree of variance in the true effect size within the population regardless of the effect size of one given sample. What that means is we have to be a little bit cautious when making claims about a study. Ultimately the higher the power the better.\nBelow you could calculate the actual sample size required to achieve a power of .8:\n\nsample_size &lt;- pwr.t.test(power = .8,\n                          d = .4, \n                          type = \"paired\", \n                          alternative = \"two.sided\",\n                          sig.level = .05) %&gt;%\n  pluck(\"n\") %&gt;% \n  ceiling()\n\nsample_size\n[1] 52\n\n\nSuggesting a sample size of n = 52 would be appropriate."
  },
  {
    "objectID": "11-power.html#words-from-this-chapter",
    "href": "11-power.html#words-from-this-chapter",
    "title": "\n10  Power and Effect Sizes\n",
    "section": "\n10.7 Words from this Chapter",
    "text": "10.7 Words from this Chapter\nBelow you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the PsyTeachR Glossary. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter.\n\n\n\n\nterm\ndefinition\n\n\n\nalpha\nThe threshold chosen in Neyman-Pearson hypothesis testing to distinguish test results that lead to the decision to reject the null hypothesis, or not, based on the desired upper bound of the Type 1 error rate. An alpha level of 5% it most commonly used, but other alpha levels can be used as long as they are determined and preregistered by the researcher before the data is analyzed.\n\n\nbeta\n\n\n\nfalse negative\n\n\n\nfalse positive\n\n\n\nhypothesis\n\n\n\npower\n\n\n\nprobability\n\n\n\nreplicability\n\n\n\nsample\n\n\n\nsecondary data\ndata that has been collected already and made available to you to ask research questions of."
  },
  {
    "objectID": "11-power.html#additional-information",
    "href": "11-power.html#additional-information",
    "title": "\n10  Power and Effect Sizes\n",
    "section": "\n10.8 Additional Information",
    "text": "10.8 Additional Information\n\n10.8.1 A blog on how to choose an effect size of interest\nA really quick analogy from Ian Walker’s “Research Methods and statistics”, is say your test is not a stats test but a telescope. And say you have a telescope that is specifically designed only for spotting animals that are the size of elephants or larger (similar to saying a cohens d of .8 or greater for example - very big effect). If your telescope can only reliably detect something down to the size of an elephant but when you look through it you see something smaller that you think might be a mouse, you can’t say that the “object”” is definitely is a mouse as you don’t have enough power in your telescope - it is too blurry. But likewise you can’t rule out that it isn’t a mouse as that would be something you don’t know for sure - both of these are true because your telescope was only designed to spot things the size of an elephant or larger. You only bought a telescope that was able to spot elephants because that was all your were interested in. Had you been interested in spotting mice you would have had to have bought a more powerful telescope. And that is the point of Lakens’ SESOI (Smallest Effect Size of Interest) blog mentioned at the start - you power to the minimum effect size (minimum object size) you would be interested in. This is why it is imperative that you decide before your study what effect you are interested in - and you can base this on previous literature or theory.\n\n10.8.2 A blog on interpreting and writing up power\nA few points on interpreting power to consolidate things a bit. Firstly, it is great that you are now thinking about power and effect sizes in the first place. It is important that this becomes as second nature as thinking about the design of your study and in future years and future studies the first question you should ask yourself when designing your study/secondary analysis is what size are my APES - Alpha, Power, Effect Size and Sample. And remember that a priori power analysis is the way ahead. The power and alpha are determined in advance of the study and you are using them to determine the effect size or the sample size.\nPower is stated more and more commonly again in papers now and you will start to notice it in the Methods or Results sections. You will see something along the lines of “Based on a power =….. and alpha =…., given we had X voices in our sample, a power analysis (pwr package citation) revealed d = …… as the minimum effect sizes we could reliably determine.”\nBut how do you interpret a study in terms of power? Well, lets say you run a power analysis for a t-test (or for a correlation), and you set the smallest effect size of interest as d = .4 (or the equivalent r-value). If you then run your analysis and find d = .6 and the effect is significant, then your study had enough power to determine this effect. The effect that you found was bigger than the effect you could have found. You can have some confidence that you have a reliable effect at that given power and alpha values. However, say that instead of d = .6 you found a significant effect but with an effect size just below .4, say d = .3 - the effect size you found is smaller than the smallest effect you could reliably find. In this case you have to be cautious as you are still unclear as to whether there actually is an effect or whether you have found an effect by chance due to your study not having enough power to reliably detect an effect size that small. You can’t say for sure that there is an effect or that there isn’t an effect. You need to consider both stances in your write up. Remember though that you have sampled a population, so how representative that sample is of your population will also influence the validity of your power. Each sample will give a slightly different effect size.\nAlternatively, and probably quite likely in many degree projects due to time constraints, say you find a non-significant effect at an effect size smaller than what you predicted; say you find a non-significant effect with an effect size of d = .2 and your power analysis said you could only reliably detect an effect as small as d = .4. The issue you have here is that you can’t determine solely based on this study if you a) have a non-significant effect because you are under powered or b) that you have a non-significant effect because there is actually no effect in the first place. Again in your discussion you would need to consider both stances. What you can however say is that the effect that you were looking for is not any bigger than d = 0.4. That is still useful information. Ok you don’t know how small the effect really is, but you can rule out any effect size bigger than your original d-value. In turn this helps future researchers plan their studies better and can guide them better in knowing how many participants to run. See how useful it would be if we published null findings!\nBasically, when your test finds an effect size smaller than you can detect, you don’t know what it is but you know what it isn’t - we aren’t sure if it is a mouse but we know it is not an elephant. Instead you would use previous findings to support the object being a mouse or not but caveat the conclusion with the suggestion that the test isn’t really sensitive to finding a mouse. Similar to a finding that has an effect size smaller than you can detect. You can use previous literature to support their not being an effect but you can’t rule it out for sure. You might have actually found an effect had you had a more powerful test. Just like you might have been able to determine that it was a mouse had you had a more powerful telescope.\nTaking this a bit further in some studies there really is enough power (in terms of N - say a study of 25000 participants) to find a flea on the proverbial mouse, but where nevertheless there is a non-significant finding. In this case you have the fortunate situation where you have a well-powered study and so can say with some degree of confidence that your hypothesis and design is unlikely to ever produce a replicable significant result. That is probably about as certain as you can get in our science or as close as you can get to a “fact”, a very rare and precious thing. However, incredibly high powered studies, with lots of participants, tend to be able to find any difference as a significant difference. A within-subjects design with 10000 participants (Power = .8, \\(\\alpha = .05\\)) can determine reliably detect an incredibly small effect size of d = 0.04. The question at that stage is whether that effect has any real world significance or meaning.\nSo the take-home message here is that your discussion should always consider the result in relation to the hypothesis, integrating previous research and theory, and if there is an additional issue of power, then your discussion could also consider the result in relation to whether you can truly determine the effect and how that might be resolved (e.g. re-assessing the effect size, changing the design (within is more powerful), low sample, power to high (e.g. .9), alpha to low (e.g. .01)). This issue of power would probably be a small part in the generalisability/limitation section.\nAnd finally, n all of the above you can swap effect and relationship, d and r, and other analyses accordingly.\nThat is end of this chapter. Be sure to look again at anything you were unsure about and make some notes to help develop your own knowledge and skills. It would be good to write yourself some questions about what you are unsure of and see if you can answer them later or speak to someone about them. Good work today!"
  },
  {
    "objectID": "13-visualisation.html#viz-a1",
    "href": "13-visualisation.html#viz-a1",
    "title": "\n12  Visualisation\n",
    "section": "\n12.1 Activity 1: Set-up Visualisation",
    "text": "12.1 Activity 1: Set-up Visualisation\n\nOpen R Studio and set the working directory to your chapter folder. Ensure the environment is clear.\n\nOpen a new R Markdown document and save it in your working directory. Call the file “Visualisation”.\n\nDownload Zhang et al. 2014 Study 3.csv and save it in your chapter folder. Make sure that you do not change the file name at all.\nIf you’re on the server, avoid a number of issues by restarting the session - click Session - Restart R\n\nDelete the default R Markdown welcome text and insert a new code chunk that loads the package tidyverse using the library() function.\nRun the below code to load and wrangle the data into tidy data.\n\n\nlibrary(tidyverse)\nzhang_data &lt;- read_csv(\"Zhang et al. 2014 Study 3.csv\")%&gt;%\n  select(Gender, Age,Condition, T1_Predicted_Interest_Composite, T2_Actual_Interest_Composite)%&gt;%\n  mutate(subject = row_number())%&gt;%\n  pivot_longer(names_to = \"time\",values_to = \"interest\",\n               cols = T1_Predicted_Interest_Composite:T2_Actual_Interest_Composite)%&gt;%\n  mutate(Condition = recode(Condition, \"1\" = \"Ordinary\", \"2\" = \"Extraordinary\"))%&gt;%\n  mutate(time = recode(time, \"T1_Predicted_Interest_Composite\" = \"time1_interest\", \"T2_Actual_Interest_Composite\" = \"time2_interest\"),\n         Gender = recode(Gender, \"1\" = \"male\", \"2\" = \"female\")) %&gt;%\n  filter(Gender %in% c(\"male\", \"female\"))"
  },
  {
    "objectID": "13-visualisation.html#viz-a2",
    "href": "13-visualisation.html#viz-a2",
    "title": "\n12  Visualisation\n",
    "section": "\n12.2 Activity 2: Histograms",
    "text": "12.2 Activity 2: Histograms\nFirst, let’s create histograms for interest to check the distribution. The first line of code creates the ggplot() object and specifies which dataset is being used, and what should be represented on the x and y-axis. Because this is a histogram, you only need to specify the variable on the x-axis because y is always frequency\n\n12.2.1 Basic histogram\nThe code below will create a simple histogram with default appearance and no customisation. You wouldn’t use this graph in a paper, but if you just want to quickly check your distributions, for e.g., normality, this code might be enough.\n\nggplot(zhang_data, aes(interest))+ \n  geom_histogram()\n\n\n\nBasic histogram\n\n\n\n\n12.2.2 Colour and fill\nThe next section of code will change the appearance. Plots in ggplot2 are highly customisable - R for Data Science has an excellent chapter on ggplot if you would like additional information.\nAdding binwidth to geom_histogram() changes the bins of the histogram, i.e., how wide the bars are. The default is 30. Sometimes this may be appropriate but often you will want to change the binwidth. What value you give will depend upon your data.\ncolour() changes the colour of the line around the bars. fill() changes the fill of the bars.\n\nggplot(zhang_data, aes(x = interest))+ \n  geom_histogram(binwidth = .3, \n                 colour = \"black\",  \n                 fill = \"grey\") \n\n\n\nHistogram with colour changes\n\n\n\n\n12.2.3 Axis labels\nThe next section of code changes the labels on the graphs. Note that the labels are an additional layer (i.e., it comes after an +, rather than being an argument to geom_histogram()).\nThe function you use will depend on your data, the most common are scale_x/y_continuous and scale_x/y_discrete depending on whether you are displaying continuous or categorical data. Again, each axis is a separate layer.\nThese scale functions control all the information about the axis, from the label to the breaks, to the minimum and maximum values. For more information use the help documentation.\nFor our labelling purposes, there are two main arguments:\n\n\nname() controls the main name of the axis\n\nlabels() controls the name of the breaks\n\nFor our histogram we will just change the main axis labels.\n\nggplot(zhang_data, aes(x = interest))+ \n  geom_histogram(binwidth = .3, \n                 colour = \"black\",  \n                 fill = \"grey\") + \n  scale_x_continuous(name = \"Mean interest score (1-7)\") +\n  scale_y_continuous(name = \"Count\") \n\n\n\nHistogram with label changes\n\n\n\n\n12.2.4 Density curve\nThe following section adds a normal density curve to the histogram, which can be useful for checking the assumption of normality.\nTo add the line you must change the geom_histogram() to use density on the y-axis (the default is count) and add a stat_function() layer that draws the line.\n\nggplot(zhang_data, aes(interest))+ \n  geom_histogram(binwidth = .3, \n                 colour = \"black\", \n                 fill = \"grey\",\n                 aes(y = ..density..))+ # change y-axis to density\n  scale_x_continuous(name = \"Mean interest score (1-7)\") +\n  scale_y_continuous(name = \"Count\") +\n  stat_function(fun = dnorm, # this adds a normal density function curve\n                colour = \"red\", # this makes it red\n                args = list(mean = mean(zhang_data$interest, na.rm = TRUE),\n                           sd = sd(zhang_data$interest, na.rm = TRUE)))\n\n\n\nHistogram with normal density curve"
  },
  {
    "objectID": "13-visualisation.html#viz-a3",
    "href": "13-visualisation.html#viz-a3",
    "title": "\n12  Visualisation\n",
    "section": "\n12.3 Activity 3: Scatterplots",
    "text": "12.3 Activity 3: Scatterplots\n\n12.3.1 Basic scatterplot\nNow let’s make a scatterplot plotting Age and interest to see if there is any relationship between the two. We need to specify both the x and y-axis variables. The following code will produce a very simple scatterplot. Again, you wouldn’t use this graph in a paper, but for eye-balling your data it would suffice.\n\nggplot(zhang_data, aes(x = interest,y = Age))+\n       geom_point()\n\n\n\nBasic scatterplot\n\n\n\n\n12.3.2 Axis labels\nFrom this plot it doesn’t look like there is much of a relationship between age and interest ratings. We can now change the labels using the same scale functions as before.\n\nggplot(zhang_data, aes(x = interest,y = Age))+\n       geom_point()+\n  scale_x_continuous(name = \"Mean interest score (1-7)\") + \n  scale_y_continuous(name = \"Age\")\n\n\n\nScatterplot with label changes\n\n\n\n\n12.3.3 Adding a regression line\nIt’s often useful to add a regression line or line of best fit to a scatterplot. The regression line is added with geom_smooth() and by default will also provide a 95% confidence interval. You can specify what type of line you want to draw, most often you will need method = lm, i.e., a linear model or a straight line. Look up the help documentation for geom_smooth() and see what other methods you can use.\n\nggplot(zhang_data, aes(x = interest,y = Age))+\n  geom_point()+\n  scale_x_continuous(name = \"Mean interest score (1-7)\") + \n  scale_y_continuous(name = \"Age\")+\n  geom_smooth(method=lm) # if you don't want the shaded CI, add se = FALSE to this\n\n\n\nScatterplot with regression line\n\n\n\n\n12.3.4 Grouped scatterplots\nWe can use ggplot to show how the relationship might differ for different populations within our data. We do this by adding colour() to aes() and setting it as whatever variable we would like to distinguish between. In this case, we will see how the relationship between age and interest differs for the male and female participants. There are a few participants with missing gender so we will first filter them out.\n\nzhang_data %&gt;%\n  filter(Gender %in% c(\"male\", \"female\")) %&gt;%\n           ggplot(aes(x = interest,y = Age, colour = Gender))+\n  geom_point()+\n  scale_x_continuous(name = \"Mean interest score (1-7)\") + \n  scale_y_continuous(name = \"Age\")+\n  geom_smooth(method=lm)\n\n\n\nGrouped scatterplot\n\n\n\nAnd here’s that plot with the labels tidied up. Notice the use of scale_color_discrete() to adjust the labels for Gender.\n\n\n\nWhen you change the labels, R will simply overwrite the names in the dataset. If you wanted to actually change the order of the categories (e.g., have male as the red line) you need to change the order of the factor. We will do this later, for now, just be sure that you’re changing the name of the right category (i.e., female comes first))\n\n\n\n\nggplot(zhang_data, aes(x = interest,y = Age, colour = Gender))+\n  geom_point()+\n  scale_x_continuous(name = \"Mean interest score (1-7)\") + \n  scale_y_continuous(name = \"Age\")+\n  geom_smooth(method=lm)+\n  scale_color_discrete(name = \"Gender\",\n                       labels = c(\"Female\", \"Male\"))\n\n\n\nGrouped scatterplot with adjusted labels"
  },
  {
    "objectID": "13-visualisation.html#viz-a4",
    "href": "13-visualisation.html#viz-a4",
    "title": "\n12  Visualisation\n",
    "section": "\n12.4 Activity 4: Boxplots",
    "text": "12.4 Activity 4: Boxplots\n\n12.4.1 Basic boxplot\nThe following code will produce a simple boxplot for eye-balling your data.\n\nggplot(zhang_data, aes(x = Condition, y = interest))+\n  geom_boxplot()\n\n\n\nBasic boxplot\n\n\n\n\n12.4.2 Adding data points\nIf we add another layer geom_point() we can add our raw data points to our boxplots to make them more informative.\n\nggplot(zhang_data, aes(x = Condition, y = interest))+\n  geom_boxplot()+\n  geom_point()\n\n\n\nBoxplot with overplotting\n\n\n\nHowever, this plot suffers from over-plotting, that is, there are multiple data points on top of each other. We can change this by using geom_jitter(), which adds a layer of points that are jittered so that each one is visible.\nheight and width affect how much each point is jittered. Play around with the values to see how it affects the data points.\n\nggplot(zhang_data, aes(x = Condition, y = interest))+\n  geom_boxplot()+\n  geom_jitter(height = 0, width = .1)\n\n\n\nBoxplot with jittered data\n\n\n\n\n12.4.3 Adding colour\nWe may want to add colour to our graph (and for consistency, we’ll sort out the labels). We do this by adding the ‘fill’ argument to the ggplot aesthetic by specifying which variable the colour of the fill should be organised by.\n\nggplot(zhang_data, aes(x = Condition, y = interest, fill = Condition))+\n  geom_boxplot()+\n  geom_jitter(height = 0, width = .1)+\n  scale_x_discrete(name = \"Condition\") + # note the x-axis is discrete\n  scale_y_continuous(name = \"Mean interest rating (1-7)\")+\n  scale_fill_discrete(guide = FALSE) # this suppresses the legend because we don't need it\n\n\n\nBoxplot with colour\n\n\n\n\n12.4.4 Boxplots for multiple factors\nWhen you only have one IV, using the fill command to change the colour is a little redundant, as the colours don’t add any additional information. It makes more sense to use colour to represent an additional IV.\nFor this example, we’ll use Condition and time as IVs. fill() now specifies a second IV, rather than repeating the IV on the x-axis as in the previous plot.\nWith multiple IVs the command to overlay the raw data points changes as the data points also need dodged (try running the code with the previous geom_jitter function to see what happens)\n\nggplot(zhang_data, aes(x = Condition, y = interest, fill = time))+\n  geom_boxplot()+\n  geom_point(position=position_jitterdodge(jitter.width = .1))\n\n\n\nBoxplot for two factors\n\n\n\n\n12.4.5 Colour-blind friendly options\nThere is one more fill option that we can use. Rather than specifying scale_fill_discrete(), we can use scale_fill_viridis_d(). This function does exactly the same thing but it uses a colour-blind friendly palette (which also prints in black and white). There are 5 different options for colours and you can see them by changing option to A, B, C, D or E. Personally I like option E with alpha = .6 (to control transparency) but that’s not an official School position.\n\nggplot(zhang_data, aes(x = Condition, y = interest, fill = time))+\n  geom_boxplot(alpha = .6)+\n  geom_point(position=position_jitterdodge(jitter.width = .1)) +\n  scale_fill_viridis_d(option = \"E\")\n\n\n\nBoxplots with friendly colours"
  },
  {
    "objectID": "13-visualisation.html#viz-a5",
    "href": "13-visualisation.html#viz-a5",
    "title": "\n12  Visualisation\n",
    "section": "\n12.5 Activity 5: Reordering factors",
    "text": "12.5 Activity 5: Reordering factors\nR orders categorical variables alphabetically. For gender it didn’t really matter whether male or female was represented first and for time 1 and 2 it makes sense for them to be in this order but we may want to change the order of Condition (in my mind it makes more sense for Ordinary to come first, but that may just be me).\nTo do this we can use mutate() and fct_level() to change the factor levels to the order we want.\n\nzhang_data &lt;- zhang_data %&gt;%\n  mutate(Condition = fct_relevel(Condition, c(\"Ordinary\", \"Extraordinary\")))\n\nNow we can re-run the boxplot. That’s better.\n\nggplot(zhang_data, aes(x = Condition, y = interest, fill = time))+\n  geom_boxplot(alpha = .6)+\n  geom_point(position=position_jitterdodge(jitter.width = .1)) +\n  scale_fill_viridis_d(option = \"E\")\n\n\n\nBoxplot with reordered factors"
  },
  {
    "objectID": "13-visualisation.html#viz-a6",
    "href": "13-visualisation.html#viz-a6",
    "title": "\n12  Visualisation\n",
    "section": "\n12.6 Activity 6: Bar Charts",
    "text": "12.6 Activity 6: Bar Charts\n\n12.6.1 Basic bar chart\nBar charts should only be used for counts because they can distort your understanding of the data if you use them to represent means (see here for a great example.\nFirst, we’ll do a bar chart for the count of male and females in our sample.\n\nggplot(zhang_data, aes(x=Gender))+\n  geom_bar()\n\n\n\nBasic bar chart\n\n\n\n\n12.6.2 Bar charts with two factors\nWe can also use fill() to separate gender by Condition\n\nggplot(zhang_data, aes(x=Gender, fill = Condition))+\n  geom_bar(position = \"dodge\", alpha = .6) + # the position argument places the bars next to each other, rather than on top of each other, try removing this\n  scale_fill_viridis_d(option = \"E\")\n\n\n\nBar chart with two factors"
  },
  {
    "objectID": "13-visualisation.html#viz-a7",
    "href": "13-visualisation.html#viz-a7",
    "title": "\n12  Visualisation\n",
    "section": "\n12.7 Activity 7: Violin plots",
    "text": "12.7 Activity 7: Violin plots\n\n12.7.1 Basic violin plot\nViolin plots are so-called because with a normal distribution the shape would look something like a violin. They show density, i.e., the fatter the violin the more data points there are for that value.\n\nggplot(zhang_data, aes(x = Condition, y = interest))+\n  geom_violin()\n\n\n\nBasic violin plot\n\n\n\n\n12.7.2 Violin plots with raw data points\nLike the boxplot, we can also add the raw data points to our violin plot, making sure to use jitter to avoid over-plotting.\n\nggplot(zhang_data, aes(x = Condition, y = interest))+\n  geom_violin()+\n  geom_jitter(height = 0, width = .1)\n\n\n\nViolin plot with data points\n\n\n\n\n\n\nIt’s important to remember that R is very literal. ggplot2 works on a system of layers. It will add new geoms on top of existing ones and it won’t stop to think whether this is a good idea. Try running the above code but put geom_jitter() first and then add geom_violin(). The order of your layers matters."
  },
  {
    "objectID": "13-visualisation.html#viz-a8",
    "href": "13-visualisation.html#viz-a8",
    "title": "\n12  Visualisation\n",
    "section": "\n12.8 Activity 8: Violin-boxplots",
    "text": "12.8 Activity 8: Violin-boxplots\nOne increasingly common graph is a violin + boxplot + summary plot that shows a huge amount of information about your data in a single plot.\n\nThis code uses two calls to stat_summary() that was introduced during the t-test chapter. The first draws a point to represent the mean, and the second draws an errorbar that represents standard error (mean_se).\n\n\nguides is a new function and can be used to adjust whether legends are displayed. This has the same effect as specifying show.legend = FALSE in both geom_violin() and geom_boxplot() but it uses less code to do so.\n\n\nfatten = NULL removes the median line from the boxplots. This can be useful if you’re running a test where you’re comparing means as it makes it easier to see the point range.\nYou may get warning messages telling you that R has removed rows containing missing values, you do not need to worry about this.\n\n\nggplot(zhang_data, aes(x = Condition, y = interest, fill = Condition))+\n  geom_violin(alpha = .6, trim = FALSE)+\n  geom_boxplot(width = .2, alpha = .7, fatten = NULL)+\n  stat_summary(fun = \"mean\", geom = \"point\") +\n  stat_summary(fun.data = \"mean_se\", geom = \"errorbar\", width = .1) +\n  scale_fill_viridis_d(option = \"E\", label = c(\"Ordinary\", \"Extraordinary\"))+\n  scale_y_continuous(name = \"Mean interest rating (1-7)\") +\n  guides(fill = FALSE)\n\n\n\nViolin-boxplot with summary data"
  },
  {
    "objectID": "13-visualisation.html#viz-a9",
    "href": "13-visualisation.html#viz-a9",
    "title": "\n12  Visualisation\n",
    "section": "\n12.9 Activity 9: Faceting",
    "text": "12.9 Activity 9: Faceting\nggplot2 contains a facet function that produces different plots for each level of a grouping variable which can be very useful when you have more than two factors, for example, for a three-way ANOVA. The following code displays produces violin-boxplots for Condition ~ interest, but separately for male and female participants.\n\nThis code adds an extra argument position = position_dodge(.9) to align the layers with the violin plots. Try removing this argument from each layer to see what happens, and also try adjusting the value from .9 to another number.\n\n\nggplot(zhang_data, aes(x = Condition, y = interest, fill = time))+\n  geom_violin(alpha = .6, trim = FALSE)+\n  geom_boxplot(width = .2, \n               alpha = .6, \n               fatten = NULL,\n               position = position_dodge(.9))+\n  stat_summary(fun = \"mean\", geom = \"point\",\n               position = position_dodge(.9)) +\n  stat_summary(fun.data = \"mean_se\", geom = \"errorbar\", width = .1,\n               position = position_dodge(.9))+\n  scale_fill_viridis_d(option = \"E\") +\n  facet_wrap(~Gender)\n\n\n\nViolin-boxplot facetted by gender\n\n\n\n\n12.9.1 Facet labelling\nFinally, changing the labels within the facets is a little more complicated - there’s no additional scale layer, instead, you adjust this inside facet_wrap() using labeller. This has always felt unintuitive to me and I have to look it up every single time so don’t worry if it is confusing - just remember where to look for the example.\n\nggplot(zhang_data, aes(x = Condition, y = interest, fill = time))+\n  geom_violin(alpha = .6, trim = FALSE)+\n  geom_boxplot(width = .2, \n               alpha = .6, \n               fatten = NULL,\n               position = position_dodge(.9))+\n  stat_summary(fun = \"mean\", geom = \"point\",\n               position = position_dodge(.9)) +\n  stat_summary(fun.data = \"mean_se\", geom = \"errorbar\", width = .1,\n               position = position_dodge(.9))+\n  scale_fill_viridis_d(option = \"E\") +\n  facet_wrap(~Gender, labeller = labeller(Gender = (c(female = \"Female\", male = \"Male\"))))\n\n\n\nFacetted plot with updated labels"
  },
  {
    "objectID": "13-visualisation.html#viz-a10",
    "href": "13-visualisation.html#viz-a10",
    "title": "\n12  Visualisation\n",
    "section": "\n12.10 Activity 10: Split-violins and raincloud plots",
    "text": "12.10 Activity 10: Split-violins and raincloud plots\nFinally, we’re going to do something a bit snazzy. As well as the functions that are included in packages, anyone can also write custom functions and share the code. One such custom function allows us to create raincloud plots which are highly informative and very pretty. See here for more information about their creation and function (and to cite them if you use them in a publication or report).\nIn order to use this custom function code you will need to install the plyr package, although crucially, don’t load it like you normally would using library(). The custom function code will just use one very specific function, if you load the entire package you risk creating a function conflict.\n\ninstall.packages(\"plyr\")\n\n\n12.10.1 Split-violin plots\nBecause the functions we need don’t exist in a package we can load, we need to create them. Copy and paste all the below code without changing anything. You do not need to understand this code. I certainly don’t. When you run this, you should see geom_split_violin appear in the Environment pane under Functions.\n\nGeomSplitViolin &lt;- ggproto(\n  \"GeomSplitViolin\", \n  GeomViolin, \n  draw_group = function(self, data, ..., draw_quantiles = NULL) {\n    data &lt;- transform(data, \n                      xminv = x - violinwidth * (x - xmin), \n                      xmaxv = x + violinwidth * (xmax - x))\n    grp &lt;- data[1,'group']\n    newdata &lt;- plyr::arrange(\n      transform(data, x = if(grp%%2==1) xminv else xmaxv), \n      if(grp%%2==1) y else -y\n    )\n    newdata &lt;- rbind(newdata[1, ], newdata, newdata[nrow(newdata), ], newdata[1, ])\n    newdata[c(1,nrow(newdata)-1,nrow(newdata)), 'x'] &lt;- round(newdata[1, 'x']) \n    if (length(draw_quantiles) &gt; 0 & !scales::zero_range(range(data$y))) {\n      stopifnot(all(draw_quantiles &gt;= 0), all(draw_quantiles &lt;= 1))\n      quantiles &lt;- ggplot2:::create_quantile_segment_frame(data, draw_quantiles)\n      aesthetics &lt;- data[rep(1, nrow(quantiles)), setdiff(names(data), c(\"x\", \"y\")), drop = FALSE]\n      aesthetics$alpha &lt;- rep(1, nrow(quantiles))\n      both &lt;- cbind(quantiles, aesthetics)\n      quantile_grob &lt;- GeomPath$draw_panel(both, ...)\n      ggplot2:::ggname(\"geom_split_violin\", \n                       grid::grobTree(GeomPolygon$draw_panel(newdata, ...), quantile_grob))\n    } else {\n      ggplot2:::ggname(\"geom_split_violin\", GeomPolygon$draw_panel(newdata, ...))\n    }\n  }\n)\n\ngeom_split_violin &lt;- function (mapping = NULL, \n                               data = NULL, \n                               stat = \"ydensity\", \n                               position = \"identity\", ..., \n                               draw_quantiles = NULL, \n                               trim = TRUE, \n                               scale = \"area\", \n                               na.rm = FALSE, \n                               show.legend = NA, \n                               inherit.aes = TRUE) {\n  layer(data = data, \n        mapping = mapping, \n        stat = stat, \n        geom = GeomSplitViolin, \n        position = position, \n        show.legend = show.legend, \n        inherit.aes = inherit.aes, \n        params = list(trim = trim, \n                      scale = scale, \n                      draw_quantiles = draw_quantiles, \n                      na.rm = na.rm, ...)\n  )\n}\n\nThe split-violin is a version of the violin-boxplot that is good for visualising interactions. If you look at the faceted graph we made, there’s actually quite a lot of unnecessary space used up because we only need half of the violin to see the distribution - the other half is just repeating the same information.\n\nggplot(zhang_data, aes(x = Condition, y = interest, fill = Gender))+\n  geom_split_violin(trim = FALSE, alpha = .4)+\n  geom_boxplot(width = .2, alpha = .6,\n               position = position_dodge(.25))+\n  scale_fill_viridis_d(option = \"E\") +\n  stat_summary(fun = \"mean\", geom = \"point\",\n               position = position_dodge(width = 0.25)) +\n  stat_summary(fun.data = \"mean_se\", geom = \"errorbar\", width = .1,\n               position = position_dodge(width = 0.25))\n\n\n\nSplit-violin plot\n\n\n\n\n12.10.2 Raincloud plots\nThe second custom function is geom_flat_violin. Copy and paste all of this code and again you should see it appear in your Environment pane.\n\n\"%||%\" &lt;- function(a, b) {\n  if (!is.null(a)) a else b\n}\n\ngeom_flat_violin &lt;- function(mapping = NULL, data = NULL, stat = \"ydensity\",\n                             position = \"dodge\", trim = TRUE, scale = \"area\",\n                             show.legend = NA, inherit.aes = TRUE, ...) {\n  layer(\n    data = data,\n    mapping = mapping,\n    stat = stat,\n    geom = GeomFlatViolin,\n    position = position,\n    show.legend = show.legend,\n    inherit.aes = inherit.aes,\n    params = list(\n      trim = trim,\n      scale = scale,\n      ...\n    )\n  )\n}\n\nGeomFlatViolin &lt;-\n  ggproto(\"Violinist\", Geom,\n          setup_data = function(data, params) {\n            data$width &lt;- data$width %||%\n              params$width %||% (resolution(data$x, FALSE) * 0.9)\n            \n            # ymin, ymax, xmin, and xmax define the bounding rectangle for each group\n            data %&gt;%\n              group_by(group) %&gt;%\n              mutate(ymin = min(y),\n                     ymax = max(y),\n                     xmin = x,\n                     xmax = x + width / 2)\n            \n          },\n          \n          draw_group = function(data, panel_scales, coord) {\n            # Find the points for the line to go all the way around\n            data &lt;- transform(data, xminv = x,\n                              xmaxv = x + violinwidth * (xmax - x))\n            \n            # Make sure it's sorted properly to draw the outline\n            newdata &lt;- rbind(plyr::arrange(transform(data, x = xminv), y),\n                             plyr::arrange(transform(data, x = xmaxv), -y))\n            \n            # Close the polygon: set first and last point the same\n            # Needed for coord_polar and such\n            newdata &lt;- rbind(newdata, newdata[1,])\n            \n            ggplot2:::ggname(\"geom_flat_violin\", GeomPolygon$draw_panel(newdata, panel_scales, coord))\n          },\n          \n          draw_key = draw_key_polygon,\n          \n          default_aes = aes(weight = 1, colour = \"grey20\", fill = \"white\", size = 0.5,\n                            alpha = NA, linetype = \"solid\"),\n          \n          required_aes = c(\"x\", \"y\")\n  )\n\nThis plot is similar to the split-violin, but it adds in the raw data points and looks a bit like a raincloud as a result.\nFirst, we will run the plot for just one variable, Condition. Again, try changing the arguments (adjust any numbers and change FALSE to TRUE) to see how you can control different aspects of the plot, in particular, try removing coord_flip() to see what happens.\n\nggplot(zhang_data, aes(x = Condition, y = interest))+\n  geom_flat_violin(position = position_nudge(x = .25, y = 0), \n                   trim=FALSE, alpha = 0.75) +\n  geom_jitter(aes(color = Condition), \n             width = .2, size = .5, alpha = .75, show.legend = FALSE)+\n  geom_boxplot(width = .1, alpha = 0.5, fatten = NULL)+\n  stat_summary(fun = \"mean\", geom = \"point\",\n               position = position_dodge(width = 0.25)) +\n  stat_summary(fun.data = \"mean_se\", geom = \"errorbar\", width = .1,\n               position = position_dodge(width = 0.3)) +\n  coord_flip()\n\n\n\nRaincloud plot for one factor\n\n\n\n\n12.10.3 Raincloud plots with multiple factors\nNow we can run the code for a 2 x 2 plot, adding in Gender to fill argument. This is quite a complicated plot, do not worry if you are struggling to understand the code but remember, you just need to understand which bits to change.\n\nggplot(zhang_data, \n       aes(x = Condition, y = interest, fill = Gender))+\n  geom_flat_violin(position = position_nudge(x = .25, y = 0), \n                   trim=FALSE, \n                   alpha = 0.6) +\n  geom_point(position = position_jitter(width = .05, height = 0.05), \n             size = .5, \n             alpha = .7, \n             show.legend = FALSE, \n             aes(colour = Gender))+\n  geom_boxplot(width = .3, \n               alpha = 0.5, \n               position = \"dodge\")+\n  stat_summary(fun = \"mean\", geom = \"point\",\n               position = position_dodge(width = 0.3)) +\n  stat_summary(fun.data = \"mean_se\", geom = \"errorbar\", width = .1,\n               position = position_dodge(width = 0.3)) +\n  scale_fill_viridis_d(option = \"E\") +\n  scale_colour_viridis_d(option = \"E\")\n\n\n\nRaincloud plot for two factors\n\n\n\n\n12.10.4 Finished!\nAnd you’re done! As we’ve said throughout this chapter, you do not need to remember all of this code, you just need to remember what’s possible and where to find the examples that you can modify."
  },
  {
    "objectID": "appendix-a-installing-r.html#installing-base-r",
    "href": "appendix-a-installing-r.html#installing-base-r",
    "title": "Appendix A — Installing R",
    "section": "\nA.1 Installing Base R",
    "text": "A.1 Installing Base R\nInstall base R. Choose the download link for your operating system (Linux, Mac OS X, or Windows).\nIf you have a Mac, install the latest release from the newest R-x.x.x.pkg link (or a legacy version if you have an older operating system). After you install R, you should also install XQuartz to be able to use some visualisation packages.\nIf you are installing the Windows version, choose the “base” subdirectory and click on the download link at the top of the page. After you install R, you should also install RTools; use the “recommended” version highlighted near the top of the list.\nIf you are using Linux, choose your specific operating system and follow the installation instructions."
  },
  {
    "objectID": "appendix-a-installing-r.html#installing-rstudio",
    "href": "appendix-a-installing-r.html#installing-rstudio",
    "title": "Appendix A — Installing R",
    "section": "\nA.2 Installing RStudio",
    "text": "A.2 Installing RStudio\nGo to rstudio.com and download the RStudio Desktop (Open Source License) version for your operating system under the list titled Installers for Supported Platforms."
  },
  {
    "objectID": "appendix-a-installing-r.html#rstudio-settings",
    "href": "appendix-a-installing-r.html#rstudio-settings",
    "title": "Appendix A — Installing R",
    "section": "\nA.3 RStudio Settings",
    "text": "A.3 RStudio Settings\nThere are a few settings you should fix immediately after updating RStudio. Go to Global Options... under the Tools menu (⌘,), and in the General tab, uncheck the box that says Restore .RData into workspace at startup. If you keep things around in your workspace, things will get messy, and unexpected things will happen. You should always start with a clear workspace. This also means that you never want to save your workspace when you exit, so set this to Never. The only thing you want to save are your scripts.\nYou may also want to change the appearance of your code. Different fonts and themes can sometimes help with visual difficulties or dyslexia.\n\n\n\n\nRStudio General and Appearance settings\n\n\n\nYou may also want to change the settings in the Code tab. Foe example, Lisa prefers two spaces instead of tabs for my code and likes to be able to see the whitespace characters. But these are all a matter of personal preference.\n\n\n\n\nRStudio Code settings"
  },
  {
    "objectID": "appendix-a-installing-r.html#installing-latex",
    "href": "appendix-a-installing-r.html#installing-latex",
    "title": "Appendix A — Installing R",
    "section": "\nA.4 Installing LaTeX",
    "text": "A.4 Installing LaTeX\nYou can install the LaTeX typesetting system to produce PDF reports from RStudio. Without this additional installation, you will be able to produce reports in HTML but not PDF. This course will not require you to make PDFs. To generate PDF reports, you will additionally need to install tinytex (R-tinytex?) and run the following code:\n\ntinytex::install_tinytex()"
  },
  {
    "objectID": "appendix-a1-updating-packages.html#updating-r",
    "href": "appendix-a1-updating-packages.html#updating-r",
    "title": "Appendix B — Updating packages",
    "section": "\nB.1 Updating R",
    "text": "B.1 Updating R\nFinally, you may also wish to update R itself. The key thing to be aware of is that when you update R, if you just download the latest version from the website, you will lose all your packages. The easiest way to update R and not cause yourself a huge headache is to use the installr package. When you use the updateR() function, a series of dialogue boxes will appear. These should be fairly self-explanatory but there is a full step-by-step guide available for how to use installr, the important bit is to select “Yes” when it asked if you would like to copy your packages from the older version of R.\n\n# Install the installr package\ninstall.packages(\"installr\")\n\n# Load installr\nlibrary(installr)\n\n# Run the update function\nupdateR()\n\nAs always, if you’re having issues, please ask on Teams or book into a GTA session."
  },
  {
    "objectID": "appendix-a2-additional-learning-resources.html",
    "href": "appendix-a2-additional-learning-resources.html",
    "title": "Appendix A — Additional Resources",
    "section": "",
    "text": "The truth about programming\n\n\n\nIf you would like additional practice, you can check out the other UofG PsyTeachR course books.\n\n\nLevel 1 - Intro to R (overlaps with Msc Conv book), data wrangling, data viz, descriptive statistics\n\n\nLevel 2 - Our second-year undergraduate course introduces statistical concepts such as permutation tests,t-tests, NHST, alpha, power, effect size, and sample size. Semester 2 focusses on correlations and the general linear model.\n\nLevel 3: This third-year undergraduate course teaches students how to specify, estimate, and interpret statistical models corresponding to various study designs, using a General Linear Models approach.\n\nMSc Data Skills: This course provides an overview of skills needed for reproducible research and open science using the statistical programming language R. Students will learn about data visualisation, data tidying and wrangling, archiving, iteration and functions, probability and data simulations, general linear models, and reproducible workflows.\n\nWe also highly recommend the following, they will help practice your data wrangling skills but also they’re great options if you’re enjoying R and want to stretch yourself:\n\n\nOpen Stats Lab - this wonderful resource gives you practice at running statistical tests by providing you with datasets from published papers.\n\nR for Data Science - written by the authors of the tidyverse, this is a great resource for additional data wrangling practice and more depth on many of the tidyverse functions.\n\nText Mining with R - Shows you how to use R to work with text. This isn’t something we cover in this course, but it uses the same data wrangling skills and be a very useful additional skill to have.\n\nHow to make BBC style graphics - Ever wondered how the BBC News makes their data visualisation? Well, now you can make your own!\n\nData Vizualisation - this is an entire book on data visualisation and goes into detail on how to take ggplot to its limits."
  },
  {
    "objectID": "appendix-a3-How-to-cite-R.html",
    "href": "appendix-a3-How-to-cite-R.html",
    "title": "Appendix B — Citing R and RStudio",
    "section": "",
    "text": "How to cite R and RStudio\nYou may be some way off writing a scientific report where you have to cite and reference R, however, when the time comes it is important to do so to give the people who built it (most of them for free!) credit. You should provide separate citations for R, RStudio, and the packages you use.\nTo get the citation for the version of R you are using, simply run the citation() function which will always provide you with the most recent citation.\n\ncitation()\n\nTo cite R in publications use:\n\n  R Core Team (2023). _R: A Language and Environment for Statistical\n  Computing_. R Foundation for Statistical Computing, Vienna, Austria.\n  &lt;https://www.R-project.org/&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Manual{,\n    title = {R: A Language and Environment for Statistical Computing},\n    author = {{R Core Team}},\n    organization = {R Foundation for Statistical Computing},\n    address = {Vienna, Austria},\n    year = {2023},\n    url = {https://www.R-project.org/},\n  }\n\nWe have invested a lot of time and effort in creating R, please cite it\nwhen using it for data analysis. See also 'citation(\"pkgname\")' for\nciting R packages.\n\n\nTo generate the citation for any packages you are using, you can also use the citation() function with the name of the package you wish to cite.\n\ncitation(\"tidyverse\")\n\nTo cite package 'tidyverse' in publications use:\n\n  Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R,\n  Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller\n  E, Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V,\n  Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H (2019). \"Welcome to\n  the tidyverse.\" _Journal of Open Source Software_, *4*(43), 1686.\n  doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Article{,\n    title = {Welcome to the {tidyverse}},\n    author = {Hadley Wickham and Mara Averick and Jennifer Bryan and Winston Chang and Lucy D'Agostino McGowan and Romain François and Garrett Grolemund and Alex Hayes and Lionel Henry and Jim Hester and Max Kuhn and Thomas Lin Pedersen and Evan Miller and Stephan Milton Bache and Kirill Müller and Jeroen Ooms and David Robinson and Dana Paige Seidel and Vitalie Spinu and Kohske Takahashi and Davis Vaughan and Claus Wilke and Kara Woo and Hiroaki Yutani},\n    year = {2019},\n    journal = {Journal of Open Source Software},\n    volume = {4},\n    number = {43},\n    pages = {1686},\n    doi = {10.21105/joss.01686},\n  }\n\n\nTo generate the citation for the version of RStudio you are using, you can use the RStudio.Vesion() function:\n\nRStudio.Version()\n\nFinally, here’s an example of how that might look in the write-up of your method section:\n\nAnalysis was conducted using R (R Core Team, 2020), RStudio (Rstudio Team, 2020), and the tidyverse package (Wickham, 2017).\n\nAs noted, you may not have to do this for a while, but come back to this when you do because it’s important to give the open-source community credit for their work."
  },
  {
    "objectID": "appendix-b-symbols.html",
    "href": "appendix-b-symbols.html",
    "title": "Appendix C — Symbols",
    "section": "",
    "text": "Symbol\npsyTeachR Term\nAlso Known As\n\n\n\n()\n(round) brackets\nparentheses\n\n\n[]\nsquare brackets\nbrackets\n\n\n{}\ncurly brackets\nsquiggly brackets\n\n\n&lt;&gt;\nchevrons\nangled brackets / guillemets\n\n\n&lt;\nless than\n\n\n\n&gt;\ngreater than\n\n\n\n&\nampersand\n“and” symbol\n\n\n#\nhash\npound / octothorpe\n\n\n/\nslash\nforward slash\n\n\n\\\nbackslash\n\n\n\n-\ndash\nhyphen / minus\n\n\n_\nunderscore\n\n\n\n*\nasterisk\nstar\n\n\n^\ncaret\npower symbol\n\n\n~\ntilde\ntwiddle / squiggle\n\n\n=\nequal sign\n\n\n\n==\ndouble equal sign\n\n\n\n.\nfull stop\nperiod / point\n\n\n!\nexclamation mark\nbang / not\n\n\n?\nquestion mark\n\n\n\n’\nsingle quote\nquote / apostrophe\n\n\n”\ndouble quote\nquote\n\n\n%&gt;%\npipe\nmagrittr pipe\n\n\n|\nvertical bar\npipe\n\n\n,\ncomma\n\n\n\n;\nsemi-colon\n\n\n\n:\ncolon\n\n\n\n@\n“at” symbol\nvarious hilarious regional terms\n\n\n…\nglossary(\"ellipsis\")\ndots\n\n\n\n\n\n\n\nImage by James Chapman/Soundimals"
  },
  {
    "objectID": "appendix-y-license.html#citation",
    "href": "appendix-y-license.html#citation",
    "title": "License",
    "section": "Citation",
    "text": "Citation\nBartlett, J.E. & Toivo, W. (2024). Fundamentals of Quantitative Analysis (Version 3.0). https://github.com/PsyTeachR/quant-fundamentals-v3"
  },
  {
    "objectID": "appendix-d-probability.html#introduction-to-probability",
    "href": "appendix-d-probability.html#introduction-to-probability",
    "title": "Appendix D — Probability",
    "section": "\nD.1 Introduction to probability?",
    "text": "D.1 Introduction to probability?\nProbability (p) is the extent to which an event is likely to occur and is represented by a number between 0 and 1. For example, the probability of flipping a coin and it landing on ‘heads’ would be estimated at p = .5, i.e., there is a 50% chance of getting a head when you flip a coin.\nIn fact, calculating the probability of any individual event occurring can be formulated as:\n\\[p = \\frac{number \\  of  \\ ways \\ the \\ event \\ could \\  arise}{number \\ of \\ possible \\ outcomes}\\] For example, what is the probability of randomly drawing your name out of a hat of 12 names where one name is definitely yours? Well, if there are 12 possible outcomes, and only 1 way for your name to arise, then it the above formula becomes:\n\\[p = \\frac{1}{12} = 0.0833333\\]\nMeaning that the probability is 0.0833333. Or, if you wanted to write that as a percentage then it would be 8.3333333%, meaning that out of every 100 draws from the hat you would expect your name to come out about 8.3 times. And if there had been four names in the hat and one was yours then it would be:\n\\[p = \\frac{1}{4} = 0.25\\]\nAnd if it had been 24 names in the hat and one was yours then it would have been:\n\\[p = \\frac{1}{24} = 0.0416667\\]\nSo you can see that the probability of an event occurring changes with the number of possible outcomes. Makes sense really! The more possible outcomes, the less likely any specific one outcome is going to happen. So far so good!\n\nD.1.0.1 Activity 1: Probability\nTry to answer these questions below to check your understanding.\n\nWhat would be the probability of selecting your name from a hat when there are ten names in the hat and your name is one of them? \n0.1\n0.25\n0.0416666666666667\n0.0833333333333333\n\nWhat would be the probability of selecting your name from a hat when there are 100 names in the hat and your name is not one of them? Be careful on this one! \n0.1\n0\n0.1\n0.01"
  },
  {
    "objectID": "appendix-d-probability.html#types-of-data",
    "href": "appendix-d-probability.html#types-of-data",
    "title": "Appendix D — Probability",
    "section": "\nD.2 Types of data",
    "text": "D.2 Types of data\nHow you tackle probability also depends on the type of data/variables you are working with (i.e. discrete or continuous). This is also referred to as Level of Measurements and here we will recap on those different types of data.\nDiscrete data can only take integer values (whole numbers). For example, the number of participants in an experiment would be discrete - we can’t have half a participant! Discrete variables can also be further broken down into nominal and ordinal variables.\n\n\nOrdinal data is a set of ordered categories; you know which is the top/best and which is the worst/lowest, but not the difference between categories. For example, you could ask participants to rate the attractiveness of different faces based on a 5-item Likert scale (very unattractive, unattractive, neutral, attractive, very attractive). You know that very attractive is better than attractive but we can’t say for certain that the difference between neutral and attractive is the same size as the distance between very unattractive and unattractive.\n\nNominal data is also based on a set of categories but the ordering doesn’t matter (e.g. left or right handed). Nominal is sometimes simply referred to as categorical data.\n\nContinuous data on the other hand can take any value. For example, we can measure age on a continuous scale (e.g. we can have an age of 26.55 years), other examples include reaction time or the distance you travel to university every day. Continuous data can be broken down into Interval or Ratio data.\n\n\nInterval data is data which comes in the form of a numerical value where the difference between points is standardised and meaningful. For example temperature, the difference in temperature between 10-20 degrees is the same as the difference in temperature between 20-30 degrees.\n\nRatio data is very like interval but has a true zero point. With our interval temperature example above, we have been experiencing negative temperatures (-1,-2 degrees) in Glasgow but with ratio data you don’t see negative values such as these i.e. you can’t be -10 cm tall.\n\n\nD.2.0.1 Activity 2: Types of data\nTry to answer these questions below to check your understanding. What types of data are the below measurements?\n\nTime taken to run a marathon (in seconds): \ncategorical\nratio\nordinal\ninterval\n\nFinishing position in marathon (e.g. 1st, 2nd, 3rd): \nratio\ncategorical\ninterval\nordinal\n\nWhich Sesame Street character a runner was dressed as: \nratio\ninterval\nordinal\ncategorical\n\nTemperature of a runner dressed in a cookie monster outfit (in degrees Celsius): \nratio\ninterval\ncategorical\nordinal"
  },
  {
    "objectID": "appendix-d-probability.html#probability-distributions",
    "href": "appendix-d-probability.html#probability-distributions",
    "title": "Appendix D — Probability",
    "section": "\nD.3 Probability distributions",
    "text": "D.3 Probability distributions\nOK great. So we know a bit more about probability and a bit more about data types. Next thing we need to think about are probability distributions! A probability distribution is the theoretical counterpart to the observed frequency distribution. A frequency distribution simply shows how many times a certain event actually occurred. A probability distribution says how many times it should have occurred. Say for example you run a test on how many times different flips of a coin produce either heads or tails. What you count yourself is the frequency distribution. What was expected, based on simulationsGenerating data, as opposed to collecting data, from summary parameters such as the mean and standard deviation by mathematicians, is the probability distribution. Mathematicians have actually simulated a number of different probability distributions, and we know that different types of data will tend to naturally fall into a known distribution. From this, we can use these distributions to help us calculate the probability of an event without having to run it ourselves. To say that in another way, we can determine the probability of an event by running a test many many times ourselves, or we can use one of these simulated probability distributions which would save us a lot of time and effort. And that is what we are going to show you here.\nThe three distributions we will look at, to help us understand probability, are:\n\nThe uniform distribution\n\nThe binomial distribution\n\nThe normal distribution"
  },
  {
    "objectID": "appendix-d-probability.html#the-uniform-distribution",
    "href": "appendix-d-probability.html#the-uniform-distribution",
    "title": "Appendix D — Probability",
    "section": "\nD.4 The uniform distribution",
    "text": "D.4 The uniform distribution\nThe uniform distribution is when each possible outcome has an equal chance of occurring. Let’s take the example from above, pulling your name out of a hat of 12 names. Each individual name has an equal chance of being drawn (p = .08). If we visualised this distribution, it would look like this distribution below - each outcome, in this case each name, has the same chance of occurring:\n\n\n\n\nThe Uniform distribution, where every outcome has an equal probability of occurring.\n\n\n\nThe uniform distribution does not feature that regularly in Psychology, except perhaps in experiments where you are randomising which block people get first or when performing a chi-square test, but it helps us start to understand that each outcome has a probability in a distribution."
  },
  {
    "objectID": "appendix-d-probability.html#the-binomial-distribution",
    "href": "appendix-d-probability.html#the-binomial-distribution",
    "title": "Appendix D — Probability",
    "section": "\nD.5 The binomial distribution",
    "text": "D.5 The binomial distribution\nThe next distribution we want to look at is the binomial distribution. The binomial (bi = two, nominal = categories) distribution, is used for discrete data, and is a probability distribution which calculates probabilities of success for situations where there are two possible outcomes e.g., flipping a coin; your outcomes are either heads or tails! A binomial distribution models the probability of any number of successes being observed (e.g. was it a heads when you wanted heads), given the probability of a success and the number of observations (e.g. how many times did you get heads (a success) over ten coin flips (the observations)). It is probably worth pointing out that you as the researcher determine what is the success (heads or tails) but for ease here we will try to stick to heads.\nLet’s say we flip a coin 10 times. Assuming the coin is fair (probability of heads = .5), how many heads should we expect to get? The below figure shows the results of a simulation for 10,000 coin flips (if you’d like to do this simulation yourself, you can see the code by clicking “Show the code”). However, what this distribution means is that we can use what we know about our data and the binomial distribution to work out the probability of different outcomes. For example, instead of running a whole bunch of tests, we could use the distribution to answer the question of what is the probability of getting at least 3 heads if you flip a coin 10 times?.\n\n\n\n\nProbability of no. of heads from 10 coin tosses\n\n\n\n\n\nShow the code\n\nNote that you are not expected to understand this code right now\n\nheads10000 &lt;- replicate(n = 10000, \n                        expr = sample(0:1, \n                                      10, \n                                      TRUE) %&gt;%\n                          sum())\n\ndata10000 &lt;- tibble(heads = heads10000) %&gt;%\n                group_by(heads) %&gt;%     \n                summarise(n = n(),\n                          p=n/10000)\n\nggplot(data10000, aes(x = heads,y = p)) + \n  geom_bar(stat = \"identity\") + \n  labs(x = \"Number of Heads\", \n       y = \"Probability of Heads in 10 flips (p)\") +\n  theme_bw() +\n  scale_x_continuous(breaks = c(0,1,2,3,4,5,6,7,8,9,10))\n\n\nAgain, the binomial distribution is not hugely common in Psychology but we are really starting to see how we can ask questions about outcomes based on probability distributions as opposed to running tests ourselves. Let’s then look at this in a distribution that is very common in psychology - the normal distribution"
  },
  {
    "objectID": "appendix-d-probability.html#the-normal-distribution",
    "href": "appendix-d-probability.html#the-normal-distribution",
    "title": "Appendix D — Probability",
    "section": "\nD.6 The normal distribution",
    "text": "D.6 The normal distribution\nThe normal distribution, reflects the probability of any value occurring for a continuous variable. Examples of continuous variables include height or age, where a single person can score anywhere along a continuum. For example, a person could be 21.5 years old and 176 cm tall.\nThe normal distribution looks like this:\n\n\n\n\nNormal Distribution of height. \\(\\mu\\) = the mean (average), \\(\\sigma\\) = standard deviation\n\n\n\nSomething to note is that the normal distribution is symmetrical, meaning there is an equal probability of observations above and below the mean occurring. This means that, if the mean in the above plot of heights is 170 cm, we could expect the number of people who have a height of 160 cm to be the same as the number of people who have a height of 180 cm. A second thing to note is that as the distribution is symmetrical, the mean, median, and mode of the distribution are all equal and in the middle of the distribution and have the highest probability of occurring. As you move away from the middle of the distribution, the probability of those outcomes occurring starts to reduce. This plays an important role in analyses as we will come on to see in later chapters.\nNow, however, in the same way that we could with the coin flips, we can then use what we know about our data and the normal distribution to estimate the probability of certain outcomes, such as what’s the probability that someone would be taller than 190cm?\nAs with any probabilities, real-world data will come close to the normal distribution, but will (almost certainly) never match it exactly. As we collect more observations from data that we might expect to be normally distributed, our data will get increasingly closer to a normal distribution. As an example, here’s a simulation of an experiment in which we collect heights from 5000 participants. As you can see, as we add more observations, our data starts to look more and more like the normal distribution in the previous figure.\n\n\n\n\nA simulation of an experiment collecting height data from 2000 participants\n\n\n\n\nD.6.0.1 Activity 3: Normal distribution\nComplete the sentences to make sure that you are understanding the above.\n\nIn a normal distribution, the mean, median, and mode \nare all equal\nare always different\nsum to zero.\nIn a normal distribution, the further away from the mean an observation is \nthe lower its probability of occuring\nthe higher its probability of occuring.\nWhereas the binomial distribution is based on situations in which there are two possible outcomes, the normal distribution is based on situations in which the data \nhas three possible values\nis a categorical variable\nis a continuous variable.\n\nD.6.0.2 Activity 4: Distribution test\nWhich distribution is likely to be associated with the following?\n\nScores on an IQ test \nUniform distribution\nBinomial distribution\nNormal distribution\n\nWhether a country has won or lost the Eurovision song contest \nUniform distribution\nBinomial distribution\nNormal distribution\n\nPicking a spade card out of a normal pack of playing cards\nUniform distribution\nBinomial distribution\nNormal distribution"
  },
  {
    "objectID": "appendix-d-probability.html#using-the-binomial-distribution",
    "href": "appendix-d-probability.html#using-the-binomial-distribution",
    "title": "Appendix D — Probability",
    "section": "\nD.7 Using the binomial distribution",
    "text": "D.7 Using the binomial distribution\nNow, we’re going to calculate probabilities based on the binomial distribution. In this chapter, for the first time we don’t need to load the tidyverse. All of the functions we need are contained in Base R. If you want a refresher on the difference between Base R and packages, see Programming Basics.\n\nD.7.0.1 Activity 5: Getting Set-Up\n\nOpen a new R Markdown document, call it “Probability” and save it in the relevant chapter folder, remembering to delete the default text which we do not need.\n\nWe’re going to use three Base R functions to work with the binomial distribution:\n\n\ndbinom() - the density function: gives you the probability of x successes given the number of trials and the probability of success on a single trial (e.g., what’s the probability of flipping 8/10 heads with a fair coin?).\n\npbinom() - the probability distribution function: gives you the cumulative probability of getting a number of successes below a certain cut-off point (e.g. probability of getting 0 to 5 heads out of 10 flips), given the size and the probability. This is known as the cumulative probability distribution function or the cumulative density function.\n\nqbinom() - the quantile function: is the opposite of pbinom() in that it gives you the x axis value for a given probability p, plus given the size and prob, that is if the probability of flipping a head is .5, how many heads would you expect to get with 10 flips?\n\nSo let’s try these functions out to answer two questions:\n\nWhat is the probability of getting exactly 5 heads on 10 flips?\nWhat is the probability of getting at most 2 heads on 10 flips?\n\nD.7.0.2 Activity 6: dbinom()\n\nLet’s start with question 1, what is the probability of getting exactly 5 heads on 10 flips?\nWe want to predict the probability of getting 5 heads in 10 trials (coin flips) where the probability of success on each flip is 0.5 (it’ll either be heads or tails so you have a 50/50 chance which we write as 0.5). We will use dbinom() to work this out:\nThe dbinom() (density) function has three arguments:\n\n\nx: the number of ‘heads’ we want to know the probability of. Either a single value, 3, or a series of values, 0:10. In this case we want to know about 5 heads, so we write 5.\n\nsize: the number of trials (flips) we are simulating; in this case, 10 flips.\n\nprob: the probability of ‘heads’ on one trial. Here chance is 50-50 which as a probability we state as 0.5 or .5\n\nType and run the below code in a new code chunk:\n\ndbinom(x = 5, size = 10, prob = 0.5)\n\nLooking at the outcome, answer the following questions:\n\nTo two decimal places, what is the probability of getting 5 heads out of 10 coin flips? \n\nWhat is this probability expressed in percent? \n0.25%\n2.5%\n25%\n\n\nD.7.0.3 Activity 7: pbinom()\n\nOK, question 2. What is the probability of getting at most 2 heads on 10 flips?\nThis time we use pbinom() as we want to know the cumulative probability of getting a maximum of 2 heads from 10 coin flips. So we have set a cut-off point of 2 but we still have a probability of getting a heads of 0.5.\n\n\nNote: pbinom() takes the arguments size and prob argument just like dbinom(). However, the first input argument is q rather than x. This is because in dbinom x is a fixed number, whereas q is all the possibilities up to and including a given number (e.g. 0, 1, 2).\n\nType and run the below code in a new code chunk:\n\npbinom(q = 2, size = 10, prob = 0.5)\n\nLooking at the outcome, answer the following question:\n\nWhat is the probability of getting a maximum of 2 heads on 10 coin flips to 2 decimal places? \n\nWhat is this probability expressed in percent? \n0.05%\n0.5%\n5%\n\n\nD.7.0.4 Activity 8: pbinom() 2\nLet’s try one more scenario with a cut-off point to make sure you have understood this. What is the probability of getting 7 or more heads on 10 flips?\nWe can use the same function as in the previous example, however, there’s an extra argument if we want to get the correct answer. Let’s try running the code we used above first but change q = 2 to q = 7 to see what we get.\n\npbinom(q = 7, size = 10, prob = .5) \n\n[1] 0.9453125\n\n\nThis tells us that the probability is .95 or 95% - that doesn’t seem right does it? It seems very high for getting 7 or more heads out of 10 coin flips! Why is that? Well, the default behaviour for pbinom() is to calculate the cumulative probability for the lower tail of the curve, i.e., if you specify q = 2 it calculates the probability of all outcomes up to and including 2. We specified q = 7 which means that we have calculated the probability of getting an outcome of 0, 1, 2, 3, 4, 5, 6, or 7 - shown here in the blue area in the below figure - which is obviously very high.\n\n\n\n\nLower and upper tails\n\n\n\nTo get the right answer, we have to add lower.tail = FALSE to our code as we are interested in the upper tail of the distribution. Because we want the cumulative probability to include 7, and because we know q words as up to and including, in order to get 7 or more, we set q = 6. This will now calculate the cumulative probability of getting 7, 8, 9, or 10 heads out of 10 coin flips. Remember, if we set q = 7 that would be up to including 7, and looking at the upper tail of the distribution would only give us 8, 9 and 10. We want 7, 8, 9 and 10, so we have to set up to and including 6, which leaves us 7 and more.\nTry and run the below code in a new code chunk:\n\npbinom(q = 6, size = 10, prob = .5, lower.tail = FALSE) \n\nLooking at the outcome, answer the following question:\n\nWhat is the probability of getting between 7 and 10 heads from 10 coin flips to 2 decimal places? \n\nWhat is this probability expressed in percent? \n0.017%\n0.17\n17%\n\n\nD.7.0.5 Activity 9: qbinom()\n\nOK great! You are doing excellent as this is tricky stuff. Remember though the whole point is to show you that using probability distributions you can ask all sorts of questions about the probability of any outcome or series of outcomes.\nNow let’s consider a scenario in which you’d use the quantile function qbinom. Imagine that you’ve been accosted by a street magician and they want to bet you that they can predict whether the coin will land on heads or tails. You suspect that they’ve done something to the coin so that it’s not fair and that the probability of the coin landing on a head is no longer .5 or 50/50 - you suspect the coin is now very much more likely to land on tails. Your null hypothesis is that the coin is not a trick coin and that the probability of heads or tails should be even. You are going to run a single experiment to test your hypothesis, with 10 trials. What is the minimum number of heads that is acceptable if p really does equal .5?\nYou have used the argument prob in the previous two functions, dbinom and pbinom, and it represents the probability of success on a single trial (here it is the probability of ‘heads’ in one coin flip, .5). For qbinom, prob still represents the probability of success in one trial, whereas p represents the overall probability of success across all trials. When you run pbinom, it calculates the number of heads that would give that probability.\nWe know from looking at the binomial distribution above that sometimes even when the coin is fair, we won’t get exactly 5/10 heads. Instead, we want to set a cut-off, a probability that below which we’ll say that it’s so unlikely we’d get that result if the coin was fair and in this example we will use the default cut-off for statistical significance in psychology, .05, or 5%.\nIn other words, you ask for the minimum number of successes (e.g. heads) to maintain an overall probability of .05, in 10 flips, when the probability of a success on any one flip is .5. To do that we use the below code:\n\nqbinom(p = .05, size = 10, prob = .5)\n\n[1] 2\n\n\nFrom the code we see that the answer is 2. That means that if the magician flipped fewer than two heads out of ten, you could conclude that there is a less than 5% probability that would happened if the coin was fair. You would reject the null hypothesis that the coin was unbiased against heads and very very politely ask the kind magician for your money back!\nHowever, ten trials is probably far too few if you want to accuse the magician of being a bit dodge. Run the below code and then answer the following questions:\n\nqbinom(p = .05, size = c(100, 1000, 10000), prob = .5)\n\n\nWhat would your cut-off be if you ran 100 trials? \n\nWhat would your cut-off be if you ran 1000 trials? \n\nWhat would your cut-off be if you ran 10,000 trials? \n\n\nNotice that the more trials you run, the more precise the estimates become, that is, the closer they are to the probability of success on a single flip (.5). Again this is a simplification, but think about how this relates to sample size in research studies, the more participants you have, the more precise your estimate will be.\nWe should also mention that qbinom also uses the lower.tail argument and it works in a similar fashion to pbinom. We won’t try that out here but it is good to know in case you ever need it.\n\nVisualise it!\nHave a go at playing around with different numbers of coin flips and probabilities in our dbinom() and pbinom() app!"
  },
  {
    "objectID": "appendix-d-probability.html#using-the-normal-distribution",
    "href": "appendix-d-probability.html#using-the-normal-distribution",
    "title": "Appendix D — Probability",
    "section": "\nD.8 Using the normal distribution",
    "text": "D.8 Using the normal distribution\nA similar set of functions exist to help us work with other distributions, including the normal distribution and we’re going to use three of these:\n\n\ndnorm()- the density function, for calculating the probability of a specific value\n\npnorm()- the probability or distribution function, for calculating the probability of getting at least or at most a specific value\n\nqnorm()- the quantile function, for calculating the specific value associated with a given probability\n\nAs you can probably see, these functions are very similar to the functions that are used to work with the binomial distribution. We will use data about height in Scottish people to show you how the above functions work in the normal distribution\n\nD.8.1 Probability of heights\nData from the Scottish Health Survey (2008) shows that:\n\nThe average height of a 16-24 year old Scottish man is 176.2 centimetres, with a standard deviation of 6.748.\nThe average height of a 16-24 year old Scottish woman is 163.8 cm, with a standard deviation of 6.931.\nAt the time of writing, there is currently no data on Scottish trans and non-binary people.\n\nThe below figure is a simulation of this information - again, you can see the code used to run this simulation by clicking the “Show me the code” button but note that you are not asked to understand this right now.\n\n\nShow me the code\n\n\nmen &lt;- rnorm(n = 100000, mean = 176.2, sd = 6.748)\nwomen &lt;- rnorm(n = 100000, mean = 163.8, sd = 6.931)\n\nheights &lt;- tibble(men, women) %&gt;%\n  pivot_longer(names_to = \"sex\", values_to = \"height\", men:women)\n\nggplot(heights, aes(x = height, fill = sex)) +\n  geom_density(alpha = .6) +\n  scale_fill_viridis_d(option = \"E\") +\n  theme_minimal()\n\n\n\n\n\n\nSimulation of Scottish height data\n\n\n\nSo to test the normal distribution, and to round off this chapter, we will use the above information to calculate the probability of observing at least or at most a specific height with pnorm(), and the heights that are associated with specific probabilities with qnorm().\n\nD.8.1.1 Activity 10:pnorm()\n\npnorm() requires three arguments:\n\n\nq is the value that you want to calculate the probability of. Note however you set this as exactly the number you want and not 1 less than the number you want. This is because the data is continuous and not discrete as in the binomial distribution.\n\nmean is the mean of the data\n\nsd is the standard deviation of the data\n\nlower.tail works as above and depends on whether you are interested in the upper or lower tail,\n\nType the code below into a code chunk and replace the NULLs to calculate the probability of meeting a 16-24 y.o. Scottish woman who is as tall or taller than the average 16-24 y.o. Scottish man.\n\n\nhint: You are asking about the female distribution so use that mean and sd\n\nhint: the average male is 176.2\n\nhint: tall or taller is upper.\n\nhint: the solution is at the end of the chapter if you are stuck.\n\n\npnorm(q = NULL, mean = NULL, sd = NULL, lower.tail = NULL)\n\nLooking at your outcome, answer the following questions.\n\nWhat is the probability of meeting a 16-24 y.o. Scottish woman who is taller than the average 16-24 y.o. Scottish man? \n\nWhat is this probability expressed in percent? \n0.04%\n0.4%\n4%\n\n\nD.8.1.2 Activity 11: pnorm 2\nFiona is a very tall Scottish woman (181.12 cm) in the 16-24 y.o. range who will only date men who are taller than her.\n\nUsing pnorm() again, what is the proportion of Scottish men Fiona would be willing to date to 2 decimal places? \n\nhint: you want to know about the male population\n\nhint: Fiona is 181.12 cm tall and you want taller than her.\n\n\nWhat is this probability expressed in percent? \n0.23%\n2.3%\n23%\n\n\nD.8.1.3 Activity 12: pnorm 3\nOn the other hand, Fiona is bisexual and will only date women who are shorter than her.\n\nWhat is the proportion of Scottish women would Fiona be willing to date to 2 decimal places? \n\nhint: female distribution, lower than Fiona.\n\n\nWhat is this probability expressed in percent? \n0.99%\n9.9%\n99%\n\n\nD.8.1.4 Activity 13: qnorm()\n\nFinally, in the previous examples we calculated the probability of a particular outcome. Now we want to calculate what outcome would be associated with a particular probability and we can use qnorm() to do this.\nqnorm() is very similar to pnorm() with one exception, rather than specifying q our known observation or quantile, instead we have to specify p, our known probability.\n\nqnorm(p = NULL, mean = NULL, sd = NULL, lower.tail = NULL)\n\nReplace the NULLs in the above code to calculate how tall a 16-24 y.o. Scottish man would have to be in order to be in the top 5% (i.e., p = .05) of the height distribution for Scottish men in his age group. Remember the solutions are at the end of the chapter. You can confirm if you are right or not by answering this question:\nThe answer to this last question was:\n\n175.352037231422193.581696140348187.299472274669176.2\n\n\nVisualise it!\nHave a go at playing around with different distributions in our dnorm() and pnorm() app - access it here"
  },
  {
    "objectID": "appendix-d-probability.html#finished",
    "href": "appendix-d-probability.html#finished",
    "title": "Appendix D — Probability",
    "section": "\nD.9 Finished",
    "text": "D.9 Finished\nAnd that’s it! The key concepts to take away from this chapter are that different types of data tend to follow known distributions, and that we can use these distributions to calculate the probability of particular outcomes. This is the foundation of many of the statistical tests that you will learn about in this course. For example, if you want to compare whether the scores from two groups are different, that is, whether they come from different distributions, you can calculate the probability that the scores from group 2 would be in the same distribution as group 1. If this probability is less than 5% (p = .05), you might conclude that the scores were significantly different. That’s an oversimplification obviously, but if you can develop a good understanding of probability distributions it will stand you in good stead for the rest of the statistics content.\nThis was a long read so there is no test yourself today but be sure to make notes and to check your understanding of different concepts. Please also remember to ask any questions you are unsure of."
  },
  {
    "objectID": "appendix-d-probability.html#prob-sols",
    "href": "appendix-d-probability.html#prob-sols",
    "title": "Appendix D — Probability",
    "section": "\nD.10 Activity solutions",
    "text": "D.10 Activity solutions\n\nD.10.0.1 Activity 6\n\nTo two decimal places, what is the probability of getting 5 heads out of 10 coin flips?\n\n\n.25\n\n\nD.10.0.2 Activity 7\n\nWhat is the probability of getting a maximum of 2 heads on 10 coin flips to 2 decimal places?\n\n\n.06\n\n\nD.10.0.3 Activity 8\n\nWhat is the probability of getting between 7 and 10 heads from 10 coin flips to 2 decimal places?\n\n\n.17\n\n\nD.10.0.4 Activity 10\n\nWhat is the probability of meeting a 16-24 y.o. Scottish woman who is taller than the average 16-24 y.o. Scottish man?\n\n\npnorm(q = 176.2, mean = 163.8, sd = 6.931, lower.tail = FALSE)\n\n\nD.10.0.5 Activity 11\n\nUsing pnorm() again, what is the proportion of Scottish men Fiona would be willing to date to 2 decimal places?\n\n\npnorm(q = 181.12, mean = 176.2, sd = 6.748, lower.tail = FALSE)\n\n\nD.10.0.6 Activity 12\n\nWhat is the proportion of Scottish women would Fiona be willing to date to 2 decimal places?\n\n\npnorm(q = 181.12, mean = 163.8, sd = 6.931, lower.tail = TRUE)\n\n\nD.10.0.7 Activity 13\nThe answer to this last question was:\n\nqnorm(p = .05, mean = 176.2, sd = 6.748, lower.tail = FALSE)"
  },
  {
    "objectID": "appendix-d-probability.html#words-from-this-chapter",
    "href": "appendix-d-probability.html#words-from-this-chapter",
    "title": "Appendix D — Probability",
    "section": "\nD.11 Words from this Chapter",
    "text": "D.11 Words from this Chapter\nBelow you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the PsyTeachR Glossary. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter.\n\n\n\n\nterm\ndefinition\n\n\n\nbinomial distribution\n\n\n\nchi-square\n\n\n\ncontinuous\n\n\n\ndiscrete\n\n\n\ndistribution\n\n\n\ninferential\n\n\n\ninteger\n\n\n\nInterval\n\n\n\nLikert\n\n\n\nnominal\n\n\n\nnormal distribution\n\n\n\nordinal\n\n\n\npopulation\n\n\n\nprobability\n\n\n\nRatio\n\n\n\nsample\n\n\n\nsimulation\nGenerating data, as opposed to collecting data, from summary parameters such as the mean and standard deviation\n\n\nuniform distribution\n\n\n\n\n\n\nThat is end of this chapter. Be sure to look again at anything you were unsure about and make some notes to help develop your own knowledge and skills. It would be good to write yourself some questions about what you are unsure of and see if you can answer them later or speak to someone about them. Good work today!"
  },
  {
    "objectID": "14-anova.html",
    "href": "14-anova.html",
    "title": "\n13  One-way ANOVA\n",
    "section": "",
    "text": "13.0.1 Background: Intrusive memories\nIn the lecture reading materials you have worked through calculating an ANOVA by hand in order to gain a conceptual understanding. However, when you run an ANOVA, typically the computer does all of these calculations for you. In this chapter we’ll show you how to run a one-factor and factorial ANOVA using the afex package and post-hoc tests using a package called emmeans.\nIn this example we will be using data from experiment 2 of James, E. L., Bonsall, M. B., Hoppitt, L., Tunbridge, E. M., Geddes, J. R., Milton, A. L., & Holmes, E. A. (2015). Computer game play reduces intrusive memories of experimental trauma via reconsolidation-update mechanisms. Psychological Science, 26, 1201-1215.\nThe abstract for the paper is as follows:\n\nMemory of a traumatic event becomes consolidated within hours. Intrusive memories can then flash back repeatedly into the mind’s eye and cause distress. We investigated whether reconsolidation - the process during which memories become malleable when recalled - can be blocked using a cognitive task and whether such an approach can reduce these unbidden intrusions. We predicted that reconsolidation of a reactivated visual memory of experimental trauma could be disrupted by engaging in a visuospatial task that would compete for visual working memory resources. We showed that intrusive memories were virtually abolished by playing the computer game Tetris following a memory-reactivation task 24 hr after initial exposure to experimental trauma. Furthermore, both memory reactivation and playing Tetris were required to reduce subsequent intrusions (Experiment 2), consistent with reconsolidation-update mechanisms. A simple, non-invasive cognitive-task procedure administered after emotional memory has already consolidated (i.e., &gt; 24 hours after exposure to experimental trauma) may prevent the recurrence of intrusive memories of those emotional events.\n\n\n13.0.2 Activity 1: Set-up\nDo the following:\n\nOpen R Studio and set the working directory to your chapter folder. Ensure the environment is clear.\n\nOpen a new R Markdown document and save it in your working directory. Call the file “One-way ANOVA”.\n\nDownload James Holmes_Expt 2_DATA.csv and save it in your chapter folder.\n\nIf you’re on the server, avoid a number of issues by restarting the session - click Session - Restart R\n\nIn a new code chunk, type and run the code that loads pwr, lsr, car, broom, afex, emmeans, performance and tidyverse using the library() function and loads the data into an object named dat using read_csv(). If you are working on your own machine you may need to install afex and emmeans but as always do not install packages on university machines.\n\nAdd (hint: mutate) a column to dat called subjectthat equals row_number() to act as a participant ID which is currently missing from the data set.\n\n13.0.3 Activity 2: Data wrangling\nThere are a lot of columns in this data set that we don’t need for this analysis and the names of the variable are also long and difficult to work with.\n\nCreate a new object called dat2 that just has the three columns we need - use select() to select the columns subject, Condition, and Days_One_to_Seven_Image_Based_Intrusions_in_Intrusion_Diary\n\nUse rename() to rename Days_One_to_Seven_Image_Based_Intrusions_in_Intrusion_Diary to intrusions\n\nSee if you can do this all in one pipeline\nHint: in rename, new_name = old_name\n\n\n13.0.4 Activity 3: Numbers and factors\nIn addition to the names of the variables being too long, the levels of Condition are named 1,2,3,4 which R will think is a number rather than a category. We’re going to overwrite the column Condition with a column that recodes these numbers as a factor. Copy and paste the code below into your Markdown and then run it.\n\ndat2 &lt;- dat2 %&gt;%\n  mutate(Condition = as.factor(Condition))\n\nThis is a really important step. If you forget to recode variables as factors and R treats them as numbers, a lot of things won’t work. Trust us, we’ve spent a lot of time trying to figure out what was wrong because we forgot to do this step!\n\n13.0.5 Activity 4: Create summary statistics\nNext we want to calculate some descriptive statistics. We’re really interested in the scores from each experimental group rather than overall.\n\nCreate an object called sum_datthat contains the mean, standard deviation and standard error for the number of intrusions grouped by Condition\n\nUse the pipe to achieve this in one pipeline\n\nYour table should have four columns, Condition, mean, sd, and se.\n\n\n\nHint\n\n\n\n\n* Use group_by(some_grouping_variable) %&gt;% summarise(...)\n* standard error = sd/sqrt(n) =  sd/sqrt(length(some_variable_name)\n\n\n\n\n13.0.6 Activity 5: Visualisation\nNow we can visualise the data. In the original paper they use a bar plot, which we will reproduce later but for now let’s use a better plot that gives us more information about the data.\n\nCreate the below violin-boxplot with number of intrusions on the y-axis and condition on the x-axis (see the Visualisation chapter for more info).\nChange the labels on the x-axis to something more informative (hint: scale_x_discrete(labels = c(\"label names\"))\n\n\n\n\n\nNumber of intrusions by condition\n\n\n\nWe can see from this plot that there are outliers in each of the groups. This information isn’t present in the bar plot, which is why it’s not a good idea to use them but we will reproduce it anyway.The below code shows you how to produce the bar plot that is presented in the paper. Try and figure out what each bit of code is doing in the plot (remember to use the help documentation for each function) and see what happens when you change the values for each argument.\n\nggplot(sum_dat, aes(x = Condition, y = mean, fill = Condition))+\n  stat_summary(fun = \"mean\", geom = \"bar\", show.legend = FALSE)+\n  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), width = 0.25)+\n  scale_y_continuous(limits = c(0,7), \n                     breaks = c(0,1,2,3,4,5,6,7), \n                     name = \"Intrusive-Memory Frequency (Mean for the Week\")+\n  scale_x_discrete(labels = c(\"No-task control\", \"Reactivation plus Tetris\", \"Tetris only\",\n                                \"Reactivation only\"))\n\n\n\nBar plot of instrusions by condition\n\n\n\n\n13.0.7 Activity 6: One-way ANOVA\nNow we can run the one-way ANOVA using aov_ez from the afex package and save it to the object mod. As well as running the ANOVA, the aov_ez function also conducts a Levene’s test for homogeneity of variance so that we can test our final assumption.\naov_ez() will likely produce some messages that look like errors, do not worry about these, they are just letting you know what it’s done.\n\nCopy and paste the below code to run and then view the results of the ANOVA using anova(mod).\n\n\nmod &lt;- aov_ez(id = \"subject\", # the column containing the subject IDs\n              dv = \"intrusions\", # the DV \n              between = \"Condition\", # the between-subject variable\n              es = \"pes\", # sets effect size to partial eta-squared\n              type = 3, # this affects how the sum of squares is calculated, set this to 3\n              include_aov = TRUE,\n              data = dat2)\n\nanova(mod)\n\nJust like with the t-tests and correlations, we can use tidy() to make the output easier to work with.\n\nRun the below code to transform the output. Don’t worry about the warning message, it is just telling you it doesn’t know how to automatically rename the columns so it will keep the original names.\n\n\nmod_output &lt;- (mod$anova_table) %&gt;% tidy()\n\nWarning in tidy.anova(.): The following column names in ANOVA output were not\nrecognized or transformed: num.Df, den.Df, MSE, ges\n\n\n\n\nterm = the IV\n\n\nnum.Df = degrees of freedom effect\n\nden.Df = degrees of freedom residuals\n\nMSE = Mean-squared errors\n\nstatistic = F-statistic\n\nges = effect size\n\n\np.value = p.value\n\nYou should refer to the lecture for more information on what each variable means and how it is calculated.\n\nIs the overall effect of Condition significant? \nYes\nNo\n\nWhat is the F-statistics to 2 decimal places? \n\nAccording to the rules of thumb, the effect size is \nSmall\nMedium\nLarge\n\n\n13.0.8 Activity 7: Assumption checking\nYou may be wondering why we haven’t yet checked the assumptions. Well, unlike the t-tests and correlations, in order to test the assumptions we need to use the model we created with aov_ez(), so we couldn’t assess them all until this point. For a one-way independent ANOVA, the assumptions are the same as for a Student’s t-test:\n\nThe DV is interval or ratio data\nThe observations should be independent\nThe residuals should be normally distributed\nThere should be homogeneity of variance between the groups\n\nWe know that 1 and 2 are met because of the design of our study. To test 3, we can look at the QQ-plot of the residuals and test for normality with the Shapiro-Wilk test. The residuals have been stored as one of the components of mod. To access them we specify mod$aov$residuals.\n\nqqPlot(mod$aov$residuals)\nshapiro.test(mod$aov$residuals)\n\n[1] 11 60\n\n    Shapiro-Wilk normality test\n\ndata:  mod$aov$residuals\nW = 0.87739, p-value = 4.252e-06\n\n\n\n\nFigure 13.1: qq-plot for model residuals\n\n\n\nThere are a few things to note about the assumption test results. First, look at the p-value for the Shapiro-Wilk test - 4.252e-06. Whenever you see the e at the end of a number it means that R is using scientific notation. Scientific notation is a way of writing very large or very small numbers. Because the number after the e is negative it means the number should be divided by 10 to the power of six. Put simply, move the decimal place six places to the left and you will get the standard number. When reporting p-values in your results section, you should not use scientific notation, instead you should round to 3 decimal places.\n\nWhat is the value of 4.252e-06? \n.004252\n42.52\n.000004252\n\n\nIf you want R to round this for you to make it easier to read, you could use the below code to save it to an object, tidy it and then round the p.value. Just remember that in APA style you should never write “p = 0”, instead, you should write “p &lt; .001” (because p will never equal actual zero, it can just be very, very, very small).\n\nshapiro &lt;- shapiro.test(mod$aov$residuals) %&gt;% #run the test\n  tidy() %&gt;% # tidy the output\n  mutate(p.value = round(p.value, digits = 3)) # overwrite the p-value with one rounded to 3 decimal places\n\nIf you find scientific notation difficult to read, you can paste and run the following code in your console to turn it off\n\noptions(scipen=999)\n\nThe second thing to note is that from both the qq-plot and the Shapiro-Wilk test it is clear that the assumption of normality has not been met. Is this a problem? Well, Field et al. (2009) say that if the sample sizes for each group are equal then ANOVA is robust to violations of both normality and of homogeneity of variance. There’s also a good discussion of this here but it is a bit technical. We can check how many participants are in each condition using count():\n\ndat2 %&gt;% count(Condition)\n\n\n\n\n\nCondition\nn\n\n\n\n1\n18\n\n\n2\n18\n\n\n3\n18\n\n\n4\n18\n\n\n\n\n\nThankfully the sample sizes are equal so we should be OK to proceed with the ANOVA. It is not clear whether normality was checked in the original paper.\nFor the last assumption, we can test homogeneity of variance with Levene’s test and the function test_levene() from performance. The code for this is very simple, you just need to supply the ANOVA model we created earlier mod.\n\ntest_levene(mod)\n\nWarning: Functionality has moved to the 'performance' package.\nCalling 'performance::check_homogeneity()'.\n\n\nWarning: Variances differ between groups (Levene's Test, p = 0.039).\n\n\nThe results from Levene’s test show that the assumption of homogeneity of variance has also not been met. The paper does indicate this might be the case as it specifies that the ANOVAs do not assume equal variance, however, the results of the ANOVA that are reported are identical to our results above where no correction has been made although the post-hoc tests are Welch tests (you can tell this because the degrees of freedom have been adjusted and are not whole numbers).\nWhilst all of this might seem very confusing - we imagine you might be wondering what the point of assumption testing is given that it seems to be ignored - we’re showing you this for three reasons:\n\nTo reassure you that sometimes the data can fail to meet the assumptions and it is still ok to use the test. To put this in statistical terms, many tests are robust to mild deviations of normality and unequal variance, particularly with equal sample sizes.\nAs a critical thinking point, to remind you that just because a piece of research has been published does not mean it is perfect and you should always evaluate whether the methods used are appropriate.\nTo reinforce the importance of pre-registration where these decisions could be made in advance, and/or open data and code so that analyses can be reproduced exactly to avoid any ambiguity about exactly what was done. In this example, given the equal sample sizes and the difference in variance between the groups isn’t too extreme, it looks like it is still appropriate to use an ANOVA but the decisions and justification for those decisions could have been more transparent.\n\n13.0.9 Activity 8: Post-hoc tests\nFor post-hoc comparisons, as mentioned, the paper appears to have computed Welch t-tests but there is no mention of any multiple comparison correction. We could reproduce these results by using t.test for each of the contrasts.\nFor example, to compare condition 1 (the control group) with condition 2 (the reactivation plus tetris group) we could run:\n\ndat2 %&gt;%\n  filter(Condition %in% c(\"1\", \"2\")) %&gt;%\n  droplevels() %&gt;% \n  t.test(intrusions ~ Condition, data = .)\n\n\n\n\nBecause Condition has four levels, we can’t just specify intrustion ~ Condition because a t-test compares two groups and it wouldn’t know which of the four to compare so first we have to filter the data and use a new function droplevels(). It’s important to remember that when it comes to R there are two things to consider, the data you can see and the underlying structure of that data. In the above code we use filter() to select only conditions 1 and 2 so that we can compare them. However, that doesn’t change the fact that R “knows” that Condition has four levels - it doesn’t matter if two of those levels don’t have any observations any more, the underlying structure still says there are four groups. droplevels() tells R to remove any unused levels from a factor. Try running the above code but without droplevels() and see what happens.\n\n\n\nHowever, a quicker and better way of doing this that allows you apply a correction for multiple comparisons easily is to use emmeans() which computes all possible pairwise comparison t-tests and applies a correction to the p-value.\nFirst, we use emmeans() to run the comparisons and then we can pull out the contrasts and use tidy() to make it easier to work with.\n\nRun the code below. Which conditions are significantly different from each other? Are any of the comparisons different from the ones reported in the paper now that a correction for multiple comparisons has been applied?\n\n\nmod_pairwise &lt;-emmeans(mod, pairwise ~ Condition, adjust = \"bonferroni\")\nmod_contrasts &lt;- mod_pairwise$contrasts %&gt;% tidy()\n\n\n\n\nThe inquisitive amongst you may have noticed that mod is a list of 5 and seemingly contains the same thing three times: anova_table, aov and Anova. The reasons behind the differences are too complex to go into detail on this course (see here for more info) but the simple version is that anova_table and Anovause one method of calculating the results (type 3 sum of squares) and aov uses a different method (type 1 sum of squares). What’s important for your purposes is that you need to use anova_table to view the overall results (and replicate the results from papers) and aovto run the follow-up tests and to get access to the residuals (or lm() for factorial ANOVA). As always, precision and attention to detail is key.\n\n\n\n\n13.0.10 Activity 9: Power and effect size\nFinally, we can replicate their power analysis using pwr.anova.test.\n\nOn the basis of the effect size of d = 1.14 from Experiment 1, we assumed a large effect size of f = 0.4. A sample size of 18 per condition was required in order to ensure an 80% power to detect this difference at the 5% significance level.\n\n\npwr.anova.test(k = 4, f = .4, sig.level = .05, power = .8)\n\n\n     Balanced one-way analysis of variance power calculation \n\n              k = 4\n              n = 18.04262\n              f = 0.4\n      sig.level = 0.05\n          power = 0.8\n\nNOTE: n is number in each group\n\n\nWe’ve already got the effect size for the overall ANOVA, however, we should also really calculate Cohen’s D using cohensD from lsr for each of the pairwise comparisons. This code is a little complicated because you need to do it separately for each comparison, bind them all together and then add them to mod_contrasts - just make sure your understand which bits of the code you would need to change to run this on different data.\n\nd_1_2 &lt;- cohensD(intrusions ~ Condition, \n                 data = filter(dat2, Condition %in% c(1,2)) %&gt;% \n                   droplevels())\n\nd_1_3 &lt;- cohensD(intrusions ~ Condition, \n                 data = filter(dat2, Condition %in% c(1,3)) %&gt;%\n                   droplevels()) \n\nd_1_4 &lt;- cohensD(intrusions ~ Condition, \n                 data = filter(dat2, Condition %in% c(1,4)) %&gt;%\n                   droplevels())\n\nd_2_3 &lt;- cohensD(intrusions ~ Condition, \n                 data = filter(dat2, Condition %in% c(2,3)) %&gt;% \n                   droplevels())\n\nd_2_4 &lt;- cohensD(intrusions ~ Condition, \n                 data = filter(dat2, Condition %in% c(2,4)) %&gt;% \n                   droplevels())\n\nd_3_4 &lt;- cohensD(intrusions ~ Condition, \n                 data = filter(dat2, Condition %in% c(3,4)) %&gt;%\n                   droplevels())\n\npairwise_ds &lt;- c(d_1_2,d_1_3,d_1_4,d_2_3,d_2_4,d_3_4)\n\nmod_contrasts &lt;- mod_contrasts %&gt;%\n  mutate(eff_size = pairwise_ds)\n\n\n\n\nWhat are your options if the data don’t meet the assumptions and it’s really not appropriate to continue with a regular one-way ANOVA? As always, there are multiple options and it is a judgement call.\n\n\n\nYou could run a non-parametric test, the Kruskal-Wallis for between-subject designs and the Friedman test for within-subject designs.\n\n\nIf normality is the problem, you could try transforming the data. Field et al. (2009) has a good section on data transformation.\n\n\nYou could use bootstrapping, which is not something we will cover in this course at all. Again, Field et al. (2009) covers this although it is a little complicated.\n\n\n\n\n\n13.0.11 Activity 10: Write-up\nThe below code replicates the write-up in the paper, although has changed the Welch t-test to the pairwise comparisons from emmeans.\n\nSecond, and critically, for the 7-day diary postintervention, there was a significant difference between groups in overall intrusion frequency in daily life, F(`r mod_output$num.Df`, `r mod_output$den.Df`) = `r mod_output$statistic %&gt;% round(2)`, p = `r mod_output$p.value %&gt;% round(3)`, ηp2 = .`r mod_output$ges %&gt;% round(2)`. Planned comparisons demonstrated that relative to the no-task control group, only those in the reactivation-plus-Tetris group, t(`r mod_contrasts$df[1]`) = `r mod_contrasts$statistic[1] %&gt;% round(2)`, p = `r mod_contrasts$adj.p.value[1] %&gt;% round(2)`, d = `r mod_contrasts$eff_size[1] %&gt;% round(2)`, experienced significantly fewer intrusive memories; this finding replicated Experiment 1. The reactivation-plus-Tetris group had significantly fewer intrusive thoughts than the reactivation-only group, t(`r mod_contrasts$df[5]`) = `r mod_contrasts$statistic[5] %&gt;% round(2)`, p = `r mod_contrasts$adj.p.value[5] %&gt;% round(2)`, d = `r mod_contrasts$eff_size[5] %&gt;% round(2)`. Further, there were no significant differences between the reactivation-plus-Tetris group and the Tetris-only group, t(`r mod_contrasts$df[4]`) = `r mod_contrasts$statistic[4] %&gt;% round(2)`, p = `r mod_contrasts$adj.p.value[4] %&gt;% round(2)`, d = `r mod_contrasts$eff_size[4] %&gt;% round(2)`, the no-task control group and the reactivation-only group, t(`r mod_contrasts$df[3]`) = `r mod_contrasts$statistic[3] %&gt;% round(2)`, p = `r mod_contrasts$adj.p.value[3] %&gt;% round(2)`, or between the no-task control group and the Tetris-only group, t(`r mod_contrasts$df[2]`) = `r mod_contrasts$statistic[2] %&gt;% round(2)`, p = `r mod_contrasts$adj.p.value[2] %&gt;% round(2)`\n\nSecond, and critically, for the 7-day diary postintervention, there was a significant difference between groups in overall intrusion frequency in daily life, F(3, 68) = 3.79, p = 0.014, ηp2 = .0.14. Planned comparisons demonstrated that relative to the no-task control group, only those in the reactivation-plus-Tetris group, t(68) = 3.04, p = 0.02, d = 1, experienced significantly fewer intrusive memories; this finding replicated Experiment 1. Critically, as predicted by reconsolidation theory, the reactivation-plus-Tetris group had significantly fewer intrusive memories than the Tetris-only group, t(68) = -1.89, p = 0.38, d = 0.84, as well as the reactivation-only group, t(68) = -2.78, p = 0.04, d = 1.11. Further, there were no significant differences between the no-task control group and the reactivation-only group, t(68) = 0.26, p = 1, or between the no-task control group and the Tetris-only group, t(68) = 1.15, p = 1\n\n13.0.12 Activity solutions\nBelow this line you will find the solutions to the above tasks. Only look at them after giving the tasks a good try yourself!\n\n13.0.12.1 Activity 1\n\n\nSolution\n\n\nlibrary(\"pwr\")\nlibrary(\"lsr\")\nlibrary(\"car\")\nlibrary(\"broom\")\nlibrary(\"afex\")\nlibrary(\"emmeans\")\nlibr\\ry(\"performance\")\nlibrary(\"tidyverse\")\n\ndat &lt;- read_csv(\"James Holmes_Expt 2_DATA.csv\")%&gt;%\n  mutate(subject = row_number())\n\n\n** Click tab to see solution **\n\n13.0.12.2 Activity 2\n\n\nSolution\n\n\ndat2 &lt;- dat%&gt;%\n  select(subject,Condition,Days_One_to_Seven_Image_Based_Intrusions_in_Intrusion_Diary)%&gt;%\n  rename(intrusions = Days_One_to_Seven_Image_Based_Intrusions_in_Intrusion_Diary)\n\n\n** Click tab to see solution **\n\n13.0.12.3 Activity 4\n\n\nSolution\n\n\nsum_dat&lt;-dat2%&gt;%\n  group_by(Condition)%&gt;%\n  summarise(mean = mean(intrusions),\n            sd = sd(intrusions),\n            se = sd/sqrt(length(intrusions)))\n\n\n** Click tab to see solution **\n\n13.0.12.4 Activity 5\n\n\nSolution\n\n\nggplot(dat2, aes(x = Condition, y = intrusions))+\n  geom_violin(trim = FALSE)+\n  geom_boxplot(width = .2)\n\n\n** Click tab to see solution **"
  },
  {
    "objectID": "15-factorial-anova.html",
    "href": "15-factorial-anova.html",
    "title": "\n14  Factorial ANOVA\n",
    "section": "",
    "text": "For this chapter, we’re going to look at an example of a factorial ANOVA. You’ll learn more about interpreting these in the lectures, but for now, we’ll just focus on the code.\nWe’re going to reproduce the analysis from Experiment 3 of Zhang, T., Kim, T., Brooks, A. W., Gino, F., & Norton, M. I. (2014). A “present” for the future: The unexpected value of rediscovery. Psychological Science, 25, 1851-1860.. You may remember this study from the Chapter Visualisation chapter.\nThis experiment has a 2 x 2 mixed design:\n\nThe first IV is time (time1, time2) and is within-subjects\nThe second IV is type of event (ordinary vs. extraordinary) and is a between-subjects factor\nThe DV we will use is interest\n\n\n\n14.0.1 Activity 1: Set-up\n\nOpen R Studio and set the working directory to your chapter folder. Ensure the environment is clear.\nOpen a new R Markdown document and save it in your working directory. Call the file “Factorial ANOVA”.\nDownload Zhang et al. 2014 Study 3.csv and extract the files in to your Chapter 15 folder.\nIf you’re on the server, avoid a number of issues by restarting the session - click Session - Restart R\n\nIf you are working on your own computer, install the package rcompanion. Remember do not install packages on university computers, they are already installed.\nType and run the code that loads pwr, rcompanion, lsr, car, broom, afex, emmeans and tidyverse using the library() function.\n\nRun the below code to load the data and wrangle it into the format we need. You don’t need to write this code yourself but do make sure you can understand what each line is doing - a good way to do this when the code uses pipes (%&gt;%) is to highlight and run each line progressively so you can see how it builds up. Line-by-line the code:\n\nReads in the data file\nSelect the three columns we need\n\nAdds on a column of subject IDs\n\nTidies the data\nRecodes the values of Condition from numeric to text labels\nRecodes the values of time to be easier to read/write\n\n\nfactorial &lt;- read_csv(\"Zhang et al. 2014 Study 3.csv\")%&gt;%\n  select(Condition, T1_Predicted_Interest_Composite, T2_Actual_Interest_Composite)%&gt;%\n  mutate(subject = row_number())%&gt;%\n  pivot_longer(names_to = \"time\",values_to = \"interest\", cols =       c(\"T1_Predicted_Interest_Composite\",\"T2_Actual_Interest_Composite\"))%&gt;%\n  mutate(Condition = dplyr::recode(Condition, \"1\" = \"Ordinary\", \"2\" = \"Extraordinary\"))%&gt;%\n  mutate(time = dplyr::recode(time, \"T1_Predicted_Interest_Composite\" = \"time1_interest\",\n                       \"T2_Actual_Interest_Composite\" = \"time2_interest\")) %&gt;%\n  mutate(Condition = as.factor(Condition)) %&gt;% \n  mutate (time= as.factor(time))\n\n\n14.0.2 Activity 2: Descriptive statistics\n\nCalculate descriptive statistics (mean and SD) for interest for each Condition for each time (hint: you will need to group_by() two variables) and store it in an object named sum_dat_factorial. These are known as the cells means.\n\n14.0.3 Activity 3: Violin-boxplots\nWe’re going to produce two kinds of plots to visualise our data. First, we’ll produce violin-boxplots so that we can see the distribution of our data.\n\nWrite the code that produces the below violin-boxplots for the scores in each group.\n\nHint 1: you will need to add in the second IV in the first call to ggplot as a fill argument (aes(x,y,fill)).\nHint 2: you will need to add position = position_dodge(.9) to geom_boxplot to get the plots to align.\n\n\n\nYou don’t need to replicate the exact colour scheme used below, see if you can play around with the settings to whatever colour scheme you think works best.\n\n\n\n\nViolin-boxplot by condition and time\n\n\n\n\n14.0.4 Activity 4: Interaction plots\nNow we’re going to produce an interaction plot that makes it easier to see how the IVs are interacting, which requires some ggplot2 functions we haven’t come across yet. Rather than using the raw data in dat_factorial, we use the means that we produced in sum_dat_factorial. This type of plot requires two geoms, one to draw the points, and one to draw the lines that connect them.\nThis plot reproduces the plot used in the paper.\n\nRun the code and then play around with how it looks by changing the arguments for e.g., colour, line-type, and the theme.\n\n\nggplot(sum_dat_factorial, aes(x = time, y = mean, group = Condition, shape = Condition)) +\n  geom_point(size = 3) +\n  geom_line(aes(linetype = Condition))+\n  scale_x_discrete(labels = c(\"Time 1\", \"Time 2\"))+\n  theme_classic()\n\n\n\nInteraction plot\n\n\n\n\n14.0.5 Activity 5: ANOVA\n\nComplete the below code to run the factorial ANOVA. Remember that you will need to specify both IVs and that one of them is between-subjects and one of them is within-subjects. Look up the help documentation for aov_ez to find out how to do this.\nSave the ANOVA model to an object called mod_factorial\nPull out the anova table, you can either do this with mod_factorial$anova_table or anova(mod_factorial) both have the same result. Save this to an object named factorial_output and make sure you have used tidy().\n\n\nmod_factorial &lt;- aov_ez(id = \"NULL\",\n               data = NULL, \n               between = \"NULL\", \n               within = \"NULL\",\n               dv = \"NULL\", \n               type = 3,\n               es = \"NULL\") \n\nfactorial_output &lt;- NULL\n\nLook at the results. Remember the pre-class information about how to read p-values in scientific notation.\n\nIs the main effect of condition significant? \nYes\nNo\n\nIs the main effect of time significant? \nYes\nNo\n\nIs the two-way interaction significant? \nYes\nNo\n\n\n14.0.6 Activity 6: Assumption checking\nThe assumptions for a factorial ANOVA are the same as the one-way ANOVA.\n\nThe DV is interval or ratio data\nThe observations should be independent\nThe residuals should be normally distributed\nThere should be homogeneity of variance between the groups\n\nAs before, we know assumption 2 is met from the design of the study. Assumption 1 throws up an interesting issue which is the problem of ordinal data. Ordinal data are the kind of data that come from Likert scales and are very common in psychology. The problem is that ordinal data aren’t interval or ratio data, there’s a fixed number of values they can take (the values of the Likert scale) and you can’t claim that the distance between the values is equal (is the difference between strongly agree and agree the same as the difference between agree and neutral?).\nTechnically, we shouldn’t use an ANOVA to analyse ordinal data - but almost everyone does. Most people would argue that if there are multiple Likert scale items that are averaged (which is the case in our study) and this averaged data are normally distributed, then it is not a problem. There is a minority (who are actually correct) that argue you should use non-parametric methods or more complicated tests such as ordinal regression for this type of data. Whichever route you choose, you should understand the data you have and you should be able to justify your decision.\n\nTo test assumption 3, extract the residuals from the model (mod_factorial$lm$residuals), create a qq-plot and conduct a Shapiro-Wilk test.\nAre the residuals normally distributed? \nYes\nNo\nNo, but given the sample it is probably acceptable to proceed\n\nFor the final assumption, we can again use test_levene() to test homogeneity of variance.\n\nConduct Levene’s test. Is assumption 4 met? \nYes\nNo\n\n\n14.0.7 Activity 7: Post-hoc tests\nBecause the interaction is significant, we should follow this up with post-hoc tests using emmeans() to determine which comparisons are significant. If the overall interaction is not significant, you should not conduct additional tests.\nemmeans() requires you to specify the aov object, and then the factors you want to contrast. For an interaction, we use the notation pairwise ~ IV1 | IV2 and you specify which multiple comparison correction you want to apply. Finally, you can use tidy() to tidy up the output of the contrasts and save it into a tibble.\n\nRun the below code and view the results.\n\n\n# run the tests\nposthoc_factorial &lt;- emmeans(mod_factorial, \n                             pairwise ~ time| Condition, \n                             adjust = \"bonferroni\")\n\n# tidy up the output of the tests\ncontrasts_factorial &lt;- posthoc_factorial$contrasts %&gt;%\n  tidy()\n\nNote that because there are two factors, we could also reverse the order of the IVs. Above, we get the results contrasting time 1 and time 2 for each event condition. Instead, we could look at the difference between ordinary and extraordinary events at each time point.\n\nRun the below code and look at the output of contrast_factorial and contrasts_factorial2 carefully making sure you understand how to interpret the results. You will find it useful to refer to the interaction plot we made earlier.\n\n\nposthoc_factorial2 &lt;- emmeans(mod_factorial, \n                             pairwise ~ Condition| time, \n                             adjust = \"bonferroni\") \n\ncontrasts_factorial2 &lt;- posthoc_factorial2$contrasts %&gt;%\n  tidy()\n\nBecause our main effects (condition and time) only have two levels, we don’t need to do any post-hoc tests to determine which conditions differ from each other, however, if one of our factors had three levels then we could use emmeans() to calculate the contrast for the main effects, like we did for the one-way ANOVA.\nFinally, to calculate effect size for the pairwise comparisons we again need to do this individually using ’cohensD()fromlsr`.\n\nRun the below code to add on effect sizes to contrasts_factorial and contrasts_factorial2.\n\n\nd_extra_t1_t2 &lt;- cohensD(interest ~ time, \n                         data = (filter(factorial, Condition == \"Extraordinary\") %&gt;% droplevels())) \n\nd_ord_t1_t2 &lt;- cohensD(interest ~ time, \n                         data = (filter(factorial, Condition == \"Ordinary\") %&gt;% droplevels())) \n\n\nCondition_ds &lt;- c(d_extra_t1_t2, d_ord_t1_t2)\n\ncontrasts_factorial &lt;- contrasts_factorial %&gt;%\n  mutate(eff_size = Condition_ds)\n\nd_time1_extra_ord &lt;- cohensD(interest ~ Condition, \n                         data = (filter(factorial, time == \"time1_interest\") %&gt;% droplevels())) \n\nd_time2_extra_ord &lt;- cohensD(interest ~ Condition, \n                         data = (filter(factorial, time == \"time2_interest\") %&gt;% droplevels()))\n\n\ntime_ds &lt;- c(d_time1_extra_ord, d_time2_extra_ord)\n\ncontrasts_factorial2 &lt;- contrasts_factorial2 %&gt;%\n  mutate(eff_size = time_ds)\n\n\n14.0.8 Activity 8: Write-up\n\np-values of &lt; .001 have been entered manually. There is a way to get R to produce this formatting but it’s overly complicated for our purposes. If you want to push yourself, look up the papaja package.\nThe values of partial eta-squared do not match between our analysis and those reported in the paper. I haven’t figured out why this is yet - if you know, please get in touch!\nWe have replaced the simple effects in the main paper with our pairwise comparisons.\n\nFirst we need to calculate descriptives for the main effect of time as we didn’t do this earlier.\n\ntime_descrip &lt;- factorial %&gt;% \n  group_by(time) %&gt;%\n  summarise(mean_interest = mean(interest, na.rm = TRUE),\n            sd_interest = sd(interest, na.rm = TRUE))\n\nCopy and paste the below into white-space.\n\nWe conducted the same repeated measures ANOVA with interest as the dependent measure and again found a main effect of time, F(`r factorial_output$num.Df[2]`, `r factorial_output$den.Df[2]`) = `r factorial_output$statistic[2] %&gt;% round(2)`, p &lt; .001, ηp2 = `r factorial_output$ges[2] %&gt;% round(3)`; anticipated interest at Time 1 (M = `r time_descrip$mean_interest[1] %&gt;% round(2)`), SD = `r time_descrip$sd_interest[1]%&gt;% round(2)`)) was lower than actual interest at Time 2 (M = `r time_descrip$mean_interest[2]%&gt;% round(2)`, SD = `r time_descrip$sd_interest[2]%&gt;% round(2)`).We also observed an interaction between time and type of experience, F(`r factorial_output$num.Df[3]`, `r factorial_output$den.Df[3]`) = `r factorial_output$statistic[3] %&gt;% round(3)`, p = `r factorial_output$p.value[3] %&gt;% round(2)`, ηp2 = `r factorial_output$ges[3] %&gt;% round(3)`. Pairwise comparisons revealed that for ordinary events, predicted interest at Time 1 (M = `r sum_dat_factorial$mean[3]%&gt;% round(2)`, SD = `r sum_dat_factorial$sd[3]%&gt;% round(2)`) was lower than experienced interest at Time 2 (M = `r sum_dat_factorial$mean[4]%&gt;% round(2)`, SD = `r sum_dat_factorial$sd[4]%&gt;% round(2)`), t(`r contrasts_factorial$df[2]%&gt;% round(2)`) = `r contrasts_factorial$statistic[2]%&gt;% round(2)`, p &lt; .001, d = `r contrasts_factorial$eff_size[2]%&gt;% round(2)`. Although predicted interest for extraordinary events at Time 1 (M = `r sum_dat_factorial$mean[1]%&gt;% round(2)`, SD = `r sum_dat_factorial$sd[1]%&gt;% round(2)`) was lower than experienced interest at Time 2 (M = `r sum_dat_factorial$mean[2]%&gt;% round(2)`, SD = `r sum_dat_factorial$sd[2]%&gt;% round(2)`), t(`r contrasts_factorial$df[1]%&gt;% round(2)`) = `r contrasts_factorial$statistic[1]%&gt;% round(2)`, p &lt; .001, d = `r contrasts_factorial$eff_size[1]%&gt;% round(2)` , the magnitude of underestimation was smaller than for ordinary events.\n\n\nWe conducted the same repeated measures ANOVA with interest as the dependent measure and again found a main effect of time, F(1, 128) = 25.88, p &lt; .001, ηp2 = 0.044; anticipated interest at Time 1 (M = 4.2), SD = 1.12)) was lower than actual interest at Time 2 (M = 4.69, SD = 1.19).We also observed an interaction between time and type of experience, F(1, 128) = 4.445, p = 0.04, ηp2 = 0.008. Pairwise comparisons revealed that for ordinary events, predicted interest at Time 1 (M = 4.04, SD = 1.09) was lower than experienced interest at Time 2 (M = 4.73, SD = 1.24), t(128) = -5.05, p &lt; .001, d = 0.59. Although predicted interest for extraordinary events at Time 1 (M = 4.36, SD = 1.13) was lower than experienced interest at Time 2 (M = 4.65, SD = 1.14), t(128) = -2.12, p &lt; .001, d = 0.25 , the magnitude of underestimation was smaller than for ordinary events.\n\n\n14.0.9 Activity 9: Transforming data\nIn this chapter we decided that the violation of the assumption of normality was ok so that we could replicate the results in the paper. But what if we weren’t happy with this or if the violation had been more extreme? One option to deal with normality is to transform your data. If you want more information on this you should consult the Appendix chapter on data transformation.\nThere are various options for how you can transform data but we’re going to use Tukeys Ladder of Powers transformation. This finds the power transformation that makes the data fit the normal distribution as closely as possible with this type of transformation.\n\nRun the below code. This will use mutate() to add a new variable to the data-set, interest_tukey which is going to be our transformed DV. The function transformTukey() is from the rcompanion package. Setting plotit = TRUE will automatically create qqPlots and histograms so that we can immediately visualise the new variable.\n\n\nfactorial &lt;- factorial %&gt;%\n  mutate(interest_tukey = transformTukey(interest, plotit=TRUE))\n\nNow that you’ve transformed the DV we can re-run the ANOVA with this new variable.\n\ntukey_factorial &lt;- aov_ez(id = \"subject\",\n               data = factorial, \n               between = \"Condition\", \n               within = \"time\",\n               dv = \"interest_tukey\", \n               type = 3)\n\ntukey_factorial\n\nNotice that doing this hasn’t changed the pattern of the ANOVA results, the p-values for the main effects and interactions are very slightly different but the overall conclusions remain the same. This is likely because the violations of normality was quite mild and there is a large sample size, however, with the transformation we can be more confident in our results and it may not always be the case that the transformed ANOVA is the same if the violations were more extreme.\n\n14.0.9.1 Finished!\n\n14.0.10 Activity solutions\n\n14.0.10.1 Activity 1\n\n\nActivity 1\n\n\nlibrary(\"pwr\")\nlibrary(\"rcompanion\")\nlibrary(\"car\")\nlibrary(\"lsr\")\nlibrary(\"broom\")\nlibrary(\"afex\")\nlibrary(\"emmeans\")\nlibrary(\"tidyverse\")\n\n\n** Click tab to see solution **\n\n14.0.10.2 Activity 2\n\n\nSolution\n\n\nsum_dat_factorial&lt;-factorial%&gt;%\n  group_by(Condition, time)%&gt;%\n  summarise(mean = mean(interest, na.rm = TRUE),\n            sd = sd(interest, na.rm = TRUE)\n            )\n\n\n** Click tab to see solution **\n\n14.0.10.3 Activity 3\n\n\nSolution\n\n\nggplot(factorial, \n       aes(x = time , y = interest, fill = Condition))+\n  geom_violin(trim = FALSE, \n              alpha = .4)+\n  geom_boxplot(position = position_dodge(.9), \n               width = .2, \n               alpha = .6)+\n  scale_x_discrete(labels = c(\"Time 1\", \"Time 2\"))+\n  scale_fill_viridis_d(option = \"E\")+\n  stat_summary(fun = \"mean\", geom = \"point\",\n               position = position_dodge(width = 0.9)) +\n  stat_summary(fun.data = \"mean_se\", geom = \"errorbar\", width = .1,\n               position = position_dodge(width = 0.9)) +\n  theme_minimal()\n\n\n** Click tab to see solution **\n\n14.0.10.4 Activity 5\n\n\nSolution\n\n\nmod_factorial &lt;- aov_ez(id = \"subject\",\n               data = factorial, \n               between = \"Condition\", \n               within = \"time\",\n               dv = \"interest\", \n               type = 3) \n\nfactorial_output &lt;- anova(mod_factorial) %&gt;% tidy()\n\n# OR\n\nfactorial_output &lt;- mod_factorial$anova_table %&gt;% tidy()\n\n\n** Click tab to see solution **\n\n14.0.10.5 Activity 6\n\n\nSolution\n\n\n# normality testing\nqqPlot(mod_factorial$lm$residuals)\nshapiro.test(mod_factorial$lm$residuals)\n\n# levene's test\ntest_levene(mod_factorial)\n\n\n** Click tab to see solution **"
  },
  {
    "objectID": "16-regression.html#regression-a1",
    "href": "16-regression.html#regression-a1",
    "title": "\n15  Regression\n",
    "section": "\n15.1 Activity 1: Setup",
    "text": "15.1 Activity 1: Setup\n\nOpen R Studio and set the working directory to your chapter folder. Ensure the environment is clear.\n\nOpen a new R Markdown document and save it in your working directory. Call the file “Regression”.\n\nDownload L3_stars.csv and psess.csv and save them in your chapter folder. Make sure that you do not change the file name at all.\n\nIf you’re on the server, avoid a number of issues by restarting the session - click Session - Restart R\n\nDelete the default R Markdown welcome text and insert a new code chunk that loads pwr, broom, see, performance, report and tidyverse using the library() function.\nLoad the two CSV datasets into variables called stars and engage using read_csv()."
  },
  {
    "objectID": "16-regression.html#regression-a2",
    "href": "16-regression.html#regression-a2",
    "title": "\n15  Regression\n",
    "section": "\n15.2 Activity 2: Tidy the data",
    "text": "15.2 Activity 2: Tidy the data\n\nTake a look at both of the datasets you loaded in.\n\nThe next thing we need to do is to calculate a mean anxiety score for each student (recall that individual students are identified by the ID variable).\nRecall the difference between wide and tidy data. In wide data, each row represents an individual case, with observations for that case in separate columns; in tidy data, each row represents a single observation, and the observations are grouped together into cases based on the value of a variable (for these data, the ID variable).\n\nThe STARS data are currently in \nwide\ntidy format.\n\nBefore we calculate means, you need to use pivot_longer() to restructure the STARS data into the appropriate “tidy” format; i.e., so that it looks like the table below.\n\n\n\n\nID\nQuestion\nScore\n\n\n\n3\nQ01\n1\n\n\n3\nQ02\n1\n\n\n3\nQ03\n1\n\n\n3\nQ04\n1\n\n\n3\nQ05\n1\n\n\n3\nQ06\n1\n\n\n\n\n\n\nWrite and run the code to do tidy the STARS data, and store the resulting table as stars2."
  },
  {
    "objectID": "16-regression.html#regression-a3",
    "href": "16-regression.html#regression-a3",
    "title": "\n15  Regression\n",
    "section": "\n15.3 Activity 3: Calculate mean anxiety for each student",
    "text": "15.3 Activity 3: Calculate mean anxiety for each student\n\nNow that you’ve got the data into a tidy format, use summarise() and group_by() to calculate mean anxiety scores (mean_anxiety) for each student (ID). Store the resulting table in a variable named stars_means."
  },
  {
    "objectID": "16-regression.html#regression-a4",
    "href": "16-regression.html#regression-a4",
    "title": "\n15  Regression\n",
    "section": "\n15.4 Activity 4: Join the datasets together",
    "text": "15.4 Activity 4: Join the datasets together\n\nIn order to perform the regression analysis, combine the data from stars_means with engage using inner_join(). Call the resulting table joined. It should look like this:\n\n\n\n\n\nID\nmean_anxiety\nn_weeks\n\n\n\n3\n1.06\n5\n\n\n7\n2.71\n2\n\n\n12\n2.24\n3\n\n\n16\n2.86\n2\n\n\n23\n1.71\n6\n\n\n29\n1.80\n7"
  },
  {
    "objectID": "16-regression.html#regression-a5",
    "href": "16-regression.html#regression-a5",
    "title": "\n15  Regression\n",
    "section": "\n15.5 Activity 5: Calculate descriptives for the variables overall",
    "text": "15.5 Activity 5: Calculate descriptives for the variables overall\nIt is also useful to calculate descriptives statistics for the sample overall so that you can check that the sample scores are what you were expecting (e.g., are they comparable to previous studies and samples?). This is also useful for the write-up.\n\nRun the below code. Read each line and ensure you understand what is being calculated.\n\n\ndescriptives &lt;- joined %&gt;%\n  summarise(mean_anx = mean(mean_anxiety, na.rm = TRUE),\n            sd_anx = sd(mean_anxiety, na.rm = TRUE),\n            mean_weeks = mean(n_weeks, na.rm = TRUE),\n            sd_weeks = sd(n_weeks, na.rm = TRUE))"
  },
  {
    "objectID": "16-regression.html#regression-a6",
    "href": "16-regression.html#regression-a6",
    "title": "\n15  Regression\n",
    "section": "\n15.6 Activity 6: Visualisations",
    "text": "15.6 Activity 6: Visualisations\n\nNow that you’ve have all of the variables in one place, write the code to reproduce the exact scatterplot below (using ggplot2).\n\n\n\n\n\nScatteplot of mean anxiety and attendance\n\n\n\n\nAccording to the scatterplot, \nthere is no apparent relationship\nas anxiety increases, engagement decreases\nas anxiety increases, engagement increases"
  },
  {
    "objectID": "16-regression.html#regression-a7",
    "href": "16-regression.html#regression-a7",
    "title": "\n15  Regression\n",
    "section": "\n15.7 Activity 7: Run the regression",
    "text": "15.7 Activity 7: Run the regression\nThe lm() function from Base R is the main function to estimate a Linear Model (hence the function name lm). lm() uses formula syntax that you have seen before, i.e., DV ~ predictor.\n\nUse the lm() function to predict n_weeks (DV) from mean_anxiety (predictor). Store the result of the call to lm() in the variable mod. To see the results, use summary(mod).\n\n\nmod &lt;- lm(n_weeks ~ mean_anxiety, joined)\nmod_summary &lt;- summary(mod)\n\nAnswer the following questions about the model. You may wish to refer to the lecture notes to help you answer these questions.\n\nThe estimate of the y-intercept for the model, rounded to three decimal places, is \n\nTo three decimal places, if the GLM for this model is \\(Y_i = \\beta_0 + \\beta_1 X_i + e_i\\), then \\(\\beta_1\\) is \n\nTo three decimal places, for each unit increase in anxiety, n_weeks decreases by \n\nTo two decimal places, what is the overall F-ratio of the model? \n\nIs the overall model significant? \nYes\nNo\n\nWhat proportion of the variance does the model explain? \n\n\n\n\nExplain these answers\n\n\nIn the summary table, this is the estimate of the intercept.\nIn the summary table, this is the estimate of mean_anxiety, i.e., the slope.\nIn the summary table, this is also the estimate of mean_anxiety, the slope is how much it decreases so you just remove the - sign.\nIn the summary table, the F-ratio is noted as he F-statistic.\nThe overall model p.value is .001428 which is less than .05, therefore significant.\nThe variance explained is determined by R-squared, you simply multiple it by 100 to get the percent. You should always use the adjusted R-squared value."
  },
  {
    "objectID": "16-regression.html#regression-a8",
    "href": "16-regression.html#regression-a8",
    "title": "\n15  Regression\n",
    "section": "\n15.8 Activity 8: Assumption checking",
    "text": "15.8 Activity 8: Assumption checking\nJust like with ANOVA, you can’t check the assumptions until you’ve run the regression so now we’ll do that to check whether there’s anything to be concerned about. As we covered in the lecture, the assumptions for regression are a little bit more involved than they were for ANOVA.\n\nThe outcome/DV is a interval/ratio level data\nThe predictor variable is interval/ratio or categorical (with two levels)\nAll values of the outcome variable are independent (i.e., each score should come from a different participant)\nThe predictors have non-zero variance\nThe relationship between outcome and predictor is linear\nThe residuals should be normally distributed\nThere should be homoscedasticity (homogeneity of variance, but for the residuals)\n\nAssumptions 1-3 are nice and easy. We know this from the data we have and the design of the study. Assumption 4 simply means that there is some spread in the data - for example, there’s no point running a regression with age as a variable if all your participants are 20 years old. We can check this using the scatterplot we created in Activity 4 and we can see that this assumption is met, we do indeed have a spread of scores.\nFor the rest of the assumptions, we’re going to use functions from the packages see and performance that make life a whole lot easier.\nFirst, we can use check_model() to produce a range of assumption test visualisations. Helpfully, this function also provides a brief explanation of what you should be looking for in each plot - if only all functions in R were so helpful!\n\nIf you get the error message Failed with error:  ‘there is no package called ‘qqplotr’’, install the package qqplotr, you don’t need to load it using library(), but check_model() uses it in the background.\nIf your check_model() plots are not showing, try maximising your plot window.\n\n\ncheck_model(mod)\n\n\n\nVisual assumption checks\n\n\n\nFor Assumption 5, linearity, the plot suggests it’s not perfect but it looks pretty good.\nAs we’ve already noted, it’s good to visualise your assumption checks because just relying on statistics can be problematic, as they can be sensitive to small or large sample sizes. However, it can also be reassuring to have a statistical test to back up your intuitions from the plot.\nFor Assumption 6, normality of residuals, the plot does suggest that the residuals might not be normal, so we can check this with check_normality() which runs a Shapiro-Wilk test.\n\ncheck_normality(mod)\n\nWarning: Non-normality of residuals detected (p = 0.008).\n\n\nThe result confirms that the residuals are not normally distributed, something that is likely being exacerbated by the relatively small sample size. If you’re feeling confident, you can see how we might resolve this below, but for the core aims of this chapter we’ll conclude that it’s because of the sample and continue.\n\n\nTransforming the data to correct for non-normality\n\nThere are multiple ways you can transform data to deal with non-normality, you can find more information about data transformation in the Appendix here.\nFirst, we need to get a sense of what the issue is with our dependent variable, in this case n_weeks. A simple histogram shows that the DV isn’t a normal distribution, instead, it looks more like a uniform distribution.\n\nggplot(joined, aes(x = n_weeks)) +\n  geom_histogram(binwidth = 1)\n\n\n\n\n\n\n\nIt’s important to remember that the assumptions of regression are that the residuals are normally distributed, not the raw data, however, transforming the DV can help.\nTo transform the uniform distribution to a normal distribution, we’re going to use the unif2norm function from the faux package (which you may need to install).\nThis code uses mutate() to create a new variable n_weeks_transformed that is the result of the transformation.\n\nlibrary(faux)\njoined &lt;- mutate(joined, \n                 n_weeks_transformed = unif2norm(n_weeks))\n\nggplot(joined, aes(x = n_weeks_transformed)) +\n  geom_histogram()\n\n\n\n\n\n\n\nYou’ll notice that the histogram for the transformed variable still doesn’t look amazing, but remember it’s the residuals, not the raw data that matters. If we re-run the regression with the transformed data and then check the model again, things are looking much better.\n\nmod_transformed &lt;- lm(n_weeks_transformed ~ mean_anxiety, joined)\ncheck_normality(mod_transformed)\ncheck_model(mod_transformed)\n\n\n\n\n\n\n\nOK: residuals appear as normally distributed (p = 0.107).\n\n\nIt’s worth saying at this point that which transformation you use, and whether it works, can be a bit of trial-and-error.\n\n\nFor homoscedasticity, the plot looks mostly fine, but we can double check this with check_heteroscedasticity() and the result confirms that the data have met this assumption.\n\ncheck_heteroscedasticity(mod)\n\nOK: Error variance appears to be homoscedastic (p = 0.542)."
  },
  {
    "objectID": "16-regression.html#regression-a9",
    "href": "16-regression.html#regression-a9",
    "title": "\n15  Regression\n",
    "section": "\n15.9 Activity 9: Power and effect size",
    "text": "15.9 Activity 9: Power and effect size\nFirst we can calculate the minimum effect size we were able to detect given the sample size and design of the study using pwr.f2.test(). As usual, we fill in all the information we have and set the effect size argument, in this case f2, to NULL.\n\npwr.f2.test(u = 1, v = 35, f2 = NULL, sig.level = .05, power = .8)\n\n\n\nExplain the pwr.f2.test function\n\nu - Numerator degrees of freedom. This the number of coefficients you have in your model (minus the intercept) v - Denominator degrees of freedom. This is calculated as v=n-u-1, where n is the number of participants f2 - The effect size - here we are solving the effect size, so this parameter is left as NULL sig.level - The significance level of your study power - The power level of your study\n\n\n\nBased on the power analysis, what is the minimum effect size we were able to detect rounded to 2 decimal places? \n\nAccording to Cohen’s guidelines, this would be a \nSmall\nMedium\nLarge effect.\n\nThere is no formula to calculate our observed f2, we must do it manually using the formula from the lecture.\n\nf2 &lt;- mod_summary$adj.r.squared/(1 - mod_summary$adj.r.squared)\n\n\nIs the observed effect size larger than the minimum effect size we could detect? \nYes, our study is sufficiently powered\nNo, our study is underpowered"
  },
  {
    "objectID": "16-regression.html#regression-a10",
    "href": "16-regression.html#regression-a10",
    "title": "\n15  Regression\n",
    "section": "\n15.10 Activity 10: Write-up",
    "text": "15.10 Activity 10: Write-up\nThere’s two ways we can use R to help with the write-up. The first is inline coding like we’ve done in the other chapters, and the second is to use the report package. Which one you use is entirely up to you but it’s nice to have options.\nWe need to manually calculate the p-value for the inline coding as you can’t extract it from the lm() model. Run the below code to do this.\n\nf &lt;-mod_summary$fstatistic\nmod_p &lt;- pf(f[1], f[2], f[3], lower=FALSE) \n\nNow, copy and paste the below code into white-space and knit the document.\n\nA simple linear regression was performed with engagement (M = `r descriptives$mean_weeks %&gt;% round(2)`, SD = `r descriptives$sd_anx %&gt;% round(2)`) as the outcome variable and statistics anxiety (M = `r descriptives$mean_anx %&gt;% round(2)`, SD = `r descriptives$sd_anx %&gt;% round(2)`) as the predictor variable. The results of the regression indicated that the model significantly predicted course engagement (F(`r mod_summary$fstatistic[2]`, `r mod_summary$fstatistic[3]`) = `r mod_summary$fstatistic[1] %&gt;% round(2)`, p &lt; .001, Adjusted R2 = `r mod_summary$adj.r.squared %&gt;% round(2)`, f2 = .63), accounting for `r (mod_summary$adj.r.squared %&gt;% round(2))*100`% of the variance. Anxiety was a significant predictor (β = `r mod$coefficients[2] %&gt;% round(2)`, p &lt; `r mod_p %&gt;% round(3)`.\n)\n\nA simple linear regression was performed with engagement (M = 4.54, SD = 0.56) as the outcome variable and statistics anxiety (M = 2.08, SD = 0.56) as the predictor variable. The results of the regression indicated that the model significantly predicted course engagement (F(1, 35) = 11.99, p &lt; .001, Adjusted R2 = 0.23, f2 = .63), accounting for 23% of the variance. Anxiety was a significant predictor (β = -2.17, p &lt; 0.001. )\nThe second option uses report. Just like with the t-test, the output of these functions doesn’t tend to be useable without some editing but particularly when you’re first learning how to write-up stats it can be useful to have this kind of template (and also to see that there’s different ways of reporting stats).\nRunning report() will output a summary of the results which you could copy and past into your Word document.\n\nreport(mod)\n\nWe fitted a linear model (estimated using OLS) to predict n_weeks with\nmean_anxiety (formula: n_weeks ~ mean_anxiety). The model explains a\nstatistically significant and moderate proportion of variance (R2 = 0.26, F(1,\n35) = 11.99, p = 0.001, adj. R2 = 0.23). The model's intercept, corresponding\nto mean_anxiety = 0, is at 9.06 (95% CI [6.32, 11.80], t(35) = 6.71, p &lt; .001).\nWithin this model:\n\n  - The effect of mean anxiety is statistically significant and negative (beta =\n-2.17, 95% CI [-3.45, -0.90], t(35) = -3.46, p = 0.001; Std. beta = -0.51, 95%\nCI [-0.80, -0.21])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation."
  },
  {
    "objectID": "16-regression.html#regression-sols",
    "href": "16-regression.html#regression-sols",
    "title": "\n15  Regression\n",
    "section": "\n15.11 Activity solutions",
    "text": "15.11 Activity solutions\n\n15.11.1 Activity 1\n\n\nSolution\n\n\nlibrary(\"pwr\")\nlibrary(\"broom\")\nlibrary(\"see\")\nlibrary(\"performance\")\nlibrary(\"report\")\nlibrary(\"tidyverse\")\n\nstars &lt;- read_csv(\"L3_stars.csv\")\nengage &lt;- read_csv(\"psess.csv\")\n\n\n** Click tab to see solution **\n\n15.11.2 Activity 2\n\n\nSolution\n\n\nstars2 &lt;- pivot_longer(data = stars, names_to = \"Question\", values_to = \"Score\",cols = Q01:Q51) %&gt;%\n  arrange(ID)\n\n\n** Click tab to see solution **\n\n15.11.3 Activity 3\n\n\nSolution\n\n\nstars_means &lt;- stars2 %&gt;%\n  group_by(ID) %&gt;%\n  summarise(mean_anxiety = mean(Score, na.rm = TRUE),\n            min = min(Score), \n            max = max(Score),\n            sd = sd(Score))\n\n\n** Click tab to see solution **\n\n15.11.4 Activity 4\n\n\nSolution\n\n\njoined &lt;- inner_join(stars_means, engage, \"ID\")\n\n\n** Click tab to see solution **\n\n15.11.5 Activity 6\n\n\nSolution\n\n\nggplot(joined, aes(mean_anxiety, n_weeks)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")+\n  theme_minimal()\n\n\n** Click tab to see solution **"
  },
  {
    "objectID": "00-foreword.html#welcome-to-the-fundamentals-of-quantitative-analysis",
    "href": "00-foreword.html#welcome-to-the-fundamentals-of-quantitative-analysis",
    "title": "How to use this book",
    "section": "Welcome to the Fundamentals of Quantitative Analysis",
    "text": "Welcome to the Fundamentals of Quantitative Analysis\nWe wrote and designed this book to support RM1 and RM2 on the MSc Psychology Conversion programme, where you will learn core quantitative data skills using R and R Studio. In addition to this book, the course team will support you with demonstration videos and we encourage you to use Teams or office hours to ask any questions.\nThe ability to work with quantitative data is a key skill for psychologists and by using R and R Studio as our tool, we can also promote reproducible research practices. Although at first it may seem like writing a programming script is more time-consuming than other point-and-click approaches, you speed up with practice. Once you have written a script that does what you need it to do, you can easily re-run your analysis without having to go through each step again manually which is easier and less likely to result in errors if you do something slightly different or forget one of the steps.\nCrucially, with an analysis script, you can demonstrate to other researchers how you got from the raw data to the statistics you report in your final paper. Sharing analysis scripts alongside published articles on sites such as the Open Science Framework is now an important open science practice. Even if you do not continue with quantitative research yourself, the skills you develop throughout these courses will allow you to evaluate quantitative research and to understand what goes on behind the scenes to produce their numbers and conclusions, allowing you to become a much more confident and competent consumer and user of research."
  },
  {
    "objectID": "00-foreword.html#how-to-use-this-book-and-the-accompanying-videos",
    "href": "00-foreword.html#how-to-use-this-book-and-the-accompanying-videos",
    "title": "How to use this book",
    "section": "How to use this book and the accompanying videos",
    "text": "How to use this book and the accompanying videos\nWithin the book itself, for many of the initial chapters, we will provide the code you need to use. We would always strongly encourage you to type out the code yourself, as this is good practice for learning to code, but remember you can copy and paste from the book if you need to. Typing the code will seem much slower at first and you will make errors, lots of them, but you will learn much more quickly this way so do try to write the code yourself where you can.\nWe also provide the solutions to many of the activities. No-one is going to check whether you tried to figured out an activity yourself rather than going straight to the solution but remember this, if you copy and paste without thinking, you will learn nothing. Learning data skills and the knowledge that underpins those skills is much like learning a language - the more you practice and the more you use it, the better you become.\nAdditionally, a number of the chapters of this book have an associated video or videos. These videos are there to support you as you get comfortable in your data skills. However, it is important that you use them wisely. You should always try to work through each chapter of the book (or if you prefer each activity) on your own first, and only then watch the video if you get stuck, or for extra information.\nFinally, this book is a living document. What that means is that on occasion we will make updates to the book such as fixing typos and including additional detail or activities. When substantial changes are made, we will create new support materials such as an accompanying video. However, it would be impossible to record a new video every time we make a minor change to an activity, therefore, sometimes there may be slight differences between the videos and the content of this book. Where there are differences between the book and the video, the book should always be considered the definitive version."
  },
  {
    "objectID": "00-foreword.html#intended-learning-outcomes",
    "href": "00-foreword.html#intended-learning-outcomes",
    "title": "How to use this book",
    "section": "Intended learning outcomes",
    "text": "Intended learning outcomes\nBy the end of the courses associated with this book, students will be able to:\n\nWrite reproducible reports using R Markdown.\nClean and wrangle data into appropriate forms for analysis.\nVisualise data using a range of plots.\nConduct and interpret a core set of statistical tests from the general linear model (regression, ANOVA).\n\n\n\n\n\nHoffman, H. J., & Elmi, A. F. (2021). Do Students Learn More from Erroneous Code? Exploring Student Performance and Satisfaction in an Error-Free Versus an Error-full SAS® Programming Environment. Journal of Statistics and Data Science Education, 0(0), 1–13. https://doi.org/10.1080/26939169.2021.1967229"
  },
  {
    "objectID": "02-starting-with-data.html#getting-ready-to-work-with-data",
    "href": "02-starting-with-data.html#getting-ready-to-work-with-data",
    "title": "2  Creating Reproducible Documents",
    "section": "\n2.6 Getting ready to work with data",
    "text": "2.6 Getting ready to work with data\nIn this chapter you will learn how to load the packages required to work with the data. You’ll then load the data into RStudio before getting it organised into a format (or structure) that helps us answer our research question. And a top tip to remember is to always think back to what we have done before - for instance, if you can’t remember what packages are, go back and revise the Programming Basics.\nBefore we begin working with the data we need to do some set-up and get the data into our working directory.\n\n2.6.1 Activity 1: Set-up the data, working directory and Rmd file\n\nDownload ahi-cesd.csv and participant-info.csv into the folder on your computer you want to use for this chapter!\n\nTo download a file from this book, right click the link and select “save link as”. Make sure that both files are saved as “.csv”. Do not open them on your machine as often other software like Excel can change setting and ruin the files and cause you problems. We will look at the data once we load it into R and RStudio.\nIf you are working on the server, you will need to upload the files to the server as well.\n\n\nNext, open RStudio and ensure the environment is clear.\n\nIf you’re on the server, avoid a number of issues by restarting the session - click Session - Restart R\n\n\n\nSet the working directory to your chapter folder. You might want to refer to Activity 2 in Chapter 2 if you are unsure about this step.\nNow open a new R Markdown document (.Rmd file) and save it in your working directory. Call the file “LoadingData”. You can refer to Activity 3 in Chapter 2\n\n\nNote: Your R Markdown file (LoadingData.Rmd) must be in the same folder as the datafiles or the code we are going to write will not work.\n\n\nFinally, delete the default R Markdown text and insert a new code chunk. Remember to only delete the text and code that comes below/after line 7.\n\nWe are now ready to begin working with the data. A top tip is to use the white space to take any notes that might help you for each activity and to make reminders to yourself about what things do!\n\n2.6.2 Activity 2: Loading a package to our library\nToday we need to use the tidyverse package. You will use this package in almost every single chapter of this course as the functions it contains are those we use for data wrangling, descriptive statistics, and visualisation. So let’s load that package into our library using the library() function.\n\nTo load the tidyverse type the following code into your code chunk and then run it.\nRemember that sometimes in the console window you will see information about the package you have loaded, but sometimes you won’t. You should however see the line of code you have just run repeated in the console window. If you see any red text, be sure to read it as it might be a warning, an error or a message.\n\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "02-starting-with-data.html#the-data",
    "href": "02-starting-with-data.html#the-data",
    "title": "2  Creating Reproducible Documents",
    "section": "\n2.7 The data",
    "text": "2.7 The data\nFor this chapter, we use real data from Woodworth et al. (2018) ‘Web-based Positive Psychology Interventions: A Reexamination of Effectiveness’. It would be useful to read the abstract to give you a sense of what the paper is about and what the data might look like, but in summary, the files contain data from two scales as well as demographic information about participants. The two scales are:\n\nThe Authentic Happiness Inventory (AHI).\nThe Center for Epidemiological Studies Depression (CES-D) scale.\n\n\n2.7.1 Activity 3: Read in data\nNow that we have our data in our folder we need to read in the data - “read” in this sense just means to bring the data into RStudio and store it in an object so we can work with it. To do this we will use the function read_csv() that allows us to read in .csv files. There are also functions that allow you to read in Excel files (e.g. .xlsx) and other formats, however in this course we will only use .csv files as they are not software specific and therefore are better for when looking to practice open science! A .csv file can be read by any basic text editor on nearly all machines.\n\nThe code chunk below reads in both datafiles. Type it into your code chunk and run them. Let’s look at what they do.\nFirst, we create an object called dat that contains the data in the ahi-cesd.csv file.\nNext we then create an object called info that contains the data in the participant-info.csv.\nNote how both lines have the same format of object &lt;- function(\"datafile_name.csv\")\n\nit is imperative that you have the double quotation marks around the datafile name and that the datafile name is spelt correctly and includes the .csv part.\nand remember that &lt;- is called the assignment operator but we can read it as “assigned to”. For example, the first line can be read as the data in ahi-cesd.csv is assigned to the object called dat.\n\n\n\n\ndat &lt;- read_csv(\"data/ahi-cesd.csv\")\npinfo &lt;- read_csv(\"data/participant-info.csv\")\n\nIf you have done this activity correctly, and the preceding activities, you should now see that the objects dat and pinfo have appeared in the environment pane. If they are not there then you should check the spelling of the filenames and the structure of the code lines as well as maybe the working directory.\n\n\n\nWATCH OUT! There is also a function called read.csv(). Be very careful NOT to use this function instead of read_csv() as they have different ways of naming columns. For the activities and the assignments we will always ask and expect you to use read_csv(). This is really a reminder to watch spelling on functions and to be careful to use the right functions."
  },
  {
    "objectID": "02-starting-with-data.html#looking-at-data",
    "href": "02-starting-with-data.html#looking-at-data",
    "title": "2  Creating Reproducible Documents",
    "section": "\n2.8 Looking at Data",
    "text": "2.8 Looking at Data\nGreat! Now that we have our data read in the first step you should always do is to have an initial check to see what your data looks like. Normally you will have an idea already from the experiment you ran but if you are using someones data you might not, so best to check it out. There are several ways you can look at your data and these are listed in Activity 4 below. Try them all to see how the results differ.\n\n2.8.1 Activity 4: Look at your data\n\n\nOption 1: In the environment pane, click on the name of the object you want to look at. For example, click the names dat and pinfo. This will open the data to give you a spreadsheet-like view (although you can’t edit it like in Excel)\n\n\nOption 2: In the environment pane, click the small blue play button to the left of dat and pinfo. This will show you the structure of the object information including the names of all the variables in that object and what type they are (also see str(pinfo))\n\nOption 3: In the console window, type and run str(pinfo) and then str(dat)\n\n\nOption 4: Repeat option 3 but this time use the summary() function - e.g. summary(dat)\n\n\nOption 5: Repeat option 3 but this time use the head() function\n\nOption 6: Type the name of the object you want to view in the console window and run it, e.g., type dat in the console window and run it.\n\nAs you can see there are various different ways to get an idea of what your data looks like. Each tells you similar but also different info. We will explore more as we get further into the book but for now just be aware that you can use all of these approaches to see your data. More often than not Option 1 and Option 2 give you the info you need, the quickest."
  },
  {
    "objectID": "02-starting-with-data.html#joining-data",
    "href": "02-starting-with-data.html#joining-data",
    "title": "2  Creating Reproducible Documents",
    "section": "\n2.9 Joining Data",
    "text": "2.9 Joining Data\nSo far so awesome! We have our data and we know what it looks like, so let’s start trying to do things with our data! The first thing we will do is combine datafiles! We have two files, dat and info but what we really want is a single file that has both the data and the demographic information about the participants as it makes it easier to work with the data when it is all combined together. To do this we are going to use the function inner_join() which comes from the dplyr package - one of the packages loaded in as part of the tidyverse. But don’t worry to much about deliberately trying to remember all the different packages and functions as it will come naturally with the practice we give you.\n\n\nTop tip: Remember to use the help function ?inner_join if you want more information about how to use a function and to use tab auto-complete to help you write your code.\n\n\n2.9.1 Activity 5: Join the files together\nThe below code will create a new object, called all_dat, that combines the data from both dat and pinfo using the information in the columns id and intervention to match the participants’ data across the two sets of data. This is going to be an inner join approach - data will only be kept for a participant if they exist in both datafiles. There are lots of different joins but we will see them as we go further into the book.\n\nType and run the below code in a new code chunk to inner join the two sets of data.\nLet’s see if we can make sense of what is happening\n\n\nall_dat is the new object that has the data combined\n\nx is the first argument and it should be the first data/object you want to combine\n\ny is the second argument and it should be the second data/object you want to combine\n\nby is the third argument and it lists the names of the columns you want to combine the data by. It uses an additional function c() to say that there is more than one column to combine by.\n\n\n\n\nall_dat &lt;- inner_join(x = dat, \n                      y = pinfo, \n                      by = c(\"id\", \"intervention\"))\n\nOnce you have run this code you should now see the all_dat in the environment pane. View the new dataset using one of the methods from Activity 4. In fact, try to remember that you should always view any new object or data that you create. Code often can run but that doesn’t necessarily mean it is correct. The programme only ever knows what the code says not what you thought you said. Get into the habit of always checking output!"
  },
  {
    "objectID": "02-starting-with-data.html#selecting-data",
    "href": "02-starting-with-data.html#selecting-data",
    "title": "2  Creating Reproducible Documents",
    "section": "\n2.10 Selecting Data",
    "text": "2.10 Selecting Data\nExcellent! We have now combined our data into one big object! However, Very frequently, datasets will have more variables, information, and data than you actually want to use and it can make life easier to create a new object with just the data you need. So, our final step today is to select just some variables of interest! In our case, the all_dat contains the responses to each individual question on both the AHI scale and the CESD scale, as well as the total score (i.e., the sum of all the individual responses). Let’s say for our analysis all we care about is the total scores and the demographic information about participants. We are going to use a new function called the select() function, again from the dplyr package, to select only the columns we are interested in and store them in (i.e. assign them to) a new object called summarydata\n\n2.10.1 Activity 6: Pull out variables of interest\n\nType and run the below code in a new code chunk. Let’s also have a quick look at the code.\n\nsummarydata is the new object we are creating using the select() function\n\n.data is the first argument and it wants to know what object are we going to select columns from. In this instance all_dat.\nnext we have a list of columns that we want to keep. Every column must be spelt correctly and must exist in the object you are selecting it from. Makes sense really; otherwise the function wouldn’t know what you wanted!\n\n\n\n\nsummarydata &lt;- select(.data = all_dat, \n                      ahiTotal, \n                      cesdTotal, \n                      sex, \n                      age, \n                      educ, \n                      income, \n                      occasion,\n                      elapsed.days)\n\nIf that has worked correctly you should see summarydata in the environment pane and can run head(summarydata) now in the console window to get a view of the output. If you see any red text in the console window it would be worth checking the spelling of the objects and columns you wanted to select. If everything has gone to plan the output should look something like this:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nahiTotal\ncesdTotal\nsex\nage\neduc\nincome\noccasion\nelapsed.days\n\n\n\n32\n50\n1\n46\n4\n3\n5\n182.03\n\n\n34\n49\n1\n37\n3\n2\n2\n14.19\n\n\n34\n47\n1\n37\n3\n2\n3\n33.03\n\n\n35\n41\n1\n19\n2\n1\n0\n0.00\n\n\n36\n36\n1\n40\n5\n2\n5\n202.10\n\n\n37\n35\n1\n49\n4\n1\n0\n0.00"
  },
  {
    "objectID": "02-starting-with-data.html#knitting-our-reproducible-code",
    "href": "02-starting-with-data.html#knitting-our-reproducible-code",
    "title": "2  Creating Reproducible Documents",
    "section": "\n2.11 Knitting our Reproducible code",
    "text": "2.11 Knitting our Reproducible code\nAs we saw in Activity 8 in Chapter 2 our final step to making a reproducible document is to knit it to HTML! Try knitting your file to HTML now! If all the code is working correctly then you should get an html document showing all your code! If you don’t get the output there could be a few issues either relating to your code or to your installation. You can use the below debugging tips to ask yourself some questions about your code. If all the code looks correct be sure to speak to one of the TEAM to see what might be wrong.\n\n2.11.1 Debugging tips\n\nWhen you downloaded the files did you save the file names exactly as they were originally? If you download the file more than once you will find your computer may automatically add a number to the end of the file name. data.csv is not the same as data(1).csv. Pay close attention to names!\nHave you used the exact same object names as we did in each activity? Remember, name is different to Name. In order to make sure you can follow along with this book, pay special attention to ensuring you use the same object names as we do.\n\nHave you used quotation marks where needed?\n\nHave you accidentally deleted any back ticks (```) from the beginning or end of code chunks?"
  },
  {
    "objectID": "02-starting-with-data.html#code-layout",
    "href": "02-starting-with-data.html#code-layout",
    "title": "2  Creating Reproducible Documents",
    "section": "\n2.12 Code Layout",
    "text": "2.12 Code Layout\nAnd one very quick point before we end for the day. You may have noticed we wrote code as such:\n\nall_dat &lt;- inner_join(x = dat, \n                      y = pinfo, \n                      by = c(\"id\", \"intervention\"))\n\nBut we could also have written it as:\n\nall_dat &lt;- inner_join(x = dat, y = pinfo, by = c(\"id\", \"intervention\"))\n\nBoth do exactly the same! In a code chunk you can take a new line after a comma (,) and the code nicely idents for you. It can make it easier to read and to debug if the code is nicely presented but it isn’t essential!"
  },
  {
    "objectID": "02-starting-with-data.html#ld-fin",
    "href": "02-starting-with-data.html#ld-fin",
    "title": "2  Creating Reproducible Documents",
    "section": "\n2.13 Finished!",
    "text": "2.13 Finished!\nAnd that’s it, well done! Remember to save your work in your chapter folder and make a note of any mistakes you made and how you fixed them. You have started on your journey to become a confident and competent member of the open scientific community!\nNow would be a good time to get comfortable with what we’ve covered already and revise the activities and support materials presented so far if needed. If you’re feeling comfortable with you can work your way through this book at your own pace or push yourself by using the additional resources highlighted in Programming Basics. And don’t forget to try out the tasks below to check your understanding and knowledge of the skills you are learning!\nFinally, if you’re using the R server, we strongly recommend that you download a copy of any files you have been working on and save them on your machine so that you have a local back-up."
  },
  {
    "objectID": "02-starting-with-data.html#ld-test",
    "href": "02-starting-with-data.html#ld-test",
    "title": "2  Creating Reproducible Documents",
    "section": "\n2.14 Test yourself",
    "text": "2.14 Test yourself\n\n2.14.1 Knowledge Questions\n\nWhen loading in a .csv file, which function should you use?\n\nread_csv()read.csv()select()library()\n\n\n\n\n\nExplain this answer\n\n\nRemember, in this course we use read_csv() and it is important that you use this function otherwise you may find that the data does not work as expected.\n\n\n\nThe function inner_join() takes the arguments x, y, by. What does by do?\n\nSpecifies the first object to joinSpecifies the second object to joinSpecifies the column to join by that both objects have in common\n\n\n\n\n\nExplain this answer\n\n\nRemember, functions have arguments and the arguments all do something slightly different. In the inner_join() the by argument says which columns to join by. If you want to join by more than one column you need to put both columns inside the c() function.\n\n\n\nWhat does the function select() do?\n\nKeeps only the observations you specifyKeeps only the columns you specifyKeeps only the objects you specify\n\n\n\n\n\nExplain this answer\n\n\nThe select() function comes from one of the tidyverse packages - dplyr to be precise. It is the main function we use to keep and remove columns we want or don’t want. You will start to remember functions you need as you work more with them. Remember the best approach is to think back to what you did!\n\n\n\n2.14.2 Debugging exercises\nOne key skill is learning how to fix errors in your code. These exercises below are specifically design to create errors. Ruun each exercise and try to solve the errors yourself before moving on to the next one. Make a note of what the error message was and how you solved it - you might find it helpful to create a new file just for error solving notes. You will find that you often make the same errors in over and over again when running analyses; experts also make tonnes of errors. The difference between a novice and an expert is that when you are first learning, an error might slow you down, but you will greatly speed you up with practice. Don’t be put off by errors!\n\nRestart the R session (Session &gt;&gt; Restart R). Make sure that the working directory is set to the right folder and then run the below code:\n\n\ndat &lt;- read_csv(\"ahi-cesd.csv\")\n\nThis will produce the error:\n`could not find function \"read_csv\"`\nOnce you figure out how to fix this error, make a note of it.\n\n\nSolution\n\n\nWhen you restarted the session you unloaded all the packages you previously had loaded - i.e. the tidyverse. The function read_csv() is part of the tidyverse package which means that in order for the code to run you need to run library(tidyverse) to reload the package so that you can use the function. Remember that we always need to load packages into our library but we only install them once. Again, think about apps on your phone!\n\n\n\nRestart the R session (Session &gt;&gt; Restart R). Make sure that the working directory is set to the right folder and then run the below code:\n\n\nlibrary(tidyverse)\ndat &lt;- read_csv(\"ahi-cesd\")\n\nThis will produce the error:\n`Error: 'ahi-cesd' does not exist in current working directory`.\nOnce you figure out how to fix this error, make a note of it.\n\n\nSolution\n\n\nWhen loading data you need to provide the full file name including the file extension. In this case the error was caused by writing ahi-cesd instead of ahi-cesd.csv. As far as coding goes, these are two completely different files and only one of them exists in the working directory.\n\n\n\nRestart the R session (Session &gt;&gt; Restart R). Make sure that the working directory is set to the right folder and then run the below code:\n\n\nlibrary(tidyverse)\ndat &lt;- read_csv (\"ahi-cesd.csv\")\npinfo &lt;- read_csv(\"participant-info.csv\")\nall_dat &lt;- inner_join(x = dat, \n                      y = pinfo, \n                      by = \"id\", \"intervention\") \nsummary(all_dat)\n\nLook at the summary for all_dat. You will see that R has duplicated the intervention variable, so that there is now an intervention.x and an intervention.y that contain the same data. Once you figure out how to fix this error, make a note of it.\n\n\nSolution\n\n\nIf you want to join two objects that have mulitple columns in common you need to use the c() command to list all of the columns. The code above hasn’t done this, it’s just listed id and intervention without enclosing them with c() so it defaults to using just the first one and ignores the other column. When it does this both objects had an intervention column so it keeps both. The rule is, when joining objects, join them by all common columns!."
  },
  {
    "objectID": "02-starting-with-data.html#words-from-this-chapter",
    "href": "02-starting-with-data.html#words-from-this-chapter",
    "title": "2  Creating Reproducible Documents",
    "section": "\n2.5 Words from this Chapter",
    "text": "2.5 Words from this Chapter\nBelow, you will find a list of words that we used in this chapter that might be new to you in case you need to refer back to what they mean. The links in this table take you to the entry for the words in the PsyTeachR Glossary. Note that numerous members of the team wrote entries in the Glossary and as such the entries may use slightly different terminology from what we used in the chapter.\n\n\n\nterm\ndefinition\n\n\n\nchunk\nA section of code in an R Markdown file\n\n\nhtml\nHyper-Text Markup Language: A system for semantically tagging structure and information on web pages.\n\n\ninline-code\nDirectly inserting the result of code into the text of a .Rmd file.\n\n\nknit\nTo create an HTML, PDF, or Word document from an R Markdown (Rmd) document\n\n\nlatex\nA typesetting program needed to create PDF files from R Markdown documents.\n\n\nmarkdown\nA way to specify formatting, such as headers, paragraphs, lists, bolding, and links.\n\n\nr-markdown\nThe R-specific version of markdown: a way to specify formatting, such as headers, paragraphs, lists, bolding, and links, as well as code blocks and inline code.\n\n\nr-project\nA project is simply a working directory designated with a .RProj file. When you open an R project, it automatically sets the working directory to the folder the project is located in.\n\n\nreproducible-research\nResearch that documents all of the steps between raw data and results in a way that can be verified.\n\n\nworking-directory\nThe filepath where R is currently loading files from and saving files to."
  },
  {
    "objectID": "03-intro-data-viz.html#data-visualisation",
    "href": "03-intro-data-viz.html#data-visualisation",
    "title": "3  Introduction to Data Visualisation",
    "section": "\n3.6 Data visualisation",
    "text": "3.6 Data visualisation\nData Visualisation. Being able to visualise our data, and relationships between our variables, is an incredibly useful and important skill. Before we do any statistical analyses or present any summary statistics, we should visualise our data as it is:\n\nA quick and easy way to check our data make sense, and to identify any unusual trends.\nA way to honestly present the features of our data to anyone who reads our research.\nA means of checking that our data fits with the assumptions of our descriptive and inferential tests and of the statistical analyses that we intend to use.\n\nAs Grolemund and Wickham tell us in R for Data Science:\n\nVisualisation is a fundamentally human activity. A good visualisation will show you things that you did not expect, or raise new questions about the data. A good visualisation might also hint that you’re asking the wrong question, or you need to collect different data. Visualisations can surprise you, but don’t scale particularly well because they require a human to interpret them.\n\nThe main package we use for visualisation within the tidyverse umbrella is called ggplot2 and the main starting function of all visualisations is ggplot(). The reason we say the “main starting function” is that ggplot() builds plots by combining layers (see, for example, Figure @ref(fig:img-layers) from Nordmann et al. (2022)) - i.e. one function creates the first layer, the basic plot area, and you add functions and arguments to add additional layers such as the data, the labels, the colors, etc. If you’re used to making plots in other software this might seem a bit odd at first, however, it means that you can customise each layer separately in order to make very complex and beautiful figures with relative ease. You can get a sense of what is possible from (this website but we will start off slow and build as we go!\n\n\n\n\nBuilding a figure using the ggplot2 layers system as shown in Nordmann et al. (2021)"
  },
  {
    "objectID": "03-intro-data-viz.html#setting-up-to-visaulise",
    "href": "03-intro-data-viz.html#setting-up-to-visaulise",
    "title": "3  Introduction to Data Visualisation",
    "section": "\n3.7 Setting up to Visaulise",
    "text": "3.7 Setting up to Visaulise\nWe will use the same files from Woodworth et al. (2018) as in Chapter 2 - Creating reproducible documents - as you already know what the data contains, so we can focus just on visualising it.\n\n3.7.0.1 Activity 1: Set-up\nThis data contains happiness and depression scores:\n\nDownload ahi-cesd.csv and participant-info.csv into the folder on your computer for this chapter!\n\nMake sure that you have downloaded both .csv files above and saved them in your chapter folder. Remember not to change the file names at all and that data.csv is not the same as data (1).csv.\n\n\nOpen RStudio and set the working directory to your chapter folder. Ensure the environment is clear.\n\nIf you’re on the server, avoid a number of issues by restarting the session - click Session - Restart R\n\n\n\nOpen a new R Markdown document and save it in your working directory. Call the file “DataVisualisation1”.\n\nDelete the default R Markdown welcome text and insert a new code chunk.\nType and run the below code to load the tidyverse package and to load in the data files.\n\n\nlibrary(tidyverse) \n\ndat &lt;- read_csv(\"ahi-cesd.csv\")\npinfo &lt;- read_csv(\"participant-info.csv\")\n\nall_dat &lt;- inner_join(dat, \n                      pinfo, \n                      by= c(\"id\", \"intervention\"))\nsummarydata &lt;- select(.data = all_dat, \n                      ahiTotal, \n                      cesdTotal, \n                      sex, \n                      age, \n                      educ, \n                      income, \n                      occasion, \n                      elapsed.days) \n\nYou should have a good idea about what this code is doing but if not here is a brief summary:\n\nIt loads in the tidyverse\nIt reads both datafiles as tibbles into separate objects, dat and pinfo.\nJoins the data together into one larger tibble and stores it in the object called all_dat\n\nSelect a number of columns to keep in our data and discards others."
  },
  {
    "objectID": "03-intro-data-viz.html#dealing-with-factors-and-categories",
    "href": "03-intro-data-viz.html#dealing-with-factors-and-categories",
    "title": "3  Introduction to Data Visualisation",
    "section": "\n3.8 Dealing with Factors and Categories",
    "text": "3.8 Dealing with Factors and Categories\nBefore we go any further we need to perform an additional step of data processing that we have glossed over up until this point. First, run the below code to look at the structure of the dataset:\n\nglimpse(summarydata)\n\nRows: 992\nColumns: 8\n$ ahiTotal     &lt;dbl&gt; 32, 34, 34, 35, 36, 37, 38, 38, 38, 38, 39, 40, 41, 41, 4…\n$ cesdTotal    &lt;dbl&gt; 50, 49, 47, 41, 36, 35, 50, 55, 47, 39, 45, 47, 33, 27, 3…\n$ sex          &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, …\n$ age          &lt;dbl&gt; 46, 37, 37, 19, 40, 49, 42, 57, 41, 41, 52, 41, 52, 58, 5…\n$ educ         &lt;dbl&gt; 4, 3, 3, 2, 5, 4, 4, 4, 4, 4, 5, 4, 5, 5, 5, 4, 3, 4, 3, …\n$ income       &lt;dbl&gt; 3, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 3, 2, 2, 3, 2, 2, 2, …\n$ occasion     &lt;dbl&gt; 5, 2, 3, 0, 5, 0, 2, 2, 2, 4, 4, 0, 4, 0, 1, 4, 0, 5, 4, …\n$ elapsed.days &lt;dbl&gt; 182.025139, 14.191806, 33.033831, 0.000000, 202.096887, 0…\n\n\nYou can see that all the variables are automatically considered as numeric (in this case double represented by &lt;dbl&gt;). This is going to be a problem because whilst the different categories within sex, educ, and income are represented by numbers, we don’t want to treat them as such because they are categories, or what we call factors. So to get around this, we need to convert these variables into factor data type. Fortunately we already know a good function for this! We can use mutate() to do this by overriding the original variable with the same data but classified as a factor.\n\n3.8.1 Activity 2: Factors\n\nType and run the below code to change the categories to factors.\n\nYou can read each line of the mutate as “overwrite the data that is in that column with the same values now considered factors and not doubles”\nSo for example, the 1s in sex change to categorical factors instead of numerical 1s.\nRemember if you mutate a new column with the same name as the old one, it will overwrite the column.\n\n\n\n\nsummarydata &lt;- summarydata %&gt;%\n  mutate(sex = as.factor(sex),\n         educ = as.factor(educ),\n         income = as.factor(income))\n\nThis is a very important step to remember if, when you look at your data, some of your categories are represented as numbers and not factors. If you do not do this then you might end up with some really confused looking figures!"
  },
  {
    "objectID": "03-intro-data-viz.html#barplots",
    "href": "03-intro-data-viz.html#barplots",
    "title": "3  Introduction to Data Visualisation",
    "section": "\n3.5 Barplots",
    "text": "3.5 Barplots\nIn the next section, we are going to cover making barplots - potentially the most common type of visualisation you will see in published research. A barplot shows counts of categorical data, or factors, where the height of each bar represents the count of that particular variable.\nYou will see people use them to represent continuous outcomes, such as showing the mean on the y-axis, but there is good reason to never use bar plots to communicate continuous data we will cover in the course materials (see Weissgerber et al., 2019 if you are interested). We will cover more advanced plots for continuous data in Chapter 7 - Building your data visualisation skills.\n\n3.5.1 Activity 6 - Covert to factors\nEarlier, we highlighted that all the variables were processed as numbers. This was fine for most of the variables, but sex, educ, and income should be categories or what we call factors.\nTo get around this, we need to convert these variables into factors. This is relates to data wrangling, so this is one final time we would like you to copy and run code, before we fully explain how to write this kind of code independently in the next chapter.\nCopy and run the following code in your R Markdown document, at least below where you read and wrangled the data:\n\n# Overwrite summary data \nsummarydata &lt;- mutate(summarydata, # mutate to change columns \n         sex = as.factor(sex), # save sex as a factor\n         educ = as.factor(educ),\n         income = as.factor(income))\n\nYou can interpret this code as “overwrite summarydata and transform three columns (sex, educ, and income) into the same values but now considered factors and not doubles”.\n\n\n\n\n\n\nError mode\n\n\n\nIf you do not do convert numbers to factors when they should represent distinct categories, you can get some weird looking figures. Instead of treating the numbers as categories, it will try and plot the full range of numerical values. If you notice this, just go back and convert your variables to factors (which we will break down in the next chapter).\n\n\n\n3.5.2 Activity 7 - Create a bar plot\nNow you are familiar with the layering system, we will jump straight into creating the barplot. As before, type and run the code in each step, making notes to yourself either in the R Markdown document outside the code chunks, or using code comments.\n\n# Plot the variable sex from summarydata\nggplot(summarydata, aes(x = sex)) + \n  geom_bar()\n\n\n\n\n\n\n\nCompared to the histogram plot, the only difference here is using the geom_bar() as the layer instead. Rather than plot the frequency of your variable in bins, we plot the frequency of each unique category.\nWe can see 1s are way more frequent than 2s, but for this to make sense to you and your reader, we need to edit the axis labels.\n\n3.5.3 Activity 8 - Edit the axis labels\nIn the histogram section, we demonstrated how to edit the axis labels. We used scale_y_continuous and scale_x_continuous as we had two continuous variables for the x-axis range and the y-axis frequency. This time, we need a slightly different layer since the x-axis now represents distinct groups: scale_x_discrete.\nType and run the following code:\n\n# Plot the variable sex from summarydata\nggplot(summarydata, aes(x = sex)) + \n  geom_bar() + \n  scale_x_discrete(name = \"Participant Sex\", \n                   labels = c(\"Female\", # 1 = Female\n                              \"Male\")) + # 2 = Male\n  scale_y_continuous(name = \"Number of Participants\")\n\n\n\n\n\n\n\nWithin scale_x_discrete, we have a new argument called “labels”. This is where we can edit the labels for each category. Instead of 1 and 2, we labelled the x-axis clearer as “Female” and “Male”, making it easier to understand there are way more female participants compared to male.\n\n\n\n\n\n\nWhat does c() mean in labels?\n\n\n\n\n\nWhen we specified the labels, you might have noticed the c(\"Female\", \"Male\") format. c() stands for concatenate and you will see it a lot in R. When we give a value to a function argument, we must provide one “value”. However, in scenarios like this, we want to apply multiple values since we have several categories.\nWe can do this by adding all of our categories within c(), separated by a comma between each category.\n\n\n\n\n\n\n\n\n\nError mode\n\n\n\nWhen you edit “labels”, it is crucial the values you give it are in the right order. There would be nothing stopping us from writing c(\"Male\", \"Female\") and R will gladly listen to you and add those labels. However, that would be inaccurate as 1s mean Female and 2s mean Male. We are only editing the labels and not the underlying values in the data.\nThese errors are the most sneaky as it will not cause an error to fix, but they are still incorrect.\n\n\n\n3.5.4 Activity 9 - Apply your plotting skills to a new variable\nAn important learning step is being able to apply or transfer what you learnt in one scenario to something new.\nIn the data set, there is a variable for the level of education: educ. Plot the new variable and try to recreate the customisation layers before checking the solution below.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow me the solution code\n\n\n\n\n\nTo recreate the plot, this is the code:\n\n# Plot the variable educ from summarydata\nggplot(summarydata, aes(x = educ)) + \n  geom_bar() + \n  theme_classic() + \n  scale_x_discrete(name = \"Level of Education\", \n                   labels = c(\"Less than year 12\", # 1\n                              \"Year 12\", # 2 \n                              \"Vocational training\", # 3\n                              \"Bachelor's degree\", # 4\n                              \"Postgraduate degree\")) + # 5 \n  scale_y_continuous(name = \"Number of Participants\")"
  },
  {
    "objectID": "03-intro-data-viz.html#the-violin-boxplot",
    "href": "03-intro-data-viz.html#the-violin-boxplot",
    "title": "\n3  Introduction to Data Visualisation\n",
    "section": "\n3.5 The Violin-boxplot",
    "text": "3.5 The Violin-boxplot\nThere are numerous different styles of visualisations and figures that you can create. They all start with the format of ggplot(data, aes(x, y)) + geom_... and will learn more as you get deeper into the book or you can look at the cheatsheets in the help menus: top menu - Help &gt;&gt; Cheat Sheets &gt;&gt; Data Visualisation with ggplot2. For instance, geom_point() for scatterplots, geom_histogram() for histograms, and geom_line() for lineplots. But we want to show you a type of figure that is becoming a lot more common in the field due to the quality of information if tells you about your data - the violin-boxplot.\n\n3.5.0.1 Activity 4: Violin-boxplot\nThe violin boxplot is actually a merge of a violin and a boxplot. The violin-boxplot is just the boxplot laid over the top of the violin plot - to give additional information. As part of our final activities today we will create a violin-boxplot, hopefully now you will be able to see how similar it is in structure to the bar chart code. In fact, there are only three differences:\n\nWe have added a y argument to the first layer because we wanted to represent two variables, not just a count.\n\ngeom_violin() has an additional argument trim.\n\ngeom_boxplot() has an additional argument width. Try adjusting the value of this and see what happens.\n\n\nType and run the below code in a new code chunk and see what it produces.\n\nTry setting the trim argument in geom_violin() to TRUE and seeing what happens.\nTry adjusting the value of the width argument within geom_boxplot() and seeing what happens.\n\n\n\n\nggplot(summarydata, aes(x = income, \n                        y = ahiTotal, \n                        fill = income)) +\n  geom_violin(trim = FALSE, \n              show.legend = FALSE, \n              alpha = .4) +\n  geom_boxplot(width = .2, \n               show.legend = FALSE, \n               alpha = .7)+\n  scale_x_discrete(name = \"Income\",\n                   labels = c(\"Below Average\", \n                              \"Average\", \n                              \"Above Average\")) +\n  scale_y_continuous(name = \"Authentic Happiness Inventory Score\")+\n  theme_minimal() +\n  scale_fill_viridis_d()\n\n\n\nViolin-boxplot"
  },
  {
    "objectID": "03-intro-data-viz.html#layer-order",
    "href": "03-intro-data-viz.html#layer-order",
    "title": "\n3  Introduction to Data Visualisation\n",
    "section": "\n3.6 Layer order",
    "text": "3.6 Layer order\nAs we said above, one key thing to note about ggplot2 is the use of layers. Whilst we have built layers up step-by-step in this chapter, they are independent and you could remove any of them except for the first layer. Additionally, although they are independent, the order you put them in does matter as we will show you now.\n\n3.6.0.1 Activity 5: Layers part 2\n\nType and run this code into a new code chunk and look at the output.\n\n\nggplot(summarydata, aes(x = income, y = ahiTotal)) +\n  geom_violin() +\n  geom_boxplot()\n\n\nNow type and run this code into a new code chunk and compare the output to the output of the code above. Do you see the difference?\n\n\nggplot(summarydata, aes(x = income, y = ahiTotal)) +\n  geom_boxplot() +\n  geom_violin()\n\nIf you compare the two figures, shown here below for ease, the first puts the boxplots on top of the violins whereas the second puts the violins on top of the boxplots. It does that because each plot is a different layer that it literally puts on top of what is already there. Again a great reason to always look at your output and not just run code blindly as you don’t always get what you think you are doing!\n\n\n\n\nShowing the impact of changing the order of layers. Figure A shows the boxplots on top of the violin plots. Figure B shows the violins on top of the boxplots. The codes are the same but the order of the geoms is different."
  },
  {
    "objectID": "03-intro-data-viz.html#saving-your-figures",
    "href": "03-intro-data-viz.html#saving-your-figures",
    "title": "3  Introduction to Data Visualisation",
    "section": "\n3.6 Saving your Figures",
    "text": "3.6 Saving your Figures\nThe final step today will be to demonstrate how to save plots you create in ggplot2. It is so useful to be able to save a copy of your plots as an image file so that you can use them in a presentation or report. One approach we can use is the function ggsave().\n\n3.6.1 Activity 10 - Saving your last plot\nThere are two ways you can use ggsave(). If you do not tell ggsave() which plot you want to save, by default it will save the last plot you created.\nTo demonstrate this, let us run the code again from Activity 8 to produce the final version of our barplot. You do not need to write the code again if you already have it available in a code chunk, but make sure you run the code:\n\n# Plot the variable sex from summarydata\nggplot(summarydata, aes(x = sex)) + \n  geom_bar() + \n  scale_x_discrete(name = \"Participant Sex\", \n                   labels = c(\"Female\", # 1 = Female\n                              \"Male\")) + # 2 = Male\n  scale_y_continuous(name = \"Number of Participants\")\n\nNow that we have the plot we want to save as our last produced plot, all that ggsave() requires is for you to tell it the file path / name that it should save the plot to and the type of image file you want to create. The example below uses .png but you could also use .jpeg or another image type.\nType and run the following code into a new code chunk and then check your figures folder. If you have performed this correctly, then you should see the saved image. This is why we include a figures folder as part of the chapter structure, so you know exactly where your figures will be if you want to find them again.\n\nggsave(\"figures/participant_sex_barplot.png\")\n\nThe image tends to save at a default size, or the size that the image is displayed in your viewer, but you can change this manually if you think that the dimensions of the plot are not correct or if you need a particular size or file type. Sometimes the dimensions look a little off when you save them, so you might need to play around with the size.\nType and run the following code to overwrite the image file with new dimensions. Try different dimensions and units to see the difference. You might want to create participant_sex_barplot-v1.png, participant_sex_barplot-v2.png etc. and compare them.\nOne final tip, by default, the plot has a transparent background which you do not notice on a white document, but looks odd on anything else. So, you can set a specific background colour through the argument bg.\n\n ggsave(\"figures/participant_sex_barplot\", \n        width = 10, # 10 inches wide\n        height = 8, # 8 inches high\n        units = \"in\", \n        bg = \"white\") # Make sure the background is white\n\nRemember, you can use ?ggsave() in the console window to bring up the help file for this function if you want to look at what other arguments are available.\n\n3.6.2 Saving a specific plot\nAlternatively, the second way of using ggsave() is to save your plot as an object, and then tell it which object you want to save.\nType and run the code below and then check your folder for the image file. Resize the plot if you think it needs it.\n\n\n\n\n\n\nWarning\n\n\n\nWe do not add on ggsave() as a plot layer. Instead it is a separate line of code and we tell it which object to save. So, do not add + ggsave() as a layer to your plot.\n\n\n\nsex_barplot &lt;- ggplot(summarydata, aes(x = sex)) +\n  geom_bar() +\n  scale_x_discrete(name = \"Participant Sex\",\n                   labels = c(\"Female\", # 1 = Female\n                              \"Male\")) + # 2 = Male\n  scale_y_continuous(name = \"Number of Participants\")\n\n\nggsave(\"figures/participant-sex-barplot.png\", \n       plot = sex_barplot)\n\nNote that when you save a plot to an object, you will not see the plot displayed anywhere. To get the figure to display, you need to type the object name in the console (i.e., sex_barplot). The benefit of saving figures this way is that if you are making several plots, you cannot accidentally save the wrong one because you are explicitly specifying which plot to save rather than just saving the last one."
  },
  {
    "objectID": "03-intro-data-viz.html#introviz-fin",
    "href": "03-intro-data-viz.html#introviz-fin",
    "title": "3  Introduction to Data Visualisation",
    "section": "\n3.7 Finished!",
    "text": "3.7 Finished!\nWell done! ggplot can be a bit difficult to get your head around at first, particularly if you’ve been used to making graphs a different way. But once it clicks, you’ll be able to make informative and professional visualisations with ease, which, amongst other things, will make any report you write look more professional!"
  },
  {
    "objectID": "03-intro-data-viz.html#test-yourself",
    "href": "03-intro-data-viz.html#test-yourself",
    "title": "3  Introduction to Data Visualisation",
    "section": "\n3.7 Test Yourself",
    "text": "3.7 Test Yourself\nTo end the chapter, we have some knowledge check questions to test your understanding of the concepts we covered in the chapter. We then have some error mode tasks to see if you can find the solution to some common errors in the concepts we covered in this chapter.\n\n3.7.1 Knowledge check\n\nWhich of these is the appropriate order of functions to create a barplot?\n\n\nggplot() + geom_bar()ggplot() %&gt;% geom_bar()geom_plot() + geom_boxplot()geom_bar() + ggplot()\n\n\nWhy would this line of code not create a barplot, assuming you already loaded all data and libraries and you spelt the data and column names correctly?\n\n\nggplot(summarydata, aes(x = sex)) +\n  geom_barplot()\n\n\nbecause you have not included a y axisbecause you have piped the barplot and not added itbecause there is no geom_barplot() and it should be geom_bar()because this would create a histogram\n\n\nIf I wanted precisely 5 bars in my histogram, what argument would I use?\n\n\nggplot() + geom_histogram()ggplot() + geom_histogram(binwidth = 5)ggplot() + geom_histogram(bars = 5)ggplot() + geom_histogram(bins = 5)\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\n\nggplot() + geom_histogram(bins = 5). This is the correct answer as you are asking ggplot2 to give you the plot organised into 5 bins.\nggplot() + geom_histogram(bars = 5). This is incorrect as you bars is not the right argument name. You want 5 bars, but the argument is bins.\nggplot() + geom_histogram(binwidth = 5). This is incorrect as binwidth controls the x-axis range to include per bar, rather than the number of bars.\nggplot() + geom_histogram(). This is incorrect as you did not control the number of bins, so it will default to 30.\n\n\n\n\n\n3.7.2 Error mode\nThe following questions are designed to introduce you to making and fixing errors. For this topic, we focus on reading data and using ggplot2. Remember to keep a note of what kind of error messages you receive and how you fixed them, so you have a bank of solutions when you tackle errors independently.\nCreate and save a new R Markdown file for these activities by following the instructions in Chapter 2. You should have a blank R Markdown file below line 10. Below, we have several variations of a code chunk and inline code errors. Copy and paste them into your R Markdown file, click knit, and look at the error message you receive. See if you can fix the error and get it working before checking the answer.\nQuestion 4. Copy the following code chunk into your R Markdown file and press knit. You should receive an error like Error in read_csv(): ! could not find function \"read_csv\".\n```{r}\npinfo &lt;- read_csv(\"data/participant-info.csv\")\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nIf you only added this code chunk in, you have not loaded tidyverse yet. Remember R Markdown knits from start to finish in a fresh session, so it will not work even if you have loaded already tidyverse outside the R Markdown document. So, you would need to add library(tidyverse) first.\n\n\n\nQuestion 5. Copy the following code chunk into your R Markdown file and press knit. You should receive an error like ! participant-info.csv does not exist in current working directory.\n```{r}\nlibrary(tidyverse)\n\npinfo &lt;- read_csv(\"participant-info.csv\")\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nYou had tidyverse loaded this time, but it is not pointing to the right folder. Your working directory should be the main chapter folder, where participant-info.csv does not exist. You will need to edit it to data/participant-info.csv to work.\n\n\n\nQuestion 7. Copy the following code chunk into your R Markdown file and press knit. You should receive a long error where the problem is buried in the first five lines:\n\nError in geom_histogram()\n\n\n! Problem while computing stat.\n\n\ni Error occurred in the 1st layer.\n\n\nCaused by error in setup_params():\n\n\n! stat_bin() requires an x or y aesthetic.\n\n```{r}\nlibrary(tidyverse)\n\npinfo &lt;- read_csv(\"data/participant-info.csv\")\n\n# Plot the variable age from pinfo\nggplot(pinfo, x = age) +   # Plot age on the x axis\n  geom_histogram()\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nThis is potentially a sneaky one where we missed the aes() argument and it is only line 5 of the error which gives it away: ! stat_bin() requires an x or y aesthetic. The first ggplot2 layer has two key components: the data object you want to use, and the aesthetics to set. You need to add “aes()” around where you specify the x-axis: ggplot(pinfo, aes(x = age)).\n\n\n\nQuestion 7. Copy the following code chunk into your R Markdown file and press knit. This…works, but does not look quite right?\n```{r}\nlibrary(tidyverse)\n\npinfo &lt;- read_csv(\"data/participant-info.csv\")\n\n# Plot the variable age from pinfo\nggplot(pinfo, aes(x = age)) # Plot age on the x axis\n  geom_histogram()\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nThere is a missing + between the two ggplot2 layers. The code should be:\n\n# Plot the variable age from pinfo\nggplot(pinfo, aes(x = age)) +  # Plot age on the x axis\n  geom_histogram()\n\nAt the moment, it runs the first layer to create an empty plot, then prints the information contained within geom_histogram.\n\n\n\nQuestion 8. Copy the following code chunk into your R Markdown file and press knit. You should receive a long error again with lines 5-7 key:\n\n! stat_bin() requires a continuous x aesthetic.\n\n\nx the x aesthetic is discrete.\n\n\ni Perhaps you want stat=\"count\"?\n\n```{r}\nlibrary(tidyverse)\n\npinfo &lt;- read_csv(\"data/participant-info.csv\")\n\n# Plot the variable age from pinfo\nggplot(pinfo, aes(x = age)) +   # Plot age on the x axis\n  geom_histogram() + \n  scale_x_discrete(name = \"Participant Age\")\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nThe error message here is a little more useful and points to how we tried to edit the x-axis name. In a histogram, the x-axis is continuous for the range of a numeric variable. We tried using the discrete version of the layer to control the axis (scale_x_discrete(name = \"Participant Age\")) which we had to use for the bar plot. To fix the error, you would need to correct the layer to scale_x_continuous(name = \"Participant Age\")."
  },
  {
    "objectID": "03-intro-data-viz.html#words-from-this-chapter",
    "href": "03-intro-data-viz.html#words-from-this-chapter",
    "title": "3  Introduction to Data Visualisation",
    "section": "\n3.8 Words from this Chapter",
    "text": "3.8 Words from this Chapter\nBelow you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the PsyTeachR Glossary. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter.\n\n\n\n\nterm\ndefinition\n\n\n\nassignment-operator\nThe symbol &lt;-, which functions like = and assigns the value on the right to the object on the left\n\n\nbarplot\nalso known as a bar chart, barplots represent the frequency or count of a variable through the height of one or more bars.\n\n\ncomment\nComments are text that R will not run as code. You can annotate .R files or chunks in R Markdown files with comments by prefacing each line of the comment with one or more hash symbols (#).\n\n\nconsole\nThe pane in RStudio where you can type in commands and view output messages.\n\n\ncsv\nComma-separated variable: a file type for representing data where each variable is separated from the next by a comma.\n\n\ndata-visualisation\nA graphical representation of your data set.\n\n\ndata-wrangling\nThe process of preparing data for visualisation and statistical analysis.\n\n\ndescriptive\nStatistics that describe an aspect of data (e.g., mean, median, mode, variance, range)\n\n\ndouble\nA data type representing a real decimal number\n\n\nenvironment\nA data structure that contains R objects such as variables and functions\n\n\nfactor-data-type\nA data type where a specific set of values are stored with labels\n\n\ngeom\nThe geometric style in which data are displayed, such as boxplot, density, or histogram.\n\n\nhistogram\nA type of plot showing the frequency of each observation organised into bins. Bins control the width of each bar and how many observations it represents.\n\n\nnumeric\nA data type representing a real decimal number or integer.\n\n\nobject\nA word that identifies and stores the value of some data for later use.\n\n\ntidyverse\nA set of R packages that help you create and work with tidy data"
  },
  {
    "objectID": "07-more-visualisation.html#viz-a1",
    "href": "07-more-visualisation.html#viz-a1",
    "title": "7  Building your data visualisation skills",
    "section": "\n7.1 Activity 1: Set-up Visualisation",
    "text": "7.1 Activity 1: Set-up Visualisation\n\nOpen R Studio and set the working directory to your chapter folder. Ensure the environment is clear.\n\nOpen a new R Markdown document and save it in your working directory. Call the file “Visualisation”.\n\nDownload Zhang et al. 2014 Study 3.csv and save it in your chapter folder. Make sure that you do not change the file name at all.\nIf you’re on the server, avoid a number of issues by restarting the session - click Session - Restart R\n\nDelete the default R Markdown welcome text and insert a new code chunk that loads the package tidyverse using the library() function.\nRun the below code to load and wrangle the data into tidy data.\n\n\nlibrary(tidyverse)\nzhang_data &lt;- read_csv(\"data/Zhang et al. 2014 Study 3.csv\")%&gt;%\n  select(Gender, Age,Condition, T1_Predicted_Interest_Composite, T2_Actual_Interest_Composite)%&gt;%\n  mutate(subject = row_number())%&gt;%\n  pivot_longer(names_to = \"time\",values_to = \"interest\",\n               cols = T1_Predicted_Interest_Composite:T2_Actual_Interest_Composite)%&gt;%\n  mutate(Condition = recode(Condition, \"1\" = \"Ordinary\", \"2\" = \"Extraordinary\"))%&gt;%\n  mutate(time = recode(time, \"T1_Predicted_Interest_Composite\" = \"time1_interest\", \"T2_Actual_Interest_Composite\" = \"time2_interest\"),\n         Gender = recode(Gender, \"1\" = \"male\", \"2\" = \"female\")) %&gt;%\n  filter(Gender %in% c(\"male\", \"female\"))"
  },
  {
    "objectID": "07-more-visualisation.html#viz-a2",
    "href": "07-more-visualisation.html#viz-a2",
    "title": "7  Building your data visualisation skills",
    "section": "\n7.2 Activity 2: Histograms",
    "text": "7.2 Activity 2: Histograms\nFirst, let’s create histograms for interest to check the distribution. The first line of code creates the ggplot() object and specifies which dataset is being used, and what should be represented on the x and y-axis. Because this is a histogram, you only need to specify the variable on the x-axis because y is always frequency\n\n7.2.1 Basic histogram\nThe code below will create a simple histogram with default appearance and no customisation. You wouldn’t use this graph in a paper, but if you just want to quickly check your distributions, for e.g., normality, this code might be enough.\n\nggplot(zhang_data, aes(interest))+ \n  geom_histogram()\n\n\n\nBasic histogram\n\n\n\n\n7.2.2 Colour and fill\nThe next section of code will change the appearance. Plots in ggplot2 are highly customisable - R for Data Science has an excellent chapter on ggplot if you would like additional information.\nAdding binwidth to geom_histogram() changes the bins of the histogram, i.e., how wide the bars are. The default is 30. Sometimes this may be appropriate but often you will want to change the binwidth. What value you give will depend upon your data.\ncolour() changes the colour of the line around the bars. fill() changes the fill of the bars.\n\nggplot(zhang_data, aes(x = interest))+ \n  geom_histogram(binwidth = .3, \n                 colour = \"black\",  \n                 fill = \"grey\") \n\n\n\nHistogram with colour changes\n\n\n\n\n7.2.3 Axis labels\nThe next section of code changes the labels on the graphs. Note that the labels are an additional layer (i.e., it comes after an +, rather than being an argument to geom_histogram()).\nThe function you use will depend on your data, the most common are scale_x/y_continuous and scale_x/y_discrete depending on whether you are displaying continuous or categorical data. Again, each axis is a separate layer.\nThese scale functions control all the information about the axis, from the label to the breaks, to the minimum and maximum values. For more information use the help documentation.\nFor our labelling purposes, there are two main arguments:\n\n\nname() controls the main name of the axis\n\nlabels() controls the name of the breaks\n\nFor our histogram we will just change the main axis labels.\n\nggplot(zhang_data, aes(x = interest))+ \n  geom_histogram(binwidth = .3, \n                 colour = \"black\",  \n                 fill = \"grey\") + \n  scale_x_continuous(name = \"Mean interest score (1-7)\") +\n  scale_y_continuous(name = \"Count\") \n\n\n\nHistogram with label changes\n\n\n\n\n7.2.4 Density curve\nThe following section adds a normal density curve to the histogram, which can be useful for checking the assumption of normality.\nTo add the line you must change the geom_histogram() to use density on the y-axis (the default is count) and add a stat_function() layer that draws the line.\n\nggplot(zhang_data, aes(interest))+ \n  geom_histogram(binwidth = .3, \n                 colour = \"black\", \n                 fill = \"grey\",\n                 aes(y = ..density..))+ # change y-axis to density\n  scale_x_continuous(name = \"Mean interest score (1-7)\") +\n  scale_y_continuous(name = \"Count\") +\n  stat_function(fun = dnorm, # this adds a normal density function curve\n                colour = \"red\", # this makes it red\n                args = list(mean = mean(zhang_data$interest, na.rm = TRUE),\n                           sd = sd(zhang_data$interest, na.rm = TRUE)))\n\n\n\nHistogram with normal density curve"
  },
  {
    "objectID": "07-more-visualisation.html#viz-a3",
    "href": "07-more-visualisation.html#viz-a3",
    "title": "7  Scatterplots, boxplots, and violin-boxplots",
    "section": "\n7.2 Scatterplots",
    "text": "7.2 Scatterplots\nThe first visualisation is a scatterplot to show the relationship between two continuous variables. One variable goes on the x-axis and the other variables goes on the y-axis. Each dot then represents the intersection of those two variables per observation/participant. You will use these plots often when reporting a correlation or regression.\n\n7.2.1 Activity 3 - Creating a basic scatterplot\nLet us start by making a scatterplot of Age and time1_interest to see if there is any relationship between the two. We need to specify both the x- and y-axis variables, but the only difference to what we created in Chapter 3 is using a new layer geom_point.\n\nzhang_data %&gt;% \n  ggplot(aes(x = time1_interest, y = Age)) +\n       geom_point()\n\n\n\n\n\n\n\n\n7.2.2 Activity 4 - Editing axis labels\nThis plot is great for some exploratory data analysis, but it looks a little untidy to put into a report. We can use the scale_x_continuous and scale_y_continuous layers to control the tick marks, as well as the axis name.\n\nzhang_data %&gt;%  \n  ggplot(aes(x = time1_interest,y = Age)) +\n  geom_point() +\n  scale_x_continuous(name = \"Time 1 interest score (1-7)\", \n                     breaks = c(1:7)) + # tick marks from 1 to 7\n  scale_y_continuous(name = \"Age\",\n                     limits = c(15, 45), # change limits to 15 to 45\n                     breaks = seq(from = 15, # sequence from 15\n                                  to = 45, # to 45 \n                                  by = 5)) # in steps of 5\n\n\n\n\n\n\n\nTo break down these new arguments/functions in the layers:\n\nbreaks set the tick marks on the plot. We demonstrate two ways of setting this. On the x-axis, we just manually set values for 1 to 7. On the y-axis, we use a second function to set the breaks.\nseq() creates a sequence of numbers and can save a lot of time when you need to add lots of values. We set three arguments, from for the starting point, to for the end point, and by for the steps the sequence goes up in.\nlimits controls the start and end point of the graph scale. In the original graph, we can see there are points below 20 and above 40, so we might want to increase the limits of the graph to include a wider range.\n\n\n\n\n\n\n\nError mode\n\n\n\nWhen controlling the limits of the graph, sometimes you want to decrease the limits range to zoom in on an element of the data. If you decrease the range which cuts off some data points, you must be very careful as it actually cuts off data which you would receive a warning about:\n\nzhang_data %&gt;%  \n  ggplot(aes(x = time1_interest,y = Age)) +\n  geom_point() +\n  scale_y_continuous(name = \"Age\",\n                     limits = c(30, 40)) # in steps of 5\n\nWarning: Removed 124 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\nYou must be very careful when truncating axes, but if you do need to do it, there is a different function layer to use:\n\nzhang_data %&gt;%  \n  ggplot(aes(x = time1_interest,y = Age)) +\n  geom_point() +\n  coord_cartesian(ylim = c(30, 40))\n\n\n\n\n\n\n\n\n\n\n7.2.3 Activity 5 - Adding a regression line\nIt is often useful to add a regression line or line of best fit to a scatterplot. You can add a regression line with the geom_smooth() layer and by default will also provide a 95% confidence interval ribbon. You can specify what type of line you want to draw, most often you will need method = \"lm\" for a linear model or a straight line.\n\nzhang_data %&gt;%  \n  ggplot(aes(x = time1_interest,y = Age)) +\n  geom_point() +\n  scale_x_continuous(name = \"Time 1 interest score (1-7)\", \n                     breaks = c(1:7)) + # tick marks from 1 to 7\n  scale_y_continuous(name = \"Age\",\n                     limits = c(15, 45), # change limits to 15 to 45\n                     breaks = seq(from = 15, # sequence from 15\n                                  to = 45, # to 45 \n                                  by = 5)) +  # in steps of 5\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\nWith the regression line, we can see there is very little relationship between age and interest score at time 1.\n\n\n\n\n\n\nImportant\n\n\n\nRemember, you can save your plots using the function ggsave(). You can use the function after creating the last plot, or saving your plot as an object and using the plot argument. You have a Figures/ directory for the chapter, so try and save the plots you make to remind yourself later.\n\n\n\n\n\n\n\n\nTry this\n\n\n\nSo far, we made a scatterplot of age against interest at time 1. Now, create a scatterplot on your own using the two interest rating variables: time1_interest and time2_interest.\nAfter you made the scatterplot, it looks like there is a \npositive\nnegative relationship between interest ratings at time 1 and time 2.\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\nzhang_data %&gt;%  \n  ggplot(aes(x = time1_interest, y = time2_interest)) +\n  geom_point() +\n  scale_x_continuous(name = \"Time 1 interest score (1-7)\", \n                     breaks = c(1:7)) + # tick marks from 1 to 7\n  scale_y_continuous(name = \"Time 2 interest score (1-7)\", \n                     breaks = c(1:7)) + # tick marks from 1 to 7\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\n\n\n\n7.2.4 Activity 6 - Creating a grouped scatterplot\nBefore we move on, we can add a third variable to show how the relationship might differ for different groups within our data. We can do this by adding the colour argument to aes() and setting it as whatever variable we would like to distinguish between. In this case, we will see how the relationship between age and interest at time 1 differs for the male and female participants. There are a few participants with missing gender, so we will first filter them out.\n\nzhang_data %&gt;%\n  drop_na(Gender) %&gt;% \n  ggplot(aes(x = time1_interest, y = Age, colour = Gender)) +\n  geom_point() +\n  scale_x_continuous(name = \"Mean interest score (1-7)\",\n                     breaks = c(1:7)) + \n  scale_y_continuous(name = \"Age\") +\n  geom_smooth(method = \"lm\")\n\n\n\nGrouped scatterplot\n\n\n\n\n\n\n\n\n\nTry this\n\n\n\nFor your independent scatterplot of the two interest rating variables: time1_interest and time2_interest, add a colour argument using the Condition variable. This will show the relationship between time 1 and time 2 interest separately for participants in the ordinary and extraordinary groups.\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\nzhang_data %&gt;%  \n  ggplot(aes(x = time1_interest, y = time2_interest, colour = Condition)) +\n  geom_point() +\n  scale_x_continuous(name = \"Time 1 interest score (1-7)\", \n                     breaks = c(1:7)) + # tick marks from 1 to 7\n  scale_y_continuous(name = \"Time 2 interest score (1-7)\", \n                     breaks = c(1:7)) + # tick marks from 1 to 7\n  geom_smooth(method = \"lm\")"
  },
  {
    "objectID": "07-more-visualisation.html#viz-a4",
    "href": "07-more-visualisation.html#viz-a4",
    "title": "7  Scatterplots, boxplots, and violin-boxplots",
    "section": "\n7.3 Boxplots",
    "text": "7.3 Boxplots\nThe next visualisation is the boxplot which presents a range of summary statistics for your outcome, which you can split between different groups on the x-axis, or add further variables to divide by. For the boxplot element, you get five summary statistics: the median centre line, the first and third quartile as the box (essentially, the interquartile range), and 1.5 times the first and third quartiles as the whiskers extending from the box. If there are any values beyond the whiskers, you see the individual data points and this is one definition of an outlier (more on that in Chapter 11)\n\n7.3.1 Activity 7 - Creating a basic boxplot\nBefore we create the boxplot, we need a final data wrangling step. At the moment, we have time1_interest and time2_interest in wide format, but to plot together, we need to express it as a single variable. For that, we must restructure the data. This is why we spent so much time on data wrangling, as you might need to quickly restructure your data to plot certain elements.\n\n\n\n\n\n\nTry this\n\n\n\nTo wrangle the data, gather the variables time1_interest and time2_interest. Create a new object called zhang_data_long and use the names Time and Interest for your column names to be consistent with the demonstrations below.\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# gather the data to convert to long format\nzhang_data_long &lt;- zhang_data %&gt;% \n  pivot_longer(cols = time1_interest:time2_interest,\n               names_to = \"Time\",\n               values_to = \"Interest\")\n\n\n\n\nIf you only want to visualise one continuous variable, we need one variable on the y-axis and a new function layer geom_boxplot().\n\nzhang_data_long %&gt;% \n  ggplot(aes(y = Interest)) +\n  geom_boxplot() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7))\n\n\n\n\n\n\n\nTypically, you want to compare the outcome between one or more categories, so we can add a categorical variable like gender to the x-axis, removing the missing values first.\n\nzhang_data_long %&gt;% \n  drop_na(Gender) %&gt;% \n  ggplot(aes(y = Interest, x = Gender)) +\n  geom_boxplot() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7))\n\n\n\n\n\n\n\n\n7.3.2 Activity 8 - Adding colour to variables\nIt is not as important when you only have one variable on the x-axis, but one useful feature is adding colour to distinguish between categories. You can control this by adding a variable to the fill argument within aes().\nBy default, we get a legend which is redundant when we only have different colours on the x-axis, so we can turn it off by adding guides(fill = FALSE) as a layer.\n\nzhang_data_long %&gt;% \n  drop_na(Gender) %&gt;% \n  ggplot(aes(y = Interest, x = Gender, fill = Gender)) +\n  geom_boxplot() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7)) + \n  guides(fill = FALSE) # remove the legend\n\n\n\n\n\n\n\n\n\n\n\n\n\nError mode\n\n\n\nYou might have noticed we have now used two different arguments to control the colour. In scatterplots, we used colour. In boxplots, we used fill. It is one of those concepts that takes time to recognise which you need, depending on the type of geom you are using. Roughly, colour is when you want to control the outline or symbol, like the points. Whereas fill is when you want the inside of a geom coloured. You can see the difference here by controlling fill first:\n\nzhang_data_long %&gt;% \n  drop_na(Gender) %&gt;% \n  ggplot(aes(y = Interest, x = Gender, fill = Gender)) +\n  geom_boxplot() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7))\n\n\n\n\n\n\n\nThen colour:\n\nzhang_data_long %&gt;% \n  drop_na(Gender) %&gt;% \n  ggplot(aes(y = Interest, x = Gender, colour = Gender)) +\n  geom_boxplot() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7))\n\n\n\n\n\n\n\n\n\n\n7.3.3 Activity 9 - Controlling colours\nggplot2 has a default colour scheme which is fine for quick plots, but it is useful to control the colour scheme. You can do this manually by editing scale_fill_discrete() and choosing colours through the type argument (you can do this through character names or choosing a HEX code: https://r-charts.com/colors/).\n\nzhang_data_long %&gt;% \n  drop_na(Gender) %&gt;% \n  ggplot(aes(y = Interest, x = Gender, fill = Gender)) +\n  geom_boxplot() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7)) + \n  scale_fill_discrete(type = c(\"blue\", \"pink\"))\n\n\n\n\n\n\n\nAlternatively (and what we recommend), you can use scale_fill_viridis_d(). This function does exactly the same thing but it uses a colour-blind friendly palette (which also prints in black and white). There are 5 different options for colours and you can see them by changing option to A, B, C, D or E. We like option E with alpha = 0.6 (to control transparency and soften the tone) but play around with the options to see what you prefer.\n\nzhang_data_long %&gt;% \n  drop_na(Gender) %&gt;% \n  ggplot(aes(y = Interest, x = Gender, fill = Gender)) +\n  geom_boxplot() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7)) + \n  scale_fill_viridis_d(option = \"E\", \n                       alpha = 0.6) + \n  guides(fill = FALSE)\n\n\n\nBoxplots with friendly colours\n\n\n\n\n\n\n\n\n\nTry this\n\n\n\nFor your independent boxplot, use zhang_data_long to visualise Interest as your continuous variable and Condition for different categories. This will show the difference in interest rating between those in the ordinary and extraordinary groups.\nComparing the ordinary and extraordinary groups, it looks like \nordinary score higher on average\nvery little difference on average\nextraordinary score higher on average.\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\nzhang_data_long %&gt;% \n  ggplot(aes(y = Interest, x = Condition, fill = Condition)) +\n  geom_boxplot() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7)) + \n  scale_fill_viridis_d(option = \"E\", \n                       alpha = 0.6) + \n  guides(fill = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n7.3.4 Activity 10 - Ordering categories\nWhen we plot variables like Gender on the x-axis, R has an internal order it sets unless you create a factor. The default is alphabetical or numerical. In previous plots, it displayed Female then Male, as F comes before M.\nControlling the order of categories is an important design choice to communicate your message, and the most direct way is controlling the factor order before plotting. Here, we add mutate() in a pipe and manually set the factor levels, just be careful as it is case sensitive to the values in your data.\n\nzhang_data_long %&gt;% \n  drop_na(Gender) %&gt;% \n  mutate(Gender = factor(Gender, \n                         levels = c(\"Male\", \"Female\"))) %&gt;% \n  ggplot(aes(y = Interest, x = Gender, fill = Gender)) +\n  geom_boxplot() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7)) + \n  scale_fill_viridis_d(option = \"E\", \n                       alpha = 0.6) + \n  guides(fill = FALSE)\n\n\n\n\n\n\n\n\n7.3.5 Activity 11- Boxplots for multiple factors\nWhen you only have one independent variable, using the fill argument to change the colour can be a little redundant as the colours do not add any additional information. It makes more sense to use colour to represent a second variable.\nFor this example, we will use Condition and Time as variables. fill() now specifies a second independent variable, rather than repeating the variable on the x-axis as in the previous plot, so we do not want to deactivate the legend.\n\nzhang_data_long %&gt;% \n  ggplot(aes(y = Interest, x = Condition, fill = Time)) +\n  geom_boxplot() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7)) + \n  scale_fill_viridis_d(option = \"E\", \n                       alpha = 0.6)\n\n\n\n\n\n\n\nAs a final point here, the fill values on the legend are not the most professional looking. Like reordering factors, the easiest way of addressing this is editing the underlying data before piping to ggplot2.\n\nzhang_data_long %&gt;% \n  mutate(Time = case_match(Time,\n                           \"time1_interest\" ~ \"Time 1\",\n                           \"time2_interest\" ~ \"Time 2\")) %&gt;% \n  ggplot(aes(y = Interest, x = Condition, fill = Time)) +\n  geom_boxplot() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7)) + \n  scale_fill_viridis_d(option = \"E\", \n                       alpha = 0.6)"
  },
  {
    "objectID": "07-more-visualisation.html#viz-a5",
    "href": "07-more-visualisation.html#viz-a5",
    "title": "7  Scatterplots, boxplots, and violin-boxplots",
    "section": "\n7.4 Activity 5: Reordering factors",
    "text": "7.4 Activity 5: Reordering factors\nR orders categorical variables alphabetically. For gender it didn’t really matter whether male or female was represented first and for time 1 and 2 it makes sense for them to be in this order but we may want to change the order of Condition (in my mind it makes more sense for Ordinary to come first, but that may just be me).\nTo do this we can use mutate() and fct_level() to change the factor levels to the order we want.\n\nzhang_data_long &lt;- zhang_data_long %&gt;%\n  mutate(Condition = fct_relevel(Condition, c(\"Ordinary\", \"Extraordinary\")))\n\nNow we can re-run the boxplot. That’s better.\n\nggplot(zhang_data_long, aes(x = Condition, y = Interest, fill = Time))+\n  geom_boxplot(alpha = .6)+\n  geom_point(position=position_jitterdodge(jitter.width = .1)) +\n  scale_fill_viridis_d(option = \"E\")\n\n\n\nBoxplot with reordered factors"
  },
  {
    "objectID": "07-more-visualisation.html#viz-a6",
    "href": "07-more-visualisation.html#viz-a6",
    "title": "7  Building your data visualisation skills",
    "section": "\n7.6 Activity 6: Bar Charts",
    "text": "7.6 Activity 6: Bar Charts\n\n7.6.1 Basic bar chart\nBar charts should only be used for counts because they can distort your understanding of the data if you use them to represent means (see here for a great example.\nFirst, we’ll do a bar chart for the count of male and females in our sample.\n\nggplot(zhang_data, aes(x=Gender))+\n  geom_bar()\n\n\n\nBasic bar chart\n\n\n\n\n7.6.2 Bar charts with two factors\nWe can also use fill() to separate gender by Condition\n\nggplot(zhang_data, aes(x=Gender, fill = Condition))+\n  geom_bar(position = \"dodge\", alpha = .6) + # the position argument places the bars next to each other, rather than on top of each other, try removing this\n  scale_fill_viridis_d(option = \"E\")\n\n\n\nBar chart with two factors"
  },
  {
    "objectID": "07-more-visualisation.html#viz-a7",
    "href": "07-more-visualisation.html#viz-a7",
    "title": "7  Scatterplots, boxplots, and violin-boxplots",
    "section": "\n7.4 Violin-boxplots",
    "text": "7.4 Violin-boxplots\nBoxplots are great for your own exploratory data analysis but you do not often see them reported in isolation. They visualise summary statistics, but you do not get much sense of the underlying distribution of values. When you want to communicate continuous outcomes, researchers in psychology are using violin-boxplots more often. This combines both elements: a violin plot to show the distribution of the data, and a boxplot to add summary statistics. This is where ggplot2 comes into it’s own as we can add and customise several layers.\n\n7.4.1 Activity 12 - Creating a basic violin plot\nViolin plots get their name as they look something like a violin when the data are roughly normally distributed. They show density, so the fatter the violin element, the more data points there are for that value. Compared to the boxplot, the only difference is changing the layer to geom_violin().\n\nzhang_data_long %&gt;% \n  drop_na(Gender) %&gt;% \n  ggplot(aes(y = Interest, x = Gender)) +\n  geom_violin() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7))\n\n\n\n\n\n\n\nThe distribution of values is great, but sometimes it might be useful to also add the underlying data points. These are all important design choices as it can be useful when you have smaller amounts of data, but overwhelming when you have thousands of data points. So, keep in mind what you want to communicate. Here, we use the layer geom_jitter() to jitter the points slightly, so they are not all in a vertical line and we get a better sense of the density.\n\nzhang_data_long %&gt;% \n  drop_na(Gender) %&gt;% \n  ggplot(aes(y = Interest, x = Gender)) +\n  geom_violin() + \n  geom_jitter(height = 0, # do not jitter height\n              width = .1) + # jitter width of points\n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7))\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIt is important to remember that R is very literal. ggplot2 works on a system of layers. It will add new geoms on top of existing ones and it will not stop to think whether this is a good idea. Try running the code above but put geom_jitter() first and then add geom_violin(). The order of your layers matters.\n\n\n\n7.4.2 Activity 13 - Creating a violin-boxplot\nInstead of adding the data points in a layer, we can add a boxplot to create the violin-boxplot. This way, we get distribution information from the violin layer and summary statistics from the boxplot layer.\n\nzhang_data_long %&gt;% \n  drop_na(Gender) %&gt;% \n  ggplot(aes(y = Interest, x = Gender)) +\n  geom_violin() + \n  geom_boxplot() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7))\n\n\n\n\n\n\n\nOn it’s own, this does not look great. We can edit the settings to reduce the width of the boxplots, add a colour scheme, and add transparency to the violin layer to make it easier to see the boxplot.\n\nzhang_data_long %&gt;% \n  drop_na(Gender) %&gt;% \n  ggplot(aes(y = Interest, x = Gender, fill = Gender)) +\n  geom_violin(alpha = 0.5) + \n  geom_boxplot(width = 0.2) + \n  scale_fill_viridis_d(option = \"E\") + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7)) + \n  guides(fill = FALSE)\n\n\n\n\n\n\n\nThe boxplot uses the median for the centre line, but in your report you might be presenting means per category which will be slightly different. One further variation is removing the centre median line, and replacing it with the mean and 95% confidence interval (more on that in the lectures and Chapter 8). This way, you get three layers: the violin plot for the density, the boxplot for distribution summary statistics, and the mean and 95% confidence interval.\nThis code uses two calls to stat_summary() which is a layer to add summary statistics. The first layer draws a point to represent the mean, and the second draws an errorbar that represents the 95% confidence interval around the mean.\n\nzhang_data_long %&gt;% \n  drop_na(Gender) %&gt;% \n  ggplot(aes(y = Interest, x = Gender, fill = Gender)) +\n  geom_violin(alpha = 0.5) + \n  geom_boxplot(width = 0.2, \n               fatten = NULL) + \n  stat_summary(fun = \"mean\", \n               geom = \"point\") +\n  stat_summary(fun.data = \"mean_cl_boot\", # confidence interval\n               geom = \"errorbar\", \n               width = 0.1) +\n  scale_fill_viridis_d(option = \"E\") + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7)) + \n  guides(fill = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nWhen you run the line stat_summary(fun.data = \"mean_cl_boot\", geom = \"errorbar\", width = .1) for the first time, you might be prompted to install the R package Hmisc. If you are on your own computer, follow the instructions in the Console to install the package. If you are on a university computer, this should already be installed.\n\n\n\n\n\n\n\n\nTry this\n\n\n\nFor your independent violin-boxplot, use zhang_data_long to visualise Interest as your continuous variable and Condition for different categories on the x-axis. Try and create the plot to look like this, so you might need to play around with different themes:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\nzhang_data_long %&gt;% \n  ggplot(aes(y = Interest, x = Condition, fill = Condition)) +\n  geom_violin(alpha = 0.5) + \n  geom_boxplot(width = 0.2, \n               fatten = NULL) + \n  stat_summary(fun = \"mean\", \n               geom = \"point\") +\n  stat_summary(fun.data = \"mean_cl_boot\", \n               geom = \"errorbar\", \n               width = .1) +\n  scale_fill_viridis_d(option = \"E\") + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7)) + \n  theme_minimal() + \n  guides(fill = FALSE)\n\n\n\n\n\n7.4.3 Activity 14 - Adding additional variables\nLike boxplots, we can add a second grouping variable to fill instead of just using it for colour.\n\nzhang_data_long %&gt;% \n  ggplot(aes(y = Interest, x = Condition, fill = Time)) +\n  geom_violin(alpha = 0.5) + \n  geom_boxplot(width = 0.2, \n               fatten = NULL) + \n  stat_summary(fun = \"mean\", \n               geom = \"point\") +\n  stat_summary(fun.data = \"mean_cl_boot\", \n               geom = \"errorbar\", \n               width = .1) +\n  scale_fill_viridis_d(option = \"E\") + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7)) + \n  theme_minimal()\n\n\n\n\n\n\n\nHowever, unless you are trying to recreate a Kandinsky painting in ggplot2, that does not look quite right. This is because we have multiple layers that each plot separate groups in different ways. To make it all fall into line, we need to add a constant value to offset the elements. We start off by defining a position dodge value as an object. This way, we can use the object name later, and we only need to edit it in one place if we wanted to change the value.\n\n# specify as an object, so we only change it in one place\ndodge_value &lt;- 0.9\n\nzhang_data_long %&gt;% \n  ggplot(aes(y = Interest, x = Condition, fill = Time)) +\n  geom_violin(alpha = 0.5) + \n  geom_boxplot(width = 0.2, \n               fatten = NULL,\n               position = position_dodge(dodge_value)) + \n  stat_summary(fun = \"mean\", \n               geom = \"point\",\n               position = position_dodge(dodge_value)) +\n  stat_summary(fun.data = \"mean_cl_boot\", \n               geom = \"errorbar\", \n               width = .1,\n               position = position_dodge(dodge_value)) +\n  scale_fill_viridis_d(option = \"E\") + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7))\n\n\n\n\n\n\n\nThis looks much better! Remember, if you want to change the legend labels, the easiest way is recoding the data before piping to ggplot2.\nFinally, we might want to add a third variable to group the data by. There is a facet function that produces different plots for each level of a grouping variable which can be very useful when you have more than two factors. The following code shows interest ratings for all three variables we have worked with: Condition, Time, and Gender.\n\n# specify as an object, so we only change it in one place\ndodge_value &lt;- 0.9\n\nzhang_data_long %&gt;% \n  drop_na(Gender) %&gt;% \n  ggplot(aes(y = Interest, x = Condition, fill = Time)) +\n  geom_violin(alpha = 0.5) + \n  geom_boxplot(width = 0.2, \n               fatten = NULL,\n               position = position_dodge(dodge_value)) + \n  stat_summary(fun = \"mean\", \n               geom = \"point\",\n               position = position_dodge(dodge_value)) +\n  stat_summary(fun.data = \"mean_cl_boot\", \n               geom = \"errorbar\", \n               width = .1,\n               position = position_dodge(dodge_value)) +\n  facet_wrap(~ Gender) + # facet by Gender\n  scale_fill_viridis_d(option = \"E\") + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7))\n\n\n\n\n\n\n\nFacets work in the same way as adding a variable to fill. It is not easy to change the labels within ggplot2, you are better off editing the values in your data first."
  },
  {
    "objectID": "07-more-visualisation.html#viz-a8",
    "href": "07-more-visualisation.html#viz-a8",
    "title": "7  Scatterplots, boxplots, and violin-boxplots",
    "section": "\n7.5 Activity 8: Violin-boxplots",
    "text": "7.5 Activity 8: Violin-boxplots\nOne increasingly common graph is a violin + boxplot + summary plot that shows a huge amount of information about your data in a single plot.\n\nThis code uses two calls to stat_summary() that was introduced during the t-test chapter. The first draws a point to represent the mean, and the second draws an errorbar that represents standard error (mean_se).\n\n\nguides is a new function and can be used to adjust whether legends are displayed. This has the same effect as specifying show.legend = FALSE in both geom_violin() and geom_boxplot() but it uses less code to do so.\n\n\nfatten = NULL removes the median line from the boxplots. This can be useful if you’re running a test where you’re comparing means as it makes it easier to see the point range.\nYou may get warning messages telling you that R has removed rows containing missing values, you do not need to worry about this.\n\n\nggplot(zhang_data_long, aes(x = Condition, y = Interest, fill = Condition))+\n  geom_violin(alpha = .6, trim = FALSE)+\n  geom_boxplot(width = .2, alpha = .7, fatten = NULL)+\n  stat_summary(fun = \"mean\", geom = \"point\") +\n  stat_summary(fun.data = \"mean_se\", geom = \"errorbar\", width = .1) +\n  scale_fill_viridis_d(option = \"E\", label = c(\"Ordinary\", \"Extraordinary\"))+\n  scale_y_continuous(name = \"Mean interest rating (1-7)\") +\n  guides(fill = FALSE)\n\n\n\nViolin-boxplot with summary data"
  },
  {
    "objectID": "07-more-visualisation.html#viz-a9",
    "href": "07-more-visualisation.html#viz-a9",
    "title": "7  Scatterplots, boxplots, and violin-boxplots",
    "section": "\n7.6 Activity 9: Faceting",
    "text": "7.6 Activity 9: Faceting\nggplot2 contains a facet function that produces different plots for each level of a grouping variable which can be very useful when you have more than two factors, for example, for a three-way ANOVA. The following code displays produces violin-boxplots for Condition ~ interest, but separately for male and female participants.\n\nThis code adds an extra argument position = position_dodge(.9) to align the layers with the violin plots. Try removing this argument from each layer to see what happens, and also try adjusting the value from .9 to another number.\n\n\nggplot(zhang_data_long, aes(x = Condition, y = Interest, fill = Time))+\n  geom_violin(alpha = .6, trim = FALSE)+\n  geom_boxplot(width = .2, \n               alpha = .6, \n               fatten = NULL,\n               position = position_dodge(.9))+\n  stat_summary(fun = \"mean\", geom = \"point\",\n               position = position_dodge(.9)) +\n  stat_summary(fun.data = \"mean_se\", geom = \"errorbar\", width = .1,\n               position = position_dodge(.9))+\n  scale_fill_viridis_d(option = \"E\") +\n  facet_wrap(~Gender)\n\n\n\nViolin-boxplot facetted by gender\n\n\n\n\n7.6.1 Facet labelling\nFinally, changing the labels within the facets is a little more complicated - there’s no additional scale layer, instead, you adjust this inside facet_wrap() using labeller. This has always felt unintuitive to me and I have to look it up every single time so don’t worry if it is confusing - just remember where to look for the example.\n\nggplot(zhang_data_long, aes(x = Condition, y = Interest, fill = Time))+\n  geom_violin(alpha = .6, trim = FALSE)+\n  geom_boxplot(width = .2, \n               alpha = .6, \n               fatten = NULL,\n               position = position_dodge(.9))+\n  stat_summary(fun = \"mean\", geom = \"point\",\n               position = position_dodge(.9)) +\n  stat_summary(fun.data = \"mean_se\", geom = \"errorbar\", width = .1,\n               position = position_dodge(.9))+\n  scale_fill_viridis_d(option = \"E\") +\n  facet_wrap(~Gender, labeller = labeller(Gender = (c(female = \"Female\", male = \"Male\"))))\n\n\n\nFacetted plot with updated labels"
  },
  {
    "objectID": "07-more-visualisation.html#viz-a10",
    "href": "07-more-visualisation.html#viz-a10",
    "title": "7  Building your data visualisation skills",
    "section": "\n7.10 Activity 10: Split-violins and raincloud plots",
    "text": "7.10 Activity 10: Split-violins and raincloud plots\nFinally, we’re going to do something a bit snazzy. As well as the functions that are included in packages, anyone can also write custom functions and share the code. One such custom function allows us to create raincloud plots which are highly informative and very pretty. See here for more information about their creation and function (and to cite them if you use them in a publication or report).\nIn order to use this custom function code you will need to install the plyr package, although crucially, don’t load it like you normally would using library(). The custom function code will just use one very specific function, if you load the entire package you risk creating a function conflict.\n\ninstall.packages(\"plyr\")\n\n\n7.10.1 Split-violin plots\nBecause the functions we need don’t exist in a package we can load, we need to create them. Copy and paste all the below code without changing anything. You do not need to understand this code. I certainly don’t. When you run this, you should see geom_split_violin appear in the Environment pane under Functions.\n\nGeomSplitViolin &lt;- ggproto(\n  \"GeomSplitViolin\", \n  GeomViolin, \n  draw_group = function(self, data, ..., draw_quantiles = NULL) {\n    data &lt;- transform(data, \n                      xminv = x - violinwidth * (x - xmin), \n                      xmaxv = x + violinwidth * (xmax - x))\n    grp &lt;- data[1,'group']\n    newdata &lt;- plyr::arrange(\n      transform(data, x = if(grp%%2==1) xminv else xmaxv), \n      if(grp%%2==1) y else -y\n    )\n    newdata &lt;- rbind(newdata[1, ], newdata, newdata[nrow(newdata), ], newdata[1, ])\n    newdata[c(1,nrow(newdata)-1,nrow(newdata)), 'x'] &lt;- round(newdata[1, 'x']) \n    if (length(draw_quantiles) &gt; 0 & !scales::zero_range(range(data$y))) {\n      stopifnot(all(draw_quantiles &gt;= 0), all(draw_quantiles &lt;= 1))\n      quantiles &lt;- ggplot2:::create_quantile_segment_frame(data, draw_quantiles)\n      aesthetics &lt;- data[rep(1, nrow(quantiles)), setdiff(names(data), c(\"x\", \"y\")), drop = FALSE]\n      aesthetics$alpha &lt;- rep(1, nrow(quantiles))\n      both &lt;- cbind(quantiles, aesthetics)\n      quantile_grob &lt;- GeomPath$draw_panel(both, ...)\n      ggplot2:::ggname(\"geom_split_violin\", \n                       grid::grobTree(GeomPolygon$draw_panel(newdata, ...), quantile_grob))\n    } else {\n      ggplot2:::ggname(\"geom_split_violin\", GeomPolygon$draw_panel(newdata, ...))\n    }\n  }\n)\n\ngeom_split_violin &lt;- function (mapping = NULL, \n                               data = NULL, \n                               stat = \"ydensity\", \n                               position = \"identity\", ..., \n                               draw_quantiles = NULL, \n                               trim = TRUE, \n                               scale = \"area\", \n                               na.rm = FALSE, \n                               show.legend = NA, \n                               inherit.aes = TRUE) {\n  layer(data = data, \n        mapping = mapping, \n        stat = stat, \n        geom = GeomSplitViolin, \n        position = position, \n        show.legend = show.legend, \n        inherit.aes = inherit.aes, \n        params = list(trim = trim, \n                      scale = scale, \n                      draw_quantiles = draw_quantiles, \n                      na.rm = na.rm, ...)\n  )\n}\n\nThe split-violin is a version of the violin-boxplot that is good for visualising interactions. If you look at the faceted graph we made, there’s actually quite a lot of unnecessary space used up because we only need half of the violin to see the distribution - the other half is just repeating the same information.\n\nggplot(zhang_data, aes(x = Condition, y = interest, fill = Gender))+\n  geom_split_violin(trim = FALSE, alpha = .4)+\n  geom_boxplot(width = .2, alpha = .6,\n               position = position_dodge(.25))+\n  scale_fill_viridis_d(option = \"E\") +\n  stat_summary(fun = \"mean\", geom = \"point\",\n               position = position_dodge(width = 0.25)) +\n  stat_summary(fun.data = \"mean_se\", geom = \"errorbar\", width = .1,\n               position = position_dodge(width = 0.25))\n\n\n\nSplit-violin plot\n\n\n\n\n7.10.2 Raincloud plots\nThe second custom function is geom_flat_violin. Copy and paste all of this code and again you should see it appear in your Environment pane.\n\n\"%||%\" &lt;- function(a, b) {\n  if (!is.null(a)) a else b\n}\n\ngeom_flat_violin &lt;- function(mapping = NULL, data = NULL, stat = \"ydensity\",\n                             position = \"dodge\", trim = TRUE, scale = \"area\",\n                             show.legend = NA, inherit.aes = TRUE, ...) {\n  layer(\n    data = data,\n    mapping = mapping,\n    stat = stat,\n    geom = GeomFlatViolin,\n    position = position,\n    show.legend = show.legend,\n    inherit.aes = inherit.aes,\n    params = list(\n      trim = trim,\n      scale = scale,\n      ...\n    )\n  )\n}\n\nGeomFlatViolin &lt;-\n  ggproto(\"Violinist\", Geom,\n          setup_data = function(data, params) {\n            data$width &lt;- data$width %||%\n              params$width %||% (resolution(data$x, FALSE) * 0.9)\n            \n            # ymin, ymax, xmin, and xmax define the bounding rectangle for each group\n            data %&gt;%\n              group_by(group) %&gt;%\n              mutate(ymin = min(y),\n                     ymax = max(y),\n                     xmin = x,\n                     xmax = x + width / 2)\n            \n          },\n          \n          draw_group = function(data, panel_scales, coord) {\n            # Find the points for the line to go all the way around\n            data &lt;- transform(data, xminv = x,\n                              xmaxv = x + violinwidth * (xmax - x))\n            \n            # Make sure it's sorted properly to draw the outline\n            newdata &lt;- rbind(plyr::arrange(transform(data, x = xminv), y),\n                             plyr::arrange(transform(data, x = xmaxv), -y))\n            \n            # Close the polygon: set first and last point the same\n            # Needed for coord_polar and such\n            newdata &lt;- rbind(newdata, newdata[1,])\n            \n            ggplot2:::ggname(\"geom_flat_violin\", GeomPolygon$draw_panel(newdata, panel_scales, coord))\n          },\n          \n          draw_key = draw_key_polygon,\n          \n          default_aes = aes(weight = 1, colour = \"grey20\", fill = \"white\", size = 0.5,\n                            alpha = NA, linetype = \"solid\"),\n          \n          required_aes = c(\"x\", \"y\")\n  )\n\nThis plot is similar to the split-violin, but it adds in the raw data points and looks a bit like a raincloud as a result.\nFirst, we will run the plot for just one variable, Condition. Again, try changing the arguments (adjust any numbers and change FALSE to TRUE) to see how you can control different aspects of the plot, in particular, try removing coord_flip() to see what happens.\n\nggplot(zhang_data, aes(x = Condition, y = interest))+\n  geom_flat_violin(position = position_nudge(x = .25, y = 0), \n                   trim=FALSE, alpha = 0.75) +\n  geom_jitter(aes(color = Condition), \n             width = .2, size = .5, alpha = .75, show.legend = FALSE)+\n  geom_boxplot(width = .1, alpha = 0.5, fatten = NULL)+\n  stat_summary(fun = \"mean\", geom = \"point\",\n               position = position_dodge(width = 0.25)) +\n  stat_summary(fun.data = \"mean_se\", geom = \"errorbar\", width = .1,\n               position = position_dodge(width = 0.3)) +\n  coord_flip()\n\n\n\nRaincloud plot for one factor\n\n\n\n\n7.10.3 Raincloud plots with multiple factors\nNow we can run the code for a 2 x 2 plot, adding in Gender to fill argument. This is quite a complicated plot, do not worry if you are struggling to understand the code but remember, you just need to understand which bits to change.\n\nggplot(zhang_data, \n       aes(x = Condition, y = interest, fill = Gender))+\n  geom_flat_violin(position = position_nudge(x = .25, y = 0), \n                   trim=FALSE, \n                   alpha = 0.6) +\n  geom_point(position = position_jitter(width = .05, height = 0.05), \n             size = .5, \n             alpha = .7, \n             show.legend = FALSE, \n             aes(colour = Gender))+\n  geom_boxplot(width = .3, \n               alpha = 0.5, \n               position = \"dodge\")+\n  stat_summary(fun = \"mean\", geom = \"point\",\n               position = position_dodge(width = 0.3)) +\n  stat_summary(fun.data = \"mean_se\", geom = \"errorbar\", width = .1,\n               position = position_dodge(width = 0.3)) +\n  scale_fill_viridis_d(option = \"E\") +\n  scale_colour_viridis_d(option = \"E\")\n\n\n\nRaincloud plot for two factors\n\n\n\n\n7.10.4 Finished!\nAnd you’re done! As we’ve said throughout this chapter, you do not need to remember all of this code, you just need to remember what’s possible and where to find the examples that you can modify.\n\n\n\n\nZhang, T., Kim, T., Brooks, A. W., Gino, F., & Norton, M. I. (2014). A “Present” for the Future: The Unexpected Value of Rediscovery. Psychological Science, 25(10), 1851–1860. https://doi.org/10.1177/0956797614542274"
  },
  {
    "objectID": "08-lm-continuous.html#set-up-the-data",
    "href": "08-lm-continuous.html#set-up-the-data",
    "title": "\n8  Regression with one continuous predictor\n",
    "section": "\n8.1 Set-up the Data",
    "text": "8.1 Set-up the Data\nAs always, the first activity is about getting ourselves ready to analyse the data so try out the steps and if you need help, consult the earlier chapters.\n\n8.1.0.1 Activity 1: Set-up\n\nOpen RStudio and set the working directory to your chapter folder. Ensure the environment is clear.\n\nIf you’re using the Rserver, avoid a number of issues by restarting the session - click Session - Restart R\n\n\n\nOpen a new R Markdown document and save it in your working directory. Call the file “Correlations”.\n\nDownload MillerHadenData.csv and save it in your folder. Make sure that you do not change the file name at all.\n\nIf you prefer you can download the data in a zip folder by clicking here\n\nRemember not to change the file names at all and that data.csv is not the same as data (1).csv.\n\n\nDelete the default R Markdown welcome text and insert a new code chunk that loads the following packages, in this specific order, using the library() function. Remember the solutions if needed.\n\nLoad the packages in this order, car,correlation, report, psych, and tidyverse\n\nwe have not used four of these packages before so you will likely need to install them using install.packages(). Remember though that you should only do this on your own machine and only in the console window. If you are using the RServer you will not need to install them.\n\n\nFinally, load the data into an object named mh using read_csv().\n\n\n\nAdditional Hints\n\n\n\nEach package requires using the library() function each time. For example, library(car), libary(correlation), etc, etc.\nmh &lt;- read_csv(“What_is_your_datafile_called.csv”)\n\n\n\n\n8.1.0.2 Activity 2: Look at your data\nExcellent! If you have loaded in the data correctly then you should be able to have a look at it through one of the various methods we have looked at already.\n\nLook at your data using the head() function and you should see the following:\n\n\n\n\n\n\nParticipant\nAbil\nIQ\nHome\nTV\n\n\n\n1\n61\n107\n144\n487\n\n\n2\n56\n109\n123\n608\n\n\n3\n45\n81\n108\n640\n\n\n4\n66\n100\n155\n493\n\n\n5\n49\n92\n103\n636\n\n\n6\n62\n105\n161\n407\n\n\n\n\n\n\nAs you can see, we have five columns and they are:\n\nthe participant number (Participant),\nReading Ability score (Abil),\nIntelligence score (IQ),\nthe number of minutes spent reading at Home per week (Home),\nand the number of minutes spent watching TV per week (TV).\n\nHere we will we will focus on Reading Ability and IQ but for further practice you can look at other relationships in your free time.\nA probable hypothesis for today could be that as Reading Ability increases so does Intelligence (remember there is no causality here). Or phrasing the alternative hypothesis (\\(H_1\\)) more formally, we hypothesise that the reading ability of school children, as measured through a standardized test, and intelligence, again measured through a standardized test, show a positive relationship. This is the hypothesis we will test today but remember that we could always state the null hypothesis (\\(H_0\\)) that there is no relationship between reading ability and IQ."
  },
  {
    "objectID": "08-lm-continuous.html#assumptions-of-the-test",
    "href": "08-lm-continuous.html#assumptions-of-the-test",
    "title": "\n8  Regression with one continuous predictor\n",
    "section": "\n8.2 Assumptions of the test",
    "text": "8.2 Assumptions of the test\nNow before running an analysis we should check the assumptions of the test, where the assumptions are checks that the data must pass before we can use certain tests. The assumptions change on the test and you should only use a given test based on how well the data meets the assumptions of the test. In short, the Pearson correlation and the Spearman correlation have different assumptions and we need to check our data to see which test to use.\n\n8.2.0.1 Activity 3: Assumptions\nFor correlations, the main assumptions we need to check are:\n\nIs the data interval, ratio, or ordinal?\nIs there a data point for each participant on both variables?\nIs the data normally distributed in both variables?\nDoes the relationship between variables appear linear?\nDoes the spread have homoscedasticity?\n\nWe will look at each of these assumptions in turn to see which correlation we should use.\nAssumption 1: Level of Measurement\nIf we want to run a Pearson correlation then we need interval or ratio data; Spearman correlations can run with ordinal, interval or ratio data. What type of data do we have?\n\nThe type of data in this analysis is most probably \nratio\ninterval\nordinal\nnominal as the data is \ncontinuous\ndiscrete and there is unlikely to be a true zero\n\n\n\nHints on data type\n\n\n\nAre the variables continuous?\nIs the difference between 1 and 2 on the scale equal to the difference between 2 and 3?\n\n\n\nAssumption 2: Pairs of Data\nGreat! So the data looks at least interval and continuous. Next, all correlations must have a data point for each participant in the two variables being correlated. This should make sense as to why - you can’t correlate against an empty cell! So now go check that you have a data point in both columns for each participant.\nNote: You can check for missing data by visual inspection - literally using your eyes. A missing data point will show as a NA, which is short for not applicable, not available, or no answer. An alternative would be to use the is.na() function. This can be really handy when you have lots of data and visual inspection would just take too long. If for example you ran the following code:\n\nis.na(mh)\n\nIf you look at the output from that function, each FALSE tells you that there is a data-point in that cell. That is because is.na() asks is that cell a NA; is it empty. If the cell was empty then it would come back as TRUE. As all cells have data in them, they are all showing as FALSE. If you wanted to ask the opposite question, is their data in this cell, then you would write !is.na() which is read as “is not NA”. Remember, the exclamation mark ! turns the question into the opposite.\nHowever you have looked at the data, it looks like that everyone has data in all the columns but let’s test our skills a little whilst we are here. Answer the following questions:\n\nHow is missing data represented in a tibble? \nan empty cell\nNA\na large number\ndon’t know\n\nWhich code would leave you with just the participants who were missing Reading Ability data in mh: \nfilter(mh, is.na(Ability)\nfilter(mh, is.na(Abil)\nfilter(mh, !is.na(Ability)\nfilter(mh, !is.na(Abil)\n\nWhich code would leave you with just the participants who were not missing Reading Ability data in mh: \nfilter(mh, is.na(Ability)\nfilter(mh, is.na(Abil)\nfilter(mh, !is.na(Ability)\nfilter(mh, !is.na(Abil)\n\n\n\n\nHints on removing missing data points\n\n\n\n\nfilter(dat, is.na(variable)) versus filter(dat, !is.na(variable))\n\n\n\n\nAssumption 3-5: Normality, linearity, homoscedasticity\nBrilliant! We know our data type and we know we have no missing data. The remaining assumptions are all best checked through visualisations. You can use histograms and QQ-plots to check that the data (Abil and IQ) are both normally distributed, and you can use a scatterplot of IQ as a function of Abil to check whether the relationship is linear, with homoscedasticity, and without outliers. An alternative would be to use z-scores to check for outliers with the cut-off usually being set at around \\(\\pm2.5SD\\) or \\(\\pm3SD\\). You could do this using the mutate function (e.g. mutate(z = (X - mean(X))/SD(X))), but today we will just use visual checks.\nWe will now ask you to create a few figures and then we will look at them together, as a whole, to answer some questions about these last assumptions.\nHistograms for Normality\n\nType the below code in a new code chunk and run it to create a histogram for Abil.\n\n\nggplot(data = mh, aes(x = Abil)) +\n  geom_histogram()\n\nThis code should look very similar to the code you used to create a bar plot in Chapter 7. We have specified that we want to display Abil on the x-axis and that the shape we want to produce is a histogram, hence geom_histogram(). Just like geom_bar(), you do not need to specify the y-axis because if it’s a histogram, it’s always a count. The figure should look as shown here.\n\n\n\n\nHistogram of Abil\n\n\n\n\nNow, in a new code chunk, write and run code to produce a histogram for the variable IQ. Remember the solutions are at the end of the chapter.\n\nQ-Q Plots for Normality\nAs we said we will look at the figures in a minute but first we need a few more plots. One being the Q-Q plot which allows us to check normality. The Q-Q plot require us to use the package car rather than ggplot2. You can make Q-Q plots in ggplot2 but they aren’t as useful, however, the code is still very simple.\n\nIn a new code chunk, type and run the below code to create a Q-Q plot for Abil.\n\n\nqqPlot(x = mh$Abil)\n\nThis code looks a little different to code you’ve used up until this point as it comes from Base R. It uses the notation object$variable so our x variable could be read as “use the variable Abil from the object mh. And the figure will look like this:\n\n\n\n\nQ-Q plot for Abil\n\n\n\n[1] 15  4\n\n\nThe Q-Q plot includes a confidence envelope (the blue dotted lines) around the data with the understanding that if your data points fall within these dotted lines then you can assume normality. The ggplot2 version of Q-Q plots make it more difficult to add on this confidence envelope, which is why we’re using a different package. qqPlot() will also print the IDs of the most extreme data points. In this case, the 4th and 15th data point in Abil are flagged, although because they fall within the confidence envelope, they don’t appear problematic. This also explains why you might see a message stating ## [1] 15 4. The 15th and 4th value are worth considering!\n\nNow, in a new code chunk, write and run code to create a Q-Q plot for IQ.\n\nInformation: Normality of the residuals\nOne thing to note before we move on is that, in terms of normality, it is in fact the normality of the residuals that matters, where the residuals are the difference between the individual data points and the line of best fit. However, to fully understand this we need to cover more information first as introducing that concept at this stage would be confusing. One approach the field can use however is that if the data is normally distributed then it is highly likely that the residuals will also be normally distributed. We will look at residuals in the next chapter, but here we will instead use the normality of the raw data as a proxy for the normality of the residuals.\nScatterplots for linearity and homoscedasticity\nFinally, in order to assess linearity and homoscedasticity, we can create a scatterplot using ggplot2.\n\nIn a new code chunk, copy and run the below code to create a scatterplot of the relationship between IQ and Ability.\n\n\nggplot(data = mh, aes(x = Abil, y = IQ)) +\n  geom_point()+\n  geom_smooth(method = lm)\n\nThe ggplot2 code is very similar to what you have already encountered with the bar chart and violin-boxplot.\n\nThe first line of data sets up the base of the plot and we specify that we wish to display Abil on the x-axis, IQ on the y-axis, and use the dataset mh.\nThe first geom, geom_point(), adds in the data points,\nthe second geom, geom_smooth, adds in the line of best fit. The shaded area around the line is a confidence interval around the data. This can be turned off by setting se = FALSE as an additional argument.\n\nThe figure should look as follows:\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\nScatterplot of scores\n\n\n\nNote: Do not worry if you see a message stating ## geom_smooth() using formula 'y ~ x'. This is just letting you know how it is plotting the line of best fit (the blue line)\n\nNow, remembering that ggplot2 works on layers and that you can customise each layer, edit the above code to add in a layer of scale_x_continuous() that changes the label Abil to Reading Ability.\n\nChecking the assumptions\nNow that we have all the figures we need we should be able to check the assumptions. Try to answer the following questions, based on the above visualisations:\n\nIs the assumption of normality met for both variables? \nYes\nNo\n\nIs the assumption of linearity met? \nYes\nNo\n\nIs the assumption of homoscedasticity met? \nYes\nNo\n\nBased on the above, which correlation method would you use? \nPearson\nSpearman\n\n\n\n\nExplain these answers\n\n\nWhen assessing assumptions through the use of visualisations your decision will always be a judgement call. In this dataset, we only have data from 25 participants therefore it is very unlikely we would ever observe perfect normality and linearity in this dataset. It is likely that a researcher would assume that this data is approximately normal, that there is no evidence of a non-linear relationship, and that the spread of data points around the line is relatively even. Many students become fixated with needing a ‘perfect’ dataset that follows an exactly normal distribution. This is unlikely to ever happen with real data - learn to trust your instincts!\nFinally, as the data is interval, continuous, normally distributed, and the relationship is linear and the assumption of homoscedasticity has been met, we would use a Pearson correlation."
  },
  {
    "objectID": "08-lm-continuous.html#descriptives-of-the-correlation",
    "href": "08-lm-continuous.html#descriptives-of-the-correlation",
    "title": "\n8  Regression with one continuous predictor\n",
    "section": "\n8.3 Descriptives of the Correlation",
    "text": "8.3 Descriptives of the Correlation\nNow that we have checked our assumptions and have confirmed we will use the Pearson correlation, the next step is descriptives. A key thing to keep in mind is that the scatterplot is actually the descriptive of the correlation. Meaning that in an article, or in a report, you would not only use the scatterplot to determine which type of correlation to use but also to describe the potential relationship in regards to your hypothesis. So you would always expect to see a scatterplot in the write-up of this type of analysis.\n\n8.3.0.1 Activity 4: Descriptive statistics\n\nLooking at the scatterplot, spend a couple of minutes thinking about and describing the relationship between Ability and IQ in terms of your hypothesis. Remember this is a descriptive analysis at this stage, so nothing is confirmed. Does the relationship appear to be as we predicted in our hypothesis? A discussion is in the solutions at the end of the chapter.\n\n\n\nHints on discussing descriptives\n\n\n\nHint 1: We hypothesised that reading ability and intelligence were positively correlated. Is that what you see in the scatterplot?\nHint 2: Keep in mind it is subjective at this stage.\nHint 3: Remember to only talk about a relationship and not a prediction. This is correlational work, not regression.\nHint 4: Can you say something about both the strength (weak, medium, strong) and the direction (positive, negative)?\n\n\n\nIn addition to the scatterplot, it can sometimes be relevant to include means and standard deviations of scales in a correlation. It is not always relevant but, as an example, if you were measuring something like anxiety, or stress, or IQ, it can be informative to include this information to help demonstrate how your sample compares to population norms. As such we will calculate some descriptives here as it is also good practice of our data-wrangling skills.\n\nIn a new code chunk, write and run code to calculate the mean score and standard deviation for Abil and IQ using summarise() and store the output of this function in an object called descriptives\n\nName the output of the calculations Abil_mean, Abil_SD, IQ_mean, and IQ_SD. Make sure to use these exact spellings otherwise later activities won’t work.\n\nhint: We have already seen how to calculate the mean(), the median(), the number of people (with n()), and the sum() within the summarise() function. Other descriptives such as the sd(), the min() and the max() can also be calculated in a similar way to using mean() and median().\n\n\n\nIf you have performed this correctly, when you view descriptives should look similar to this:\n\n\n\n\nAbil_mean\nAbil_SD\nIQ_mean\nIQ_SD\n\n\n55.12\n6.08\n100.04\n9.04\n\n\n\n\nAnswer the following questions to confirm your understanding of the output:\n\nWhat is the mean of Reading Ability? \n54.12\n56.12\n55.12\n\nWhat is the mean of IQ? \n99.04\n100.04\n101.04\n\nIf the population norm mean of IQ is 100, how comparable is your sample to the population? \nthe same\nvery different"
  },
  {
    "objectID": "08-lm-continuous.html#inferentials-of-the-correlation",
    "href": "08-lm-continuous.html#inferentials-of-the-correlation",
    "title": "\n8  Regression with one continuous predictor\n",
    "section": "\n8.4 Inferentials of the correlation",
    "text": "8.4 Inferentials of the correlation\nExcellent! So we have checked our assumptions and our descriptives. Our data looks consistent with population norms and the scatterplot would suggest a positive relationship between the two variables. Finally we will run the correlation!\nThere are often many different functions that can be used to achieve the same thing and we’re actually going to show you two ways of running a correlation as some people prefer one approach over the other because of the data type the results come in and how easy it is to work with that output.\n\n8.4.0.1 Activity 5: Run the correlation\nFirst, we’ll use the correlation() function from the correlation package. Remember that for help on any function you can type e.g., ?correlation in the console window. The correlation() function requires:\n\nThe name of the data set you are using\nThe name of the first variable you want to select for the correlation\nThe name of the second variable you want to select for the correlation\nThe type of correlation you want to run: e.g. pearson, spearman\n\nThe type of NHST tail you want to run: e.g. \"less\",\"greater\", \"two.sided\"\n\n\nFor example, if your data is stored in dat and you want to do a two-sided pearson correlation of the variables (columns) X and Y, then you would do:\n\ncorrelation(data = dat, \n            select = \"X\", \n            select2 = \"Y\",  \n            method = \"pearson\", \n            alternative = \"two.sided\")\n\nHere we are wanting to run a Pearson correlation with a two-sided alternative.\n\nIn a new code chunk, using the information about correlation() above, type and run a Pearson correlation between IQ and Ability and store the output in an object called results.\nView the output by typing View(results) in the console window\n\nThe second method is to use cor.test() which is a Base R function and uses similar code as correlation() except for how the variables are specified. cor.test() use the same object$variable syntax we saw in qqPlot():\n\nIn a new code chunk, type and run the below code and then view the output by typing results2 in the console.\n\nnot that we have specified x = mh$IQ meaning that the first variable, x, is the column IQ in the object mh.\n\n\n\n\nresults2 &lt;-  cor.test(x = mh$IQ, \n                      y = mh$Abil, \n                      method = \"pearson\", \n                      alternative = \"two.sided\")\n\nLook at how the output differs from results. We’ll come back to why we’ve shown you two ways shortly."
  },
  {
    "objectID": "08-lm-continuous.html#interpreting-output-and-writing-up",
    "href": "08-lm-continuous.html#interpreting-output-and-writing-up",
    "title": "\n8  Regression with one continuous predictor\n",
    "section": "\n8.5 Interpreting output and writing up",
    "text": "8.5 Interpreting output and writing up\nExcellent work. As you can see, running the correlation is actually really quick, and the hard work was checking the assumptions and some data-wrangling. You should now have a tibble called results that gives you the output of the correlation between Reading Ability and IQ for the school children measured in Miller and Haden (2013) Chapter 11. All that is left to do now is interpret the output and write it up.\n\n8.5.0.1 Activity 6: Interpreting the correlation\nLook at results and then answer the following questions:\n\nWhat is the value of Pearson’s r to 2 decimal places? \n\nThe direction of the relationship between Ability and IQ is: \npositive\nnegative\nno relationship\n\nThe strength of the relationship between Ability and IQ is: \nstrong\nmedium\nweak\n\nAssuming \\(\\alpha = .05\\) the relationship between Ability and IQ is: \nsignificant\nnot significant\n\nThe alternative hypothesis was that the reading ability of school children, as measured through a standardized test, and intelligence, again through a standardized test, are positively correlated. Based on the results we can say that the alternative hypothesis: \nis accepted\nis rejected\nis proven\nis not proven\n\n\n\n\nExplain these answers\n\n\n\nThe test statistic, in this case the r value, is usually labelled as the estimate.\nIf Y increases as X increases then the relationship is positive. If Y increases as X decreases then the relationship is negative. If there is no change in Y as X changes then there is no relationship\nDepending on the field most correlation values greater than .5 would be strong; .3 to .5 as medium, and .1 to .3 as small.\nThe field standard says less than .05 is significant and our p-value is less than .05.\nThe alternative hypothesis can only be accepted or rejected, never proven. In this case, our results matched our alternative hypothesis and therefore it is accepted. Remember that the null hypothesis on the other hand can only be rejected or retained.\n\n\n\n\n8.5.0.2 Activity 7: Write-up\nNow we have interpreted the output we would want to write it up. Copy and paste the below exactly into white space in your R Markdown document and then knit the file.\n\nAs shown in Figure 7.5, there appeared to be a positive relationship between Reading Ability (M = `r round(pluck(descriptives$Abil_mean),2)`, SD = `r round(pluck(descriptives$Abil_SD),2)`) and IQ (M = `r round(pluck(descriptives$IQ_mean),2)`, SD = `r round(pluck(descriptives$IQ_SD),2)`), in line with the alternative hypothesis. A Pearson correlation found a significant, medium positive correlation between the two variables (r (`r results$df_error`) = `r round(results$r, 2)`, *p* = `r round(results$p, 3)`) and the alternative hypothesis is therefore accepted. \n\nWhen you knit the code, assuming you have done all of the above tasks correctly, the code you pasted will transform into a readable passage as follows:\nAs shown in Figure 7.5, there appeared to be a positive relationship between Reading Ability (M = 55.12, SD = 6.08) and IQ (M = 100.04, SD = 9.04), in line with the alternative hypothesis. A Pearson correlation found a significant, medium positive correlation between the two variables (r (23) = 0.45, p = 0.024) and the alternative hypothesis is therefore accepted.\nSo you get a fairly ok start of a write-up. It isn’t perfect but it is a good start. For instance, the r-value should not have the first 0 and just be r = .xx. Likewise, the p-value should not have the first 0 either. So you will always have to do a bit of tidying up.\nNote: Remember that a relationship is said to be significant if the p-value of the relationship is lower than the accepted level (normally called alphaThe threshold chosen in Neyman-Pearson hypothesis testing to distinguish test results that lead to the decision to reject the null hypothesis, or not, based on the desired upper bound of the Type 1 error rate. An alpha level of 5% it most commonly used, but other alpha levels can be used as long as they are determined and preregistered by the researcher before the data is analyzed. and set at \\(\\alpha = .05\\)). Alternatively, a relationship that has a p-value higher than the accepted level is said to be non significant\nBut why two approaches\nThe reason that we have shown you two methods of performing correlations is because of the way each outputs the results. correlation() produces a tibble which means it is very easy to work with and pull out values or join to another table as needed because it is already in tidyverse format. cor.test() on the other hand produces a list type object, which is a harder to work with. However, the output of cor.test() also happens to work with functions from the report package, report() and report_table() that give you an automatic report of the analyses. For example, report() presents a fixed write-up of the correlation with all the available information. For correlations, this is perhaps less than useful, however, for more complex statistics this reporting function can really help when learning about data and output, and so we’re introducing it now. report() doesn’t currently work with the output of correlation() which is why we showed you both ways. Run the below in your console window and you will see what we mean - you will probably get an error.\n\nreport(results2)\n\nNote: The write-up that comes out of report should not be considered as something to copy and paste into a report. It is a means of just obtaining an overview quickly to help you confirm your own thinking. There are issues again with the presentation of numbers and writing, and additional info that isn’t needed. Basically, use these functions and approaches to start you off in your writing, but not as your write-up."
  },
  {
    "objectID": "08-lm-continuous.html#multiple-correlations",
    "href": "08-lm-continuous.html#multiple-correlations",
    "title": "\n8  Regression with one continuous predictor\n",
    "section": "\n8.6 Multiple Correlations",
    "text": "8.6 Multiple Correlations\nFinally, to round off this chapter, we want to briefly show you about running multiple correlations at one. Above we ran one correlation. However, when you have lots of variables in a dataset, to get a quick overview of patterns, you might want to run all the correlations at the same time or create a matrix of scatterplots at the one time. You can do this with functions from the psych and correlation packages (cor.test() only works for one correlation at a time). We will use the Miller and Haden data here again which you should still have in a tibble called mh.\n\n8.6.0.1 Activity 8: Scatterplot matrix\n\nIn a new code chunk, type and run the following code. The pairs.panels()) function comes from the psych library and creates a matrix of scatterplots, with the histograms, and correlation coefficients which you can then use to give you an overview of all the relationships at the one time. So it is useful for checking assumptions in one place.\n\n\npairs.panels(mh)\n\n\n\nScatterplot matrix\n\n\n\nNotice something wrong? pairs.panels() will create plots for all variables in your data (as will correlation() below). This means that it has correlated the Participant ID number as well, which is totally meaningless.\nInstead, we can use pipes to help us out here. The code below:\n\nTakes the dataset mh and then;\nUses select() to get rid of the Participant column and then;\nPipes the remaining data into the pairs.panels() function\nThe additional arguments:\n\n\nellipses = FALSE turns off the correlation ellipses,\n\nlm = TRUE use a linear line of best fit,\n`method = “pearson”, specifies a Pearson correlation.\n\n\n\nThere are additional arguments to adjust the plot pairs.panel creates that you can look up in the help documentation if you are interested.\n\nmh %&gt;%\n  select(-Participant) %&gt;%\n  pairs.panels(ellipses = FALSE, \n               lm = TRUE, \n               method = \"pearson\")\n\nWhich produces:\n\n\n\n\nAdjusted scatterplot matrix\n\n\n\n\n8.6.0.2 Activity 9: Running multiple correlations\nTo perform multiple correlations in one go, we will again use the correlation() function. package. Rather than specifying two variables to correlation, you can also provide a data frame that has multiple variables and it will run all possible correlations between the variables. Similar to above, we want to remove the Participant column before we do this.\n\nmethod controls which correlation is computed, the default is pearson but if you needed to run the non-parametric version you could change this to spearman.\n\np_adjust is the reason we are using the correlation package. In the lectures we discussed the problem of multiple comparisons - the idea that if you run lots and lots of tests your false positive rate will increase and the probability of finding a significant result increase.\n\nThis argument applies a correction to the p-value that adjusts for the number of correlations you have performed. There are several different methods which you can look up in the help documentation, but here we are setting bonferroni. The default setting is actually the less conservative analysis Holm-Bonferroni and you can read about why some might chose that instead in the help function by typing ?correlation in the console window.\n\n\nNote: Because you’re running multiple correlations and some may be positive and some may be negative, there is no option to specify a one or two-tailed test.\nRun the below code to calculate then view the correlation results\n\n\ncorr_results &lt;- mh %&gt;%\n  select(-Participant) %&gt;%\n  correlation(method = \"pearson\", \n              p_adjust = \"bonferroni\")\n\ncorr_results\n\nWhich produces the following output:\n\nknitr::kable(corr_results)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\nCI\nCI_low\nCI_high\nt\ndf_error\np\nMethod\nn_Obs\n\n\n\nAbil\nIQ\n0.4511699\n0.95\n0.0681965\n0.7182564\n2.4245212\n23\n0.1415557\nPearson correlation\n25\n\n\nAbil\nHome\n0.7443192\n0.95\n0.4946735\n0.8804938\n5.3451643\n23\n0.0001194\nPearson correlation\n25\n\n\nAbil\nTV\n-0.2881974\n0.95\n-0.6134691\n0.1206755\n-1.4433874\n23\n0.9743671\nPearson correlation\n25\n\n\nIQ\nHome\n0.2016786\n0.95\n-0.2102033\n0.5527604\n0.9875083\n23\n1.0000000\nPearson correlation\n25\n\n\nIQ\nTV\n0.2455425\n0.95\n-0.1656610\n0.5840118\n1.2147699\n23\n1.0000000\nPearson correlation\n25\n\n\nHome\nTV\n-0.6476572\n0.95\n-0.8303052\n-0.3393758\n-4.0765523\n23\n0.0027905\nPearson correlation\n25\n\n\n\n\n\ncorr_results is a tibble that lists the results of each correlation with its corresponding statistics. Look through the table and then answer the following questions:\n\nIs the correlation between Abil and Home positive or negative? \nPositive\nNegative\n\nThis means that as Abil scores increase, Home scores will \nIncrease\nDecrease\n\nWhat is the strongest positive correlation? \nAbil * IQ\nAbil * Home\nAbil * TV\n\nWhat is the strongest negative correlation? \nAbil * TV\nIQ * TV\nHome * TV\n\nIs the correlation between Abil and IQ significant? \nYes\nNo\n\nIs the correlation between Abil and Home significant? \nYes\nNo\n\nHow would you describe the strength of the correlation between Home and TV? \nWeak\nMedium\nStrong\n\nThink back to the lecture. Why are we not calculating an effect size?\n\n\n\nExplain these answers\n\n\n\nNegative correlations are denoted by a negative r value.\n\nPositive correlations mean that as one score goes up so does the other, negative correlations mean that as one score goes up the other goes down.\n3 & 4. Remember that correlations take values from -1 - 1 and that the nearer to one in either direction the stronger the correlation (i.e., an r value of 0 would demonstrate a lack of any relationship.\n5 & 6. The traditional cut-off for significance is .05. Anything below .05 is considered significant. Be careful to pay attention to decimal places.\n\nCohen’s guidelines recommend weak = 1. - .3, medium = .3 - .5, strong &gt; .5.\n\nBecause r is an effect size.\n\n\n\n\n\nNice work! So it can be really easy to run a lot of correlations at once. However, you need to remember about what is appropriate in research. You should not just wildly run every correlation you can and then write up your favourite. PreRegistration of ideas, or Registered Reports, helps reduce Questionable Research Practices, and this is just another example of where setting out in advance, what you plan to do, will prevent bad practice!"
  },
  {
    "objectID": "08-lm-continuous.html#corr-fin",
    "href": "08-lm-continuous.html#corr-fin",
    "title": "\n8  Regression with one continuous predictor\n",
    "section": "\n8.7 Finished!",
    "text": "8.7 Finished!\nExcellent work today! You can now add running, interpreting and writing up correlations to the list of knowledge and skills in your research methods toolbox. Remember that actually a lot of the work is in the preparation of the data and really running the correlation is just one more function. It might be worthwhile repeating the first few activities with two other variables to test your understanding. If you have any questions, please post them on Teams."
  },
  {
    "objectID": "08-lm-continuous.html#test-yourself",
    "href": "08-lm-continuous.html#test-yourself",
    "title": "\n8  Regression with one continuous predictor\n",
    "section": "\n8.6 Test Yourself",
    "text": "8.6 Test Yourself\nTo end the chapter, we have some knowledge check questions to test your understanding of the concepts we covered in the chapter. We then have some error mode tasks to see if you can find the solution to some common errors in the concepts we covered in this chapter.\n\n8.6.1 Knowledge check\nFor this chapter’s knowledge check section, we have something a little different. Instead of purely conceptual questions about functions, we have another example of linear regression from Dawtry et al. (2015). Feel free to create this model yourself, but we will show you some output and ask you questions based on it.\nFor this model, we focus on the two variables estimated population inequality index (Population_Inequality_Gini_Index) and support for wealth redistribution (redistribution). Check back to the code book in Activity 2 if you need a reminder of what the variables mean.\nQuestion 1. In the scatterplot of the relationship below, this shows a negative relationship between the inequality index and support for redistribution: \nTRUE\nFALSE.\n\n\n\n\n\n\n\n\nQuestion 2 For the next few questions, we have the output from a linear regression model and we would like you to interpret it.\n\n\n\nCall:\nlm(formula = redistribution ~ Population_Inequality_Gini_Index, \n    data = dawtry_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9478 -0.6384  0.1389  0.8511  2.3854 \n\nCoefficients:\n                                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                      3.097452   0.316914   9.774  &lt; 2e-16 ***\nPopulation_Inequality_Gini_Index 0.022879   0.008734   2.619  0.00925 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.139 on 303 degrees of freedom\nMultiple R-squared:  0.02214,   Adjusted R-squared:  0.01892 \nF-statistic: 6.861 on 1 and 303 DF,  p-value: 0.009251\n\n\nThe outcome variable in this model is \nAttitudes on Wealth Redistribution\nPopulation Inequality Index and the predictor variable is \nAttitudes on Wealth Redistribution\nPopulation Inequality Index.\nQuestion 3 Rounded to 2 decimals, when the predictor is 0, we predict a value of  for our outcome variable.\nQuestion 4 The predictor is \nsignificant\nnon-significant with a p-value of .\nQuestion 5 The predictor is \npositive\nnegative, where we expect for every 1-unit increase in the predictor a  -unit \nincrease\ndecrease in the outcome.\n\n8.6.2 Error mode\nThe following questions are designed to introduce you to making and fixing errors. For this topic, we focus on simple linear regression between two continuous variables. There are not many outright errors that people make here, more misspecifications that are not doing what you think they are doing.\nCreate and save a new R Markdown file for these activities. Delete the example code, so your file is blank from line 10. Create a new code chunk to load tidyverse and wrangle the data files:\n\n# Load the packages below\nlibrary(tidyverse)\nlibrary(effectsize)\nlibrary(correlation)\nlibrary(performance)\n\n# Load the data file\n# This should be the Dawtry_2015.csv file \ndawtry_data &lt;- read_csv(\"data/Dawtry_2015.csv\")\n\n# Reverse code redist2 and redist4\ndawtry_data &lt;- dawtry_data %&gt;%\n  mutate(redist2_R = 7 - redist2,\n         redist4_R = 7 - redist4)\n\n# calculate mean fairness and satisfaction score  \nfairness_satisfaction &lt;- dawtry_data %&gt;% \n  pivot_longer(cols = fairness:satisfaction, \n               names_to = \"Items\", \n               values_to = \"Response\") %&gt;% \n  group_by(PS) %&gt;% \n  summarise(fairness_satisfaction = mean(Response)) %&gt;% \n  ungroup()\n\n# calculate mean wealth redistribution score  \nredistribution &lt;- dawtry_data %&gt;% \n  pivot_longer(cols = c(redist1, redist2_R, redist3, redist4_R), \n               names_to = \"Items\", \n               values_to = \"Response\") %&gt;% \n  group_by(PS) %&gt;% \n  summarise(redistribution = mean(Response)) %&gt;% \n  ungroup()\n\n# join data and select columns for focus\ndawtry_clean &lt;- dawtry_data %&gt;% \n  inner_join(fairness_satisfaction, by = \"PS\") %&gt;% \n  inner_join(redistribution, by = \"PS\") %&gt;% \n  select(PS, Household_Income:redistribution, -redist2_R, -redist4_R)\n\nBelow, we have several variations of a misspecification. Copy and paste them into your R Markdown file below the code chunk to wrangle the data. Once you have copied the activities, click knit and look at the output you receive. See if you can identify the mistake and fix it before checking the answer.\nQuestion 6. Copy the following code chunk into your R Markdown file and press knit. We want to create a simple linear regression model to specify fairness_satisfaction as our outcome variable and Political_Preference as our predictor. Have we expressed that accurately?\n```{r}\nlm_fairness &lt;- lm(Political_Preference ~ fairness_satisfaction,\n                        data = dawtry_clean)\n\nsummary(lm_fairness)\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nIn this example, we mixed up the variables. The formula in lm() has the form outcome ~ predictor, so we mixed up the order. In simple linear regression, it makes no difference to the slope, but it is important to be able to express your model accurately and it would make a difference once you scale up to multiple linear regression.\n\nlm_fairness &lt;- lm(fairness_satisfaction ~ Political_Preference,\n                        data = dawtry_clean)\n                        \nsummary(lm_fairness)\n\n\n\n\nQuestion 7. Copy the following code chunk into your R Markdown file and press knit. We want to standardise the outcome and predictors, so that we get the intercept and slope estimates in standard deviations. Have we expressed that accurately?\n```{r}\ndawtry_clean &lt;- dawtry_clean %&gt;% \n  mutate(fairness_std = (fairness_satisfaction - mean(fairness_satisfaction)) / sd(fairness_satisfaction))\n\nlm_fairness &lt;- lm(fairness_std ~ Political_Preference,\n                        data = dawtry_clean)\n                        \nsummary(lm_fairness)\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nIn this example, we only standardised the outcome. When we standardise predictors, we must standardise both the outcome and predictor so they are expressed in standard deviations. It is just when we center, we only center the predictor.\n\ndawtry_clean &lt;- dawtry_clean %&gt;% \n  mutate(fairness_std = (fairness_satisfaction - mean(fairness_satisfaction)) / sd(fairness_satisfaction),\n         Political_std = (Political_Preference - mean(Political_Preference, na.rm = TRUE)) / sd(Political_Preference, na.rm = TRUE))\n\nlm_fairness &lt;- lm(fairness_std ~ Political_std,\n                        data = dawtry_clean)\n                        \nsummary(lm_fairness)"
  },
  {
    "objectID": "08-lm-continuous.html#corr-sols",
    "href": "08-lm-continuous.html#corr-sols",
    "title": "\n8  Regression with one continuous predictor\n",
    "section": "\n8.9 Activity solutions",
    "text": "8.9 Activity solutions\nBelow you will find the solutions to the above questions. Only look at them after giving the questions a good try and trying to find help on Google or Teams about any issues.\n\n8.9.0.1 Activity 1\n\nlibrary(car)\nlibrary(correlation)\nlibrary(report)\nlibrary(psych)\nlibrary(tidyverse)\nmh &lt;- read_csv(\"MillerHadenData.csv\")\n\n\n8.9.0.2 Activity 3\nThe histogram of IQ\n\nggplot(data = mh, aes(x = IQ)) +\n  geom_histogram()\n\nThe qqPlot of IQ\n\nqqPlot(x = mh$IQ)\n\n\n\n\n\n\n\n[1]  3 14\n\n\nThe scatterplot\n\nggplot(data = mh, aes(x = Abil, y = IQ)) +\n  geom_point()+\n  geom_smooth(method = lm)+\n  scale_x_continuous(name = \"Reading Ability\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n8.9.0.3 Activity 4\nThe scatterplot\nBased on the scatterplot we might suggest that as reading ability scores increase, IQ scores also increase and as such it would appear that our data is inline with our hypothesis that the two variables are positively correlated. This appears to be a medium strength relationship.\nThe means and standard deviations\n\ndescriptives &lt;- summarise(mh, \n                          Abil_mean = mean(Abil),\n                          Abil_SD = sd(Abil),\n                          IQ_mean = mean(IQ),\n                          IQ_SD = sd(IQ))\n\ndescriptives\n\n\n\n\nAbil_mean\nAbil_SD\nIQ_mean\nIQ_SD\n\n\n55.12\n6.084954\n100.04\n9.043782\n\n\n\n\n\n\n8.9.0.4 Activity 5\nThe correlation using correlation()\n\nresults &lt;- correlation(data = mh, \n                       select = \"IQ\", \n                       select2 = \"Abil\",  \n                       method = \"pearson\", \n                       alternative = \"two.sided\")\n\nresults\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\nCI\nCI_low\nCI_high\nt\ndf_error\np\nMethod\nn_Obs\n\n\nIQ\nAbil\n0.4511699\n0.95\n0.0681965\n0.7182564\n2.424521\n23\n0.0235926\nPearson correlation\n25"
  },
  {
    "objectID": "08-lm-continuous.html#words-from-this-chapter",
    "href": "08-lm-continuous.html#words-from-this-chapter",
    "title": "\n8  Regression with one continuous predictor\n",
    "section": "\n8.7 Words from this Chapter",
    "text": "8.7 Words from this Chapter\nBelow you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the PsyTeachR Glossary. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter.\n\n\n\nterm\ndefinition\n\n\n\ncentered-predictors\nUsually, centering a predictor means subtracting the mean from each value, so the mean is 0. You can then interpret the intercept as the value of your outcome for the mean value of your predictor(s).\n\n\nlist\nA container data type that allows items with different data types to be grouped together.\n\n\noutcome\nThe outcome (also known as the dependent variable) is the variable you are interested in seeing a potential change in.\n\n\npearson\nA standardised measure of the linear relationship between two variables that makes stringent assumptions about the population.\n\n\npredictor\nThe predictor (also known as an independent variable) is the variable you measure or manipulate to see how it is associated with changes in the outcome variable.\n\n\nresiduals\nThe difference between the observed value in the data and the predicted value from the model given its assumptions.\n\n\nspearman\nA standardised measure of the relationship between two variables that assumes a monotonic - but not necessarily a linear - relationship and makes less stringent assumptions about the population.\n\n\nstandardised-predictors\nStandardising involves substracting the variable mean from each value and dividing it by the variable standard deviation. It then has the property of a mean of 0 and standard deviation of 1, so you interpret the units as standard deviations."
  },
  {
    "objectID": "09-lm-categorical.html#between-subjects-t-tests-two-sample",
    "href": "09-lm-categorical.html#between-subjects-t-tests-two-sample",
    "title": "\n9  Regression with one categorical predictor\n",
    "section": "\n9.1 Between-Subjects t-tests (two-sample)",
    "text": "9.1 Between-Subjects t-tests (two-sample)\nWe will begin by looking at the between-subjects t-test which is used for comparing the outcome in two groups of different people. Here we will be using data from ‘The sound of intellect: Speech reveals a thoughtful mind, increasing a job candidate’s appeal’ (Schroeder & Epley, 2015). The abstract explains more about their study but for the purposes of this activity, we focus Experiment 4.\nTo summarise, 39 professional recruiters from Fortune 500 companies evaluated job pitches of M.B.A. candidates from the University of Chicago Booth School of Business. The methods and results appear on pages 887-889 of the article if you want to look at them specifically for more details and the original data, in wide format, can be found at the Open Stats Lab website for later self-directed learning. Today however, we will be working with a modified version in “tidy” format which can be downloaded below and what we plan to do is reproduce the results from the article on Pg 887.\n\n9.1.1 Data and Descriptives\nAs always, the first activity is about getting ourselves ready to analyse the data so try out the steps and if you need help, consult the earlier chapters.\n\n9.1.1.1 Activity 1: Set-up\n\nOpen RStudio and set the working directory to your chapter folder. Ensure the environment is clear.\n\nIf you’re using the Rserver, avoid a number of issues by restarting the session - click Session - Restart R\n\n\n\nOpen a new R Markdown document and save it in your working directory. Call the file “ttests”.\n\nDownload evaluators.csv and ratings.csv and save them in your t-test folder. Make sure that you do not change the file names at all.\n\nIf you prefer you can download the data in a zip folder by clicking here\n\nRemember not to change the file names at all and that data.csv is not the same as data (1).csv.\n\n\nDelete the default R Markdown welcome text and insert a new code chunk that loads the following packages, in this specific order, using the library() function. Remember the solutions if needed.\n\nLoad the packages in this order, Hmisc, broom, car,effectsize, report, and tidyverse\n\nagain we have not used some of these packages so you will likely need to install some of them using install.packages(). Remember though that you should only do this on your own machine and only in the console window. If you are using the RServer you will not need to install them.\n\n\nFinally, load the data held in evaluators.csv as a tibble into an object named evaluators using read_csv().\n\nRemember to have a look at your data to help you understand the structure and the layout of the data. You can do this in whatever way you prefer.\nNow that we have our data, and have explored it, there is a few things we can do to make working with it a bit easier. If you look at the data, and in particular the sex column, you will see it is actually coded as numeric but we will want to treat it as categorical. Secondly, it can be tricky to work with 1s and 2s when you mean people, so we can “recode” the variables into labels that are easier to work with. That is what we will do here using a combination of mutate(), which we already know, and the recode() function from the dplyr package that is loaded in as part of the tidyverse, and the as.factor() function from base. Converting categorical data to factors will make it easier to work with in visualisations and analysis.\n\n9.1.1.2 Activity 2: Explore the dataset\nIn a new code chunk, copy the code below and see if you can follow it.\n\nFirst we use mutate() and recode() to recode sex into a new variable called sex_labels so that 1 = male and 2 = female.\n\nBe careful using recode() as there are multiple functions in different packages called with the same name so it is better to use the package::function() approach and specify dplyr::recode() to get the right one.\n\n\nThen we use mutate() and as.factor() to overwrite sex_labels and condition as factors.\n\n\nevaluators &lt;- evaluators %&gt;%\n  mutate(sex_labels = dplyr::recode(sex, \"1\" = \"male\", \"2\" = \"female\"),\n         sex_labels = as.factor(sex_labels),\n         condition = as.factor(condition))\n\nNow see if you can create a count of the different sex labels to answer the following question. One approach would be group_by() %&gt;% count() but what would you group by? Maybe store this tibble in an object called eval_counts.\n\nHow many participants were noted as being female: \n\nHow many participants were noted as being male: \n\nHow many data points are missing for sex? \n\n\n9.1.1.3 Activity 3: Ratings\nExcellent work. Our evaluator data is ready to work with and we are now going to calculate what is called an “overall intellect rating” given by each evaluator, calculated by averaging the ratings of competent, thoughtful and intelligent from each evaluator; held within ratings.csv. This overall rating will measure how intellectual the evaluators thought candidates were, depending on whether or not the evaluators read or listened to the candidates’ resume pitches. Note, however, we are not looking at ratings to individual candidates; we are looking at overall ratings for each evaluator. This is a bit confusing but makes sense if you stop to think about it a little. What we are interested in is how the medium they received the resume impacted their rating of the candidate. Once we have done that, we will then combine the overall intellect rating with the overall impression ratings and overall hire ratings for each evaluator, with the end goal of having a tibble called ratings2 - which has the following structure:\n\n\n\n\neval_id\nCategory\nRating\ncondition\nsex_labels\n\n\n\n1\nhire\n6.000\nlistened\nfemale\n\n\n1\nimpression\n7.000\nlistened\nfemale\n\n\n1\nintellect\n6.000\nlistened\nfemale\n\n\n2\nhire\n4.000\nlistened\nfemale\n\n\n2\nimpression\n4.667\nlistened\nfemale\n\n\n2\nintellect\n5.667\nlistened\nfemale\n\n\n\n\n\nThe following steps describe how to create the above tibble and it would be good practice to try this out yourself. Look at the table and think what do I need? The trick when doing data analysis and data wrangling is to first think about what you want to achieve - the end goal - and then think about what functions you need to use to get there. The solution is hidden just below the stpes of course if you want to look at it. Let’s look at the steps. Steps 1, 2 and 3 calculate the new overall intellect rating. Steps 4 and 5 combine this rating to all other information.\n\nLoad the data found in ratings.csv as a tibble into an object called ratings. (e.g. read the csv)\nfilter() only the relevant variables (thoughtful, competent, intelligent) into a new tibble stored in an objected called something useful (we will call ours iratings), and then calculate a mean Rating for each evaluator (e.g. group_by & summarise).\nAdd on a new column called Category where every entry is the word intellect. This tells us that every number in this tibble is an intellect rating. (e.g. mutate)\nNow create a new tibble called ratings2 and filter into it just the “impression” and “hire” ratings from the original ratings tibble.\nNext, bind this tibble with the tibble you created in step 3 to bring together the intellect, impression, and hire ratings, in ratings2. (e.g. bind_rows(object1, object2))\nJoin ratings2 with the evaluator tibble that we created in Task 1 (e.g. inner_join()). Keep only the necessary columns as shown above (e.g. select()) and arrange by Evaluator and Category (e.g. arrange()).\n\n\n\nOur approach to this\n\n\n# 1. load in the data\nratings &lt;- read_csv(\"book/ratings.csv\")\n\n# 2. first step: pull out the ratings associated with intellect\niratings &lt;- ratings %&gt;%\n  filter(Category %in% c(\"competent\", \"thoughtful\", \"intelligent\"))\n\n# second step: calculate means for each evaluator\nimeans &lt;- iratings %&gt;%\n  group_by(eval_id) %&gt;%\n  summarise(Rating = mean(Rating))\n\n# 3. add Category variable \n# this way we can combine with 'impression' and 'hire' into a single table, very useful!\nimeans2 &lt;- imeans %&gt;%\n  mutate(Category = \"intellect\")\n\n# 4., 5. & 6. combine into a single table\nratings2 &lt;- ratings %&gt;%\n  filter(Category %in% c(\"impression\", \"hire\")) %&gt;%\n  bind_rows(imeans2) %&gt;%\n  inner_join(evaluators, \"eval_id\") %&gt;%\n  select(-age, -sex) %&gt;%\n  arrange(eval_id, Category)\n\n\n\nFinally, calculate the n, mean and SD for each condition and category to help with reporting the descriptive statistics.\n\n\ngroup_means &lt;- ratings2 %&gt;%\n  group_by(condition, Category) %&gt;%\n  summarise(n = n(), m = mean(Rating), sd = sd(Rating))\n\n`summarise()` has grouped output by 'condition'. You can override using the\n`.groups` argument.\n\n\n\n9.1.2 Visualising two groups\nBrilliant! Now that we have our data in a workable fashion, we are going to start looking at some visualisations and making figures. You should always visualise your data before you run a statistical analysis. Visualisations serve as part of the descriptive measures and they help you interpret the results of the test but they also give you an understanding of the spread of your data as part of the test assumptions. For data with a categorical IV, we are going to look at using the violin-boxplots that we saw in the introduction to visualisation chapter. In the past people would have tended to use barplots but as Newman and Scholl (2012) point out, barplots are misleading to viewers about how the underlying data actually looks. You can read that paper if you like, for more info, but hopefully by the end of this section you will see why violin-boxplots are more informative.\n\n9.1.2.1 Activity 4: Visualisation\nWe will visualise the intellect ratings for the listened and the read conditions. The code we will use to create our figure is as follows with the explanation below. Put this code in a new code chunk and run it.\n\nratings2 %&gt;%\n  filter(Category == \"intellect\") %&gt;%\nggplot(aes(x = condition, y = Rating)) +\n  geom_violin(trim = TRUE) +\n  geom_boxplot(aes(fill = condition), width = .2, show.legend = FALSE) + \n  stat_summary(geom = \"pointrange\", fun.data = \"mean_cl_normal\")  +\n  labs(x = \"Condition\", y = \"Rating Score\") +\n  geom_jitter(height = .1, width = .2)\n\nThe first part of the code uses a pipe to filter the data to just the intellect rating:\n\n\nratings %&gt;% filter(Category == \"intellect) is the same as filter(ratings, Category == \"intellect\")\n\nthis code also reflects nicely the difference between pipes (%&gt;%) used in wrangling and the + used in the visualisations with ggplot. Notice that we switch from pipes to plus when we start adding layers to our visualisation.\n\nThe main parts of the code to create the violin-boxplot above are:\n\nggplot() which creates our base layer and sets our data and our x and y axes.\n\ngeom_violin() which creates the density plot. The reason it is called a violin plot is because if your data are normally distributed it should look something like a violin.\n\n\ngeom_boxplot() which creates the boxplot, showing the median and inter-quartile range (see here if you would like more information). The boxplot can also give you a good idea if the data are skewed - the median line should be in the middle of the box. The more the median is moved towards one of th extremities of the box, the more your data is likely to be skewed.\n\n\ngeom_jitter() can be used to show individual data points in your dataset and you can change the width and height of the jitter. Note that this uses a randomised method to display the points so you will get a different output each time you run it.\nAnd finally, we will use stat_summary() for displaying the mean and confidence intervals. Within this function, fun.data specifies the a summary function that gives us the summary of the data we want to plot, in this case, mean_cl_normal which will calculate the mean plus the upper and lower confidence interval limits. You could also specify mean_se here if you wanted standard error. Finally, geom specifies what shape or plot we want to use to display the summary, in this case we want a pointrange (literally a point (the mean) with a range (the CI)).\n\nThe figure will look like this:\n\n\n\n\nViolin-boxplot of the evaluator data\n\n\n\nAn alternative version would be this shown below. Perhaps compare the two codes and see if you can see what makes the differences:\n\nratings2 %&gt;%\n  filter(Category == \"intellect\") %&gt;%\nggplot(aes(x = condition, y = Rating)) +\n  geom_violin(trim = FALSE) +\n  geom_boxplot(aes(fill = condition), width = .2, show.legend = FALSE) + \n  stat_summary(geom = \"pointrange\", fun.data = \"mean_cl_normal\") +\n  labs(x = \"Condition\", y = \"Rating Score\")\n\n\n\nViolin-boxplot of the evaluator data\n\n\n\nTry to answer the following question:\n\nIn which condition did the evaluators give the higher ratings overall? \nlistened\nread\n\nWould the descriptives (means, sds, figure) be inline with the hypothesis that evaluators favour resumes they have listened to more than resumes they have read? \nyes\nno\n\n\nNice and informative figure huh? It gives a good representation of the data in the two conditions, clearly showing the spread and the centre points. If you compare this to Figure 7 in the original paper you see the difference. We actually get much more information with our approach. We even get a sense that maybe the data is questionable on whether it is skewed or not, but more on that below.\nThe code is really useful as well so you know it is here if you want to use it again. But maybe have a play with the code to try out things to see what happens. For instance:\n\nTry setting trim = TRUE, show.legend = FALSE, and/or altering the value of width to see what these arguments do.\nchange the Category == \"intellect\" to Category == \"hire\" or Category == \"impression\" to create visualisations of the other conditions.\n\n9.1.3 Assumptions\nGreat. We have visualised our data as well and we have been able to make some descriptive analysis about what is going on. Now we want to get ready to run the actual analysis. But one final thing we are going to decide is which t-test? But hang on you say, didn’t we decide that? We are going to run a between-subjects t-test! Right? Yes! But, and you know what we are about to say, there is more than one between-subjects t-test you can run. The two common ones are:\n\nStudent’s between-subjects t-test\nWelch’s between-subjects t-test\n\nWe are going to recommend that, at least when doing the analysis by code, you should use Welch’s between-subjects t-test for the reasons explained in this paper by Delarce et al,m (2017) Now you don’t have to read that paper but effectively, the Welch’s between-subjects t-test is better at maintaining the false positive rate of your test (\\(\\alpha\\), usually set at \\(\\alpha\\) = .05) at the requested level. So we will show you how to run a Welch’s t-test here.\nThe assumptions for a Welch’s between-subjects t-test are:\n\nThe data are continuous, i.e. interval/ratio\nThe data are independent\nThe residuals are normally distributed for each group\n\nWe know that 1 and 2 are true from the design of the experiment, the measures used, and by looking at the data. To test assumption 3, we can create a Q-Q plots of the residuals. For a between-subject t-test the residuals are the difference between the mean of each group and each data point. E.g., if the mean of group A is 10 and a participant in group A scores 12, the residual for that participant is 2.\n\nThinking back to your lectures, if you ran a Student’s t-test instead of a Welch t-test, what would the 4th assumption be? \nHomogeneity of variance\nHomoscedascity\nNominal data\n\n\n\n9.1.3.1 Activity 5: Assumptions\n\nRun the below code to calculate then plot the residuals for the “listened” condition on “intellect” ratings.\n\n\nlistened_intellect_residuals &lt;- ratings2 %&gt;%\n  filter(condition == \"listened\", Category == \"intellect\") %&gt;%\n  mutate(group_resid = Rating - mean(Rating)) %&gt;%\n  select(group_resid)\n\nqqPlot(listened_intellect_residuals$group_resid)\n\n\nRun the below code to calculate then plot the residuals for the “read” condition on “intellect” ratings.\n\n\nread_intellect_residuals &lt;- ratings2 %&gt;%\n  filter(condition == \"read\", Category == \"intellect\") %&gt;%\n  mutate(group_resid = Rating - mean(Rating)) %&gt;%\n  select(group_resid)\n\nqqPlot(read_intellect_residuals$group_resid)\n\nIf we then look at our plots we get something that looks like this for the listened condition:\n\n\n\n\nResidual plots of listened condition. Each circle represents an indivudal rater. If data is normally distributed then it should fall close to or on the diagonal line.\n\n\n\n[1] 6 8\n\n\nAnd something like this for the read condition.\n\n\n\n\nResidual plots of read intellect condition. Each circle represents an indivudal rater. If data is normally distributed then it should fall close to or on the diagonal line.\n\n\n\n[1] 11 18\n\n\nWhat you are looking for is for the data to fall close to the diagonal line. Looking at the plots, maybe we could suggest that the “listened” condition is not so great as there is some data points moving away from the line at the far ends. The “read” condition seems a bit better, at least subjectively! There will always be some deviation from the diagonal line but at perhaps most of the data in both plots is relatively close to their respective diagonal lines.\nBut in addition to the Q-Q plots we can also run a test on the residuals known as the Shapiro-Wilk test. The Shapiro-Wilk’s test has the alternative hypothesis that the data is significantly different from normal. As such, if you find a significant result using the test then the interpretation is that your data is not normal. If you find a non-significant finding then the interpretation is that your data is not significantly different from normal. One technical point is that the test doesn’t actually say your data is normal either but just that it is not significantly different from normal. Again, remember that assumptions have a degree of subjectivity to them. We use the shapiro.wilk() function from the base package to run the Shapiro-Wilk’s test.\n\nIn a new code chunk, run both lines of code below and look at their output.\n\n\nshapiro.test(x = listened_intellect_residuals$group_resid)\nshapiro.test(x = read_intellect_residuals$group_resid)\n\nTry to answer the following questions:\n\nAccording to the Shapiro-Wilk’s test, is the data normally distributed for the listened condition? \nYes\nNo\n\nAccording to the Shapiro-Wilk’s test, is the data normally distributed for the read condition? \nYes\nNo\n\n\nSo as you can see, the p-value for the listened condition is p = .174, and the p-value for the read condition is p = .445. So here we are in an interesting position that often happens. The figures for “listened” is a bit unclear, but the figure for “read” looks ok and both tests show a non-significant difference from normality. What do we do? Well we combine our knowledge of our data to make a reasoned decision. In this situation the majority of our information is pointing to the data being normal. However, there are known issues with the Shapiro-Wilks test when there are small sample sizes so we must always take results like this with some caution. It is never a good idea to run a small sample such as this and so in reality we might want to design a study that has larger sample groups. All that said, here it would not be unreasonable to take the assumption of normality as being held.\n\n\n\nFor info though, here are some options if you are convinced your data is nor normal.\n\n\n\nTransform your data to try and normalise the distribution. We won’t cover this but if you’d like to know more, this page is a good start. Not usually recommended these days but some still use it.\n\n\nUse a non-parametric test. The non-parametric equivalent of the independent t-test is the Mann-Whitney and the equivalent of the paired-samples t-test is the Wilcoxon signed-ranks test. Though more modern permutation tests are better. Again we won’t cover these here but useful to know if you read them in a paper.\n\n\nDo nothing. Delacre, Lakens & Leys, 2017 argue that with a large enough sample (&gt;30), the Welch test is robust to deviations from assumptions. With very large samples normality is even less of an issue, so design studies with large samples.\n\n\n\n\n\n9.1.4 Inferential analysis\nNow that we have checked our assumptions and our data seems to fit our Welch’s t-test we can go ahead and run the test. We are going to conduct t-tests for the Intellect, Hire and Impression ratings separately; each time comparing evaluators’ overall ratings for the listened group versus overall ratings for the read group to see if there was a significant difference between the two conditions: i.e. did the evaluators who listened to pitches give a significant higher or lower rating than evaluators that read pitches.\n\n9.1.4.1 Activity 6: Running the t-test\n\nFirst, create separate objects for the intellect, hire, and impression data using filter(). We have completed intellect object for you so you should replace the NULLs in the below code to create one for hire and impression.\n\n\nintellect &lt;- filter(ratings2, Category == \"intellect\")\nhire &lt;- NULL\nimpression &lt;- NULL \n\nAnd we are finally ready to run the t-test. It is funny right, as you may have realised by now, most of the work in analysis involves the set-up and getting the data ready, running the tests is generally just one more function. To conduct the t-test we will use t.test() function from base which takes the following format called the formula syntax:\n\nt.test(DV_column_name ~ IV_column_name, \n       paired = FALSE,\n       data = my_object)\n\n\n\n~ is called a tilde. It can be read as ‘by’ as in “analyse the DV by the IV”.\n\nThe variable on the left of the tilde is the dependent or outcome variable, DV_column_name.\nThe variable(s) on the right of the tilde is the independent or predictor variable, IV_column_name.\n\nand paired = FALSE indicates that we do not want to run a paired-samples test and that our data is from a between-subjects design.\n\nSo let’s run our first test:\n\nIn a new code chunk, type and run the below code, and thenview the output by typing intellect_t in the console.\n\n\nintellect_t &lt;- t.test(Rating ~ condition, \n                      paired = FALSE, \n                      data = intellect,\n                      alternative = \"two.sided\")\n\nSimilar to when we used cor.test() for correlations, the output of t.test() is a list type object which can make it harder to work with. This time, we are going to show you how to use the function tidy() from the broom package to convert the output to a tidyverse format.\n\nRun the below code. You can read it as “take what is in the object intellect_t and try to tidy it into a tibble”.\n\nView the object by clicking on results_intellect in the environment.\n\n\nresults_intellect &lt;- intellect_t %&gt;%\n  tidy()\n\nAs you will see, results_intellect is now in a nice tibble format that makes it easy to extract individual values. It is worth looking at the values with the below explanations:\n\n\nestimate is the difference between the two means (alphabetically entered as mean 1 minus mean 2)\n\nestimate1 is the mean of group 1\n\nestimate2 is the mean of group 2\n\n\nstatistic is the t-statistic\n\n\np.value is the p-value\n\n\nparameter is the degrees of freedom\n\n\ncon.low and conf.high are the confidence interval of the estimate\n\n\nmethod is the type of test, Welch’s, Student’s, paired, or one-sample\n\nalternative is whether the test was one or two-tailed\n\nAnd now that we know how to run the test and tidy it, try the below:\n\nComplete the code below in a new code chunk by replacing the NULLs to run the t-tests for the hire and impression ratings, don’t tidy them yet.\n\n\nhire_t &lt;- NULL\nimpression_t &lt;- NULL\n\n\nAnd now tidy the data into the respective objects - hire_t into results_hire, etc.\n\n\nresults_hire &lt;- NULL\nresults_impression &lt;- NULL\n\nBe sure to look at each of your tests and see what the outcome of each was. To make that easier, we are going join all the results of the t-tests together using bind_rows() - which we can do because all the tibbles have the same column names after we passed them through tidy().\n\nCopy and run the below code. First, it specifies all of the individual tibbles you want to join and gives them a label (hire, impression, intellect), and then you specify what the ID column should be named (test).\n\n\nresults &lt;- bind_rows(hire = results_hire, \n                     impression = results_impression, \n                     intellect = results_intellect, \n                     .id = \"test\")\n\nWhich produces the below:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntest\nestimate\nestimate1\nestimate2\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n\nhire\n1.825397\n4.714286\n2.888889\n2.639949\n0.0120842\n36.85591\n0.4241979\n3.226596\nWelch Two Sample t-test\ntwo.sided\n\n\nimpression\n1.894333\n5.968333\n4.074000\n2.817175\n0.0080329\n33.80061\n0.5275086\n3.261158\nWelch Two Sample t-test\ntwo.sided\n\n\nintellect\n1.986722\n5.635000\n3.648278\n3.478555\n0.0014210\n33.43481\n0.8253146\n3.148130\nWelch Two Sample t-test\ntwo.sided\n\n\n\n\n\nAnd looking along the line at the p-values we might have some significant differences. However, we have to remember to consider multiple comparisons.\n\n9.1.4.2 Activity 7: Correcting for multiple comparisons\nBecause we have run three t-tests, we are actually increasing our false positive rate due to what is called familywise error - essentially, instead of a false positive rate of .05, we would have a false positive rate of 1-(1-.05)^3 = 0.142625, where the “3” in the formula is the number of tests we ran. To correct for this we can apply the multiple comparison correction just like we did with correlations when we ran a lot of correlations. So, we’re going to add on a column to our results tibble that shows the adjusted p-values using p.adj() and mutate().\n\nType and run the below code in a new code chunk and have a look at the output.\n\ninside the p.adjust(), p.value says what column the p-values are in, and bonferroni says what adjustment to use.\n\n\n\n\nresults_adj &lt;- results %&gt;%\n  mutate(p.adjusted = p.adjust(p = p.value, \n                               method = \"bonferroni\"))\n\nLooking at the adjusted p-values, try to answer the following questions:\n\nListened is significantly more preferred in the hire condition after adjusting for multiple comparisons? \nTRUE\nFALSE\n\nListened is significantly more preferred in the impression condition after adjusting for multiple comparisons? \nTRUE\nFALSE\n\nListened is significantly more preferred in the intellect condition after adjusting for multiple comparisons? \nTRUE\nFALSE\n\n\n9.1.5 Effect Size\nAs you can see, even after correcting for multiple comparisons, our effects are still significant and we have maintained our false positive rate. But one more thing we can add is the effect size. Remember that some effects are significant and large, some are significant and medium, and some are significant and small. The effect size tells us the magnitude of the effect size in a way we can compare across studies - it is said to be a standardised - and the common effect size for a t-test is called Cohen’s D.\n\n9.1.5.1 Activity 8: Effect size\nWhilst Cohen’s D is relatively straightforward by hand, here we will use the function cohens_d() from the effectsize package. The code is similar to the syntax for t.test().\n\nThe code to run the Cohen’s D for intellect has been completed below.\n\nThe first argument should specify the formula, using the same syntax as t.test(), that is dv ~ iv.\n\npooled_sd should be FALSE if you ran a Welch test where the variances are not assumed to be equal and TRUE if you ran a regular Student’s t-test.\n\n\nRun and complete the code below by replacing the NULLs to calculate the effect sizes for hire and impression\n\n\nintellect_d &lt;- cohens_d(Rating ~ condition, \n                      pooled_sd = FALSE, \n                      data = intellect)\nhire_d &lt;- NULL\nimpression_d &lt;- NULL\n\n\n9.1.6 Interpretation\nGreat Work! But let’s take a second to recap on our understanding of the data.\n\n9.1.6.1 Activity 9: Interpreting the results\n\n\nWere your results for hire significant? Enter the mean estimates and t-test results (means and t-value to 2 decimal places, p-value to 3 decimal places). Use the adjusted p-values:\n\nMean estimate1 (listened condition) = \nMean estimate2 (read condition) = \nt() = , p = \n\n\n\nWere your results for impression significant? Enter the mean estimates and t-test results (means and t-value to 2 decimal places, p-value to 3 decimal places):\n\nMeanestimate1 (listened condition) = \nMean estimate2 (read condition) = \nt() = , p = \n\n\nAccording to Cohen’s (1988) guidelines, the effect sizes for all three tests are \nSmall\nMedium\nLarge\n\n9.1.7 Write-Up\nAnd then finally on the between-subjects t-test, we should look at the write up.\n\n9.1.7.1 Activity 10: Write-up\nIf you refer back to the original paper on pg 887, you can see, for example, that the authors wrote:\nIn particular, the recruiters believed that the job candidates had greater intellect—were more competent, thoughtful, and intelligent—when they listened to pitches (M = 5.63, SD = 1.61) than when they read pitches (M = 3.65, SD = 1.91), t(37) = 3.53, p &lt; .01, 95% CI of the difference = [0.85, 3.13], d = 1.16.\nIf we were to compare our findings, we would have something like the below:\nA bonferroni-corrected Welch t-test found that recruiters rated job candidates as more intellectual when they listened to resumes (M = 5.64, SD = 1.61) than when they read resumes (M = 3.65, SD = 1.91), t(33.43) = 3.48, p = 0.004, 95% CI of the difference = [0.83, 3.15], d = 1.12.\nYou can create this same paragraph, using code, by copying and pasting the below exactly into white space in your R Markdown document and then knitting the file.\n\nA bonferroni-corrected Welch t-test found that recruiters rated job candidates as more intellectual when they listened to resumes (M = `r results_intellect$estimate1%&gt;% round(2)`, SD = `r round(group_means$sd[3], 2)`) than when they read resumes (M = `r results_intellect$estimate2%&gt;% round(2)`, SD = `r round(group_means$sd[6], 2)`), t(`r round(results_intellect$parameter, 2)`) = `r round(results_adj$statistic[3],2)`, p = `r results_adj$p.adjusted[3] %&gt;% round(3)`, 95% CI of the difference = [`r round(results_intellect$conf.low, 2)`, `r round(results_intellect$conf.high, 2)`], d = `r round(intellect_d$Cohens_d,2)`. \n\nNote that we haven’t replicated the analysis exactly - the authors of this paper conducted Student’s t-test whilst we have conducted Welch tests and we’ve also applied a multiple comparison correction. But you can look at the two examples and see the difference. It would also be worthwhile trying your own write-up of the two remaining conditions before moving on to within-subjects t-tests."
  },
  {
    "objectID": "09-lm-categorical.html#within-subjects-paired-samples",
    "href": "09-lm-categorical.html#within-subjects-paired-samples",
    "title": "\n9  Regression with one categorical predictor\n",
    "section": "\n9.2 Within-subjects (paired-samples)",
    "text": "9.2 Within-subjects (paired-samples)\nFor the final activity we will run a paired-samples t-test for a within-subject design but we will go through this one more quickly and just point out the differences to the above. For this example we will again draw from the Open Stats Lab and look at data from the data in Mehr, S. A., Song. L. A., & Spelke, E. S. (2016). For 5-month-old infants, melodies are social. Psychological Science, 27, 486-501.{target = “_blank”}.\nThe premis of the paper is that parents often sing to their children and, even as infants, children listen to and look at their parents while they are sung to. The authors sought to explore the psychological function that music has for parents and infants, by examining the research question that particular melodies may convey important social information to infants. More specifically, that common knowledge of songs and melodies convey information about social affiliation. The authors argue that melodies are shared within social groups. Whereas children growing up in one culture may be exposed to certain songs as infants (e.g., “Rock-a-bye Baby”), children growing up in other cultures (or even other groups within a culture) may be exposed to different songs. Thus, when a novel person (someone who the infant has never seen before) sings a familiar song, it may signal to the infant that this new person is a member of their social group.\nTo test this the researchers recruited 32 infants and their parents to take part in the following experiment. During their first visit to the lab, the parents were taught a new lullaby (one that neither they nor their infants had heard before). The experimenters asked the parents to sing the new lullaby to their child every day for the next 1-2 weeks. Following this 1-2 week exposure period, the parents and their infant returned to the lab to complete the experimental portion of the study. Infants were first shown a screen with side-by-side videos of two unfamiliar people, each of whom were silently smiling and looking at the infant. The researchers recorded the looking behaviour (or gaze) of the infants during this ‘baseline’ phase. Next, one by one, the two unfamiliar people on the screen sang either the lullaby that the parents learned or a different lullaby (that had the same lyrics and rhythm, but a different melody). Finally, the infants saw the same silent video used at baseline, and the researchers again recorded the looking behaviour of the infants during this ‘test’ phase. For more details on the experiment’s methods, please refer to Mehr et al. (2016) Experiment 1.\n\n9.2.1 The Data\n\n9.2.1.1 Activity 11: Getting the data ready\n\nFirst, download Mehr Song and Spelke 2016 Experiment 1.csv by clicking on the link and putting it into your working directory.\n\nagain if easier you can download the data as a zip file by clicking this link.\n\n\nNext, type and run the below code in a new code chunk. The code loads in the data and then does some wrangling to get the data into a working format:\n\nit filters so we just have the first experiment from the paper\nselects the id and the preferential looking time of babies at the baseline stage and at the test stage.\nfinally it renames the two preferential looking time columns to have names that are easier to work with using the rename() function.\n\n\n\n\ngaze &lt;- read_csv(\"Mehr Song and Spelke 2016 Experiment 1.csv\") %&gt;%\n  filter(exp1 == 1) %&gt;%\n  select(id,\n         Baseline_Proportion_Gaze_to_Singer,\n         Test_Proportion_Gaze_to_Singer) %&gt;%\n  rename(baseline = Baseline_Proportion_Gaze_to_Singer,\n         test = Test_Proportion_Gaze_to_Singer)\n\n\n9.2.2 Assumptions\nSo now that we have our data ready to work with, and be sure to look at it to get an understanding of the data, we want to consider the assumptions of the within-subjects t-test.\nThe assumptions for this t-test are a little different (although very similar) to the between-subjects t-tests above. They are\n\nThe data is continuous, i.e. interval/ratio\nAll participants should appear in both conditions/groups.\nThe residuals are normally distributed.\n\nAside from the data being paired rather than independent, i.e. it is the same participants in two conditions, rather than two groups of people in different conditions, the key difference is that for the within-subjects test, the data is actually determined as the difference between the scores in the two conditions for each participant. So for example, say participant one scores 10 in condition 1 and 7 in condition 2, then there data is actually 3, and you do that for all participants. So it isn’t looking at what they scored in either condition by itself, but what was the difference between conditions. And it is that data that must be continuous and that the residuals must be normally distributed for.\n\n9.2.2.1 Activity 12: Assumptions\n\nType and run the below code to first calculate the difference scores (diff) and then the residuals (group_resid).\nnext it plots the Q-Q plot of the residuals before carrying out a Shapiro-Wilk’s test on the residuals\n\n\ngaze_residual &lt;- gaze %&gt;%\n  mutate(diff = baseline - test) %&gt;%\n  mutate(group_resid = diff - mean(diff))\n\nqqPlot(gaze_residual$group_resid)\n\nshapiro.test(gaze_residual$group_resid)\n\nAnd if we look at the plot we see:\n\n\n\n\n\n\n\n\n[1] 22 29\n\n\nand the Shapiro-Wilk’s suggests:\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  gaze_residual$group_resid\nW = 0.97818, p-value = 0.7451\n\n\nNow as we saw above, with the Q-Q plot we want the data to fall approximately on the diagonal line, and with the Shapiro-Wilks test we are looking for a non-significant finding. Based on those two tests, we can therefor say that our data meets the assumption of normality and so we can proceed.\n\n9.2.3 Descriptives\nNow we are going to look at some descriptives. It made sense to keep the data in wide-form until this point to make it easy to calculate a column for the difference score, but now we will transform it to tidy data so that we can easily create descriptives and plot the data using tidyverse tools.\n\n9.2.3.1 Activity 13: Descriptives and visualisations\n\nType and run the below code to gather the data using pivot_longer().\nNext create a violin-boxplot of the data using your knowledge (and code) from Activity 4 above.\nFinally, create a descriptives table that contains the n, the mean, and the standard deviation of each condition.\n\nIf you prefer, you could actually work on the difference scores instead of the two different conditions. Whilst we analyse the difference, people plot either the difference or the two conditions as descriptives.\n\n\n\n\ngaze_tidy &lt;- gaze %&gt;%\n  pivot_longer(names_to = \"time\", \n               values_to = \"looking\", \n               cols = c(baseline, test))\n\nIf you have done this step correctly, you should see a plot that looks like this:\n\n\n\n\nPreferential Looking time for infants at baseline stage (left) and test stage (right).\n\n\n\nAnd the descriptives:\n\n\n\n\ntime\nn\nmean_looking\nsd_looking\n\n\n\nbaseline\n32\n0.5210967\n0.1769651\n\n\ntest\n32\n0.5934912\n0.1786884\n\n\n\n\n\nAgain you could look at the differences and if you know how you could plot the confidence interval of the difference, but it is not essential here. But looking at what you have done it would be worth spending a few minutes to try and predict the outcome of the t-test if the null hypothesis is that there is no difference in preferential looking time in babies between the baseline and test conditions.\n\n9.2.4 Inferential Analysis\nWhich brings us on to running the t-test and the effect size. The code is almost identical to the independent code with two differences:\n\nIn t.test() you should specify paired = TRUE rather than FALSE\n\nIn cohens_d() you should specify method = paired rather than pooled_sd\n\n\n\n9.2.4.1 Activity 14: Paired-samples t-test\n\nNow have a go at running the within-subjects t-test based on your knowledge. The data you need is in gaze_tidy(). Store the output of the t-test as a tibble in the object gaze_test\n\ni.e. pipe the output of the t-test into `tidy() in the one line of code.\n\n\ncalculate the Cohen’s D for the t-test and store it in gaze_d\n\n\n\ngaze_test &lt;- NULL\ngaze_d &lt;- NULL\n\nAnd if you have done that correctly, you should see in gaze_test something like this:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nestimate\nstatistic\np.value\nparameter\nconf.low\nconf.high\nmethod\nalternative\n\n\n-0.0723946\n-2.41643\n0.0217529\n31\n-0.133497\n-0.0112922\nPaired t-test\ntwo.sided\n\n\n\n\n\n9.2.5 Write-Up and Interpretation\nLooking at the output of the test, it is actually very similar to the between-subjects t-test, with one exception. Rather than providing the means of both conditions, there is a single estimate. This is the mean difference score between the two conditions and if you had calculated the descriptives on the diff we created above you would get the same answer.\n\n\nEnter the mean estimates and t-test results (means and t-value to 2 decimal places, p-value to 3 decimal places):\n\nMean estimate = \nt() = , p = \n\n\n\n\n9.2.5.1 Activity 15: Write-up\nNow have a go at summarising this finding in a sentence using the standard APA formatting. We have hidden our version just below for you to look at when you have had a go.\n\n\nShow our write-up\n\n\nAt test stage (M = .59, SD = .18), infants showed a significantly longer preferential looking time to the singer of the familiar melody than they had shown the same singer at baseline (M = .52, SD = .18), t(31) = 2.42, p = .022, d = .41.\nAlternatively:\nAt test stage, infants showed a significantly longer preferential looking time to the singer of the familiar melody than they had shown the same singer at baseline (Mean Difference = 0.07, SD = 0.17), t(31) = 2.42, p = .022, d = .41."
  },
  {
    "objectID": "09-lm-categorical.html#ttest-fin",
    "href": "09-lm-categorical.html#ttest-fin",
    "title": "\n9  Regression with one categorical predictor\n",
    "section": "\n9.3 Finished!",
    "text": "9.3 Finished!\nThat was a long chapter but hopefully you will see that it really is true that the hardest part is the set-up and the data wrangling. As we’ve said before, you don’t need to memorise lines of code - you just need to remember where to find examples and to understand which bits of them you need to change. Play around with the examples we have given you and see what changing the values does. There is no specific Test Yourself section for this chapter but make sure you check your understanding of the different sections before moving on."
  },
  {
    "objectID": "09-lm-categorical.html#ttest-sols",
    "href": "09-lm-categorical.html#ttest-sols",
    "title": "\n9  Regression with one categorical predictor\n",
    "section": "\n9.4 Activity solutions",
    "text": "9.4 Activity solutions\nBelow you will find the solutions to the above questions. Only look at them after giving the questions a good try and trying to find help on Google or Teams about any issues.\n\n9.4.0.1 Activity 1\n\nlibrary(broom)\nlibrary(car)\nlibrary(effectsize)\nlibrary(report)\nlibrary(tidyverse)\nevaluators &lt;- read_csv(\"evaluators.csv\")\n\n\n9.4.0.2 Activity 2\nThis was our code:\n\nevaluators &lt;- evaluators %&gt;%\n  mutate(sex_labels = dplyr::recode(sex, \"1\" = \"male\", \"2\" = \"female\"),\n         sex_labels = as.factor(sex_labels),\n         condition = as.factor(condition))\n\nand you could summarise as below to give an output:\n\neval_counts &lt;- group_by(evaluators, sex_labels) %&gt;% count()\n\n\n9.4.0.3 Activity 6\n\nintellect &lt;- filter(ratings2, Category == \"intellect\")\nhire &lt;- filter(ratings2, Category == \"hire\")\nimpression &lt;- filter(ratings2, Category == \"impression\")\n\n\n9.4.0.4 Activity 8\n\nintellect_d &lt;- cohens_d(Rating ~ condition, \n                      pooled_sd = FALSE, \n                      data = intellect)\nhire_d &lt;- cohens_d(Rating ~ condition, \n                      pooled_sd = FALSE, \n                      data = hire)\nimpression_d &lt;- cohens_d(Rating ~ condition, \n                      pooled_sd = FALSE, \n                      data = impression)\n\n\n9.4.0.5 Activity 13\nFor the plot:\n\nggplot(gaze_tidy, aes(x = time, y = looking)) +\n  geom_violin(trim = FALSE) +\n  geom_boxplot(aes(fill = time), width = .2, show.legend = FALSE) + \n  stat_summary(geom = \"pointrange\", fun.data = \"mean_cl_normal\") +\n  labs(x = \"Experimental Stage\", \n       y = \"Preferential Looking Time (Proportion)\")\n\nFor the descriptives:\n\ndesc &lt;- gaze_tidy %&gt;% \n  group_by(time) %&gt;% \n  summarise(n = n(), \n            mean_looking = mean(looking), \n            sd_looking = sd(looking))\n\n\n9.4.0.6 Activity 14\nFor the t-test:\n\ngaze_test &lt;- t.test(looking ~ time, \n                    paired = TRUE, \n                    data = gaze_tidy) %&gt;% \n  tidy()\n\nFor the Cohen’s D:\n\ngaze_d &lt;- cohens_d(looking ~ time, \n                   method = \"paired\", \n                   data = gaze_tidy)"
  },
  {
    "objectID": "09-lm-categorical.html#words-from-this-chapter",
    "href": "09-lm-categorical.html#words-from-this-chapter",
    "title": "\n9  Regression with one categorical predictor\n",
    "section": "\n9.8 Words from this Chapter",
    "text": "9.8 Words from this Chapter\nBelow you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the PsyTeachR Glossary. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter.\n\n\n\n\nterm\ndefinition\n\n\n\ndummy-coding\nEntering a categorical predictor using two values such as 0 and 1.\n\n\nreference-group\nIn a dummy-coded variable, the first level of your variable, typically 0.\n\n\nstudent-t-test\nCalculating a t-value based on the mean difference divided by the pooled standard deviation. In the Student t-test, we times the pooled standard deviation by a term containing the sample sizes of each group.\n\n\ntarget-group\nIn a dummy-coded variable, the second level of your variable, typically 1.\n\n\nwelch-t-test\nCalculating a t-value based on the mean difference divided by a term containing the variance of each group. We also correct the degrees of freedom for the difference in variances."
  },
  {
    "objectID": "10-power.html#designing-studies",
    "href": "10-power.html#designing-studies",
    "title": "\n10  Statistical Power\n",
    "section": "\n10.1 Designing Studies",
    "text": "10.1 Designing Studies\nTo reiterate, power is defined as the probability of correctly rejecting the null hypothesis for a fixed effect size and fixed sample size. As such, power is a key decision when you design your study, under the premis that the higher the power of your planned study, the better.\nTwo relationships you will learn in this chapter are that:\n\nfor a given sample size and \\(\\alpha\\), the power of your study is higher if the effect you are looking for is assumed to be a large effect as opposed to a small effect; large effects are easier to detect.\nand, for a given effect size and \\(\\alpha\\), the power of your study is higher when you increase your sample size.\n\nFrom these relationships we see that, because you have little control over the size of the effect you are trying to detect (it lives in the real world which you don’t control), you can instead increase the power of your study by increasing the size of your sample (and also reducing sources of noise and measurement error in your study). As such, when planning a study, any good researcher will consider the following four key elements - and we thank Dr Ian Walker (University of Bath) for the excellent acronym - the APES:\n\n\nalpha - most commonly thought of as the significance level (i.e., your p-value); usually set at \\(\\alpha = .05\\)\n\n\npower - the probability of correctly rejecting the null hypothesis for a given effect size and sample size, typically set at \\(power = .8\\).\n\neffect size - size of the relationship/difference between two variables\n\nsample size - the number of observations (usually, participants, but sometimes also stimuli) in your study.\n\nAnd the beautiful thing is that if you know three of these elements then you can calculate the fourth. The two most common calculations prior to a study would be:\n\nto determine the appropriate sample size required to obtain the effect size that you are interested in. That is, prior to the experiment you decide you would be interested in testing for a small, medium, or large effect sizes, so you know everything except the sample size - how many people you need to run in your study. Generally, the smaller the effect size, the more participants you will need, assuming power and alpha are held constant at .8 and .05 respectively.\n\n\nHere you know alpha, the power, and the effect size and you want to know the sample size.\n\n\nto determine the smallest effect size you can reliably detect given your sample size. For example, you know everything except the effect size. For example, say you are taking a secondary datadata that has been collected already and made available to you to ask research questions of. approach and using an open dataset, and you know they have run 100 participants, you can’t add any more participants, but you want to know what is the minimum effect size you could reliably detect in this dataset.\n\n\nHere you know alpha, the power, and the sample size and you want to know the smallest effect size you can determine.\n\nHopefully that gives you an idea of how we use power to determine sample sizes for studies - and that the sample size should not just be pulled out of thin air. Both of these approaches described above a priori power analyses as you are stating the power level you want before (a priori means before) the study - though the second approach of determining the smallest effect size you can determine based on a known sample size is also referred to as a sensitivity power analysis. However, you may now be thinking though, if everything is connected, then can we use the effect size from our study and the sample size to determine the power of the study after we have run it? No! Well, you can but it would be wrong to do so. This is actually called Observed or Post-Hoc power and most papers would discourage you from calculating it on the grounds that the effect size you are using is not the true effect size of the population you are interested in; it is just the effect size of your sample. As such any indication of power from this analysis is misleading. Avoid doing this. You can read more about why, here, in your own time if you like: Lakens (2014) Observed Power, and what to do if your editor asks for post-hoc power analyses. In brief, Observed Power conflates the effect size of the sample with the effect size within the population and those two are not the same. Stick to using only a priori power analyses approaches and use them to determine your required sample size or achievable reliable effect size.\nSo let’s jump into this a bit now and start running some analyses to help further our understanding of alpha, power, effect sizes and sample size! We will start by looking at effect sizes, before moving on to calculating power."
  },
  {
    "objectID": "10-power.html#effect-size-by-hand",
    "href": "10-power.html#effect-size-by-hand",
    "title": "\n10  Statistical Power\n",
    "section": "\n10.2 Effect Size By Hand",
    "text": "10.2 Effect Size By Hand\nThere are a number of different “effect sizes” that you can choose to calculate but a common one for t-tests, as we have seen previously, is Cohen’s d: the standardised difference between two means (in units of SD) and is written as d = effect-size-value. The key point is that Cohen’s d is a standardised difference, meaning that it can be used to compare against other studies regardless of how the measurement was made. Take for example height differences in men and women which is estimated at about 5 inches (12.7 cm). That in itself is an effect size, but it is an unstandardised effect size in that for every sample that you test, that difference is dependent on the measurement tools, the measurement scale, and the errors contained within them (Note: ask Helena about the time she photocopied some rulers). As such using a standardised effect size allows you to make comparisons across studies regardless of measurement error. In standardised terms, the height difference above is considered a medium effect size (d = 0.5) which Cohen (1988, as cited by Schafer and Schwarz (2019)) defined as representing “an effect likely to be visible to the naked eye of a careful observer”. Cohen (1988) in fact stated three sizes of Cohen’s d that people could use as a guide:\n\n\n\nEffect size\nCohen’s d value\n\n\n\nsmall to medium\n.2 to .5\n\n\nmedium to large\n.5 to .8\n\n\nlarge\n&gt; .8\n\n\n\n\nYou may wish to read this paper later about different effect sizes in psychology - Schafer and Schwarz (2019) The Meaningfulness of Effect Sizes in Psychological Research: Differences Between Sub-Disciplines and the Impact of Potential Biases.\nThe thing to note is that the formula is slightly different depending on the type of t-test used and it can sometimes change depending on who you read. For this worksheet, let’s go with the following formulas:\n\nOne-sample t-test & paired-sample t-test:\n\n\\[d = \\frac{t}{\\sqrt{N}}\\]\n\nIndependent t-test:\n\n\\[d = \\frac{2 \\times t}{\\sqrt{df}}\\]\nLet’s now try out some calculations. We will start with just looking at effect sizes from t-tests before calculating power in later tasks.\n\n10.2.0.1 Activity 1: Set-up\n\nOpen RStudio and set the working directory to your chapter folder. Ensure the environment is clear.\n\nIf you’re using the Rserver, avoid a number of issues by restarting the session - click Session - Restart R\n\n\n\nOpen a new R Markdown document and save it in your working directory. Call the file “APES”.\nDelete the default R Markdown welcome text and insert a new code chunk that loads the following packages, in this specific order, using the library() function. Remember the solutions if needed.\n\nLoad the packages in this order, pwr, and tidyverse\n\nwe have not used the pwr package before so you will likely need to install them using install.packages(). Remember though that you should only do this on your own machine and only in the console window. If you are using the RServer you will not need to install them.\n\n\n\n10.2.0.2 Activity 2: Effect size from a one-sample t-test\n\nYou run a one-sample t-test and discover a significant effect, t(25) = 3.24, p &lt; .05. Using the above formulas, calculate d and determine whether the effect size is small, medium or large.\n\n\n\nHelpful hint\n\n\n\nUse the appropriate formula from above for the one-sample t-tests.\nYou have been given a t-value and df (degrees of freedom), you still need to determine n before you calculate d.\nAccording to Cohen (1988), the effect size is small (.2 to .5), medium (.5 to .8) or large (&gt; .8).\n\n\n\nAnswering the following questions to check your answers. The solutions are at the bottom if you need them:\n\nEnter, in digits, how many people were run in this study: \n\nWhich of these codes is the appropriate calculation of d in this instance:\nd = t/sqrt(N)\nd = 2t/sqrt(df)\n\nEnter the correct value of d for this analysis rounded to 2 decimal places: \n\nAccording to Cohen (1988), the effect size for this t-test would probably be considered: \nsmall to medium\nmedium to large\nlarge\n\n\n10.2.0.3 Activity 3: Effect size from between-subjects t-test\n\nYou run a between-subjects t-test and discover a significant effect, t(30) = 2.9, p &lt; .05. Calculate d and determine whether the effect size is small, medium or large.\n\n\n\nHelpful hint\n\n\n\nUse the appropriate formula above for between-subjects t-tests.\nAccording to Cohen (1988), the effect size is small (.2 to .5), medium (.5 to .8) or large (&gt; .8).\n\n\n\nAnswer the following questions to check your answers. The solutions are at the bottom if you need them:\n\nEnter, in digits, how many people were run in this study: \n\nWhich of these codes is the appropriate calculation of d in this instance:\nd = t/sqrt(N)\nd = 2t/sqrt(df)\n\nEnter the correct value of d for this analysis rounded to 2 decimal places: \n\nAccording to Cohen (1988), the effect size for this t-test would probably be considered: \nsmall to medium\nmedium to large\nlarge\n\n\n10.2.0.4 Activity 4: t-value and effect size for a between-subjects Experiment\n\nYou run a between-subjects design study and the descriptives tell you: Group 1, M = 10, SD = 1.3, n = 30; Group 2, M = 11, SD = 1.7, n = 30. Calculate t and d for this between-subjects experiment.\nNote: the hint contains the appropriate t-test formula if you are unsure.\n\n\n\nHelpful hint\n\n\n\nBefore you can calculate d (using the appropriate formula for a between-subjects experiment), you need to first calculate t using the formula:\n\nt = (Mean1 - Mean2)/sqrt((var1/n1) + (var2/n2))\n\n\nvar stands for variance in the above formula. Variance is not the same as the standard deviation, right? Variance is measured in squared units. So for this equation, if you require variance to calculate t and you have the standard deviation, then you need to remember that var = SD^2.\nNow you have your t-value, but for calculating d you also need degrees of freedom. Think about how you would calculate df for a between-subjects experiment, taking n for both Group 1 and Group 2 into account.\nRemember that convention is that people report the t and d values as positive.\n\n\n\nAnswer the following questions to check your answers. The solutions are at the bottom if you need them:\n\nEnter the correct t-value for this test, rounded to two decimal places: \nWhich of these codes is the appropriate calculation of d in this instance:\nd = t/sqrt(N)\nd = 2t/sqrt(df)\nBased on the above t-value above, enter the correct value of d for this analysis rounded to 2 decimal places: \nAccording to Cohen (1988), the effect size for this t-test would probably be described as: \nsmall to medium\nmedium to large\nlarge\n\nExcellent! Now that you are comfortable with calculating effect sizes, we will look at using them to establish the sample size for a required power. One thing you will realise as we progress is that the true effect size in a population is something we do not know, but we need to justify one for our design. A clever approach is laid out by Daniel Lakens in the blog on the Smallest Effect Size of Interest (SESOI) - you set the smallest effect that you as a researcher would be interested in! This can be determined through theoretical analysis, through previous studies, through pilot studies, or through rules of thumb like Cohen (1988). However, also keep in mind that the lower the effect size, the larger the sample size you will need. Everything is a trade-off."
  },
  {
    "objectID": "10-power.html#power-calculations",
    "href": "10-power.html#power-calculations",
    "title": "\n10  Statistical Power\n",
    "section": "\n10.3 Power Calculations",
    "text": "10.3 Power Calculations\nToday we will use the functions pwr.t.test(), pwr.r.test() and pwr.chisq.test from the package pwr to run power calculations for t-tests, correlations and chi-square.\n\n10.3.1 t-tests\nRemember that for more information on a function, for example pwr.t.test(), simply do ?pwr.t.test in the console. Or you can have a look at these webpages later to get an idea (or bad ideas if you spot where they erroneously calculate post-hoc power!):\n\nA quick-R summary of the pwr package - https://www.statmethods.net/stats/power.html\n\nthe pwr package vignette -  https://cran.r-project.org/web/packages/pwr/vignettes/pwr-vignette.html\n\n\nFrom these you will see that pwr.t.test() takes a series of inputs:\n\n\nn - Number of observations/participants, per group for the independent samples version, or the number of subjects or matched pairs for the paired and one-sample designs.\n\nd - the effect size of interest (Cohen’s d) - difference between the means divided by the pooled standard deviation\n\nsig.level - the significance level (False Positive Rate) or \\(\\alpha\\)\n\n\npower - the power of test (1 minus False Negative Rate) or \\(1-\\beta\\)\n\n\ntype - the type of t test : one.sample, two.sample, or paired\n\n\nalternative - the type of hypothesis; \"two.sided\", \"greater\", \"less\"\n\n\nAnd the function works on a leave one out principle. You give it all the information you have and it returns the element you are missing. So, for example, say you needed to know how many people per group (n) you would need to detect an effect size of d = 0.4 with power = .8, alpha = .05 in a two.sample (between-subjects) t-test on a two.sided hypothesis test.\n\n10.3.1.1 Activity 5: pwr.t.test()\n\n\nRun the below code:\n\n\npwr.t.test(d = .4,\n           power = .8,\n           sig.level = .05,\n           alternative = \"two.sided\",\n           type = \"two.sample\")\n\nThe output tells you that you would need 99.0803248 people per condition. But you only get whole people and we like to be conservative on our estimates so we would actually run 100 per condition. That is a lot of people!!!\nTo make the output of pwr.t.test() easier to work with, we’re going to amend the code to just give us exactly the number that we want.\n\n\npluck() will pull out the value from the analysis that we want. e.g. pluck(\"n\") will give us the sample size and pluck(\"d\") will give us the effect size.\n\nceiling() rounds up to give us the next highest whole number\n\n\npwr.t.test(d = .4,\n           power = .8,\n           sig.level = .05,\n           alternative = \"two.sided\",\n           type = \"two.sample\") %&gt;% \n  pluck(\"n\") %&gt;%\n  ceiling()\n\nNote: ceiling() is better to use than round() when dealing with people as it always rounds up. For example, ceiling(1.1) gives you 2. round() on the other hand is useful for rounding an effect size, for example, to two decimal places - e.g. d = round(.4356, 2) would give you d = 0.44. So use ceiling() for sample sizes and round() for effect sizes.\n\n10.3.1.2 Activity 6: Sample size for standard power one-sample t-test\n\nAssuming you are interested in detecting a minimum Cohen’s d of d = 0.23, what would be the minimum number of participants you would need in a one-sample t-test, assuming power = .8, \\(\\alpha\\) = .05, on a two-sided hypothesis?\n\nUsing a pipeline, store the answer as a single, rounded value called sample_size_t (i.e. use pluck() %&gt;% ceiling()).\n\n\nHelpful hint\n\n\n\nUse the list of inputs above as a kind of check-list to clearly determine which inputs are known or unknown. This can help you enter the appropriate values to your code.\nThe structure of the pwr.t.test() would be very similar to the one shown above except two.sample would become one.sample\nYou will also need to use pluck(\"n\") to help you obtain the sample size and %&gt;% ceiling() to round up to the nearest whole participant.\n\n\n\nAnswer the following question to check your answers. The solutions are at the bottom if you need them:\n\nEnter the minimum number of participants you would need in this one-sample t-test: \n\n\n10.3.1.3 Activity 7: Effect size from a high power between-subjects t-test\n\nAssuming you run a between-subjects t-test with 50 participants per group and want a power of .9, what would be the minimum effect size you can reliably detect? Assume standard \\(\\alpha\\) and alternative hypothesis settings.\n\nAnswer the following questions to check your answers. The solutions are at the bottom if you need them:\n\nBased on the information given, what will you set type as in the function?\n\none.sampletwo.sample\n\n\nBased on the output, enter the minimum effect size you can reliably detect in this test, rounded to two decimal places: \n\nAccording to Cohen (1988), the effect size for this t-test is\n\nsmall to mediummedium to largelarge\n\n\nSay you run the study and find that the effect size determined is d = 0.50. Given what you know about power, select the statement that is true:\n\nthe study is sufficiently powered as the analysis indicates you can detect only effect sizes smaller than d = 0.65the study is underpowered as the analysis indicates you can detect only effect sizes larger than d = 0.65\n\n\n\n10.3.1.4 Uneven groups\nThere is an additional function that is very worthwhile knowing about called pwr.t2n.test() that allows you to run power analyses for t-tests where there are uneven sample sizes in the two groups. For instance, say you wanted to know the minimum effect size you could determine in a between-subjects t-test where you have 25 participants in one group and 30 participants in the second group. The additional aspect of this function is that instead of n =, you would do:\n\n\nn1 = ... for the number of people in group 1\n\nn2 = ... for the number of people in group 2\nnote that there is no type argument in this function because it has to be two samples.\n\nAssuming \\(\\alpha = .05\\), Power = .8, and it is a two-tailed test, you would do:\n\npwr.t2n.test(n1 = 25,\n             n2 = 30,\n             power = .8,\n             sig.level = .05,\n             alternative = \"two.sided\") %&gt;%\n  pluck(\"d\") %&gt;%\n  round(3)\n\n[1] 0.773\n\n\nMeaning that the minimum effect size you could determine would be d = 0.773.\n\n10.3.2 Correlations\nNow, we’re going to do the same thing but for a correlation analysis using pwr.r.test. The structure of this function is very similar to pwr.t.test() and works on the same leave-one-out principle:\n\n\nn - Number of observations\n\nr - Correlation coefficient\n\nsig.level - Significance level (Type I error probability)\n\npower - Power of test (1 minus Type II error probability)\n\nalternative - a character string specifying the alternative hypothesis, must be one of two.sided (default), greater (a positive correlation) or less (a negative correlation).\n\n\n10.3.2.1 Activity 8: Sample size for a correlation\n\nAssuming you are interested in detecting a minimum correlation of r = .4 (in either direction), what would be the minimum number of participants you would need for a correlation analysis, assuming power = .8, \\(\\alpha\\) = .05?\n\nUsing a pipeline, store the answer as a single, rounded value called sample_size_r (i.e. use pluck() %&gt;% ceiling()).\n\nEnter the minimum number of participants you would need in this correlation: \n\n\n10.3.2.2 Activity 9: Effect size for a correlation analysis\n\nYou run a correlation analysis with 50 participants and the standard power and alpha levels and you have hypothesised a positive correlation, what would be the minimum effect size you can reliably detect? Answer the following questions to check your answers. The solutions are at the bottom if you need them:\nBased on the information given, what will you set alternative as in the function? \ntwo.sided\ngreater\nless\nBased on the output, enter the minimum effect size you can reliably detect in this test, rounded to two decimal places: \nAccording to Cohen (1988), the effect size for this correlation is \nsmall to medium\nmedium to large\nlarge\n\nSay you run the study and find that the effect size determined is d = 0.24. Given what you know about power, select the statement that is true:\n\nthe study is sufficiently powered as the analysis indicates you can detect only effect sizes smaller than d = 0.24the study is underpowered as the analysis indicates you can detect only effect sizes larger than d = 0.34\n\n\n\n10.3.3 Effect Sizes in Published Research\n\n10.3.3.1 Activity 10: Power of published research\nThus far we have used hypothetical situations - now go look at the paper on the Open Stats Lab website called Does Music Convey Social Information to Infants? (we have used this dataset in the t-test chapter). You can download the pdf and look at it, but here we will determine the power of the significant t-tests reported in Experiment 1 under the Results section on Pg489. There is a one-sample t-test and a paired-samples t-test to consider, summarised below. Assume testing was at power = .8, alpha = .05. Based on your calculations are either of the stated effects underpowered?\n\none-sample: t(31) = 2.96, p = .006, d = 0.52\npaired t-test: t(31) = 2.42, p = .022, d= 0.43\n\n\n\nHelpful hint\n\n\n\nTo calculate n: n = df + 1.\n\n\n\nWhich of the t-tests do you believe to be underpowered? Why do you think this may be? Additional information about this can be found in the solution to task 8 at the end of this activity.\nOne caveat to Task 10: We have to keep in mind that here we are looking at single studies using one sample from a potentially huge number of samples within a population. As such there will be a degree of variance in the true effect size within the population regardless of the effect size of one given sample. What that means is we have to be a little bit cautious when making claims about a study. Ultimately the higher the power the better as you can detect smaller effect sizes!"
  },
  {
    "objectID": "10-power.html#power-fin",
    "href": "10-power.html#power-fin",
    "title": "\n10  Statistical Power\n",
    "section": "\n10.4 Finished!",
    "text": "10.4 Finished!\nGreat! Hopefully you are now starting to see the interaction between alpha, power, effect sizes, and sample size. We should always want really high powered studies and depending on the size of the effect we are interested in (small to large), and our \\(\\alpha\\) level, this will mean we will need to run more or less participants to make sure our study is well powered. Points to note:\n\nLowering the \\(\\alpha\\) level (e.g. .05 to .01) will reduce the power.\nLowering the effect size (e.g. .8 to .2) will reduce the power.\nIncreasing power (.8 to .9) will require more participants.\n\nA high-powered study looking to detect a small effect size at a low alpha will require a large number of participants!\nThere are additional functions in the pwr package for other types of statistical analyses. We will include these calculates as part of the ANOVA and regression chapters.\nIf you want more examples of power to reinforce your understanding, go back and calculate the power of the t-tests, correlations, and chi-squares from earlier chapters."
  },
  {
    "objectID": "10-power.html#test-yourself",
    "href": "10-power.html#test-yourself",
    "title": "\n10  Statistical Power and Effect Sizes\n",
    "section": "\n10.6 Test Yourself",
    "text": "10.6 Test Yourself\nTo end the chapter, we have some knowledge check questions to test your understanding of the concepts we covered in the chapter. We then have some error mode tasks to see if you can find the solution to some common errors in the concepts we covered in this chapter.\n\n10.6.1 Knowledge check\nQuestion 1. If you want to conduct an a priori power analysis , what input do you leave blank to solve for?\n\nsample sizeeffect sizepoweralpha\n\nQuestion 2. If you want to conduct a sensitivity power analysis , what input do you leave blank to solve for?\n\nsample sizealphapowereffect size\n\nRead the following output for an a priori power analysis. The next two questions are based on this output.\n\n\n\n     Two-sample t test power calculation \n\n              n = 89.95986\n              d = 0.42\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nQuestion 3. Our smallest effect size of interest is:\n\nd = 0.80r = .80r = .42d = 0.42\n\nQuestion 4. For these inputs, we would need to recruit how many participants per group?\n\n89428090\n\nRead the following output for a sensitivity power analysis. The next two questions are based on this output.\n\n\n\n     approximate correlation power calculation (arctangh transformation) \n\n              n = 72\n              r = 0.3695127\n      sig.level = 0.05\n          power = 0.9\n    alternative = two.sided\n\n\nQuestion 5. Our final sample size was:\n\n72509036\n\nQuestion 6. For these inputs, what effect size would we be sensitive to detect?\n\nr = .05r = .90r = .37r = .72\n\n\n10.6.2 Error mode\nThe following questions are designed to introduce you to making and fixing errors. For this topic, we focus on simple linear regression between two continuous variables. There are not many outright errors that people make here, more misspecifications that are not doing what you think they are doing.\nCreate and save a new R Markdown file for these activities. Delete the example code, so your file is blank from line 10. Create a new code chunk to load the packages tidyverse and pwr.\nBelow, we have several variations of a code chunk error or misspecification. Copy and paste them into your R Markdown file below the code chunk to load tidyverse and pwr. Once you have copied the activities, click knit and look at the error message you receive. See if you can fix the error and get it working before checking the answer.\n\nunconverted effect sizes\n\nQuestion 7. Copy the following code chunk into your R Markdown file and press knit. You should get a cryptic sounding error like Error in uniroot(function(n) eval(p.body) - power, c(4 + 1e-10, 1e+09)): f() values at end points not of opposite sign.\n```{r}\npwr.r.test(n = NULL, \n           r = .20, \n           sig.level = .05, \n           power = .95, \n           alternative = \"less\")\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nIn this example, we specified a positive effect size but negative one-tailed test. They must be consistent, so you either need to make the hypothesis the same:\n\npwr.r.test(n = NULL, \n           r = .20, \n           sig.level = .05, \n           power = .95, \n           alternative = \"greater\")\n\nOr the effect size the same:\n\npwr.r.test(n = NULL, \n           r = -.20, \n           sig.level = .05, \n           power = .95, \n           alternative = \"less\")\n\nBoth will produce the same sample size as it is the absolute effect which is important, but we recommend making it consistent with your research question / hypothesis.\n\n\n\nQuestion 8. Copy the following code chunk into your R Markdown file and press knit. You want to conduct a sensitivity power analysis when you have unequal sample sizes. You should get the following error: Error in pwr.t.test(n1 = 40, n2 = 50, d = NULL, sig.level = 0.05, power = 0.9,  : unused arguments (n1 = 40, n2 = 50).\n```{r}\npwr.t.test(n1 = 40, \n           n2 = 50,\n           d = NULL, \n           sig.level = .05, \n           power = .90, \n           alternative = \"two.sided\")\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nIn this example, we used the wrong function. pwr.t.test() only accepts n as a single argument. If you want a sensitivity power analysis for unequal sample sizes, you need the function pwr.t2n.test():\n\npwr.t2n.test(n1 = 40, n2 = 50,\n           d = NULL, \n           sig.level = .05, \n           power = .90, \n           alternative = \"two.sided\")\n\n\n\n\nQuestion 9. Copy the following code chunk into your R Markdown file and press knit. In your research to establish your smallest effect size of interest, you found a meta-analysis which found the average effect size for your topic was d = 0.54. For your correlational study, you use this effect size for your a priori power analysis. This…works, but is this all consistent?\n```{r}\npwr.r.test(n = NULL, \n           r = .54, \n           sig.level = .05, \n           power = .95, \n           alternative = \"two.sided\")\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nIn this example, we used the wrong effect size. We see this error a lot when people are looking for past studies to inform their smallest effect size of interest. You find a meta-analysis which is perfect, but it reports Cohen’s d when you want Pearson’s r for your study. You can convert between effect sizes (with the caveat the studies should be comparable), but the same number means different things. Mistaking d = 0.54 for Pearson’s r is going to vastly underestimate the sample size you need, as it would be converted to r = .26.\n\npwr.r.test(n = NULL, \n           r = .26, \n           sig.level = .05, \n           power = .95, \n           alternative = \"two.sided\")"
  },
  {
    "objectID": "10-power.html#power-sols",
    "href": "10-power.html#power-sols",
    "title": "\n10  Statistical Power\n",
    "section": "\n10.6 Activity solutions",
    "text": "10.6 Activity solutions\nBelow you will find the solutions to the above questions. Only look at them after giving the questions a good try and trying to find help on Google or Teams about any issues.\n\n10.6.0.1 Activity 1\n\nlibrary(pwr)\nlibrary(broom)\nlibrary(tidyverse)\n\n\n10.6.0.2 Activity 2\n\nd &lt;- 3.24 / sqrt(25 +1)\n\n# effect is medium to large; d = .64\n\n\n10.6.0.3 Activity 3\n\nd &lt;- (2*2.9) / sqrt(30)\n\n# effect is large; d = 1.06\n\n\n10.6.0.4 Activity 4\n\nt = (10 - 11)/sqrt((1.3^2/30) + (1.7^2/30))\n\nd = (2*t)/sqrt((30-1) + (30-1))\n\n# t = 2.56\n# d = .67\n\n# Remember that convention is that people report the t and d as positive.\n\n\n10.6.0.5 Activity 6\n\nsample_size_t &lt;- pwr.t.test(d = .23,\n                            power = .8, \n                            sig.level = .05, \n                            alternative = \"two.sided\", \n                            type = \"one.sample\") %&gt;% pluck(\"n\") %&gt;% ceiling()\n\nsample_size_t\n[1] 151\n\n\n10.6.0.6 Activity 7\n\npwr.t.test(n = 50,\n           power = .9, \n           sig.level = .05, \n           alternative = \"two.sided\", \n           type = \"two.sample\") %&gt;%\n  pluck(\"d\") %&gt;%\n  round(2)\n[1] 0.65\n\n\n10.6.0.7 Activity 8\n\nsample_size_r &lt;- pwr.r.test(r = .4, \n                            sig.level = .05, \n                            power = .8, \n                            alternative = \"two.sided\") %&gt;%\n  pluck(\"n\") %&gt;% \n  ceiling()\n\n\n10.6.0.8 Activity 9\n\npwr.r.test(n = 50,\n           sig.level = .05, \n           power = .8, \n           alternative = \"greater\") %&gt;%\n  pluck(\"r\") %&gt;%\n  round(3)\n[1] 0.344\n\n\n10.6.0.9 Activity 10\nAchievable Cohen d for Example 1\n\npwr.t.test(power = .8, \n           n = 32, \n           type = \"one.sample\", \n           alternative = \"two.sided\", \n           sig.level = .05) %&gt;%\n  pluck(\"d\") %&gt;%\n  round(2)\n[1] 0.51\n\n\nGiving an achievable effect size of 0.51 and they found an effect size of 0.52.\n\nThis study seems ok as the authors could achieve an effect size as low as .51 and found an effect size at .52\nAchievable Cohen d for Example 2\n\npwr.t.test(power = .8, \n           n = 32, \n           type = \"paired\", \n           alternative = \"two.sided\", \n           sig.level = .05) %&gt;%\n  pluck(\"d\") %&gt;%\n  round(2)\n[1] 0.51\n\n\nGiving an achievable effect size of 0.51 and they found an effect size of 0.43.\n\nThis effect might not be reliable given that the effect size found was much lower than the achievable effect size. The issue here is that the researchers established their sample size based on a previous effect size and not on the minimum effect size that they would find important. If an effect size as small as .4 was important then they should have powered all studies to that level and ran the appropriate n ~52 babies (see below). Flipside of course is that obtaining 52 babies isnt easy; hence why some people consider the Many Labs approach a good way ahead.\nONE CAVEAT to the above is that before making the assumption that this study is therefore flawed, we have to keep in mind that this is one study using one sample from a potentially huge number of samples within a population. As such there will be a degree of variance in the true effect size within the population regardless of the effect size of one given sample. What that means is we have to be a little bit cautious when making claims about a study. Ultimately the higher the power the better.\nBelow you could calculate the actual sample size required to achieve a power of .8:\n\nsample_size &lt;- pwr.t.test(power = .8,\n                          d = .4, \n                          type = \"paired\", \n                          alternative = \"two.sided\",\n                          sig.level = .05) %&gt;%\n  pluck(\"n\") %&gt;% \n  ceiling()\n\nsample_size\n[1] 52\n\n\nSuggesting a sample size of n = 52 would be appropriate."
  },
  {
    "objectID": "10-power.html#words-from-this-chapter",
    "href": "10-power.html#words-from-this-chapter",
    "title": "\n10  Statistical Power and Effect Sizes\n",
    "section": "\n10.7 Words from this Chapter",
    "text": "10.7 Words from this Chapter\nBelow you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the PsyTeachR Glossary. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter.\n\n\n\n\nterm\ndefinition\n\n\n\nalpha\n(stats) The cutoff value for making a decision to reject the null hypothesis; (graphics) A value between 0 and 1 used to control the levels of transparency in a plot\n\n\nbeta\nThe false negative rate we accept for a statistical test.\n\n\nfalse-negative\nWhen a test concludes there is no effect when there really is an effect\n\n\nfalse-positive\nWhen a test concludes there is an effect when there really is no effect\n\n\nhypothesis\nA proposed explanation made on the basis of limited evidence as a starting point for further investigation.\n\n\npower\nThe probability of rejecting the null hypothesis when it is false.\n\n\nprobability\nA number between 0 and 1 where 0 indicates impossibility of the event and 1 indicates certainty"
  },
  {
    "objectID": "10-power.html#additional-information",
    "href": "10-power.html#additional-information",
    "title": "\n10  Statistical Power\n",
    "section": "\n10.8 Additional Information",
    "text": "10.8 Additional Information\n\n10.8.1 A blog on how to choose an effect size of interest\nA really quick analogy from Ian Walker’s “Research Methods and statistics”, is say your test is not a stats test but a telescope. And say you have a telescope that is specifically designed only for spotting animals that are the size of elephants or larger (similar to saying a cohens d of .8 or greater for example - very big effect). If your telescope can only reliably detect something down to the size of an elephant but when you look through it you see something smaller that you think might be a mouse, you can’t say that the “object”” is definitely is a mouse as you don’t have enough power in your telescope - it is too blurry. But likewise you can’t rule out that it isn’t a mouse as that would be something you don’t know for sure - both of these are true because your telescope was only designed to spot things the size of an elephant or larger. You only bought a telescope that was able to spot elephants because that was all your were interested in. Had you been interested in spotting mice you would have had to have bought a more powerful telescope. And that is the point of Lakens’ SESOI (Smallest Effect Size of Interest) blog mentioned at the start - you power to the minimum effect size (minimum object size) you would be interested in. This is why it is imperative that you decide before your study what effect you are interested in - and you can base this on previous literature or theory.\n\n10.8.2 A blog on interpreting and writing up power\nA few points on interpreting power to consolidate things a bit. Firstly, it is great that you are now thinking about power and effect sizes in the first place. It is important that this becomes as second nature as thinking about the design of your study and in future years and future studies the first question you should ask yourself when designing your study/secondary analysis is what size are my APES - Alpha, Power, Effect Size and Sample. And remember that a priori power analysis is the way ahead. The power and alpha are determined in advance of the study and you are using them to determine the effect size or the sample size.\nPower is stated more and more commonly again in papers now and you will start to notice it in the Methods or Results sections. You will see something along the lines of “Based on a power =….. and alpha =…., given we had X voices in our sample, a power analysis (pwr package citation) revealed d = …… as the minimum effect sizes we could reliably determine.”\nBut how do you interpret a study in terms of power? Well, lets say you run a power analysis for a t-test (or for a correlation), and you set the smallest effect size of interest as d = .4 (or the equivalent r-value). If you then run your analysis and find d = .6 and the effect is significant, then your study had enough power to determine this effect. The effect that you found was bigger than the effect you could have found. You can have some confidence that you have a reliable effect at that given power and alpha values. However, say that instead of d = .6 you found a significant effect but with an effect size just below .4, say d = .3 - the effect size you found is smaller than the smallest effect you could reliably find. In this case you have to be cautious as you are still unclear as to whether there actually is an effect or whether you have found an effect by chance due to your study not having enough power to reliably detect an effect size that small. You can’t say for sure that there is an effect or that there isn’t an effect. You need to consider both stances in your write up. Remember though that you have sampled a population, so how representative that sample is of your population will also influence the validity of your power. Each sample will give a slightly different effect size.\nAlternatively, and probably quite likely in many degree projects due to time constraints, say you find a non-significant effect at an effect size smaller than what you predicted; say you find a non-significant effect with an effect size of d = .2 and your power analysis said you could only reliably detect an effect as small as d = .4. The issue you have here is that you can’t determine solely based on this study if you a) have a non-significant effect because you are under powered or b) that you have a non-significant effect because there is actually no effect in the first place. Again in your discussion you would need to consider both stances. What you can however say is that the effect that you were looking for is not any bigger than d = 0.4. That is still useful information. Ok you don’t know how small the effect really is, but you can rule out any effect size bigger than your original d-value. In turn this helps future researchers plan their studies better and can guide them better in knowing how many participants to run. See how useful it would be if we published null findings!\nBasically, when your test finds an effect size smaller than you can detect, you don’t know what it is but you know what it isn’t - we aren’t sure if it is a mouse but we know it is not an elephant. Instead you would use previous findings to support the object being a mouse or not but caveat the conclusion with the suggestion that the test isn’t really sensitive to finding a mouse. Similar to a finding that has an effect size smaller than you can detect. You can use previous literature to support their not being an effect but you can’t rule it out for sure. You might have actually found an effect had you had a more powerful test. Just like you might have been able to determine that it was a mouse had you had a more powerful telescope.\nTaking this a bit further in some studies there really is enough power (in terms of N - say a study of 25000 participants) to find a flea on the proverbial mouse, but where nevertheless there is a non-significant finding. In this case you have the fortunate situation where you have a well-powered study and so can say with some degree of confidence that your hypothesis and design is unlikely to ever produce a replicable significant result. That is probably about as certain as you can get in our science or as close as you can get to a “fact”, a very rare and precious thing. However, incredibly high powered studies, with lots of participants, tend to be able to find any difference as a significant difference. A within-subjects design with 10000 participants (Power = .8, \\(\\alpha = .05\\)) can determine reliably detect an incredibly small effect size of d = 0.04. The question at that stage is whether that effect has any real world significance or meaning.\nSo the take-home message here is that your discussion should always consider the result in relation to the hypothesis, integrating previous research and theory, and if there is an additional issue of power, then your discussion could also consider the result in relation to whether you can truly determine the effect and how that might be resolved (e.g. re-assessing the effect size, changing the design (within is more powerful), low sample, power to high (e.g. .9), alpha to low (e.g. .01)). This issue of power would probably be a small part in the generalisability/limitation section.\nAnd finally, n all of the above you can swap effect and relationship, d and r, and other analyses accordingly.\nThat is end of this chapter. Be sure to look again at anything you were unsure about and make some notes to help develop your own knowledge and skills. It would be good to write yourself some questions about what you are unsure of and see if you can answer them later or speak to someone about them. Good work today!"
  },
  {
    "objectID": "11-screening-data.html#the-set-up-and-the-data",
    "href": "11-screening-data.html#the-set-up-and-the-data",
    "title": "\n11  Screening Data\n",
    "section": "\n11.1 The Set-Up and the Data",
    "text": "11.1 The Set-Up and the Data\nAs always we first need to start with setting up our working environment, bringing in our data and looking at it.\n\n11.1.0.1 Activity 1: Set-up\n\nOpen RStudio and set the working directory to your chapter folder. Ensure the environment is clear.\n\nIf you’re using the Rserver, avoid a number of issues by restarting the session - click Session - Restart R\n\n\n\nOpen a new R Markdown document and save it in your working directory. Call the file “screeningdata”.\n\nDownload messy.csv and save it in your Screening Data folder. Make sure that you do not change the file name at all.\n\nIf you prefer you can download the data in a zip folder by clicking here\n\nRemember not to change the file names at all and that data.csv is not the same as data (1).csv.\n\n\nDelete the default R Markdown welcome text and insert a new code chunk that loads the following packages, in this specific order, using the library() function. Remember the solutions if needed.\n\nLoad the packages in this order, psych then tidyverse\n\nagain we have not used some of these packages so you will likely need to install some of them using install.packages(). Remember though that you should only do this on your own machine and only in the console window. If you are using the RServer you will not need to install them.\n\n\nFinally, load the data held in messy.csv as a tibble into an object named messy using read_csv(). If unsure, have a look at the solution at the end of the chapter\n\n11.1.0.2 Activity 2: Look at the data\nmessy is simulated data for an experiment looking at the effect of note-taking on test performance and whether this is affected by being first language English. Participants are first given a pre-test to judge their baseline knowledge, then they watch a lecture and take notes. Immediately after the lecture is finished they take another test. Finally, they are tested after a week’s delay. The maximum score for any test is 30. Participants lose marks for incorrect answers so minus scores are also possible. The dataset has six variables:\n\n\nid showing the participant ID number\n\nage showing the age of the participant\n\nspeakershowing if the participant are first language English or not\n\n\ngender showing if the participant is male, female, or non-binary\n\n\npre showing pre-test score before any notes were taken\n\n\npost showing post-test score immediately after the lecture\n\n\ndelay showing test score after one week delay"
  },
  {
    "objectID": "11-screening-data.html#missing-data",
    "href": "11-screening-data.html#missing-data",
    "title": "\n11  Missing data, outliers, and checking assumptions\n",
    "section": "\n11.2 Missing data",
    "text": "11.2 Missing data\nChecking whether data are missing are relatively straight forward. Missing values in a spreadsheet will be recorded as NA and there are a few ways of identifying them. The much more difficult part of missing data is considering why they are missing in the first place. For example, it might be because:\n\nYour participants accidentally missed a question.\nYou made a mistake while setting up your questionnaire/experiment and some responses did not save.\nYour participants intentionally did not want to answer a question.\nYour participants did not turn up to a final testing session.\n\nFor the first two reasons, it is not ideal as we are losing data but there is no systematic pattern to why the data is missing. For the latter two reasons, there might be a relationship between a key variable and whether the data are missing. This is where it is particularly important to consider the role of missing data. We are focusing on data skills here rather than the conceptual understanding, but missing data are commonly categorised as:\n\nMissing completely at random.\nMissing at random.\nMissing not at random.\n\nFor this introductory course, we do not have time to investigate strategies to address missing data apart from focusing on complete cases and ignoring missing data, but you might find Jakobsen et al. (2017) useful if you want to explore options like data imputation.\n\n11.2.1 Identifying missing data\nReturning to data skills, the simplest way of getting an overview of whether any data are missing is using the summary() function. For this part, we will focus on Dawtry et al. (2015).\n\nsummary(dawtry_clean)\n\n       PS      Household_Income Political_Preference      age      \n Min.   :  1   Min.   :    20   Min.   :1.000        Min.   :19.0  \n 1st Qu.: 77   1st Qu.: 25000   1st Qu.:3.000        1st Qu.:28.0  \n Median :153   Median : 42000   Median :4.000        Median :33.5  \n Mean   :153   Mean   : 54732   Mean   :4.465        Mean   :37.4  \n 3rd Qu.:229   3rd Qu.: 75000   3rd Qu.:6.000        3rd Qu.:46.0  \n Max.   :305   Max.   :350000   Max.   :9.000        Max.   :69.0  \n               NA's   :4        NA's   :4            NA's   :1     \n     gender     Population_Inequality_Gini_Index Population_Mean_Income\n Min.   :1.00   Min.   :14.26                    Min.   : 14205        \n 1st Qu.:1.00   1st Qu.:31.10                    1st Qu.: 47250        \n Median :1.00   Median :35.66                    Median : 58650        \n Mean   :1.48   Mean   :35.51                    Mean   : 58605        \n 3rd Qu.:2.00   3rd Qu.:40.73                    3rd Qu.: 67875        \n Max.   :2.00   Max.   :57.45                    Max.   :138645        \n NA's   :3                                                             \n Social_Circle_Inequality_Gini_Index Social_Circle_Mean_Income\n Min.   : 2.00                       Min.   : 12000           \n 1st Qu.:19.79                       1st Qu.: 36000           \n Median :25.59                       Median : 51060           \n Mean   :26.35                       Mean   : 54294           \n 3rd Qu.:33.27                       3rd Qu.: 66375           \n Max.   :61.36                       Max.   :148500           \n                                                              \n fairness_satisfaction redistribution\n Min.   :1.000         Min.   :1.00  \n 1st Qu.:2.000         1st Qu.:3.25  \n Median :3.000         Median :4.00  \n Mean   :3.539         Mean   :3.91  \n 3rd Qu.:5.000         3rd Qu.:4.75  \n Max.   :9.000         Max.   :6.00  \n                                     \n\n\nWe get a range of summary statistics for each variable but importantly for our purposes here, the final entry is NA's where relevant. We can see there are 4 missing values for household income, 4 for political preference, 1 for age, and 3 for gender.\n\n\n\n\n\n\nTry this\n\n\n\nIf you explore lopez_clean from Lopez et al. (2023), do we have any missing data to worry about? \nYes\nNo.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nYes, it looks like there is also a small amount of missing data here. There is 1 for sex, 2 for estimated ounces, and 3 for estimates calories.\n\nsummary(lopez_clean)\n\n ParticipantID       Sex              Age          Ethnicity    \n Min.   :1001   Min.   :0.0000   Min.   :18.00   Min.   :1.000  \n 1st Qu.:1202   1st Qu.:1.0000   1st Qu.:19.00   1st Qu.:3.000  \n Median :1462   Median :1.0000   Median :20.00   Median :3.000  \n Mean   :1456   Mean   :0.8099   Mean   :20.47   Mean   :3.261  \n 3rd Qu.:1704   3rd Qu.:1.0000   3rd Qu.:21.00   3rd Qu.:4.000  \n Max.   :1928   Max.   :3.0000   Max.   :54.00   Max.   :8.000  \n                NA's   :1                                       \n   OzEstimate       CalEstimate      M_postsoup     F_CaloriesConsumed\n Min.   :  0.010   Min.   :  1.0   Min.   : 0.600   Min.   :  13.31   \n 1st Qu.:  2.000   1st Qu.: 50.0   1st Qu.: 5.575   1st Qu.: 123.65   \n Median :  4.000   Median : 90.0   Median : 8.700   Median : 192.97   \n Mean   :  6.252   Mean   :124.6   Mean   :10.203   Mean   : 226.30   \n 3rd Qu.:  8.000   3rd Qu.:160.0   3rd Qu.:13.125   3rd Qu.: 291.11   \n Max.   :100.000   Max.   :800.0   Max.   :46.200   Max.   :1024.72   \n NA's   :2         NA's   :3                                          \n   Condition      Condition_label   \n Min.   :0.0000   Length:464        \n 1st Qu.:0.0000   Class :character  \n Median :0.0000   Mode  :character  \n Mean   :0.4698                     \n 3rd Qu.:1.0000                     \n Max.   :1.0000                     \n                                    \n\n\n\n\n\n\n11.2.2 Removing missing data\nOnce we know whether missing data are present, we must consider what to do with them. For this chapter, we are only going to control removing participants, but you could apply a data imputation technique at this point.\nFor all the modelling techniques we apply in this book, the functions will remove participants who have one or more missing values from any variable involved in the analysis. The functions will give you a warning to highlight when this happens, but it is normally a good idea to remove participants with missing yourself so you have a note of how many participants you remove.\nFor dawtry_clean, the tidyverse function drop_na() is the easiest way of removing missing data, either participants with any missing data or by specifying individual variables.\n\ndawtry_all_missing &lt;- dawtry_clean %&gt;% \n  drop_na()\n\ndawtry_income_missing &lt;- dawtry_clean %&gt;% \n  drop_na(Household_Income)\n\nWe can compare the number of participants by using the nrow() function to count how many rows are in each object.\n\n# How many rows in the full data? \nnrow(dawtry_clean)\n\n# How many rows when we remove missing data in one variable? \nnrow(dawtry_income_missing)\n\n# How many rows when we remove any missing value?\nnrow(dawtry_all_missing)\n\n[1] 305\n[1] 301\n[1] 294\n\n\nLike most data skills and statistics concepts, the key skill here comes in decision making; documenting and justifying the approach that you take."
  },
  {
    "objectID": "11-screening-data.html#listwise-deletion",
    "href": "11-screening-data.html#listwise-deletion",
    "title": "\n11  Screening Data\n",
    "section": "\n11.3 Listwise Deletion",
    "text": "11.3 Listwise Deletion\nOne method for dealing with missing data is listwise. This approach removes any participant who have a missing value (i.e. a NA) in any variable. So if there is missing data in any of the columns in the dataset, that participant will be removed and you will only be left with participants with complete datasets. For example the below participants would be removed along with all others with a similar profile:\n\n\n\n\nid\nage\nspeaker\ngender\npre\npost\ndelay\n\n\n\nS008\n48\nenglish\nNA\n12\n15\n17\n\n\nS009\n22\nNA\nmale\n5\n18\n5\n\n\nS010\n31\nNA\nfemale\n13\n35\n17\n\n\nS011\n26\nenglish\nNA\n18\n19\n16\n\n\n\n\n\nWe can achieve this using the drop_na() function from the tidyr package that comes in as part of tidyverse.\n\n11.3.0.1 Activity 4: Listwise deletion\n\nRun the below code and then view the tibble in the object called messy_listwise.\n\n\nmessy_listwise &lt;- drop_na(messy)\n\nAs you can see messy_listwise now only contains data from participants with a complete set of data - i.e. responses in each column.\nNow, however, whilst this might seem like a good thing, and sometimes it is the most appropriate option, there are a couple of important points to consider.\n\nFirst, gender might not be part of our experiment; it might just be there as demographic information. So whilst we might not include gender in any of our analyses, because of the listwise deletion approach we have deleted experimental data if the participant was missing gender which means we are removing participants we could actual use.\nRelatedly, using a listwise deletion approach may result in the loss of a lot of data. Compare messy to messy_listwise. The original dataset had 200 participants. After using drop_na() we only have 143 participants meaning that we have lost over 25% of our data with this approach which is a lot of data.\n\n\n\nNote: It is worth mentioning that if you do use a listwise approach you should check that the missing values are not coming from one particular group (i.e., non-random attrition).\n\nTo counter these issues, one option is to amend the use of drop_na() so that it doesn’t include gender, or any column for that matter that we don’t want to exclude people based on. We can do this using a similar approach to what we have seen when using select(). For example, run the below code, have a look at the output and then answer the question:\n\nmessy_listwise2 &lt;- drop_na(messy, -gender)\n\n\nHow many observations does messy_listwise2 have? \n\n\nSo that approach says “remove participants with NAs from messy based on all columns except gender”. Alternatively, you could do “remove participants with NAs from messy based on only the columns of speaker and delay” as follows:\n\nmessy_listwise3 &lt;- drop_na(messy, speaker, delay)\n\nSo you actually have a lot of control with drop_na() as long as you plan your approach in advance."
  },
  {
    "objectID": "11-screening-data.html#pairwise-deletion",
    "href": "11-screening-data.html#pairwise-deletion",
    "title": "\n11  Screening Data\n",
    "section": "\n11.4 Pairwise Deletion",
    "text": "11.4 Pairwise Deletion\nThe alternative to listwise deletion is pairwise. This is when cases are removed depending upon the analysis. For example, if we were to calculate the correlations between pre, post, and delay without first removing participants with missing data, we would basically just use different numbers of participants in each correlation depending on missing data. For example, if you compare the degrees of freedom for the following two correlations:\n\ncor.test(messy$pre, messy$post)\n\n\n    Pearson's product-moment correlation\n\ndata:  messy$pre and messy$post\nt = 7.0493, df = 198, p-value = 2.924e-11\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.3296550 0.5523276\nsample estimates:\n      cor \n0.4479101 \n\n\n\ncor.test(messy$pre, messy$delay)\n\n\n    Pearson's product-moment correlation\n\ndata:  messy$pre and messy$delay\nt = 7.9619, df = 178, p-value = 1.927e-13\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.3958642 0.6127887\nsample estimates:\n      cor \n0.5124561 \n\n\nYou can see that the correlation of pre versus post has df = 198 whereas pre versus delay has df = 178. Meaning that the correlation is by default run only on the participants who have data in both columns - pairwise deletion. The problem here is remembering to write up the output accordingly as the dfs are changing and they may be different from the number of participants you stated in your methods section. Again it is about looking at your data!"
  },
  {
    "objectID": "11-screening-data.html#summarising-data-with-missing-values",
    "href": "11-screening-data.html#summarising-data-with-missing-values",
    "title": "\n11  Screening Data\n",
    "section": "\n11.5 Summarising data with missing values",
    "text": "11.5 Summarising data with missing values\nSo when running inferential tests like correlations, the analysis will usually know when to ignore missing values. However, if you’re calculating descriptive statistics or if you want to calculate the average score of a number of different items, you need to explicitly state to ignore the missing values. We can do this through na.rm = TRUE\n\n11.5.0.1 Activity 5: na.rm = TRUE\n\n\nRun the below code to calculate the mean score for each testing condition.\n\n\nsummarise(messy, \n          pre_mean = mean(pre),\n          post_mean = mean(post),\n          delay_mean = mean(delay)\n          )\n\nThis gives a table similar to below. We have rounded all the values to two decimal places but yours might have more decimal places.\n\n\n\n\npre_mean\npost_mean\ndelay_mean\n\n\n10.02\n17.27\nNA\n\n\n\n\nAs you can see, the mean score for delay shows as NA. This is because we are trying to calculate an average of a variable that has missing data and that just isn’t doable. As such we need to calculate the mean but ignoring the missing values by adding na.rm = TRUE - which you can read this as “remove the NAs? Yes”.\n\nRun the below code and then answer the question.\n\n\nsummarise(messy, \n          pre_mean = mean(pre),\n          post_mean = mean(post),\n          delay_mean = mean(delay, na.rm = TRUE)\n          )\n\n\nWhat is the mean score for the delay condition to 2 decimal places? \n\n\n\n\n\nIt’s really important that you think about whether you want to calculate your descriptives from participants that have missing data. For example, if you are calculating the average reaction time from hundreds of trials, a few missing data points won’t affect the validity of the mean. However, if you are using a standardised questionnaire that has been validated using complete responses but your participants didn’t answer 3/10 questions, it may not be appropriate to calculate a mean score from the remaining data."
  },
  {
    "objectID": "11-screening-data.html#implausible-values",
    "href": "11-screening-data.html#implausible-values",
    "title": "\n11  Screening Data\n",
    "section": "\n11.6 Implausible values",
    "text": "11.6 Implausible values\nAlong with looking for missing values, an additional crucial step of data screening is checking for implausible values - values that should not exist in your data. What is implausible depends on the data you’ve collected!\n\n11.6.0.1 Activity 6: Implausible values\nAdditional functions we can put inside a summarise() function are min() and max().\n\nRun the below code and look at the output and answer the questions below:\n\n\nmessy %&gt;%\n  summarise(max_age = max(age, na.rm = TRUE),\n            min_age = min(age, na.rm = TRUE),\n            max_pre = max(pre, na.rm = TRUE),\n            min_pre = min(pre, na.rm = TRUE),\n            max_post = max(post, na.rm = TRUE),\n            min_post = min(post, na.rm = TRUE),\n            max_delay = max(delay, na.rm = TRUE),\n            min_delay = min(delay, na.rm = TRUE))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmax_age\nmin_age\nmax_pre\nmin_pre\nmax_post\nmin_post\nmax_delay\nmin_delay\n\n\n470\n18\n26\n-5\n40\n3\n29\n-3\n\n\n\n\n\n\nDoes the max value of age look plausible? \nYes\nNo\n\nDoes the max value of pre look plausible? \nYes\nNo\n\nDo the max value of post look plausible? \nYes\nNo\n\nDo the min value of delay look plausible? \nNo\nYes\n\n\n\n\nExplain these answers\n\n\nThe maximum value for age is 470, this is unlikely to be correct!\nThe maximum value for pre, post, and delay should be 30, as we described at the start of the chapter. However, for post, the maximum value is 40 so something is wrong. This is a very important check to do on your data, not just for the raw data but if you’ve calculated a total score.\nThe min value for delay is plausible, given the explanation at the start of the chapter. Remember that participants can be deducted points for incorrect answers, so negative values are possible.\n\n\nThat code above does look a bit long and could be written quicker as below. We won’t go into detail as to how this works but see if you can figure it out by comparing the output to the version above:\n\nmessy %&gt;% \n  summarise_at(c(\"age\",\"pre\",\"post\",\"delay\"),\n               c(max, min),\n               na.rm = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nage_fn1\npre_fn1\npost_fn1\ndelay_fn1\nage_fn2\npre_fn2\npost_fn2\ndelay_fn2\n\n\n470\n26\n40\n29\n18\n-5\n3\n-3\n\n\n\n\n\nAnd there is always summary(messy) if you prefer. But the main point is that we should always check our values to make sure they are allowed in our data. But whilst looking at the values is useful, it can be easier to visualise the data.\n\n11.6.0.2 Activity 7: Visualising implausible values\nThere are a number of different ways to visualise the data as you know and this depends on the data, and your preferences. You could produce violin-boxplots with the data points on top to check the distributions as follows:\n\nmessy %&gt;%\n  pivot_longer(cols = c(\"pre\", \"post\", \"delay\"), \n               names_to = \"test\", \n               values_to = \"score\") %&gt;%\n  ggplot(aes(x = test, y = score)) +\n  geom_violin() +\n  geom_boxplot() +\n  geom_jitter(width = .2)\n\n\n\nData screening plots\n\n\n\nAnd if it helped, you could add some max and min lines to help spot issues using geom_hline() as follows:\n\nmessy %&gt;%\n  pivot_longer(cols = c(\"pre\", \"post\", \"delay\"), \n               names_to = \"test\", \n               values_to = \"score\") %&gt;%\n  ggplot(aes(x = test, y = score)) +\n  geom_violin() +\n  geom_boxplot() +\n  geom_jitter(width = .2) +\n  geom_hline(yintercept = c(0,30), color = \"red\", linetype = 2)\n\n\n\nData screening plots\n\n\n\nAlternatively you could also use a histogram to spot an outlier:\n\nggplot(messy, aes(x = age)) +\n  geom_histogram()\n\n\n\nHistogram of age for data screening\n\n\n\nAnd we can make use of facet_wrap() which we have seen before to help split figures based on different conditions:\n\nmessy %&gt;%\n  pivot_longer(cols = c(\"pre\", \"post\", \"delay\"), \n               names_to = \"test\", \n               values_to = \"score\") %&gt;%\n  ggplot(aes(x = score)) +\n  geom_histogram(binwidth = 1) +\n  facet_wrap(~test)\n\n\n\nHistogram of the DVs for data screening\n\n\n\nWhatever method you choose, make sure that you look at your data before trying to work with it and that you know in advance what range your values should take (for example, if your Likert scale is 1-7, you shouldn’t have a score of 8, for reaction times, 50ms is unlikely to reflect a real response)."
  },
  {
    "objectID": "11-screening-data.html#dealing-with-implausible-values-or-missing-data",
    "href": "11-screening-data.html#dealing-with-implausible-values-or-missing-data",
    "title": "\n11  Screening Data\n",
    "section": "\n11.7 Dealing with implausible values or missing data",
    "text": "11.7 Dealing with implausible values or missing data\nOnce we have spotted some implausible or missing values we then need to decide what to do with them. However, there is no hard and fast rule about what to do with missing data. You should review the missing data to see if there are any patterns, for example, is all the missing data from one condition? A pattern may indicate a problem with your design. Alternatively, does a single participant have a lot of missing data and should they be removed? This might indicate they were not paying attention.\nOne way of dealing with implausible values is to use the replace() and mutate() functions to change such values to Na.\n\nFor age, we know that we have one very specific data point that is implausible, an age of 470 so we can specify just to replace this one value with NA.\nFor post, there are multiple missing values so we specify to replace any data point that is over the maximum plausible value (30) with NA.\n\n\nmessy_screen &lt;-  messy %&gt;% \n  mutate(age = replace(age, age == 470, NA),\n         post = replace(post, post &gt; 30, NA))\n\nAn alternative method for dealing with implausible data is to impute the data, i.e., to replace missing data with substituted values. There are many methods of doing this, for example, you can replace missing values with the mean value of the distribution. We won’t go into which method you should choose this in this chapter but there’s more information available online about the various options if you’re interested. The code for imputing missing data is relatively simple and uses mutate() and replace_na().\n\nYou can read the below code as “create a new variable named post_impute that replaces the values of post if they’re NA with the mean of the values in post.\n\n\nmessy_impute &lt;- messy_screen %&gt;%\n  mutate(post_impute = replace_na(post, \n                                  mean(post, na.rm = TRUE)))\n\nAnd if we look at a participant who had a NA for post we can see the change:\n\n\n\n\nid\nage\nspeaker\ngender\npre\npost\ndelay\npost_impute\n\n\nS016\n40\nenglish\nfemale\n21\nNA\n12\n16.71134\n\n\n\n\nSo you can see that they have been given the value of the mean of the distribution in this new variable and then can be used in different analyses!"
  },
  {
    "objectID": "11-screening-data.html#alternative-function-for-descriptive-statistics",
    "href": "11-screening-data.html#alternative-function-for-descriptive-statistics",
    "title": "\n11  Screening Data\n",
    "section": "\n11.8 Alternative function for descriptive statistics",
    "text": "11.8 Alternative function for descriptive statistics\nAnd before we end this chapter we wanted to just add a small section on an alternative function for calculating some useful descriptives that you can use to check your data. So far in this book, we’ve calculated descriptive statistics using summarise() from the tidyverse. There’s a good reason we’ve done this - the output of summarise() works well with ggplot() and the code is very flexible. However, it can be hard to calculate descriptives such as skew and kurtosis within summarise() and it can be useful to know of other functions that help create these descriptives. For example, the psych package contains many functions that are useful for psychology research. One of the functions of psych is describe().\n\nRun the below code and look at the output as shown below.\n\n\ndescriptives &lt;- describe(messy)\ndescriptives\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvars\nn\nmean\nsd\nmedian\ntrimmed\nmad\nmin\nmax\nrange\nskew\nkurtosis\nse\n\n\n\nid*\n1\n200\n100.500000\n57.8791845\n100.5\n100.500000\n74.1300\n1\n200\n199\n0.0000000\n-1.2180144\n4.0926764\n\n\nage\n2\n200\n36.075000\n32.3102015\n34.0\n33.931250\n13.3434\n18\n470\n452\n12.0951922\n159.6718805\n2.2846763\n\n\nspeaker*\n3\n180\n1.511111\n0.5012709\n2.0\n1.513889\n0.0000\n1\n2\n1\n-0.0440855\n-2.0091259\n0.0373625\n\n\ngender*\n4\n180\n1.688889\n0.7268889\n2.0\n1.611111\n1.4826\n1\n3\n2\n0.5452331\n-0.9643153\n0.0541791\n\n\npre\n5\n200\n10.015000\n5.0039959\n10.0\n9.987500\n4.4478\n-5\n26\n31\n0.0555773\n0.2559528\n0.3538359\n\n\npost\n6\n200\n17.270000\n6.3386110\n17.0\n16.968750\n5.9304\n3\n40\n37\n0.5802699\n0.7133158\n0.4482075\n\n\ndelay\n7\n180\n13.600000\n5.1563271\n14.0\n13.645833\n4.4478\n-3\n29\n32\n-0.0462551\n0.4985955\n0.3843299\n\n\n\n\n\nAs you can see describe() produces a full set of descriptive statistics, including skew, kurtosis and standard error for the entire dataset! Run ?describe to see a full explanation of all the statistics it calculates.\nYou may notice that id, speaker and gender all have a star next to their name. This star signifies that these variables are factors, and so it is not really appropriate to calculate these statistics, but we asked it to apply describe() to the entire dataset so it’s done what you asked. However, we could describe()with select() to remove these variables and just get the data we want:\n\ndescriptives2 &lt;- messy %&gt;%\n  select(-id, -speaker, -gender) %&gt;%\n  describe()\n\ndescriptives2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvars\nn\nmean\nsd\nmedian\ntrimmed\nmad\nmin\nmax\nrange\nskew\nkurtosis\nse\n\n\n\nage\n1\n200\n36.075\n32.310201\n34\n33.93125\n13.3434\n18\n470\n452\n12.0951922\n159.6718805\n2.2846763\n\n\npre\n2\n200\n10.015\n5.003996\n10\n9.98750\n4.4478\n-5\n26\n31\n0.0555773\n0.2559528\n0.3538359\n\n\npost\n3\n200\n17.270\n6.338611\n17\n16.96875\n5.9304\n3\n40\n37\n0.5802699\n0.7133158\n0.4482075\n\n\ndelay\n4\n180\n13.600\n5.156327\n14\n13.64583\n4.4478\n-3\n29\n32\n-0.0462551\n0.4985955\n0.3843299\n\n\n\n\n\nThe output of describe() is a little harder to work with in terms of manipulating the table and using the data in subsequent plots and analyses, so we still strongly recommend that you use summarise() and group_by() for these operations, however, for getting a comprehensive overview of your data, describe() is a good function to know about."
  },
  {
    "objectID": "11-screening-data.html#screening-fin",
    "href": "11-screening-data.html#screening-fin",
    "title": "\n11  Screening Data\n",
    "section": "\n11.9 Finished!",
    "text": "11.9 Finished!\nAnd you’re done! Excellent work today! This isn’t a comprehensive tutorial on every type of dataset you will come across and the concept of tidy data will take practice but hopefully this should give you a good starting point for when you have your own real, messy data."
  },
  {
    "objectID": "11-screening-data.html#screening-sols",
    "href": "11-screening-data.html#screening-sols",
    "title": "\n11  Screening Data\n",
    "section": "\n11.10 Activity solutions",
    "text": "11.10 Activity solutions\n\n11.10.1 Activity 1\n\nlibrary(psych)\nlibrary(tidyverse)\nmessy &lt;- read_csv(\"messy.csv\")"
  },
  {
    "objectID": "11-screening-data.html#words-from-this-chapter",
    "href": "11-screening-data.html#words-from-this-chapter",
    "title": "\n11  Missing data, outliers, and checking assumptions\n",
    "section": "\n11.6 Words from this Chapter",
    "text": "11.6 Words from this Chapter\nBelow you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the PsyTeachR Glossary. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter."
  },
  {
    "objectID": "12-anova.html",
    "href": "12-anova.html",
    "title": "\n12  One-way ANOVA\n",
    "section": "",
    "text": "12.1 Chapter preparation",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>One-way ANOVA</span>"
    ]
  },
  {
    "objectID": "13-factorial-anova.html",
    "href": "13-factorial-anova.html",
    "title": "\n13  Factorial ANOVA\n",
    "section": "",
    "text": "13.1 Chapter preparation",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Factorial ANOVA</span>"
    ]
  },
  {
    "objectID": "14-multiple-regression.html#mulregression-a1",
    "href": "14-multiple-regression.html#mulregression-a1",
    "title": "\n14  Multiple Regression\n",
    "section": "\n14.1 Activity 1: Set-up",
    "text": "14.1 Activity 1: Set-up\n\nOpen R Studio and set the working directory to your chapter folder. Ensure the environment is clear.\n\nOpen a new R Markdown document and save it in your working directory. Call the file “Multiple Regression”.\n\nDownload wellbeing.csv, participant_info.csv and screen_time.csv and save them in your Chapter folder. Make sure that you do not change the file names at all.\n\nIf you’re on the server, avoid a number of issues by restarting the session - click Session - Restart R\n\nDelete the default R Markdown welcome text and insert a new code chunk that loads pwr, see, performance, report, and tidyverse using the library() function.\nLoad the CSV datasets into variables called pinfo, wellbeing and screen using read_csv()."
  },
  {
    "objectID": "14-multiple-regression.html#mulregression-a2",
    "href": "14-multiple-regression.html#mulregression-a2",
    "title": "\n14  Multiple Regression\n",
    "section": "\n14.2 Activity 2: Look at the data",
    "text": "14.2 Activity 2: Look at the data\nTake a look at the resulting tibbles pinfo, wellbeing, and screen. The wellbeing tibble has information from the WEMWBS questionnaire; screen has information about screen time use on weekends (variables ending with we) and weekdays (variables ending with wk) for four types of activities: using a computer (variables starting with Comph; Q10 on the survey), playing video games (variables starting with Comp; Q9 on the survey), using a smartphone (variables starting with Smart; Q11 on the survey) and watching TV (variables starting with Watch; Q8 on the survey). If you want more information about these variables, look at the items 8-11 on pages 4-5 of the the PDF version of the survey on the OSF website.\n\nThe variable corresponding to gender is located in the table named \npinfo\nwellbeing\nscreen and this variable is called .\nThe WEMWBS data is in \nlong\nwide format, and contains observations from  participants on  items.\nIndividual participants in this dataset are identified by the variable named  [be sure to type the name exactly, including capitalization]. This variable will allow us to link information across the three tables.\nRun summary() on the three data-sets. Are there any missing data points? \nYes\nNo"
  },
  {
    "objectID": "14-multiple-regression.html#mulregression-a3",
    "href": "14-multiple-regression.html#mulregression-a3",
    "title": "\n14  Multiple Regression\n",
    "section": "\n14.3 Activity 3: Compute the well-being score for each respondent",
    "text": "14.3 Activity 3: Compute the well-being score for each respondent\nThe WEMWBS well-being score is simply the sum of all the items.\n\nWrite the code to create a new table called wemwbs, with two variables: Serial (the participant ID), and tot_wellbeing, the total WEMWBS score.\n\n\n\nHint\n\n\n“pivot” the table from wide to long\n\n\n\n\nAnother Hint\n\n\n\ngroup_by(); summarise(tot_wellbeing = ...)\n\n\n\nSanity check: Verify for yourself that the scores all fall in the 14-70 range. Przybylski and Weinstein reported a mean of 47.52 with a standard deviation of 9.55. Can you reproduce these values?\n\n\nHint\n\n\n\nsummarise(), min(), max()\n\n\n\n\n\nNow visualise the distribution of tot_wellbeing in a histogram using ggplot2.\n\n\n\nHint\n\n\ngeom_histogram()\n\n\n\n\nSolution\n\n\nggplot(wemwbs, aes(tot_wellbeing)) + geom_histogram() \n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nThe distribution of well-being scores is \nsymmetric\nnegatively skewed\npositively skewed."
  },
  {
    "objectID": "14-multiple-regression.html#mulregression-a4",
    "href": "14-multiple-regression.html#mulregression-a4",
    "title": "\n14  Multiple Regression\n",
    "section": "\n14.4 Activity 4: Visualise the relationship",
    "text": "14.4 Activity 4: Visualise the relationship\nLet’s take a quick look at the relationship between screen time (for the four different technologies) and measures of well-being. Here is code to do this.\n\nRun the below code and try and explain in words what each line of code is doing (remember, pronounce %&gt;% as “and then”). You may find it easier to look at each of the tables that are produced.\n\n\nscreen_long &lt;- screen %&gt;%\n  pivot_longer(names_to = \"var\", values_to = \"hours\", -Serial) %&gt;%\n  separate(var, c(\"variable\", \"day\"), \"_\")\n\nscreen2 &lt;- screen_long %&gt;%\n  mutate(variable = dplyr::recode(variable,\n               \"Watch\" = \"Watching TV\",\n               \"Comp\" = \"Playing Video Games\",\n               \"Comph\" = \"Using Computers\",\n               \"Smart\" = \"Using Smartphone\"),\n     day = dplyr::recode(day,\n              \"wk\" = \"Weekday\",\n              \"we\" = \"Weekend\"))\n\ndat_means &lt;- inner_join(wemwbs, screen2, \"Serial\") %&gt;%\n  group_by(variable, day, hours) %&gt;%\n  summarise(mean_wellbeing = mean(tot_wellbeing))\n\nggplot(dat_means, aes(hours, mean_wellbeing, linetype = day)) +\n  geom_line() +\n  geom_point() +\n  facet_wrap(~variable, nrow = 2)\n\n\n\nRelationship between wellbeing and screentime usage by technology and weekday\n\n\n\nThe graph makes it evident that smartphone use of more than 1 hour per day is associated with increasingly negative well-being. Note that we have combined the tables using an inner_join(), such that we only include data for which we have observations across the wemwbs and screen2 tables.\nIn the next step, we are going to focus in on the smartphone/well-being relationship."
  },
  {
    "objectID": "14-multiple-regression.html#mulregression-a5",
    "href": "14-multiple-regression.html#mulregression-a5",
    "title": "\n14  Multiple Regression\n",
    "section": "\n14.2 Multiple linear regression",
    "text": "14.2 Multiple linear regression\nNow that we have explored the data, we can start preparing for the analysis. Note that in this analysis, we have:\n\nA continuous\\(^*\\) outcome: well-being.\nOne continuous\\(^*\\) predictor: screen time.\nOne categorical predictor: gender.\n\n\\(^*\\)these variables are only quasi-continuous as only discrete values are possible. This returns up to the ordinal dilemma, particularly for the outcome of well-being. However, there are a sufficient number of discrete values that we can treat them as effectively continuous.\nWe want to estimate two slopes relating screen time to well-being, one for girls and one for boys, and then statistically compare these slopes. So, this problem seems simultaneously like a situation where you would run a regression (to estimate the slopes) but also one where you would need a t-test (to compare two groups). This is the power of regression models as you can look at the interaction between one continuous and one categorical predictor, something that is not possible in factorial ANOVA.\n\n14.2.1 Activity 5 - Complete the final wrangling steps\nFor this analysis, we are going to average weekday and weekend use for smartphones. We need one final round of wrangling to prepare for creating a multiple linear regression model.\n\n\n\n\n\n\nTry this\n\n\n\nStep 1. Create a new data object smarttot that has the mean number of hours per day of smartphone use for each participant, averaged over weekends/weekdays. Then filter the data to only include those who use a smart phone for more than one hour per day.\nTo do this, you will need to:\n\nFilter the data screen_long to only include smartphone use and not other technologies.\nGroup the results by the participant ID (Serial).\nSummarise the data to calculate the mean number of hours per participant. Call this variable total_hours.\nFilter the data to only include participants who use a smartphone for more than 1 hour per day.\n\nThe data smarttot should have two variables: Serial (the participant) and total_hours.\nStep 2. Once you have smarttot, combine (join) this data object with the information in wemwbs and pinfo. Call this new object smart_wb. This is the final object you need for the multiple linear regression model.\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\nsmarttot &lt;- screen_long %&gt;%\n  filter(variable == \"Using Smartphone\") %&gt;%\n  group_by(Serial) %&gt;%\n  summarise(total_hours = mean(hours)) %&gt;% \n  filter(total_hours &gt; 1)\n\nsmart_wb &lt;- smarttot %&gt;%\n  inner_join(wemwbs, \n             by = \"Serial\") %&gt;%\n  inner_join(pinfo, \n             by = \"Serial\") \n\n\n\n\n\n14.2.2 Activity 6 - Mean-centering variables\nAs we discussed in the course materials, when you have continuous variables in a regression model, it is often sensible to transform them by mean centering. We covered this in Chapter 8, but it is particularly important in multiple linear regression. You mean center a predictor X by subtracting the mean of the predictor (X_centered = X - mean(X)). This has two useful consequences:\n\nThe model intercept reflects the prediction for \\(Y\\) at the mean value of the predictor variable, rather than at the zero value of the unscaled variable.\nIf there are interactions in the model, any lower-order effects can be given the same interpretation as they receive in ANOVA (main effects, rather than simple effects).\n\nFor categorical predictors with two levels, these become coded as -.5 and .5 (because the mean of these two values is 0).\n\n\n\n\n\n\nTry this\n\n\n\nUse mutate() to add two new variables to smart_wb:\n\ntotal_hours_c: calculated as a mean-centered version of the total_hours predictor\nmale_c: recoded as -.5 for female and .5 for male, and then converts both male and male_c as factors, so that R knows not to treat them as real numbers.\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\nsmart_wb &lt;- smart_wb %&gt;%\n  mutate(total_hours_c = total_hours - mean(total_hours),\n         male_c = case_when(male == 1 ~ .5, \n                            male == 0 ~ -.5),\n         male_c = as.factor(male_c),\n         male = as.factor(male))\n\n\n\n\n\n14.2.3 Activity 7 - Running the regression\nFor the data in smart_wb, use the lm() function to calculate the multiple regression model:\n\\(Y_i = \\beta_0 + \\beta_1 X_{1i} + \\beta_2 X_{2i} + \\beta_3 X_{3i} + e_i\\)\nwhere\n\n\\(Y_i\\) is the well-being score for participant \\(i\\);\n\\(X_{1i}\\) is the mean-centered smartphone use variable for participant \\(i\\);\n\\(X_{2i}\\) is gender (-.5 = female, .5 = male);\n\\(X_{3i}\\) is the interaction between smartphone use and gender (\\(= X_{1i} \\times X_{2i}\\))\n\n\n\n\n\n\n\nTry this\n\n\n\nSave your model to the object ml_model.\nSave the summary() of your model to the object model_summary.\nPrint the model_summary to see the results and answer the following questions:\n\nThe interaction between smartphone use and gender is shown by the variable \nthours_c\nmale_c\nthours_c:male_c, and this interaction was \nsignificant\nnon-significant at the \\(\\alpha = .05\\) level.\nTo 2 decimal places, adjusted \\(R^2\\) suggests the overall model explains what percentage of the variance in well-being scores? \nThe p-value for the overall model fit is &lt;2e-16. Is this statistically significant? \nYes\nNo\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\nml_model &lt;- lm(formula = total_wellbeing ~ total_hours_c * male_c, \n               data = smart_wb)\n\nmod_summary &lt;- summary(ml_model)\n\nmod_summary\n\n\nCall:\nlm(formula = total_wellbeing ~ total_hours_c * male_c, data = smart_wb)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-36.881  -5.721   0.408   6.237  27.264 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)             44.86740    0.04478 1001.87   &lt;2e-16 ***\ntotal_hours_c           -0.77121    0.02340  -32.96   &lt;2e-16 ***\nmale_c0.5                5.13968    0.07113   72.25   &lt;2e-16 ***\ntotal_hours_c:male_c0.5  0.45205    0.03693   12.24   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.135 on 71029 degrees of freedom\nMultiple R-squared:  0.09381,   Adjusted R-squared:  0.09377 \nF-statistic:  2451 on 3 and 71029 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n14.2.4 Activity 8 - Visualising interactions\nIt is very difficult to understand an interaction from the coefficient alone, so your best bet is visualising the interaction to help you understand the results and communicate your results to your readers.\nThere is a great package called sjPlot which takes regression models and helps you plot them in different ways. We will demonstrate plotting interactions, but for further information and options, see the online documentation.\nTo plot the interaction, you need the model object (not the summary), specify “pred” as the type as we want to plot predictions, and add the terms you want to plot.\n\nplot_model(ml_model, \n           type = \"pred\", \n           terms = c(\"total_hours_c\", \"male_c\"))\n\n\n\n\n\n\n\nWhat is the most reasonable interpretation of the interaction?\n\nsmartphone use harms girls more than boyssmartphone use was more negatively associated with wellbeing for girls than for boysthere is no evidence for gender differences in the relationship between smartphone use and well-beingsmartphone use harms boys more than girls\n\nThis is fine for helping you to interpret your model, but you would need to customise it before adding it into a report. Like afex_plot() we introduced you to in Chapter 13, plot_model() uses ggplot2 in the background. You can add further customisation by adding layers after the initial function.\n\n\n\n\n\n\nNote\n\n\n\nSince plot_model() uses ggplot2, you can use ggsave() to save your plots and insert them into your work.\n\n\nFor example, we can tidy up the axis labels and remove the title, and set a theme.\n\nplot_model(ml_model, \n           type = \"pred\", \n           terms = c(\"total_hours_c\", \"male_c\")) + \n  labs(x = \"Total Hours Smartphone Use\",\n       y = \"Total Well-Being Score\",\n       title = \"\") + \n  theme_classic()\n\n\n\n\n\n\n\nFor communicating interactions, it is normally better to plot a version using the raw predictors instead of the mean centered versions as the interaction does not change and it will be easier for your readers to understand.\n\n14.2.5 Activity 9 - Assumption checking\nNow it’s time to test those pesky assumptions. The assumptions for multiple regression are the same as simple regression but there is one additional assumption, that of multicollinearity. This is the idea that predictor variables should not be too highly correlated.\n\nThe outcome/DV is a interval/ratio level data.\nThe predictor variable is interval/ratio or categorical (with two levels).\nAll values of the outcome variable are independent (i.e., each score should come from a different participant).\nThe predictors have non-zero variance.\nThe relationship between outcome and predictor is linear.\nThe residuals should be normally distributed.\nThere should be homoscedasticity (homogeneity of variance, but for the residuals).\nMulticollinearity: predictor variables should not be too highly correlated.\n\nFrom the work we have done so far, we know that we meet assumptions 1 - 4 and we can use the plot() function for diagnostic plots, plus check_model() from the performance package.\nOne difference from when we used check_model() previously is that rather than just letting it run all the tests it wants, we are going to specify which tests to stop it throwing an error. A word of warning - these assumption tests will take longer than usual to run because it’s such a big data set. The first line of code will run the assumption tests and save it to an object, calling the object name will then display the plots.\n\nassumptions &lt;- check_model(ml_model, \n                           check = c(\"vif\", \n                                     \"qq\", \n                                     \"normality\", \n                                     \"linearity\", \n                                     \"homogeneity\"))\n\nassumptions\n\n\n\nFigure 14.1: Assumption plots from the performance package.\n\n\n\nFor assumption 5, linearity, we already know from looking at the scatterplot that the relationship is linear, but the residual plot also confirms this.\nFor assumption 6, normality of residuals, the residuals look good in both plots and this provides an excellent example of why it’s often better to visualise than rely on statistics. With a sample size this large, any statistical diagnostic tests will be highly significant as they are sensitive to sample size.\nFor assumption 7, homoscedasticity, the plot is missing the reference line. Fun fact, this took us several days of our lives and asking for help on social media to figure out. The reason the line is not there is because the data set is so large that is creates a memory issue. However, if you use the plot() version, it does show the reference line.\n\nplot(ml_model,\n     which = 3)\n\n\n\n\n\n\n\nIt is not perfect, but the reference line is roughly flat to suggest there are no serious issues with homoscedasticity.\nFinally, for assumption 8, multicollinearity, the plot also indicates no issues but we can also test this statistically using check_collinearity() to produce VIF (variance inflation factor) and tolerance values.\nEssentially, this function estimates how much the variance of a coefficient is “inflated” because of linear dependence with other predictors, i.e., that a predictor is not actually adding any unique variance to the model, it’s just really strongly related to other predictors. You can read more about this online. Thankfully, VIF is not affected by large samples like other statistical diagnostic tests.\nThere are various rules of thumb, but most converge on a VIF of above 2 - 2.5 for any one predictor being problematic.\n\ncheck_collinearity(ml_model)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTerm\nVIF\nVIF_CI_low\nVIF_CI_high\nSE_factor\nTolerance\nTolerance_CI_low\nTolerance_CI_high\n\n\n\ntotal_hours_c\n1.721968\n1.704219\n1.740165\n1.312238\n0.5807308\n0.5746582\n0.5867789\n\n\nmale_c\n1.035552\n1.028488\n1.044369\n1.017621\n0.9656682\n0.9575159\n0.9723014\n\n\ntotal_hours_c:male_c\n1.716349\n1.698683\n1.734463\n1.310095\n0.5826319\n0.5765474\n0.5886915\n\n\n\n\n\n\n\n14.2.6 Activity 10 - Power and effect sizes\nFinally, we will calculate power and an effect size specific to multiple linear regression. Your coefficients represent the effect size for individual variables, but you can summarise the whole regression model with \\(R^2\\) and \\(f^2\\).\nUsing your understanding of power analysis from Chapter 10 and the function specific to regression models, calculate the minimum effect size we could reliably observe given our sample size and design but for 99% power and 5% alpha.\nHint: for v, it is the sample size minus u minus 1 (N - u - 1)\n\npwr.f2.test(u = ?, \n            v = ?, \n            f2 = NULL, \n            sig.level = ?, \n            power = ?)\n\nTo 2 decimals, what is the value of \\(f^2\\) the study would be sensitive to? \n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\npwr.f2.test(u = 3, \n            v = 71029, \n            f2 = NULL, \n            sig.level = .05, \n            power = .99)\n\n\n     Multiple regression power calculation \n\n              u = 3\n              v = 71029\n             f2 = 0.0003673651\n      sig.level = 0.05\n          power = 0.99\n\n\nThe study was incredibly sensitive, where they would detect effects of \\(f^2\\) = .0004 with 99% power.\n\n\n\nThe effect size \\(f^2\\) is a kind of transformed version of \\(R^2\\). You can calculate it through the equation:\n\\(f^2 = \\frac{adj R^2}{1 - adj R^2}\\)\nOr as code:\n\nf2 &lt;- adj_R2/(1 - adj_R2)\n\n\n\n\n\n\n\nTry this\n\n\n\nCalculate the \\(f^2\\) value from the multiple regression model using one of these methods. Try and use the values directly from the model object to avoid typing in the values.\nWhat is the observed effect size (in \\(f^2\\)) for the study to 2 decimal places? \n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\nf2 &lt;- mod_summary$adj.r.squared/(1 - mod_summary$adj.r.squared)\n\nf2\n\n[1] 0.1034697\n\n\n\n\n\nComparing the observed effect size against the effect size the study was sensitive to with 99% power, do you think the study was sufficiently powered? \nYes\nNo"
  },
  {
    "objectID": "14-multiple-regression.html#mulregression-a6",
    "href": "14-multiple-regression.html#mulregression-a6",
    "title": "\n14  Multiple Regression\n",
    "section": "\n14.6 Activity 6: Mean-centering variables",
    "text": "14.6 Activity 6: Mean-centering variables\nAs discussed in the lecture, When you have continuous variables in a regression, it is often sensible to transform them by mean centering. You mean center a predictor X simply by subtracting the mean (X_centered = X - mean(X)). This has two useful consequences:\n\nthe model intercept reflects the prediction for \\(Y\\) at the mean value of the predictor variable, rather than at the zero value of the unscaled variable;\nif there are interactions in the model, any lower-order effects can be given the same interpretation as they receive in ANOVA (main effects, rather than simple effects).\n\nFor categorical predictors with two levels, these become coded as -.5 and .5 (because the mean of these two values is 0).\n\nUse mutate to add two new variables to smart_wb: tothours_c, calculated as a mean-centered version of the tothours predictor; and male_c, recoded as -.5 for female and .5 for male.\nTo create male_c you will need to use if_else(male == 1, .5, -.5) You can read this code as “if the variable male equals 1, recode it as .5, if not, recode it as -.5”.\nFinally, recode male and male_c as factors, so that R knows not to treat them as a real numbers."
  },
  {
    "objectID": "14-multiple-regression.html#mulregression-a7",
    "href": "14-multiple-regression.html#mulregression-a7",
    "title": "\n14  Multiple Regression\n",
    "section": "\n14.7 Activity 7: Visualise the relationship",
    "text": "14.7 Activity 7: Visualise the relationship\n\nReverse-engineer the below plot. Calculate mean well-being scores for each combination of male and tothours, and then create a scatterplot plot that includes separate regression lines for each gender.\nYou may find it useful to refer to the Visualisation chapter.\n\n\n\nHint\n\n\n\ngroup_by() both variables then summarise()\n\ncolour = variable_you_want_different_colours_for\n\n\n\n\n\n\nRelationship between mean wellbeing and smartphone use by gender\n\n\n\nWrite an interpretation of the above plot in plain English.\n\n\nPossible solution\n\nGirls show lower overall well-being compared to boys. In addition, the slope for girls appears more negative than that for boys; the one for boys appears relatively flat. This suggests that the negative association between well-being and smartphone use is stronger for girls."
  },
  {
    "objectID": "14-multiple-regression.html#mulregression-a8",
    "href": "14-multiple-regression.html#mulregression-a8",
    "title": "\n14  Multiple Regression\n",
    "section": "\n14.8 Activity 8: Running the regression",
    "text": "14.8 Activity 8: Running the regression\nNow we’re going to see if there is statistical support for our above interpretation of the graph.\nFor the data in smart_wb, use the lm() function to calculate the multiple regression model:\n\\(Y_i = \\beta_0 + \\beta_1 X_{1i} + \\beta_2 X_{2i} + \\beta_3 X_{3i} + e_i\\)\nwhere\n\n\n\\(Y_i\\) is the well-being score for participant \\(i\\);\n\n\\(X_{1i}\\) is the mean-centered smartphone use variable for participant \\(i\\);\n\n\\(X_{2i}\\) is gender (-.5 = female, .5 = male);\n\n\\(X_{3i}\\) is the interaction between smartphone use and gender (\\(= X_{1i} \\times X_{2i}\\))\n\nThen use summary() to view the results and store this in an object called mod_summary().\n\n\nHint\n\n\nR formulas look like this: y ~ a + b + a:b where a:b means interaction\n\n\n\nThe interaction between smartphone use and gender is shown by the variable \nthours_c\nmale_c\nthours_c:male_c, and this interaction was \nsignificant\nnonsignificant at the \\(\\alpha = .05\\) level.\nTo 2 decimal places, what proportion of the variance in well-being scores does the overall model explain? \nThe p-value for the overall model fit is &lt; 2.2e-16. Is this significant? \nYes\nNo\nWhat is the most reasonable interpretation of these results? \nsmartphone use harms girls more than boys\nsmartphone use harms boys more than girls\nthere is no evidence for gender differences in the relationship between smartphone use and well-being\nsmartphone use was more negatively associated with wellbeing for girls than for boys"
  },
  {
    "objectID": "14-multiple-regression.html#mulregression-a9",
    "href": "14-multiple-regression.html#mulregression-a9",
    "title": "\n14  Multiple Regression\n",
    "section": "\n14.9 Activity 9: Assumption checking",
    "text": "14.9 Activity 9: Assumption checking\nNow it’s time to test those pesky assumptions. The assumptions for multiple regression are the same as simple regression but there is one additional assumption, that of multicollinearity, the idea that predictor variables should not be too highly correlated.\n\nThe outcome/DV is a interval/ratio level data\nThe predictor variable is interval/ratio or categorical (with two levels)\nAll values of the outcome variable are independent (i.e., each score should come from a different participant)\nThe predictors have non-zero variance\nThe relationship between outcome and predictor is linear\nThe residuals should be normally distributed\nThere should be homoscedasticity (homogeneity of variance, but for the residuals)\nMulticollinearity: predictor variables should not be too highly correlated\n\nFrom the work we’ve done so far we know that assumptions 1 - 4 are met and we can use the functions from the performance package again to check the rest, like we did with the simple linear regression chapter.\nOne difference from when we used check_model() previously is that rather than just letting it run all the tests it wants, we’re going to specify which tests, to stop it throwing an error. A word of warning - these assumptions tests will take longer than usual to run, because it’s such a big dataset. The first line of code will run the assumption tests and save it to an object, calling the object name will then display the plots.\n\nassumptions &lt;- check_model(mod, check = c(\"vif\", \"qq\", \"normality\", \"linearity\", \"homogeneity\"))\n\nassumptions\n\n\n\nAssumption plots\n\n\n\nFor assumption 5, linearity, we already know from looking at the scatterplot that the relationship is linear, but the residual plot also confirms this.\nFor assumption 6, normality of residuals, again the residuals look good in both plots and this provides an excellent example of why it’s often better to visualise than rely on statistics because if we use check_normality() which calls the Shapiro-Wilk test:\n\ncheck_normality(mod)\n\nWarning: Non-normality of residuals detected (p &lt; .001).\n\n\nIt tells us that the residuals are not normal, despite the fact that the plots look almost perfect. And that’s because with large sample sizes, any deviation from perfect normality can be flagged as non-normal.\nFor assumption 7, homoscedasticity, the plot is missing the reference line - fun fact, this took us several days of our lives and asking for help on Twitter to figure out. The reason the line isn’t there is because the dataset is so large that is creates a memory issue so we need to create the plot ourselves using code the developers of the package see provided to us on Twitter. The default code would try to draw confidence intervals around the line which is what causes the memory issue, this code removes that with se = FALSE.\nPlease note that with most datasets you wouldn’t have to do this extra step, but it’s a good example that when it comes to programming, it doesn’t matter how long you’ve been doing it, there will always be a problem you haven’t come across and that asking for help is part of the process.\n\nggplot(assumptions$HOMOGENEITY, aes(x, y)) +\n    geom_point2() +\n    stat_smooth(\n      method = \"loess\",\n      se = FALSE,\n      formula = y ~ x,\n    ) +\n    labs(\n      title = \"Homogeneity of Variance\",\n      subtitle = \"Reference line should be flat and horizontal\",\n      y = expression(sqrt(\"|Std. residuals|\")),\n      x = \"Fitted values\"\n    ) \n\n\n\nAdjusted homogeneity plot that will produce reference line\n\n\n\nAgain like normality, the plot isn’t perfect but it is pretty good and another example of why visualisation is better than running statistical tests as we see the same significant result if we run:\n\ncheck_homogeneity(mod)\n\nWarning: Variances differ between groups (Bartlett Test, p = 0.000).\n\n\nFor assumption 8, linearity, again the plot looks fine, and we could also have used the grouped scatterplots above to look at this.\nFinally, for assumption 9, multicollinearity, the plot also indicates no issues but we can also test this statistically using check_collinearity().\nEssentially, this function estimates how much the variance of a coefficient is “inflated” because of linear dependence with other predictors, i.e., that a predictor isn’t actually adding any unique variance to the model, it’s just really strongly related to other predictors. You can read more about this here. Thankfully, VIF is not affected by large samples like the other tests.\nThere are various rules of thumb, but most converge on a VIF of above 2 - 2.5 for any one predictor being problematic.\n\ncheck_collinearity(mod)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTerm\nVIF\nVIF_CI_low\nVIF_CI_high\nSE_factor\nTolerance\nTolerance_CI_low\nTolerance_CI_high\n\n\n\nthours_c\n1.721968\n1.704219\n1.740165\n1.312238\n0.5807308\n0.5746582\n0.5867789\n\n\nmale_c\n1.035552\n1.028488\n1.044369\n1.017621\n0.9656682\n0.9575159\n0.9723014\n\n\nthours_c:male_c\n1.716349\n1.698683\n1.734463\n1.310095\n0.5826319\n0.5765474\n0.5886915"
  },
  {
    "objectID": "14-multiple-regression.html#mulregression-a10",
    "href": "14-multiple-regression.html#mulregression-a10",
    "title": "\n14  Multiple Regression\n",
    "section": "\n14.10 Activity 10: Power and effect size",
    "text": "14.10 Activity 10: Power and effect size\nFinally, we’ll calculate power and effect size as usual.\n\nUsing the code from Power and Effect Size calculate the minimum effect size we could reliably observe given our sample size and design but for 99% power. Report this to 2 decimal places \n\n\n\nWhat is the observed effect size for the study to 2 decimal places? \n\nIs the study sufficiently powered? \nYes\nNo"
  },
  {
    "objectID": "14-multiple-regression.html#mulregression-a11",
    "href": "14-multiple-regression.html#mulregression-a11",
    "title": "\n14  Multiple Regression\n",
    "section": "\n14.3 Reporting the results of multiple linear regression",
    "text": "14.3 Reporting the results of multiple linear regression\nThe same as previous chapters like ANOVA and factorial ANOVA, we can use inline code to help with the write-up. First, copy and paste the code below into white-space in your R Markdown document and then knit. Note that we enter the p-values manually because of the APA “p &lt; .001” formatting.\n\nAll continuous predictors were mean-centered and deviation coding was used for categorical predictors. The results of the regression indicated that the model significantly predicted course engagement (F(`r mod_summary$fstatistic[2]`, `r mod_summary$fstatistic[3] %&gt;% round(2)`) = `r mod_summary$fstatistic[1] %&gt;% round(2)`, p &lt; .001, Adjusted R2 = `r mod_summary$adj.r.squared %&gt;% round(2)`, f^2^ = `r f2%&gt;% round(2)`), accounting for `r (mod_summary$adj.r.squared %&gt;% round(2))*100`% of the variance. Total screen time was a significant negative predictor of wellbeing scores (β = `r ml_model$coefficients[2] %&gt;% round(2)`, *p* &lt; .001, as was gender (β = `r ml_model$coefficients[3] %&gt;% round(2)`, *p* &lt; .001, with girls having lower wellbeing scores than boys. Importantly, there was a significant interaction between screentime and gender (β = `r ml_model$coefficients[4] %&gt;% round(2)`, *p* &lt; .001), smartphone use was more negatively associated with wellbeing for girls than for boys. \n\n\nAll continuous predictors were mean-centered and deviation coding was used for categorical predictors. The results of the regression indicated that the model significantly predicted course engagement (F(3, 7.1029^{4}) = 2450.89, p &lt; .001, Adjusted R2 = 0.09, f2 = 0.1), accounting for 9% of the variance. Total screen time was a significant negative predictor of wellbeing scores (β = -0.77, p &lt; .001, as was gender (β = 5.14, p &lt; .001, with girls having lower wellbeing scores than boys. Importantly, there was a significant interaction between screentime and gender (β = 0.45, p &lt; .001), smartphone use was more negatively associated with wellbeing for girls than for boys."
  },
  {
    "objectID": "14-multiple-regression.html#mulregression-fin",
    "href": "14-multiple-regression.html#mulregression-fin",
    "title": "\n14  Multiple Regression\n",
    "section": "\n14.4 End of Chapter",
    "text": "14.4 End of Chapter\nYou are done!\nNot just with this chapter but with the R/RStudio component of Research Methods 2. The progress that you have made is truly astonishing. Even if you struggled with R/RStudio and have not quite understood every single line of code, what you are capable of with data wrangling and visualisation alone makes you some of the most highly competitive psychology graduates in the world. Try and think of everything you have learnt from week 1 of Research Methods 1 to now. Hopefully, you have proved to yourself you can do this.\nRegardless of whether you continue with quantitative methods and using R/RStudio, remember the more important critical skills that you have learned as part of this process. The next time you see a data set or you see data being talked about in the news, think about all the work that was put into getting the data into the final format. More importantly, think about all the decisions that the researcher needed to make along the way and how that might have affected the outcome.\n\n\n\n\nPrzybylski, A. K., & Weinstein, N. (2017). A Large-Scale Test of the Goldilocks Hypothesis: Quantifying the Relations Between Digital-Screen Use and the Mental Well-Being of Adolescents. Psychological Science, 28(2), 204–215. https://doi.org/10.1177/0956797616678438"
  },
  {
    "objectID": "14-multiple-regression.html#mulregression-sols",
    "href": "14-multiple-regression.html#mulregression-sols",
    "title": "\n14  Multiple Regression\n",
    "section": "\n14.13 Activity solutions",
    "text": "14.13 Activity solutions\n\n14.13.1 Activity 3\n\n\nSolution\n\n\nwemwbs &lt;- wellbeing %&gt;%\n  pivot_longer(names_to = \"var\", values_to = \"score\", -Serial) %&gt;%\n  group_by(Serial) %&gt;%\n  summarise(tot_wellbeing = sum(score))\n\n# sanity check values\n\nwemwbs %&gt;% summarise(mean = mean(tot_wellbeing),\n                     sd = sd(tot_wellbeing),\n                     min = min(tot_wellbeing), \n                     max = max(tot_wellbeing))\n\n\n\n14.13.2 Activity 5\n\n\nSolution\n\n\nsmarttot &lt;- screen2 %&gt;%\n  filter(variable == \"Using Smartphone\") %&gt;%\n  group_by(Serial) %&gt;%\n  summarise(tothours = mean(hours))\n\nsmart_wb &lt;- smarttot %&gt;%\n  filter(tothours &gt; 1) %&gt;%\n  inner_join(wemwbs, \"Serial\") %&gt;%\n  inner_join(pinfo, \"Serial\") \n\n\n\n14.13.3 Activity 6\n\n\nSolution\n\n\nsmart_wb &lt;- smarttot %&gt;%\n  filter(tothours &gt; 1) %&gt;%\n  inner_join(wemwbs, \"Serial\") %&gt;%\n  inner_join(pinfo, \"Serial\") %&gt;%\n  mutate(thours_c = tothours - mean(tothours),\n         male_c = ifelse(male == 1, .5, -.5),\n         male_c = as.factor(male_c),\n         male = as.factor(male))\n\n\n\n14.13.4 Activity 7\n\n\nSolution\n\n\nsmart_wb_gen &lt;- smart_wb %&gt;%\n  group_by(tothours, male) %&gt;%\n  summarise(mean_wellbeing = mean(tot_wellbeing))\n\nggplot(smart_wb_gen, aes(tothours, mean_wellbeing, color = male)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  scale_color_discrete(name = \"Gender\", labels = c(\"Female\", \"Male\"))+\n  scale_x_continuous(name = \"Total hours smartphone use\") +\n  scale_y_continuous(name = \"Mean well-being score\")\n\n\n\n14.13.5 Activity 8\n\n\nSolution\n\n\nmod &lt;- lm(tot_wellbeing ~ thours_c * male_c, smart_wb)\n# alternatively: \n# mod &lt;- lm(tot_wellbeing ~ thours_c + male_c + thours_c:male_c, smart_wb)\n\nmod_summary &lt;- summary(mod)\n\n\n\n14.13.6 Activity 9\n\n\nSolution\n\n\nqqPlot(mod$residuals)\n\n\n\n14.13.7 Activity 10\n\n\nSolution\n\n\npwr.f2.test(u = 3, v = 71029, f2 = NULL, sig.level = .05, power = .99)\nf2 &lt;- mod_summary$adj.r.squared/(1 - mod_summary$adj.r.squared)\n\n\n\n\n\n\nPrzybylski, A. K., & Weinstein, N. (2017). A Large-Scale Test of the Goldilocks Hypothesis: Quantifying the Relations Between Digital-Screen Use and the Mental Well-Being of Adolescents. Psychological Science, 28(2), 204–215. https://doi.org/10.1177/0956797616678438"
  },
  {
    "objectID": "15-dissertation-prep.html",
    "href": "15-dissertation-prep.html",
    "title": "15  Dissertation Preparation",
    "section": "",
    "text": "Now you have completed all the chapters, you have developed a bunch of foundational skills for analysing quantitative data. As a conversion programme, there is only so much content we can fit in, and you might need additional techniques or analyses we have not covered before. So, in this chapter, we will outline some resources which might be useful to you as you tackle your independent research project.\n\nEquivalence testing.\nBayesian statistics.\nGeneralised linear models."
  },
  {
    "objectID": "16-analysis-journey-1.html",
    "href": "16-analysis-journey-1.html",
    "title": "16  Analysis Journey 1: Data Wrangling",
    "section": "",
    "text": "Activity on data wrangling."
  },
  {
    "objectID": "17-analysis-journey-2.html",
    "href": "17-analysis-journey-2.html",
    "title": "17  Analysis Journey 2: Simple Linear Regression",
    "section": "",
    "text": "Activity on simple linear regression."
  },
  {
    "objectID": "18-analysis-journey-3.html",
    "href": "18-analysis-journey-3.html",
    "title": "18  Analysis Journey 3: ANOVA",
    "section": "",
    "text": "Activity on ANOVA."
  },
  {
    "objectID": "19-analysis-journey-4.html",
    "href": "19-analysis-journey-4.html",
    "title": "19  Analysis Journey 4: Multiple Linear Regression.",
    "section": "",
    "text": "Activity on multiple linear regression."
  },
  {
    "objectID": "17-analysis-journey-1.html",
    "href": "17-analysis-journey-1.html",
    "title": "16  Analysis Journey 1: Data Wrangling",
    "section": "",
    "text": "16.1 Task preparation",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Analysis Journey 1: Data Wrangling</span>"
    ]
  },
  {
    "objectID": "18-analysis-journey-2.html",
    "href": "18-analysis-journey-2.html",
    "title": "17  Analysis Journey 2: Simple Linear Regression",
    "section": "",
    "text": "Activity on simple linear regression."
  },
  {
    "objectID": "19-analysis-journey-3.html",
    "href": "19-analysis-journey-3.html",
    "title": "18  Analysis Journey 3: ANOVA",
    "section": "",
    "text": "Activity on ANOVA."
  },
  {
    "objectID": "20-analysis-journey-4.html",
    "href": "20-analysis-journey-4.html",
    "title": "19  Analysis Journey 4: Multiple Linear Regression.",
    "section": "",
    "text": "Activity on multiple linear regression."
  },
  {
    "objectID": "17-analysis-journey-1.html#data-overview",
    "href": "17-analysis-journey-1.html#data-overview",
    "title": "16  Analysis Journey 1: Data Wrangling",
    "section": "16.1 Data overview",
    "text": "16.1 Data overview"
  },
  {
    "objectID": "17-analysis-journey-1.html#tasks",
    "href": "17-analysis-journey-1.html#tasks",
    "title": "16  Analysis Journey 1: Data Wrangling",
    "section": "16.2 Tasks",
    "text": "16.2 Tasks"
  },
  {
    "objectID": "17-analysis-journey-1.html#solution",
    "href": "17-analysis-journey-1.html#solution",
    "title": "16  Analysis Journey 1: Data Wrangling",
    "section": "16.3 Solution",
    "text": "16.3 Solution"
  },
  {
    "objectID": "18-analysis-journey-2.html#data-overview",
    "href": "18-analysis-journey-2.html#data-overview",
    "title": "17  Analysis Journey 2: Simple Linear Regression",
    "section": "17.1 Data overview",
    "text": "17.1 Data overview"
  },
  {
    "objectID": "18-analysis-journey-2.html#tasks",
    "href": "18-analysis-journey-2.html#tasks",
    "title": "17  Analysis Journey 2: Simple Linear Regression",
    "section": "17.2 Tasks",
    "text": "17.2 Tasks"
  },
  {
    "objectID": "18-analysis-journey-2.html#solution",
    "href": "18-analysis-journey-2.html#solution",
    "title": "17  Analysis Journey 2: Simple Linear Regression",
    "section": "17.3 Solution",
    "text": "17.3 Solution"
  },
  {
    "objectID": "19-analysis-journey-3.html#data-overview",
    "href": "19-analysis-journey-3.html#data-overview",
    "title": "18  Analysis Journey 3: ANOVA",
    "section": "18.1 Data overview",
    "text": "18.1 Data overview"
  },
  {
    "objectID": "19-analysis-journey-3.html#tasks",
    "href": "19-analysis-journey-3.html#tasks",
    "title": "18  Analysis Journey 3: ANOVA",
    "section": "18.2 Tasks",
    "text": "18.2 Tasks"
  },
  {
    "objectID": "19-analysis-journey-3.html#solution",
    "href": "19-analysis-journey-3.html#solution",
    "title": "18  Analysis Journey 3: ANOVA",
    "section": "18.3 Solution",
    "text": "18.3 Solution"
  },
  {
    "objectID": "20-analysis-journey-4.html#data-overview",
    "href": "20-analysis-journey-4.html#data-overview",
    "title": "19  Analysis Journey 4: Multiple Linear Regression.",
    "section": "19.1 Data overview",
    "text": "19.1 Data overview"
  },
  {
    "objectID": "20-analysis-journey-4.html#tasks",
    "href": "20-analysis-journey-4.html#tasks",
    "title": "19  Analysis Journey 4: Multiple Linear Regression.",
    "section": "19.2 Tasks",
    "text": "19.2 Tasks"
  },
  {
    "objectID": "20-analysis-journey-4.html#solution",
    "href": "20-analysis-journey-4.html#solution",
    "title": "19  Analysis Journey 4: Multiple Linear Regression.",
    "section": "19.3 Solution",
    "text": "19.3 Solution"
  },
  {
    "objectID": "00-foreword.html#data-sets",
    "href": "00-foreword.html#data-sets",
    "title": "How to use this book",
    "section": "Data sets",
    "text": "Data sets\nAll the skills we teach you in this programme apply to what researchers use in published research. You will develop your skills from RM1 to RM2, and RM2 to your own independent research project for your dissertation. Almost all the demonstrations and activities use real data from published research to reinforce how these skills are the same ones researchers use behind the scenes of their articles. We use a range of data from our own research, open data researchers share with their papers, while others we adapted from the Open Stats Lab who created activities using open data."
  },
  {
    "objectID": "00-foreword.html#data-set-acknowledgements",
    "href": "00-foreword.html#data-set-acknowledgements",
    "title": "How to use this book",
    "section": "Data set acknowledgements",
    "text": "Data set acknowledgements\nAlmost all the demonstrations and activities in this book use real data from published research to reinforce how these skills are the same ones researchers use behind the scenes of their articles. We use a range of data from our own research, open data that researchers share with their papers, and some we adapted from the Open Stats Lab who created activities using open data."
  },
  {
    "objectID": "00-foreword.html#how-to-use-this-book",
    "href": "00-foreword.html#how-to-use-this-book",
    "title": "How to use this book",
    "section": "How to use this book",
    "text": "How to use this book\nWe follow a scaffolding approach in this book to build your skills from following along to independently being able to apply these skills to new scenarios.\nIn each chapter, we first guide you through a set of demonstrations focused on different data skills, highlighting key parts of the output and what it means (just keep in mind we focus on the practical side of doing and interpreting in this book, the course lectures cover the conceptual background). We strongly encourage you to type out the code yourself, as this is good practice for learning to code, but remember you can copy and paste from the book if you need to. Typing the code will seem much slower at first and you will make lots errors, but you will learn much more quickly this way.\nAs you work through the book, you will see technical terms highlighted like console which link to a glossary we have developed as a team. If you hover the cursor over the highlighted word, it will show you a little definition, and you will be able to see a full list of words we highlighted at the bottom of each chapter. There are also different colour-coded boxes to emphasise different content. These provide information, warn you about something, highlight if something is dangerous and you should really pay attention, and try it yourself boxes when we have activities for you to complete.\n\n\n\n\n\n\nNote\n\n\n\nThese boxes have little interesting - but not critical - bits of information.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThese boxes warn you about something important in R / R Studio, so you pay attention when you use it.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThese boxes highlight where you need to be cautious when using or interpreting something, as it might be easy to make an error.\n\n\n\n\n\n\n\n\nTry this\n\n\n\nThese boxes will invite you to try something yourself, like complete independent activities or answer questions.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThese boxes will include small hints or solutions to check your understanding. Here we show the explanations by default, but normally they will be collapsed.\n\n\n\nAfter these demonstrations, we give you little activities and independent tasks using a new data set to test your understanding using interactive questions. This gives you instant feedback on whether you could apply the skills or if there is something you need to check again.\nSome of these activities are what we call “error mode”. You never stop making errors when coding - we still make them all the time - but you get faster at recognising and fixing common sources of error. Hoffman & Elmi (2021) demonstrated incorporating errors in learning materials can be useful to students, so we will give you a few segments of code containing errors that you need to fix. Seeing errors can be one of the most intimidating parts of learning to code, so this activity will normalise making errors and develop your problem solving skills.\nFinally, there are four data analysis journeys we will direct you to at key points throughout the book. We will tell you the end product you are aiming for from a new raw data set we provide, and your job is to break that end product down and identify a list of tasks to get there. Completing an independent data analysis task is the skill set you will need once it comes to assessments and your dissertation, as this is the point where you are the one making decisions.\nIn contrast to assignments, for all of these activities and data analysis journeys we provide solutions at the end of each chapter. No one is going to check whether you tried to figure out an activity yourself, rather than going straight to the solution, but if you copy and paste without thinking, you will learn nothing. Developing data skills and the knowledge that underpins those skills is like learning a language: the more you practice and the more you use it, the better you become."
  },
  {
    "objectID": "00-foreword.html#accompanying-videos",
    "href": "00-foreword.html#accompanying-videos",
    "title": "How to use this book",
    "section": "Accompanying videos",
    "text": "Accompanying videos\nMost of the chapters of this book have an associated video that you can access via Moodle. These videos are there to support you as you get comfortable in your data skills as you can see how someone else interacts with R / R Studio. However, it is important that you use them wisely. You should always try to work through each chapter of the book on your own first, and only then watch the video if you get stuck, or for extra information.\nFinally, this book is a living document. That means occasionally we will make updates to the book such as fixing typos and including additional detail or activities. When we make substantial changes, we will create new support materials such as the videos. However, it would be impossible to record a new video every time we make a minor change to an activity, so you may notice slight differences between the videos and the content of this book. Where there are differences between the book and the video, the book should always be considered the definitive version."
  },
  {
    "objectID": "01-programming-basics.html",
    "href": "01-programming-basics.html",
    "title": "1  Introduction to programming with R/R Studio",
    "section": "",
    "text": "1.1 R and RStudio\nR is a programming language that you will write code in and RStudio is an Integrated Development Environment (IDE) which makes working with R easier. Think of it as knowing English and using a plain text editor like NotePad to write a book versus using a word processor like Microsoft Word. You could do it, but it would not look as good and it would be much harder without things like spell-checking and formatting.\nIn a similar way, you can use R without RStudio but we wouldn not recommend it. The key thing to remember is that although you will do all of your work using RStudio for this course, you are actually using two pieces of software. This means that you will need both, you need to keep both up-to-date, and you should cite both in any work you do (see the Appendix on citing R and RStudio when needed).\nBut first we need to look at starting up R and RStudio. There are two ways you can use R for Psychology as a student here at the University of Glasgow. First, you can use a online version of R and R through your web browser and we will refer to this as the R server. Second, you can download and install R and RStudio for free on your laptop or desktop computer.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to programming with R/R Studio</span>"
    ]
  },
  {
    "objectID": "02-starting-with-data.html#file-structure-and-using-your-working-directory",
    "href": "02-starting-with-data.html#file-structure-and-using-your-working-directory",
    "title": "2  Creating Reproducible Documents",
    "section": "\n2.1 File structure and using your working directory",
    "text": "2.1 File structure and using your working directory\nIn chapter 1, we never worked with files, so you never had to worry about where you put things on your computer. Before we can start working with R Markdown files, we must explain what a working directory is and how your computer knows where to find things. Your working directory is the folder where your computer starts to look for files. It would be able to access files from within that folder and within sub-folders in your working directory, but it would not be able to access folders outside your working directory.\nIn this course, we are going to prescribe a way of working to support an organised file system, helping you to know where everything is and where R will try to save things on your computer and where it will try to save and load things. Once you become more comfortable working with files, you can work in a different way that makes sense to you, but we recommend following our instructions for at least the first few chapters.\n\n2.1.1 Activity 1: Create a folder for all your work\nIn your documents or OneDrive, create a new folder called ResearchMethods1_2. This will be your highest level folder where you will save everything for Research Methods 1 and 2.\n\n\n\n\n\n\nTop tip\n\n\n\nWhen you are a student at the University of Glasgow, you have access to the full Microsoft suite of software. One of those is the cloud-based storage system OneDrive. We heavily recommend using this to save all your work in as it backs up your work online and you could access it from multiple devices.\n\n\nWithin that folder, create two new folders called Assessments and Quant_Fundamentals. In Assessments, you can save all your assessments for this course as you come to them. In Quant_Fundamentals, that is where you will save all your work as you work through this book.\nWithin Quant_Fundamentals, create a new folder called Chapter_02_reproducible_docs. As you work through the book, you will create a new chapter folder each time you start a new chapter and the sub-folders will always be the same. Within Chapter_02_reproducible_docs, create two new folders called data and figures. As a diagram, it should look like Figure 2.1.\n\n\n\n\nFigure 2.1: Prescribed files structure for Research Methods 1 and 2.\n\n\n\n\n\n\n\n\n\nTop tip\n\n\n\nYou might notice in the folder names we avoided using spaces by adding things like underscores (_) or capitalising different words. Historically, spaces in names could cause problems, but now its just slightly easier when file names and folder names do not have spaces in them.\nFor naming files and folders, try and choose something sensible so you know what it refers to. You are trying to balance being as short as possible, while still being immediately identifiable. For example, instead of fundamentals of quantitative analysis, we called it Quant_Fundamentals.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nWhen you create and name folders to use with R / RStudio, Whatever you do, do not call the folder “R”. If you do this, sometimes R has an identity crisis and will not save or load your files properly. It can also really damage your setup of R and lead you to having to reinstall everything. The reason calling your folder “R” can be a problem is R tends to save all the packages in a folder called R. If there is another folder called R, then it gets confused and stops working properly.\n\n\n\n\n\n\n\n\nFile management when using the online server\n\n\n\n\n\nIf we support you to use the online University of Glasgow R Server, working with files is a little different. If you downloaded R / R Studio to your own computer or you are using one of the computers, please ignore this section.\nThe main disadvantage to using the R server is that you will need create folders on the server and then upload and download any files you are working on to and from the server. Please be aware that there is no link between your computer and the R server. If you change files on the server, they will not appear on your computer until you download them from the server, and you need to be very careful when you submit your assessment files that you are submitting the right file. This is the main reason we recommend installing R / RStudio on your computer wherever possible.\nGoing forward throughout this book, if you are using the server, you will need to follow an extra step where you also upload them to the sever. As an example:\n\nLog on to the R server using the link we provided to you.\nIn the file pane, click New folder and create the same structure we demonstrated above.\nDownload ahi-cesd.csv and participant-info.csv into the data folder you created for chapter 2. To download a file from this book, right click the link and select “save link as”. Make sure that both files are saved as “.csv”. Do not open them on your machine as often other software like Excel can change setting and ruin the files.\nNow that the files are stored on your computer, go to RStudio on the server and click Upload then Browse and choose the folder for the chapter you are working on.\nClick Choose file and go and find the data you want to upload.\n\n\n\n\n\n2.1.2 Activity 2: Set the working directory\nOk great, now that we have a folder structure that will keep everything nice and ordered you need to set the working directory by clicking on the top menu, Session &gt;&gt; Set Working Directory &gt;&gt; Choose Directory and then select the relevant folder for this chapter as your working directory.\nNote: Setting the working directory means that you are telling R where the data is that you want to work on. It is also where you are going to save files and output. More often than not, when learning, the most common error is because people have not set the working directory and R does not know where the data is!\nTop tip: One of the first things we always do when we open R in RStudio is set the working directory to where our data is.\n\n\n\n\nSetting the working directory"
  },
  {
    "objectID": "02-starting-with-data.html#r-markdown-for-data-skills-and-portfolio-assignments",
    "href": "02-starting-with-data.html#r-markdown-for-data-skills-and-portfolio-assignments",
    "title": "2  Creating Reproducible Documents",
    "section": "\n2.2 R Markdown for data skills and portfolio assignments",
    "text": "2.2 R Markdown for data skills and portfolio assignments\nNow you know how to navigate files and folders on your computer, we can start working with R Markdown files.\nThroughout this data skills book and related assignments, you will use a worksheet format called R Markdown (abbreviated as .Rmd) which is a great way to create dynamic documents combining regular text and embedded code chunks.\nR Markdown documents are self-contained and fully reproducible, meaning if you have the necessary data, you should be able to run someone else’s analyses. This is an important part of your open science training as one of the reasons we teach data skills this way is that it enables us to share open and reproducible information.\nUsing these worksheets enables you to keep a record of all the code you write as you progress through this book, for data skills assessments we can give you a task to add required code, and in your research reports you can independently process, visualise, and analyse your data all from one file.\nFor more information about R Markdown, feel free to have a look at their main webpage http://rmarkdown.rstudio.com, but for now the key advantage to know about is that it allows you to write code into a document, along with regular text, and then knit it to create your document as either a webpage (html), a PDF, or Word document (.docx).\n\n2.2.1 Activity 3: Open, save, and knit a new R Markdown document\nOpen a new R Markdown document by clicking the ‘new item’ icon and then click ‘R Markdown’ like Figure 2.5.\n\n\n\n\n\n\n\n\n\nFigure 2.5: Creating a new R Markdown document from the menu (left) and setting title, author, date, and output (right).\n\n\nAfter selecting R Markdown, there are different format options you can explore in time, but Select Document and there are four boxes to complete:\n\nTitle: This is the title for the document which will appear at the top of the page. For this chapter, enter 02 Creating Reproducible Documents.\nAuthor: This is where you can add your name or names for multiple people. For this chapter, enter your GUID as this will be good practice for the data skills assignments.\nDate: By default, it adds today’s date, so it will update every time you knit the document. Leave the default so you know when you completed the chapter, but if you untick, you can manually enter a static date.\nDefault Output Format: You have the option to select from html, PDF, and Word. We will demonstrate how to change output format later, so keep html for now as its the most flexible format.\n\nOnce you click OK, this will open a new R Markdown document.\nSave this R Markdown document by clicking File &gt;&gt; Save as from the top menu, and name this file “02_reproducible_docs”. Note the document title and file name are separate, so you still have to name the file when you save it.\nIf you have set the working directory correctly, you should now see this file appear in your file window in the bottom right hand corner like Figure 2.6, alongside your .Rproj file and two folders. .\n\n\n\n\nFigure 2.6: New .Rmd file in your working directory.\n\n\n\nNow you have the default version of the R Markdown file, you have a bunch of text and code to show its capabilities (Figure 2.7).\n\n\n\n\nFigure 2.7: Default text and code in a new R Markdown document.\n\n\n\nWe will demonstrate what it looks like to knit a document. This way, you can check it knits and there are no errors. So, as we add changes in the following activities, you can identify if and when any errors appear and fix them quicker.\nAt the top of your R Markdown window, you should see a Knit button next to a little ball of yarn (Figure 2.8). If you click that, the document will knit and produce a html file.\n\n\n\n\nFigure 2.8: Clicking the knit button on a .Rmd document.\n\n\n\nYou will see a small version of the knitted document appear in the Viewer tab in the bottom right of your screen. You will also see it has created a new file in your working directory. It will have the same name as your R Markdown file, but with .html as the file ending. You can view the knitted document by clicking the “Show in new window” button or opening the file from your folder (Figure 2.9). This should open the document in your default internet browser as websites are created in html.\n\n\n\n\n\n\n\n\n\nFigure 2.9: On the left, you can see a small version of the knitted document in the Viewer tab. On the right, you can see the full version open in your internet browser.\n\n\nNow everything is working and knitting, we can start editing the R Markdown file to add new content.\n\n2.2.2 Activity 4: Create a new code chunk\nLet’s start using your new R Markdown document to combine code and text. Follow these steps:\n\nDelete everything below line 10.\nOn line 12, type “## About me”.\nWith your cursor on line 14, insert a blank code chunk by clicking on the top menu Code &gt;&gt; Insert Chunk or using the shortcut at the top of the R Markdown window that looks like a small green c and select R.\n\nYour document should now look something like Figure 2.10.\n\n\n\n\nFigure 2.10: Creating a new R chunk in your blank R Markdown document\n\n\n\nWhat you have created is called a code chunk. R Markdown assumes anything written outside of a code chunk is just normal text, just like you would have in a text editor like Word. It assumes anything written inside the code chunk is R code. This makes it easy to combine both text and code in one document.\n\n\n\n\n\n\nError mode\n\n\n\nWhen you create a new code chunk you should notice that the grey box starts and ends with three back ticks (), followed by the {r}, and then it ends with three back ticks again (). This is the structure that creates a code chunk. You could actually just type this structure instead of using the Insert approach but we are introducing you to some shortcuts\nOne common mistake is to accidentally delete or more of these back ticks. A useful thing to notice is that code chunks tend to have a different color background - in the default appearance of RStudio a code chunk is grey and the normal text is white. You can use this to look for mistakes. If the colour of certain parts of your Markdown does not look right, check that you have not deleted the backticks.\nRemember it is backticks (i.e. this `) and not single quotes (i.e. not this ’).\n\n\n\n2.2.3 Activity 5: Write some code\nAwesome! You are doing great and learning more than you think you are!\nNow we’re going to use the code examples you read about in Programming Basics to add some code to our R Markdown document.\n\nIn your code chunk write the below code but replace the values of name/age/birthday with your own details). Remember that the four lines of code should all be inside the code chunk!\n\nNote: Text and dates need to be contained in quotation marks, e.g. “my name”. Numerical values are written without quotation marks, e.g. 45.\nTop tip: Missing and/or unnecessary quotation marks are a common cause of code not working - remember this!\n\nname &lt;- \"Emily\" \nage &lt;- 35\ntoday &lt;- Sys.Date()\nnext_birthday &lt;- as.Date(\"2021-07-11\")"
  },
  {
    "objectID": "02-starting-with-data.html#running-code-in-r-markdown",
    "href": "02-starting-with-data.html#running-code-in-r-markdown",
    "title": "2  Creating Reproducible Documents",
    "section": "\n2.3 Running code in R Markdown",
    "text": "2.3 Running code in R Markdown\nBrilliant! We now have code in our code chunk and now we are going to run the code! Running the code just trying to make it work, or seeing if it works! When you’re working in an R Markdown document, there are several ways to run your lines of code.\n\nFirst, one slow option is you can highlight the code you want to run and then click Run &gt;&gt; Run Selected Line(s).\n\n\n\n\n\nSlow method of running code\n\n\n\n\nAlternatively, you can press the green “play” button at the top-right of the code chunk and this will run all lines of code in that chunk.\n\n\n\n\n\nSlightly faster method of running code that runs all lines within the code chunk!\n\n\n\nEven better though is to learn some of the keyboard shortcuts below so it becomes more natural and fluid in your typing and makes your learning easier!\n\nTo run a single line of code, make sure that the cursor is in the line of code you want to run and press ctrl + enter.\nIf you want to run all of the code in the code chunk, press ctrl + shift + enter. Note: When using this last method of running lines of code - by positioning the cursor on the line and using ctrl + enter on your keyboard, note that the cursor does not have to be at any specific point of the line, i.e. it does not have to be at the start, middle or the end, it can literally be anywhere.\n\n\n2.3.1 Activity 6: Run your code\n\nNow run your code using one of the methods above. You should see the variables name, age, today, and next_birthday appear in the environment pane in the top right corner.\nClear out the environment using the broom handle approach we saw in Chapter 1 and try a different method to see which works best for you!\n\n2.3.2 Activity 7: Inline code\nSuperb! Our code works and we know how to run it. But one of the incredible benefits we said about R Markdown is that you can mix text and code. Even better is that you can combined code into a sentence to put specific outputs of your code, like a value, using what is called inline code. Think about a time you’ve had to copy and paste a value or text from one file in to another and you’ll know how easy it can be to make mistakes. Inline code avoids this. It’s easier to show you what inline code does rather than to explain it so let’s have a go.\nFirst, copy and paste this text exactly (do not change anything) to the underneath and outside your code chunk - this will be the white section under the grey code chunk if you are using default views.\n\nMy name is `r name` and I am `r age` years old. \n\nIt is `r next_birthday - today` days until my birthday.\n\nOk so nothing happened there but that is because we have not done the last magic step - in the next activity!\n\n2.3.3 Activity 8: Knitting your file\nAs our final step we are going to knit our file. This means that we’re going to compile (i.e. turn) our code into a document that is more presentable. * From the top menu, click Knit &gt;&gt; Knit to HMTL. R Markdown will now create a new HTML document and it will automatically save this file in your working directory.\nNow let’s look at this outputted HTML document and at the sentence we copied in from Activity 7. As if by magic, that slightly odd bit of text you copied and pasted now appears as a normal sentence with the values pulled in from the objects you created.\nMy name is Emily and I am 35 years old. It is -1104 days until my birthday.\nPretty amazing isn’t it! We’re not going to use inline coding very often in the rest of the course but hopefully you can see just how useful this would be when writing up a report with lots of numbers! R Markdown is an incredibly powerful and flexible format - this book was written using it! The key thing about using inline coding is the structure, i.e. the backtick, followed by the lower case r, then space, then the code, then another backtick. You will get the hang of it as the semester goes on with a little practice.\nThere are a few final things to note about knitting that will be useful for going forward with your data skills learning and assignments:\n\nR Markdown will only knit if your code works - this is a good way of checking for assignments whether you’ve written functioning code!\nYou can choose to knit to a Word document rather than HTML. This can be useful for e.g., sharing with others, however, it may lose some functionality and it probably won’t look as good so we’d recommend always knitting to HTML.\nYou can choose to knit to PDF, however, unless you’re using the server this requires a LaTex installation and is quite complicated. If you don’t already know what LaTex is and how to use it, do not knit to PDF. If you do know how to use LaTex, you don’t need us to give you instructions!\nR will automatically open the knitted HTML file in the viewer, however, you can also navigate to the folder it is stored in and open the HTML file in your web browser (e.g., Chrome or Firefox)."
  },
  {
    "objectID": "02-starting-with-data.html#finished",
    "href": "02-starting-with-data.html#finished",
    "title": "2  Creating Reproducible Documents",
    "section": "\n2.4 Finished",
    "text": "2.4 Finished\nAnd you’re done! On your very first time using R you’ve not only written functioning code but you’ve written a reproducible output! You could send someone else your R Markdown document and they would be able to produce exactly the same HTML document as you, just by pressing knit.\nThe key thing we want you to take away from this chapter is that the data skills that you are going to learn can be broken down into manageable chunks and that is how we are going to teach you to help you learn them. The skills might be very new to a lot of you, but we’re going to take you through it step-by-step. You’ll be amazed at how quickly you can start producing professional-looking data visualisations and analysis.\nIf you have any questions about anything contained in this chapter or in Programming Basics, please remember to ask us!"
  },
  {
    "objectID": "02-starting-with-data.html#test-yourself",
    "href": "02-starting-with-data.html#test-yourself",
    "title": "2  Creating Reproducible Documents",
    "section": "\n2.4 Test yourself",
    "text": "2.4 Test yourself\nTo end the chapter, we have some knowledge check questions to test your understanding of the concepts we covered in the chapter. We then have some error mode tasks to see if you can find the solution to some common errors in the concepts we covered in this chapter.\n\n2.4.1 Knowledge check\nQuestion 1. One of the key first steps when we open RStudio is to:\n\nset your working directory/open a projectput on some music as we will be here a whilecheck out the newsmake a coffee\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nOne of the most common issues we see where code does not work the first time is because people have forgotten to set the working directory. The working directory is the starting folder on your computer where you want to save any files, any output, or contains your data. R/RStudio needs to know where you want it to look, so you must either manually set your working directory, or open a .Rproj file.\n\n\n\nQuestion 2. When using the default environment color settings for RStudio, what color would the background of a code chunk be in R Markdown? \nwhite\nred\ngreen\ngrey\nQuestion 3. When using the default environment color settings for RStudio, what color would the background of normal text be in R Markdown? \nwhite\nred\ngreen\ngrey\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nAssuming you have not changed any of the settings in RStudio, code chunks will tend to have a grey background and normal text will tend to have a white background. This is a good way to check that you have closed and opened code chunks correctly.\n\n\n\nQuestion 4. Code chunks start and end with:\n\nthree single quotesthree backticksthree double quotesthree single clefs\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nCode chunks always take the same general format of three backticks followed by curly parentheses and a lower case r inside the parentheses ({r}). People often mistake these backticks for single quotes but that will not work. If you have set your code chunk correctly using backticks, the background color should change to grey from white\n\n\n\nQuestion 5. Inline code is:\n\nwhere you nicely organise your code in a line.where you make sure all the code is nicely indented from the side.a fancy way of saying you have written good code.an approach of integrating code and text in a sentence outside of a code chunk.\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nInline coding is an incredibly useful approach for merging text and code in a sentence outside of a code chunk. It can be really useful for when you want to add values from your code directly into your text. If you copy and paste values, you can easily create errors, so it’s useful to add inline code where possible.\n\n\n\n\n2.4.2 Error mode\nThe following questions are designed to introduce you to making and fixing errors. For this topic, we focus on R Markdown and potential errors in using code blocks and inline code. Remember to keep a note of what kind of error messages you receive and how you fixed them, so you have a bank of solutions when you tackle errors independently.\nCreate and save a new R Markdown file by following the instructions in activity 3 and activity 4. You should have a blank R Markdown file below line 10. Below, we have several variations of a code chunk and inline code errors. Copy and paste them into your R Markdown file, click knit, and look at the error message you receive. See if you can fix the error and get it working before checking the answer.\nQuestion 5. Copy the following text/code/code chunk into your R Markdown file and press knit. You should receive an error like Error while opening file. No such file or directory.\ncity &lt;- \"Glasgow\"\n\n```{r}\n\n```\n`r city` is a city in Scotland. \n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nHere, we wrote city &lt;- \"Glasgow\" outside the code chunk. So, when we try and knit, it is not evaluated as code, and city does not exist as an object to be referenced in inline code. If you copy city &lt;- \"Glasgow\" into the code chunk and press knit, it should work.\n\n\n\nQuestion 6. Copy the following text/code/code chunk into your R Markdown file and press knit. You should receive an error like Error in parse(): ! attempt to use zero-length variable name which is not very helpful for diagnosing the problem.\n\n```{r}\ncity &lt;- \"Glasgow\"\n``\n\n`r city` is a city in Scotland. \n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nHere, we missed a final backtick in the code chunk. You might have noticed all the text had a grey background, so R Markdown thought everything was code. So, when it reached the inline code and text, it tried interpreting it as code and caused the error. If you add the final backtick to the code chunk, you should be able to click knit successfully.\n\n\n\nQuestion 7. Copy the following text/code/code chunk into your R Markdown file and press knit. You should receive an error like Error while opening file. No such file or directory.\n\n`r city` is a city in Scotland. \n\n```{r}\ncity &lt;- \"Glasgow\"\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nHere, we tried using inline code before the code chunk. R Markdown runs the code from start to finish in a fresh environment. We tried referencing city in inline code, but R Markdown did not know it existed yet. To fix it, you need to move the inline code below the code chunk, so you create city before referencing it in inline code.\n\n\n\nQuestion 8. Copy the following text/code/code chunk into your R Markdown file and press knit. This…works?\n\n```{r}\ncity &lt;- \"Glasgow\"\n```\n\n`city` is a city in Scotland. \n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nHere, we have a sneaky kind of “error” where it knits, but it is not doing what we wanted it to do. In the inline code part, we only added code formatting city, we did not add the r to get R Markdown to interpret it as R code:\n\n`r city`\n\nIf you add the r after the first backtick, it should knit and add the city object in."
  },
  {
    "objectID": "02-starting-with-data.html#file-structure-working-directories-and-r-projects",
    "href": "02-starting-with-data.html#file-structure-working-directories-and-r-projects",
    "title": "2  Creating Reproducible Documents",
    "section": "\n2.1 File structure, working directories, and R Projects",
    "text": "2.1 File structure, working directories, and R Projects\nIn chapter 1, we never worked with files, so you did not have to worry about where you put things on your computer. Before we can start working with R Markdown files, we must explain what a working directory is and how your computer knows where to find things.\nYour working directory is the folder where your computer starts to look for files. It would be able to access files from within that folder and within sub-folders in your working directory, but it would not be able to access folders outside your working directory.\nIn this course, we are going to prescribe a way of working to support an organised file system, helping you to know where everything is and where R will try to save things on your computer and where it will try to save and load things. Once you become more comfortable working with files, you can work in a different way that makes sense to you, but we recommend following our instructions for at least RM1 as the first course.\n\n2.1.1 Activity 1: Create a folder for all your work\nIn your documents or OneDrive, create a new folder called ResearchMethods1_2. This will be your highest level folder where you will save everything for Research Methods 1 and 2.\n\n\n\n\n\n\nTop tip\n\n\n\nWhen you are a student at the University of Glasgow, you have access to the full Microsoft suite of software. One of those is the cloud storage system OneDrive. We heavily recommend using this to save all your work in as it backs up your work online and you can access it from multiple devices.\n\n\nWithin that folder, create two new folders called Assessments and Quant_Fundamentals. In Assessments, you can save all your assessments for RM1 and RM2 as you come to them. In Quant_Fundamentals, that is where you will save all your work as you progress through this book.\nWithin Quant_Fundamentals, create a new folder called Chapter_02_reproducible_docs. As you work through the book, you will create a new chapter folder each time you start a new chapter and the sub-folders will always be the same. Within Chapter_02_reproducible_docs, create two new folders called data and figures. As a diagram, it should look like Figure 2.1.\n\n\n\n\nFigure 2.1: Prescribed file structure for RM 1 and RM 2.\n\n\n\n\n\n\n\n\n\nHow to name files and folders\n\n\n\nYou might notice in the folder names we avoided using spaces by adding things like underscores _ or capitalising different words. Historically, spaces in folder/file names could cause problems for code, but now it’s just slightly easier when file names and folder names do not have spaces in them.\nFor naming files and folders, try and choose something sensible so you know what it refers to. You are trying to balance being as short as possible, while still being immediately identifiable. For example, instead of fundamentals of quantitative analysis, we called it Quant_Fundamentals.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nWhen you create and name folders to use with R / RStudio, whatever you do, do not call the folder “R”. If you do this, sometimes R has an identity crisis and will not save or load your files properly. It can also really damage your setup and require you to reinstall everything as R tends to save all the packages in a folder called R. If there is another folder called R, then it gets confused and stops working properly.\n\n\n\n\n\n\n\n\nFile management when using the online server\n\n\n\n\n\nIf we support you to use the online University of Glasgow R Server, working with files is a little different. If you downloaded R / RStudio to your own computer or you are using one of the computers, please ignore this section.\nThe main disadvantage to using the R server is that you will need create folders on the server and then upload and download any files you are working on to and from the server. Please be aware that there is no link between your computer and the R server. If you change files on the server, they will not appear on your computer until you download them from the server, and you need to be very careful when you submit your assessment files that you are submitting the right file. This is the main reason we recommend installing R / RStudio on your computer wherever possible.\nGoing forward throughout this book, if you are using the server, you will need to follow an extra step where you also upload them to the sever. As an example:\n\nLog on to the R server using the link we provided to you.\nIn the file pane, click New folder and create the same structure we demonstrated above.\nDownload ahi-cesd.csv and participant-info.csv into the data folder you created for chapter 2. To download a file from this book, right click the link and select “save link as”. Make sure that both files are saved as “.csv”. Do not open them on your machine as often other software like Excel can change setting and ruin the files.\nNow that the files are stored on your computer, go to RStudio on the server and click Upload then Browse and choose the folder for the chapter you are working on.\nClick Choose file and go and find the data you want to upload.\n\n\n\n\n\n2.1.2 Manually setting the working directory\nNow that you have a folder structure that will keep everything nice and organised, we will demonstrate how you can manually set the working directory. If you open RStudio, you can check where the current working directory is by typing the function getwd() into the console and pressing enter/return. That will show you the current file path R is using to navigate files. If you look at the Files window in the bottom right, this will also show you the files and folders available from your working directory.\nIf you click on the top menu Session &gt;&gt; Set Working Directory &gt;&gt; Choose Directory..., (Figure 2.2) you can navigate through your documents or OneDrive until you can select Chapter_02_reproducible_docs. Click open and that will set the folder as your working directory. You can double check this worked by running getwd() again in the console.\n\n\n\n\nFigure 2.2: Manually setting the working directory.\n\n\n\n\n2.1.3 Activity 2 - Creating an R Project\nKnowing how to check and manually set your working directory is useful, but there is a more efficient way of setting your working directory alongside organised file management. You are going to create something called an R Project.\nTo create a new project for the work you will do in this chapter (Figure 2.3):\n\nClick on the top menu and navigate to File &gt;&gt; New Project....\nYou have the option to select from New Directory, Existing Directory, or Version Control. You already created a folder for Chapter_02_reproducible_docs, so select Existing Directory.\nClick Browse… next to Project working directory to select the folder you want to create the project in.\nWhen you have navigated to Chapter_02_reproducible_docs for this chapter, click Open and then Create Project.\n\n\n\n\n\n\n\n\n\n\nFigure 2.3: Starting a new project.\n\n\nRStudio will restart itself and open with this new project directory as the working directory. You should see something like Figure 2.4.\n\n\n\n\nFigure 2.4: RStudio screen in a new project in your chapter 2 folder.\n\n\n\nIn the files tab in the bottom right window, you will see all the contents in your project directory. You can see your two sub-folders for data and figures and a file called Chapter_02_reproducible_docs.Rproj. This is a file that contains all of the project information. When you come back to this project after closing down RStudio, if you double click on the .Rproj file, it will open up your project and have your working directory all set up and ready to go.\n\n\n\n\n\n\nWarning\n\n\n\nIn each chapter, we will repeat these instructions at the start to prescribe this file structure, but when you create your own folders and projects, do not ever save a new project inside another project. This can cause some hard to resolve problems. For example, it would be fine to create a new project within the Quant_Fundamentals folder as we will do for each new chapter, but should never create a new project within the Chapter_02_reproducible_docs folder."
  },
  {
    "objectID": "00-foreword.html#intended-learning-outcomes-ilos",
    "href": "00-foreword.html#intended-learning-outcomes-ilos",
    "title": "How to use this book",
    "section": "Intended learning outcomes (ILOs)",
    "text": "Intended learning outcomes (ILOs)\nBy the end of the courses associated with this book, you will be able to:\n\nWrite reproducible reports using R Markdown.\nClean and wrangle data into appropriate forms for analysis.\nVisualise data using a range of plots.\nConduct and interpret a core set of statistical tests from the general linear model (regression, ANOVA).\n\n\n\n\n\nHoffman, H. J., & Elmi, A. F. (2021). Do Students Learn More from Erroneous Code? Exploring Student Performance and Satisfaction in an Error-Free Versus an Error-full SAS® Programming Environment. Journal of Statistics and Data Science Education, 0(0), 1–13. https://doi.org/10.1080/26939169.2021.1967229"
  },
  {
    "objectID": "02-starting-with-data.html#creating-and-navigating-r-markdown-documents",
    "href": "02-starting-with-data.html#creating-and-navigating-r-markdown-documents",
    "title": "2  Creating Reproducible Documents",
    "section": "\n2.2 Creating and navigating R Markdown documents",
    "text": "2.2 Creating and navigating R Markdown documents\nNow you know how to navigate files and folders on your computer, we can start working with R Markdown files.\nThroughout this data skills book and related assignments, you will use a file format called R Markdown (abbreviated as .Rmd) which is a great way to create dynamic documents combining regular text and embedded code chunks.\nR Markdown documents are self-contained and fully reproducible, meaning if you have the necessary data, you should be able to run someone else’s analyses. This is an important part of your open science training as one of the reasons we teach data skills this way is that it enables us to share open and reproducible information.\nUsing these worksheets enables you to keep a record of all the code you write as you progress through this book (as well as any notes to help yourself), for data skills assessments we can give you a task to add required code, and in your research reports you can independently process, visualise, and analyse your data all from one file.\nFor more information about R Markdown, feel free to have a look at their main webpage http://rmarkdown.rstudio.com, but for now the key advantage to know about is that it allows you to write code into a document, along with regular text, and then knit it to create your document as either a webpage (html), a PDF, or Word document (.docx).\n\n2.2.1 Activity 3: Open, save, and knit a new R Markdown document\nOpen a new R Markdown document by clicking the ‘new item’ icon and then click ‘R Markdown’ like Figure 2.5.\n\n\n\n\n\n\n\n\n\nFigure 2.5: Creating a new R Markdown document from the menu (left) and setting title, author, date, and output (right).\n\n\nAfter selecting R Markdown, there are different format options you can explore in time, but Select Document and there are four boxes to complete:\n\nTitle: This is the title for the document which will appear at the top of the page. For this chapter, enter 02 Creating Reproducible Documents.\nAuthor: This is where you can add your name or names for multiple people. For this chapter, enter your GUID as this will be good practice for the data skills assignments.\nDate: By default, it adds today’s date, so it will update every time you knit the document. Leave the default so you know when you completed the chapter, but if you untick, you can manually enter a static date.\nDefault Output Format: You have the option to select from html, PDF, and Word. We will demonstrate how to change output format in a later chapter, so keep html for now as it’s the most flexible format.\n\nOnce you click OK, this will open a new R Markdown document.\nSave this R Markdown document by clicking File &gt;&gt; Save as from the top menu, and name this file “02_reproducible_docs”. Note the document title and file name are separate, so you still have to name the file when you save it.\nIf you have set the working directory correctly, you should now see this file appear in your Files window in the bottom right hand corner like Figure 2.6, alongside your .Rproj file and two folders.\n\n\n\n\nFigure 2.6: New .Rmd file in your working directory.\n\n\n\nNow you have the default version of the R Markdown file, you have a bunch of text and code to show its capabilities (Figure 2.7).\n\n\n\n\nFigure 2.7: Default text and code in a new R Markdown document.\n\n\n\nWe will now demonstrate what it looks like to knit a document. This means that we are going to compile (i.e., turn) our code into a document that is more presentable. This way, you can check it knits and there are no errors. So, as we add changes in the following activities, you can identify if and when any errors appear and fix them quicker.\nAt the top of your R Markdown window, you should see a Knit button next to a little ball of yarn (Figure 2.8). If you click that, the document will knit and produce a html file.\n\n\n\n\nFigure 2.8: Clicking the knit button on a .Rmd document.\n\n\n\nYou will see a small version of the knitted document appear in the Viewer tab in the bottom right of your screen. You will also see it has created a new file in your working directory. It will have the same name as your R Markdown file, but with .html as the file ending. You can view the knitted document by clicking the “Show in new window” button or opening the file from your folder (Figure 2.9). This should open the document in your default internet browser as websites are created in html.\n\n\n\n\n\n\n\n\n\nFigure 2.9: On the left, you can see a small version of the knitted document in the Viewer tab. On the right, you can see the full version open in your internet browser.\n\n\nNow everything is working and knitting, we can start editing the R Markdown file to add new content.\n\n2.2.2 Activity 4: Create a new code chunk\nLet’s start using your new R Markdown document to combine code and text. Follow these steps:\n\nDelete everything below line 10.\n\n\n\n\n\n\n\nWhat does the {r setup} chunk do?\n\n\n\n\n\nAt the moment, you do not need to worry about the code chunk between lines 8 and 10. We are slowly introducing you to different features in R Markdown as it’s easier to understand by doing, rather than giving you a list of explanations.\nIf you are really curious though, this setting forces R Markdown to show both the code and output for all code chunks. When we add code shortly, if you change it to echo = FALSE, it will only show the output and not the code.\n\n\n\n\nOn line 12, type “## About me”.\nWith your cursor on line 14, insert a blank code chunk by clicking on the top menu Code &gt;&gt; Insert Chunk or using the shortcut at the top of the R Markdown window that looks like a small green c and select R.\n\nYour document should now look something like Figure 2.10.\n\n\n\n\nFigure 2.10: Creating a new R chunk in your blank R Markdown document\n\n\n\nWhat you have created is called a code chunk. R Markdown assumes anything written outside of a code chunk is just normal text, just like you would have in a text editor like Word. It assumes anything written inside the code chunk is R code. This makes it easy to combine both text and code in one document.\n\n\n\n\n\n\nError mode\n\n\n\nWhen you create a new code chunk, you should notice that the grey box starts and ends with three back ticks (```), followed by the {r}, and then it ends with three back ticks again. This is the structure that creates a code chunk. You could actually just type this structure instead of using the Insert approach but we are introducing you to some shortcuts\nOne common mistake is to accidentally delete one or more of these back ticks. A useful thing to notice is that code chunks tend to have a different color background - in the default appearance of RStudio a code chunk is grey and the normal text is white. You can use this to look for mistakes. If the colour of certain parts of your Markdown does not look right, check that you have not deleted the backticks.\nRemember it is backticks (i.e. this `) and not single quotes (i.e. not this ’).\n\n\n\n\n\n\n\n\nMarkdown language\n\n\n\nWhen you typed “## About me”, you might notice the two hashes. You will see the effect of this shortly, but this is using Markdown language to add document formatting. Markdown is a type of formatting language, so instead of using buttons to add features like you would in Word, you add symbols which will produce different features when you knit the document.\nThe hashes create headers. One (#) creates a first level header (larger text), two (##) creates a second level header, and so on. Make sure there is a space between the text and hash or it will not knit properly.\nAs we progress through the book, we will slowly introduce you to different Markdown features, but you can see the RStudio Markdown Basics page if you are interested.\n\n\n\n2.2.3 Activity 5: Write some code\nNow we are going to use the code examples you read about in Chapter 1 - Introduction to programming with R/R Studio - to add some code to our R Markdown document.\nIn your code chunk, write the code below but replace the values of name/age/birthday with your own details). Remember that the four lines of code should all be inside the code chunk.\nNote: Text and dates need to be contained in quotation marks, e.g., “my name”. Numerical values are written without quotation marks, e.g., 45.\n\nname &lt;- \"James\" \nage &lt;- 30\ntoday &lt;- Sys.Date()\nnext_birthday &lt;- as.Date(\"2025-02-18\") # Year, month, day format\n\n\n\n\n\n\n\nError mode\n\n\n\nMissing and/or unnecessary quotation marks are a common cause of code not working. For example, if you try and type name &lt;- James, R will try and look for an object called James and throw an error since there is not an object called that. When you add quotation marks, R recognises you are storing a character.\n\n\n\n2.2.4 Activity 6: Run your code\nWe now have code in our code chunk and now we are going to run the code. Running the code just means making it do what you told it, such as creating objects or using functions. Remember you need to write the code first, then tell RStudio to run the code.\nWhen you are working in an R Markdown document, there are several ways to run your lines of code.\n\nOne option is you can highlight the code you want to run and then click Run &gt;&gt; Run Selected Line(s) (Figure 2.11).\n\n\n\n\n\nFigure 2.11: Slower method of running code by highlighting and clicking Run Selected Line(s).\n\n\n\n\nYou can press the green “play” button at the top-right of the code chunk and this will run all lines of code in that chunk (Figure 2.12).\n\n\n\n\n\nFigure 2.12: Slightly faster method of running all code in a chunk by clicking the green “play” button.\n\n\n\n\nThere are keyboard shortcuts to run code which will be the fastest as you learn and use RStudio more frequently. For example, to run a single line of code, make sure that the cursor is in the line of code (it can be anywhere on the line) you want to run and press ctrl + enter (command + return on a Mac).\n\n\n\n\n\n\n\nKeyboard shortcuts\n\n\n\nThere are loads of keyboard shortcuts, but you might only use a handful to speed up your day-to-day tasks. For a full list, look in the top menu Help &gt;&gt; Keyboard shortcuts help.\n\n\nNow run your code using one of the methods above. You should see the variables name, age, today, and next_birthday appear in the environment pane in the top right corner.\n\n\n\n\n\n\nTry this\n\n\n\nClear out the environment using the broom handle approach we saw in Chapter 1 and try a different method to see which works best for you.\n\n\n\n2.2.5 Activity 7: Inline code\nYour code works and you now know how to run it, but one of the incredible benefits we said about R Markdown is that you can mix text and code. Even better is the ability to combine code with text to put specific outputs of your code, like a value, using inline code.\nThink about a time you have had to copy and paste a value or text from one file into another and you will know how easy it can be to make mistakes or find the origin of your mistake. Inline code avoids this. It is easier to show you what inline code does rather than to explain it so let us have a go.\nFirst, copy and paste this text exactly (do not change anything) to underneath and outside your code chunk:\n\nMy name is `r name` and I am `r age` years old. \n\nIt is `r next_birthday - today` days until my birthday.\n\nYour .Rmd should look like Figure 2.13 but nothing will happen yet. Unlike code chunks, you cannot run inline code. You need to knit your document for it to do it’s magic.\n\n\n\n\nFigure 2.13: Complete .Rmd file with your about me section and inline code.\n\n\n\n\n\n\n\n\n\nHow does inline code work?\n\n\n\n\n\nInline code has the following form:\n\n`r object`\n\nor\n\n`r function(...)`\n\nHere, we are using the first version where we are referencing an object we already created. This is normally a good idea if you have a long function to run as it’s easier to spot mistakes in a code chunk than inline code.\nYou will see it has the form of a backtick (`), r and a space, the object/function you want to reference, and a final backtick. When the R Markdown file knits, it sees the r and recognises it as inline code and uses the object or function.\nIf you just write the two backticks without the r, it will just add code formatting and not produce inline code.\n\n\n\n\n2.2.6 Activity 8: Knitting your file\nAs our final step in this part, we are going to knit our file again to see how it looks now. So, click the Knit button to regenerate your knitted .html version.\nIf you look at the knitted .html document in the Viewer tab or in your browser, you should see the sentence we copied in from Activity 7. As if by magic, that slightly odd bit of text you copied and pasted now appears as a normal sentence with the values pulled in from the objects you created:\nMy name is James and I am 30 years old. It is 202 days until my birthday.\nR Markdown is an incredibly powerful and flexible format, we wrote this whole book using it! There are a few final things to note about knitting that will be useful going forward for your data skills learning and assessments:\n\nR Markdown will only knit if your code works. If you have an error, it will stop and tell you to fix the error before you can click knit and try again. This is a good way of checking whether you have written functioning code in your assessments.\nWhen you knit an R Markdown document, it runs the code from the start of the document to the end in order, and in a fresh session. This means it cannot access your environment, just the objects you create within that R Markdown. One common error can be writing and running code as you work on the document, but the code chunks are in the wrong order, or you created an object in the console but not in the code chunks. This means R Markdown would not know the object exists yet, or it does not have access to it at all.\nYou can choose to knit to a Word document rather than HTML. This can be useful for sharing with others or adding further edits, but you might lose some functionality. By default, html looks good and is accessible, so that will be our default throughout this book, but look out for our instructions on what output format we want your assessments in.\nYou can choose to knit to PDF, however, unless you are using the server this requires a LaTeX installation and can be quite complicated. If you do not already know what LaTeX is and how to use it, we do not recommend trying to knit to PDF just yet. If you do know how to use LaTeX, you probably do not need us to give you instructions!\n\nWe will test some of these warnings in error mode in the test yourself section, but we have one final demonstration for how R Markdown files support reproducibility."
  },
  {
    "objectID": "02-starting-with-data.html#demonstrating-reproducibility",
    "href": "02-starting-with-data.html#demonstrating-reproducibility",
    "title": "2  Creating Reproducible Documents",
    "section": "\n2.3 Demonstrating reproducibility",
    "text": "2.3 Demonstrating reproducibility\nAt the start of this chapter, we plugged the benefits of reproducible research as the ability to produce the same result for different people using the same software on different computers. We are going to end the chapter on a demonstration of this by giving you an R Markdown document and data. You should be able to click knit and see the results without editing anything. We do not expect you to understand the code included in it, we are previewing the skills you will develop over the next four chapters on visualisation and data wrangling.\n\n2.3.1 Activity 9 - Knit the reproducibility demonstration document\nPlease follow these steps and you should be able to knit the document without editing anything. Make sure you are still in your Chapter_02_reproducible_docs folder. If you are coming back to this activity, remember to set your working directory by opening the .Rproj file.\n\nIf you are working on your own computer, make sure you installed the tidyverse package. Please refer to Chapter 1 - Activity 3 if you have not completed this step yet. If you are working on a university computer or the online server, you do not need to complete this step as tidyverse will already be installed.\nDownload the R Markdown document through the following link: 02_reproducibility_demo.Rmd. To download a file from this book, right click the link and select “save link as”, or just clicking the link will save the file to your Downloads. Save or copy the file to your Chapter_02_reproducible_docs folder.\nDownload these two data files. Data file one: ahi-cesd.csv. Data file two: participant-info.csv. Right click the links and select “save link as”, or clicking the links will save the files to your Downloads. Make sure that both files are saved as “.csv”. Do not open them on your machine as often other software like Excel can change setting and ruin the files. Save or copy the file to your data/ folder within Chapter_02_reproducible_docs.\n\nAt this point, you should have “02_reproducibility_demo.Rmd” within your Chapter_02_reproducible_docs folder. You should have “ahi-cesd.csv” and “participant_info.csv” in the data/ folder within Chapter_02_reproducible_docs.\nIf you open “02_reproducibility_demo.Rmd” and followed all the steps above, you should be able to click knit. This will turn the R Markdown file into a knitted html file, showing some data wrangling, summary statistics, and two graphs (Figure 2.14). In the next chapter, you will learn how to write this code yourself, starting with creating graphs.\n\n\n\n\n\n\n\n\n\nFigure 2.14: You should see the reproducibility demonstration as the .Rmd (left) and be able to knit it into a html file (right).\n\n\nIf you have any questions or problems about anything contained in this chapter, please remember you are always welcome to post on the course Teams channel, attend a GTA support session, or attend the office hours of one of the team."
  },
  {
    "objectID": "02-starting-with-data.html",
    "href": "02-starting-with-data.html",
    "title": "2  Creating Reproducible Documents",
    "section": "",
    "text": "2.1 File structure, working directories, and R Projects\nIn chapter 1, we never worked with files, so you did not have to worry about where you put things on your computer. Before we can start working with R Markdown files, we must explain what a working directory is and how your computer knows where to find things.\nYour working directory is the folder where your computer starts to look for files. It would be able to access files from within that folder and within sub-folders in your working directory, but it would not be able to access folders outside your working directory.\nIn this course, we are going to prescribe a way of working to support an organised file system, helping you to know where everything is and where R will try to save things on your computer and where it will try to save and load things. Once you become more comfortable working with files, you can work in a different way that makes sense to you, but we recommend following our instructions for at least RM1 as the first course.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Creating Reproducible Documents</span>"
    ]
  },
  {
    "objectID": "02-starting-with-data.html#end-of-chapter",
    "href": "02-starting-with-data.html#end-of-chapter",
    "title": "2  Creating Reproducible Documents",
    "section": "\n2.6 End of chapter",
    "text": "2.6 End of chapter\nWell done on reaching the end of the second chapter! This was another long chapter as we had to cover a range of foundational skills to prepare you for learning more of the coding element in future chapters.\nThe next chapter builds on all the skills you have developed so far in R programming and creating reproducible documents to focus on something more tangible: data visualisation in R to create plots of your data."
  },
  {
    "objectID": "01-programming-basics.html#end-of-chapter",
    "href": "01-programming-basics.html#end-of-chapter",
    "title": "1  Introduction to programming with R/R Studio",
    "section": "\n1.10 End of chapter",
    "text": "1.10 End of chapter\nWell done on reaching the end of the first chapter! This was one of the longest chapters in the book to introduce you to several foundational concepts of coding in R and RStudio. The next chapter builds on these skills to produce something a little more concrete by showing you how to create reproducible documents."
  },
  {
    "objectID": "03-intro-data-viz.html",
    "href": "03-intro-data-viz.html",
    "title": "3  Introduction to Data Visualisation",
    "section": "",
    "text": "3.1 Chapter preparation",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to Data Visualisation</span>"
    ]
  },
  {
    "objectID": "03-intro-data-viz.html#ggplot2-and-the-layer-system",
    "href": "03-intro-data-viz.html#ggplot2-and-the-layer-system",
    "title": "3  Introduction to Data Visualisation",
    "section": "\n3.3 ggplot2 and the layer system",
    "text": "3.3 ggplot2 and the layer system\nThere are multiple approaches to data visualisation in R but we will use ggplot2 which uses a layered grammar of graphics where you build up plots in a series of layers. You can think of it as building a picture with multiple elements that sit over each other.\nFigure 3.2 from Nordmann et al. (2022) demonstrates the idea of building up a plot by adding layers. One function creates the first layer, the basic plot area, and you add functions and arguments to add additional layers such as the data, the labels, the colors etc. If you are used to making plots in other software, this might seem a bit odd at first, but it means that you can customise each layer separately to make complex and beautiful figures with relative ease.\nYou can get a sense of what plots are possible from the website data-to-viz, but we will build up your data visualisation skills over the RM1 and RM2 courses.\n\n\n\n\nFigure 3.2: Building a figure using the ggplot2 layering system from Nordmann et al. (2022)."
  },
  {
    "objectID": "03-intro-data-viz.html#histogram",
    "href": "03-intro-data-viz.html#histogram",
    "title": "3  Introduction to Data Visualisation",
    "section": "\n3.4 Histogram",
    "text": "3.4 Histogram\nWe are going to plot the distribution of participant age in a histogram, and add layers one-by-one to demonstrate how the plot is built step-by-step.\nStep 1: This code tells R to access the ggplot function. The first argument tells R to plot the dat dataframe. In the aes function, you specify the aesthetics of the plot, such as the axes and colours. What you need to specify depends on the plot you want to make (you’ll learn more about this later) - for a basic histogram you only need to specify the x-axis (the y-axis will automatically be counts).\n\nggplot(summarydata, aes(x = age))\n\n\n\n\n\n\n\nStep 2: You can see that the code above produces an empty plot - that’s because we haven’t specified which type of plot we want to make. We’ll do this by adding another layer: geom_histogram(). Geom is an expression of the type of plot you want to create.\n\nggplot(summarydata, aes(x = age)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nStep 3: By adding a new layer we can change the axis names:\n\nggplot(summarydata, aes(x = age)) +\n  geom_histogram()+\n  scale_x_continuous(\"Age\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nStep 4: We can also change the theme of the plot:\n\nggplot(summarydata, aes(x = age)) +\n  geom_histogram()+\n  scale_x_continuous(\"Age\")+\n  theme_bw()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "03-intro-data-viz.html#density-plot",
    "href": "03-intro-data-viz.html#density-plot",
    "title": "3  Introduction to Data Visualisation",
    "section": "\n3.5 Density plot",
    "text": "3.5 Density plot\nThe layer system makes it easy to create new types of plots by adapting existing recipes. For example, rather than creating a histogram, we can create a smoothed density plot by calling geom_density() rather than geom_histogram(). The rest of the code remains identical.\n\nggplot(summarydata, aes(x = age)) +\n  geom_density()+\n  scale_x_continuous(name = \"Age\")+\n  theme_bw()\n\n\n\nDensity plot of age.\n\n\n\nThis is going to be a problem because whilst the different categories within sex, educ, and income are represented by numbers, we don’t want to treat them as such because they are categories, or what we call factors. So to get around this, we need to convert these variables into factor data type. Fortunately we already know a good function for this! We can use mutate() to do this by overriding the original variable with the same data but classified as a factor.\n\n3.5.1 Activity 2: Factors\n\nType and run the below code to change the categories to factors.\n\nYou can read each line of the mutate as “overwrite the data that is in that column with the same values now considered factors and not doubles”\nSo for example, the 1s in sex change to categorical factors instead of numerical 1s.\nRemember if you mutate a new column with the same name as the old one, it will overwrite the column.\n\n\n\n\nsummarydata &lt;- summarydata %&gt;%\n  mutate(sex = as.factor(sex),\n         educ = as.factor(educ),\n         income = as.factor(income))\n\nThis is a very important step to remember if, when you look at your data, some of your categories are represented as numbers and not factors. If you do not do this then you might end up with some really confused looking figures!"
  },
  {
    "objectID": "03-intro-data-viz.html#end-of-chapter",
    "href": "03-intro-data-viz.html#end-of-chapter",
    "title": "3  Introduction to Data Visualisation",
    "section": "\n3.9 End of chapter",
    "text": "3.9 End of chapter\nWell done! It takes a while to get used to the layering system in ggplot2, particularly if you are used to making graphs a different way. But once it clicks, you will be able to make informative and professional visualisations with ease. Remember, data visualisation is useful for yourself to quickly plot your data, and it’s useful for your reader in communicating your key findings.\n\n\n\n\nNordmann, E., McAleer, P., Toivo, W., Paterson, H., & DeBruine, L. M. (2022). Data Visualization Using R for Researchers Who Do Not Use R. Advances in Methods and Practices in Psychological Science, 5(2), 25152459221074654. https://doi.org/10.1177/25152459221074654\n\n\nWeissgerber, T. L., Winham, S. J., Heinzen, E. P., Milin-Lazovic, J. S., Garcia-Valencia, O., Bukumiric, Z., Savic, M. D., Garovic, V. D., & Milic, N. M. (2019). Reveal, Don’t Conceal. Circulation, 140(18), 1506–1518. https://doi.org/10.1161/CIRCULATIONAHA.118.037777\n\n\nWoodworth, R. J., O’Brien-Malone, A., Diamond, M. R., & Schüz, B. (2018). Data from, “Web-based Positive Psychology Interventions: A Reexamination of Effectiveness.” Journal of Open Psychology Data, 6(1), 1. https://doi.org/10.5334/jopd.35"
  },
  {
    "objectID": "03-intro-data-viz.html#chapter-preparation",
    "href": "03-intro-data-viz.html#chapter-preparation",
    "title": "3  Introduction to Data Visualisation",
    "section": "\n3.1 Chapter preparation",
    "text": "3.1 Chapter preparation\n\n3.1.1 Introduction to the data set\nFrom now on, we are going to use different data sets from psychology to develop and practice your data skills. This will prepare you for working with different kinds of psychology data and introduce you to different kinds of research questions they might ask. For this chapter, we are using open data from Woodworth et al. (2018). The abstract of their article is:\n\nWe present two datasets. The first dataset comprises 992 point-in-time records of self-reported happiness and depression in 295 participants, each assigned to one of four intervention groups, in a study of the effect of web-based positive-psychology interventions. Each point-in-time measurement consists of a participant’s responses to the 24 items of the Authentic Happiness Inventory and to the 20 items of the Center for Epidemiological Studies Depression (CES-D) scale. Measurements were sought at the time of each participant’s enrolment in the study and on five subsequent occasions, the last being approximately 189 days after enrolment. The second dataset contains basic demographic information about each participant.\n\nIn summary, we have two files containing demographic information about participants and measurements of two scales on happiness and depression:\n\nThe Authentic Happiness Inventory (AHI),\nThe Center for Epidemiological Studies Depression (CES-D) scale.\n\n3.1.2 Organising your files and project for the chapter\nBefore we can get started, you need to organise your files and project for the chapter, so your working directory is in order. If you need a refresher of this process, you can look back over Chapter 2 - File structure, working directories, and R Projects.\n\nIn your folder for research methods and the book ResearchMethods1_2/Quant_Fundamentals, create a new folder called Chapter_03_intro_data_viz. Within Chapter_03_intro_data_viz, create two new folders called data and figures.\nCreate an R Project for Chapter_03_intro_data_viz as an existing directory for your chapter folder. This should now be your working directory.\nCreate a new R Markdown document and give it a sensible title describing the chapter, such as 03 Introduction to Data Visualisation. Delete everything below line 10 so you have a blank file to work with and save the file in your Chapter_03_intro_data_viz folder.\nDownload these two data files which we used at the end of Chapter 2. Data file one: ahi-cesd.csv. Data file two: participant-info.csv. Right click the links and select “save link as”, or clicking the links will save the files to your Downloads. Make sure that both files are saved as “.csv”. Do not open them on your machine as often other software like Excel can change setting and ruin the files. Save or copy the file to your data/ folder within Chapter_03_intro_data_viz.\n\nYou are now ready to start working on the chapter!\n\n\n\n\n\n\nReminder of file management if you use the online server\n\n\n\n\n\nIf we support you to use the online University of Glasgow R Server, working with files is a little different. If you downloaded R / RStudio to your own computer or you are using one of the library/lab computers, please ignore this section.\nThe main disadvantage to using the R server is that you will need create folders on the server and then upload and download any files you are working on to and from the server. Please be aware that there is no link between your computer and the R server. If you change files on the server, they will not appear on your computer until you download them from the server, and you need to be very careful when you submit your assessment files that you are submitting the right file. This is the main reason we recommend installing R / RStudio on your computer wherever possible.\nGoing forward throughout this book, if you are using the server, you will need to follow an extra step where you also upload them to the sever. As an example:\n\nLog on to the R server using the link we provided to you.\nIn the file pane, click New folder and create the same structure we demonstrated above.\nDownload these two data files which we used at the end of Chapter 2. Data file one: ahi-cesd.csv. Data file two: participant-info.csv. Save the two files into the data folder you created for chapter 3. To download a file from this book, right click the link and select “save link as”. Make sure that both files are saved as “.csv”. Do not open them on your machine as often other software like Excel can change setting and ruin the files.\nNow that the files are stored on your computer, go to RStudio on the server and click Upload then Browse and choose the folder for the chapter you are working on.\nClick Choose file and go and find the data you want to upload."
  },
  {
    "objectID": "02-starting-with-data.html#02-projects",
    "href": "02-starting-with-data.html#02-projects",
    "title": "2  Creating Reproducible Documents",
    "section": "\n2.1 File structure, working directories, and R Projects",
    "text": "2.1 File structure, working directories, and R Projects\nIn chapter 1, we never worked with files, so you did not have to worry about where you put things on your computer. Before we can start working with R Markdown files, we must explain what a working directory is and how your computer knows where to find things.\nYour working directory is the folder where your computer starts to look for files. It would be able to access files from within that folder and within sub-folders in your working directory, but it would not be able to access folders outside your working directory.\nIn this course, we are going to prescribe a way of working to support an organised file system, helping you to know where everything is and where R will try to save things on your computer and where it will try to save and load things. Once you become more comfortable working with files, you can work in a different way that makes sense to you, but we recommend following our instructions for at least RM1 as the first course.\n\n2.1.1 Activity 1: Create a folder for all your work\nIn your documents or OneDrive, create a new folder called ResearchMethods1_2. This will be your highest level folder where you will save everything for Research Methods 1 and 2.\n\n\n\n\n\n\nTop tip\n\n\n\nWhen you are a student at the University of Glasgow, you have access to the full Microsoft suite of software. One of those is the cloud storage system OneDrive. We heavily recommend using this to save all your work in as it backs up your work online and you can access it from multiple devices.\n\n\nWithin that folder, create two new folders called Assessments and Quant_Fundamentals. In Assessments, you can save all your assessments for RM1 and RM2 as you come to them. In Quant_Fundamentals, that is where you will save all your work as you progress through this book.\nWithin Quant_Fundamentals, create a new folder called Chapter_02_reproducible_docs. As you work through the book, you will create a new chapter folder each time you start a new chapter and the sub-folders will always be the same. Within Chapter_02_reproducible_docs, create two new folders called data and figures. As a diagram, it should look like Figure 2.1.\n\n\n\n\nFigure 2.1: Prescribed file structure for RM 1 and RM 2.\n\n\n\n\n\n\n\n\n\nHow to name files and folders\n\n\n\nYou might notice in the folder names we avoided using spaces by adding things like underscores _ or capitalising different words. Historically, spaces in folder/file names could cause problems for code, but now it’s just slightly easier when file names and folder names do not have spaces in them.\nFor naming files and folders, try and choose something sensible so you know what it refers to. You are trying to balance being as short as possible, while still being immediately identifiable. For example, instead of fundamentals of quantitative analysis, we called it Quant_Fundamentals.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nWhen you create and name folders to use with R / RStudio, whatever you do, do not call the folder “R”. If you do this, sometimes R has an identity crisis and will not save or load your files properly. It can also really damage your setup and require you to reinstall everything as R tends to save all the packages in a folder called R. If there is another folder called R, then it gets confused and stops working properly.\n\n\n\n\n\n\n\n\nFile management when using the online server\n\n\n\n\n\nIf we support you to use the online University of Glasgow R Server, working with files is a little different. If you downloaded R / RStudio to your own computer or you are using one of the library/lab computers, please ignore this section.\nThe main disadvantage to using the R server is that you will need create folders on the server and then upload and download any files you are working on to and from the server. Please be aware that there is no link between your computer and the R server. If you change files on the server, they will not appear on your computer until you download them from the server, and you need to be very careful when you submit your assessment files that you are submitting the right file. This is the main reason we recommend installing R / RStudio on your computer wherever possible.\nGoing forward throughout this book, if you are using the server, you will need to follow an extra step where you also upload them to the sever. As an example:\n\nLog on to the R server using the link we provided to you.\nIn the file pane, click New folder and create the same structure we demonstrated above.\nDownload ahi-cesd.csv and participant-info.csv into the data folder you created for chapter 2. To download a file from this book, right click the link and select “save link as”. Make sure that both files are saved as “.csv”. Do not open them on your machine as often other software like Excel can change setting and ruin the files.\nNow that the files are stored on your computer, go to RStudio on the server and click Upload then Browse and choose the folder for the chapter you are working on.\nClick Choose file and go and find the data you want to upload.\n\n\n\n\n\n2.1.2 Manually setting the working directory\nNow that you have a folder structure that will keep everything nice and organised, we will demonstrate how you can manually set the working directory. If you open RStudio, you can check where the current working directory is by typing the function getwd() into the console and pressing enter/return. That will show you the current file path R is using to navigate files. If you look at the Files window in the bottom right, this will also show you the files and folders available from your working directory.\nIf you click on the top menu Session &gt;&gt; Set Working Directory &gt;&gt; Choose Directory..., (Figure 2.2) you can navigate through your documents or OneDrive until you can select Chapter_02_reproducible_docs. Click open and that will set the folder as your working directory. You can double check this worked by running getwd() again in the console.\n\n\n\n\nFigure 2.2: Manually setting the working directory.\n\n\n\n\n2.1.3 Activity 2 - Creating an R Project\nKnowing how to check and manually set your working directory is useful, but there is a more efficient way of setting your working directory alongside organised file management. You are going to create something called an R Project.\nTo create a new project for the work you will do in this chapter (Figure 2.3):\n\nClick on the top menu and navigate to File &gt;&gt; New Project....\nYou have the option to select from New Directory, Existing Directory, or Version Control. You already created a folder for Chapter_02_reproducible_docs, so select Existing Directory.\nClick Browse… next to Project working directory to select the folder you want to create the project in.\nWhen you have navigated to Chapter_02_reproducible_docs for this chapter, click Open and then Create Project.\n\n\n\n\n\n\n\n\n\n\nFigure 2.3: Starting a new project.\n\n\nRStudio will restart itself and open with this new project directory as the working directory. You should see something like Figure 2.4.\n\n\n\n\nFigure 2.4: RStudio screen in a new project in your chapter 2 folder.\n\n\n\nIn the files tab in the bottom right window, you will see all the contents in your project directory. You can see your two sub-folders for data and figures and a file called Chapter_02_reproducible_docs.Rproj. This is a file that contains all of the project information. When you come back to this project after closing down RStudio, if you double click on the .Rproj file, it will open up your project and have your working directory all set up and ready to go.\n\n\n\n\n\n\nWarning\n\n\n\nIn each chapter, we will repeat these instructions at the start to prescribe this file structure, but when you create your own folders and projects, do not ever save a new project inside another project. This can cause some hard to resolve problems. For example, it would be fine to create a new project within the Quant_Fundamentals folder as we will do for each new chapter, but should never create a new project within the Chapter_02_reproducible_docs folder."
  },
  {
    "objectID": "03-intro-data-viz.html#reading-and-exploring-data-files",
    "href": "03-intro-data-viz.html#reading-and-exploring-data-files",
    "title": "3  Introduction to Data Visualisation",
    "section": "\n3.2 Reading and exploring data files",
    "text": "3.2 Reading and exploring data files\nBefore we can start visualising data, we need to read in the data - “read” in this sense just means to bring the data into RStudio and store it in an object so we can work with it.\nTo do this we will use the function read_csv() that allows us to read in .csv files. There are also functions that allow you to read in Excel files (e.g. .xlsx) and other formats, however in this course we will only use .csv files as they are not software specific and therefore are better for when looking to practice open science! A .csv file can be read by any basic text editor on nearly all machines.\n\nThe code chunk below reads in both datafiles. Type it into your code chunk and run them. Let’s look at what they do.\nFirst, we create an object called dat that contains the data in the ahi-cesd.csv file.\nNext we then create an object called info that contains the data in the participant-info.csv.\nNote how both lines have the same format of object &lt;- function(\"datafile_name.csv\")\n\nit is imperative that you have the double quotation marks around the datafile name and that the datafile name is spelt correctly and includes the .csv part.\nand remember that &lt;- is called the assignment operator but we can read it as “assigned to”. For example, the first line can be read as the data in ahi-cesd.csv is assigned to the object called dat.\n\n\n\n\ndat &lt;- read_csv(\"data/ahi-cesd.csv\")\n\npinfo &lt;- read_csv(\"data/participant-info.csv\")\n\nIf you have done this activity correctly, and the preceding activities, you should now see that the objects dat and pinfo have appeared in the environment pane. If they are not there then you should check the spelling of the filenames and the structure of the code lines as well as maybe the working directory.\n\n\n\nWATCH OUT! There is also a function called read.csv(). Be very careful NOT to use this function instead of read_csv() as they have different ways of naming columns. For the activities and the assignments we will always ask and expect you to use read_csv(). This is really a reminder to watch spelling on functions and to be careful to use the right functions.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to Data Visualisation</span>"
    ]
  },
  {
    "objectID": "03-intro-data-viz.html#loading-the-tidyverse-package-and-reading-data-files",
    "href": "03-intro-data-viz.html#loading-the-tidyverse-package-and-reading-data-files",
    "title": "3  Introduction to Data Visualisation",
    "section": "\n3.2 Loading the tidyverse package and reading data files",
    "text": "3.2 Loading the tidyverse package and reading data files\n\n3.2.1 Activity 1 - Loading the tidyverse package\nFor everything we do in this chapter and almost every chapter from now, we need to use the tidyverse package. The tidyverse is a package of packages, containing a kind of ecosystem of functions that work together for data wrangling, descriptive statistics, and visualisation. So let’s load that package into our library using the library() function.\nTo load the tidyverse, below line 10 of your RMarkdown document, create a code chunk, type the following code into your code chunk, and run the code:\n\nlibrary(tidyverse)\n\nRemember that sometimes in the console or below your code chunk, you will see information about the package you have loaded. If you see an error message, be sure to read it and try to identify what the problem is. For example, if you are working on your own computer, have you installed tidyverse so R/RStudio can access it? Are there any spelling mistakes?\nRemember though, not all messages are errors, tidyverse explains what packages it loaded and highlights function name clashes. See activity 3 and 4 from Chapter 1 if you need a refresher.\n\n3.2.2 Activity 2 - Reading data files using read_csv()\n\nNow we have loaded tidyverse, we can read in the data we need for the remaining activities. “Read” in this sense just means to bring the data into RStudio and store it in an object, so we can work with it.\nWe will use the function read_csv() that allows us to read in .csv files. There are also functions that allow you to read in Excel files (e.g. .xlsx) and other formats, but in this course we will only use .csv files as they are not software specific, meaning they are more accessible to share, promoting our open science principles.\nCreate a new code chunk below where you loaded tidyverse, type the following code, and run the code chunk:\n\ndat &lt;- read_csv(\"data/ahi-cesd.csv\")\n\npinfo &lt;- read_csv(\"data/participant-info.csv\")\n\nTo break down the code:\n\nFirst, we create an object called dat that contains the data in the ahi-cesd.csv file within data/.\nNext, we create an object called pinfo that contains the data in the participant-info.csv file within data/.\nBoth lines have the same format of object &lt;- function(\"folder/datafile_name.csv\")\n\n\n\n\n\n\n\nError mode\n\n\n\nThere are several common mistakes that happen here, so be careful how you are typing the code to read in the data.\n\nYou need the double quotation marks around the data file name, so R recognises you are giving it a file path.\nComputers are literal, so you must spell the data file name correctly. For example, R would not know what data/participant-inf.csv is. This is where pressing the tab key on your keyboard can be super helpful, as you can search and auto-complete your files and avoid spelling mistakes.\nFor the same reason as spelling mistakes, you must add the .csv part on the end.\nYou must point R to the right folder relative to your working directory. If you typed ahi-cesd.csv, you would receive an error as R would look in your chapter folder where ahi-cesd.csv does not exist, rather than within the data/ folder you stored it in.\n\n\n\n\nRemember that &lt;- is called the assignment operator but we can read it as “assigned to”. For example, the first line can be read as the data in data/ahi-cesd.csv is assigned to the object called dat.\n\nIf you have done this activity correctly, you should now see the objects dat and pinfo in the environment window in the top right of RStudio. If they are not there, check there are no error messages, check the spelling of the code and file names, and check your working directory is set to Chapter_03_intro_data_viz.\n\n\n\n\n\n\nBe careful to use the right read_csv() function\n\n\n\nThere is also a function called read.csv(). Be very careful not to use this function instead of read_csv() as they have different ways of naming columns. For the activities and the assignments in RM1 and RM2, we will always ask and expect you to use read_csv(). This is really a reminder to watch spelling on functions and to be careful to use the right functions, especially when the names are so close.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to Data Visualisation</span>"
    ]
  },
  {
    "objectID": "03-intro-data-viz.html#loading-the-tidyverse-and-reading-data-files",
    "href": "03-intro-data-viz.html#loading-the-tidyverse-and-reading-data-files",
    "title": "3  Introduction to Data Visualisation",
    "section": "\n3.2 Loading the tidyverse and reading data files",
    "text": "3.2 Loading the tidyverse and reading data files\n\n3.2.1 Activity 1 - Loading the tidyverse package\nFor everything we do in this chapter and almost every chapter from now, we need to use the tidyverse package. The tidyverse is a package of packages, containing a kind of ecosystem of functions that work together for data wrangling, descriptive statistics, and visualisation. So let’s load that package into our library using the library() function.\nTo load the tidyverse, below line 10 of your RMarkdown document, create a code chunk, type the following code into your code chunk, and run the code:\n\nlibrary(tidyverse)\n\nRemember that sometimes in the console or below your code chunk, you will see information about the package you have loaded. If you see an error message, be sure to read it and try to identify what the problem is. For example, if you are working on your own computer, have you installed tidyverse so R/RStudio can access it? Are there any spelling mistakes in the function or package?\nRemember though, not all messages are errors, tidyverse explains what packages it loaded and highlights function name clashes. See activity 3 and 4 from Chapter 1 if you need a refresher.\n\n3.2.2 Activity 2 - Reading data files using read_csv()\n\nNow we have loaded tidyverse, we can read in the data we need for the remaining activities. “Read” in this sense just means to bring the data into RStudio and store it in an object, so we can work with it.\nWe will use the function read_csv() that allows us to read in .csv files. There are also functions that allow you to read in Excel files (e.g. .xlsx) and other formats, but in this course we will only use .csv files as they are not software specific, meaning they are more accessible to share, promoting our open science principles.\n\n\n\n\n\n\nWhere does read_csv() come from?\n\n\n\n\n\nWhen we describe tidyverse as a package of packages, the read_csv() function comes from a package called readr. This is one of the packages that tidyverse loads and contains several functions for reading different kinds of data.\n\n\n\nCreate a new code chunk below where you loaded tidyverse, type the following code, and run the code chunk:\n\ndat &lt;- read_csv(\"data/ahi-cesd.csv\")\n\npinfo &lt;- read_csv(\"data/participant-info.csv\")\n\nTo break down the code:\n\nFirst, we create an object called dat that contains the data in the ahi-cesd.csv file within data/.\nNext, we create an object called pinfo that contains the data in the participant-info.csv file within data/.\nBoth lines have the same format of object &lt;- function(\"folder/datafile_name.csv\")\nRemember that &lt;- is called the assignment operator but we can read it as “assigned to”. For example, the first line can be read as the data in data/ahi-cesd.csv is assigned to the object called dat.\n\n\n\n\n\n\n\nError mode\n\n\n\nThere are several common mistakes that can happen here, so be careful how you are typing the code to read in the data.\n\nYou need the double quotation marks around the data file name, so R recognises you are giving it a file path.\nComputers are literal, so you must spell the data file name correctly. For example, R would not know what data/participant-inf.csv is. This is where pressing the tab key on your keyboard can be super helpful, as you can search and auto-complete your files and avoid spelling mistakes.\nFor the same reason as spelling mistakes, you must add the .csv part on the end to tell R the specific file you want.\nYou must point R to the right folder relative to your working directory. If you typed ahi-cesd.csv, you would receive an error as R would look in your chapter folder where ahi-cesd.csv does not exist, rather than within the data/ folder you stored it in.\n\n\n\nIf you have done this activity correctly, you should now see the objects dat and pinfo in the environment window in the top right of RStudio. If they are not there, check there are no error messages, check the spelling of the code and file names, and check your working directory is Chapter_03_intro_data_viz.\n\n\n\n\n\n\nBe careful to use the right read_csv() function\n\n\n\nThere is also a function called read.csv(). Be very careful not to use this function instead of read_csv() as they have different ways of naming columns. For the activities and the assignments in RM1 and RM2, we will always ask and expect you to use read_csv(). This is really a reminder to watch spelling on functions and to be careful to use the right functions, especially when the names are so close.\n\n\n\n3.2.3 Activity 3 - Wrangling the two data sets\nFor this final preparation step, we would like you to add the following code. We are not tackling data wrangling until the next chapter, so we are not going to fully explain the code just yet. Copy the code (if you hover over the code, there is a copy to clipboard icon in the top right) and paste it into a code chunk below where you read the two data files, then run the code again.\n\nall_dat &lt;- inner_join(dat, \n                      pinfo, \n                      by= c(\"id\", \"intervention\"))\n\nsummarydata &lt;- select(.data = all_dat, \n                      id,\n                      occasion, \n                      elapsed.days,\n                      intervention,\n                      ahiTotal, \n                      cesdTotal, \n                      sex, \n                      age, \n                      educ, \n                      income)\n\nFor a brief overview, we are joining the two data files by common columns (“id” and “intervention”) to create the object all_dat. We are then selecting 10 columns from the original 54 to make the data easier to work with in summarydata.\nThis final object summarydata is the source of the data we will be working with for the rest of this chapter.\n\n3.2.4 Activity 4 - Exploring the data set\nBefore we start plotting, it is a good idea to explore the data set you are working with. There is a handy function called glimpse() which provides an overview of the columns and responses in your data set.\nCreate a new code chunk below where you read and wrangled the data, and type and run the following code:\n\nglimpse(summarydata)\n\nRows: 992\nColumns: 8\n$ ahiTotal     &lt;dbl&gt; 32, 34, 34, 35, 36, 37, 38, 38, 38, 38, 39, 40, 41, 41, 4…\n$ cesdTotal    &lt;dbl&gt; 50, 49, 47, 41, 36, 35, 50, 55, 47, 39, 45, 47, 33, 27, 3…\n$ sex          &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, …\n$ age          &lt;dbl&gt; 46, 37, 37, 19, 40, 49, 42, 57, 41, 41, 52, 41, 52, 58, 5…\n$ educ         &lt;dbl&gt; 4, 3, 3, 2, 5, 4, 4, 4, 4, 4, 5, 4, 5, 5, 5, 4, 3, 4, 3, …\n$ income       &lt;dbl&gt; 3, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 3, 2, 2, 3, 2, 2, 2, …\n$ occasion     &lt;dbl&gt; 5, 2, 3, 0, 5, 0, 2, 2, 2, 4, 4, 0, 4, 0, 1, 4, 0, 5, 4, …\n$ elapsed.days &lt;dbl&gt; 182.025139, 14.191806, 33.033831, 0.000000, 202.096887, 0…\n\n\n\n\n\n\n\n\nWhere does glimpse() come from?\n\n\n\n\n\nThe glimpse() function comes from a package called dplyr, which is part of the tidyverse. This package contains many functions for wrangling data like joining data sets and selecting columns. We will explore loads of functions within dplyr in the next few chapters on data wrangling.\n\n\n\nThis function provides a condensed summary of your data. You can see there are 992 rows and 10 columns. You see all the column names for each variable in the data set. You can also see that all the variables are automatically considered as numeric (in this case double represented by &lt;dbl&gt;). Treating categorical variables like “sex” and “income” as numbers will cause us problems later, but it is fine for the variables we will be working on now."
  },
  {
    "objectID": "03-intro-data-viz.html#histograms-and-density-plots",
    "href": "03-intro-data-viz.html#histograms-and-density-plots",
    "title": "3  Introduction to Data Visualisation",
    "section": "\n3.4 Histograms and density plots",
    "text": "3.4 Histograms and density plots\nWe are going to start by plotting the distribution of participant age in a histogram, and add layers to demonstrate how we build the plot step-by-step.\n\n3.4.1 Step 1: Start with the ggplot function\nThis first layer tells R to access the ggplot function.\nThe first argument tells R to plot the summarydata dataframe. In the aes function, you specify the aesthetics of the plot, such as the axes and colours. What you need to specify depends on the plot you want to make (you will learn more about this later).\nFor a basic histogram, you only need to specify the x-axis (the y-axis will automatically be counts).\nFor each step, type the code in a new code chunk and run it after we add each layer to see it’s effect.\n\n# Plot the variable age from summarydata\nggplot(summarydata, aes(x = age)) # Plot age on the x axis\n\n\n\n\n\n\n\n\n\n\n\n\n\nR Markdown tip of the chapter: Add code comments\n\n\n\nAfter we introduced you to R Markdown to create reproducible documents in Chapter 2, we are going to add a tip in every chapter to demonstrate extra functionality.\nIn the code chunk above, we added a code comment by adding a hash (#). In code chunks and scripts, you can add a comment which R will ignore, so you can explain to yourself what the code is doing. In R Markdown, you can combine adding notes to yourself outside and inside the code chunks.\nCode comments help explain what the code is doing and why you added certain values. It might seem redundant for simple functions, but as your code becomes more complex, you will forget what it is doing when you return to it after days, months, or years. Future you will thank past you.\n\n\n\n3.4.2 Step 2: Add the geom_histogram layer\nYou can see that the code above produces an empty plot, because we have not specified which type of plot we want to make.\nWe will do this by adding another layer: geom_histogram(). A geom is an expression of the type of plot you want to create. For this variable, we want to create a histogram which is a type of plot showing the frequency of each observation.\nYou will see that you add the layers by adding a + at the end of each layer. As you read new code, try and read it line by line to walk through what it is doing. You can interpret + as “and then”. So, you could describe the plot as currently saying “plot the age variable from summary data, and then add a histogram”.\n\n# Plot the variable age from summarydata\nggplot(summarydata, aes(x = age)) +  # Plot age on the x axis\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n3.4.3 Step 3: Edit the histogram bins\nIn just two lines of code, we have a histogram! For exploratory data analysis, this is how ggplot2 is such a flexible and quick tool to get a visual overview of your data.\nAfter running the last code chunk, you might have noticed a message warning you about the bin width: stat_bin() using bins = 30. A histogram describes the frequency of values within your variable. To do so, it must collect the values into “bins”. By default - the warning ggplot2 gives you - it uses 30 bins, meaning it tries to plot 30 bars. Depending on the granularity of your data, you might want more or fewer bins.\nYou can control this using one of two arguments. First, you can add an argument called binwidth which sets the bins by how wide you want the bars on your x-axis scale. For example, we can plot the data for every 5 years:\n\n# Plot the variable age from summarydata\nggplot(summarydata, aes(x = age)) +  # Plot age on the x axis\n  geom_histogram(binwidth = 5) # collate bins into a 5-year span\n\n\n\n\n\n\n\nAlternatively, you can control precisely how many bars the histograms uses through the bins argument. For example, we can plot age by collecting the observations into 10 bars:\n\n# Plot the variable age from summarydata\nggplot(summarydata, aes(x = age)) +  # Plot age on the x axis\n  geom_histogram(bins = 10) # Plot age using 10 bars\n\n\n\n\n\n\n\n\n\n\n\n\n\nTry this\n\n\n\nPlay around with the bin and binwidth arguments to see what effect it has on the plot. One of the best ways of learning is through trial and error to see what effect your changes have on the result.\n\n\n\n3.4.4 Step 4: Edit the axis names\nBy default, the axis names come from the variable names in your data. When you are making quick plots for yourself, you rarely need to worry about this. However, as you edit your plot for a report to show other people, it is normally a good idea to edit the names so they clearly communicate what they represent.\nThere are different layers to control the axes depending on the type of variable you use. Both the x- and y-axis here are continuous numbers, so we can use the scale_x_continuous and scale_y_continuous layers to control them.\nThere are many options available in ggplot2 for controlling the axes, but you will learn through experience and searching what you need in different scenarios.\n\n# Plot the variable age from summarydata\nggplot(summarydata, aes(x = age)) +  # Plot age on the x axis\n  geom_histogram(binwidth = 5) + # collate bins into a 5-year span\n  scale_x_continuous(name = \"Age\") +\n  scale_y_continuous(name = \"Frequency\")\n\n\n\n\n\n\n\n\n3.4.5 Step 5: Change the plot theme\nSo far, we used the default plot theme which has the grey gridlines as a background. This looks pretty ugly, so we can edit the plot them by adding a theme_ layer. For example, we can add a black-and-white theme:\n\n# Plot the variable age from summarydata\nggplot(summarydata, aes(x = age)) +  # Plot age on the x axis\n  geom_histogram(binwidth = 5) + # collate bins into a 5-year span\n  scale_x_continuous(name = \"Age\") +\n  scale_y_continuous(name = \"Frequency\") + \n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\n\n\nTry this\n\n\n\nThere are loads of themes available. As you start typing theme_, you should see the full range appear as a drop-down to autocomplete. Try one or two alternatives such as theme_classic() or theme_minimal() to see how they look.\n\n\n\n3.4.6 Switch the geom layer\nThe layer system makes it easy to create new types of plots by adapting existing recipes. For example, rather than creating a histogram, we can create a smoothed density plot by calling geom_density() rather than geom_histogram(). Apart from the name of the y-axis, the rest of the code remains identical to demonstrate how easy it is to customise your ggplot2 layers.\n\n# Plot the variable age from summarydata\nggplot(summarydata, aes(x = age)) +  # Plot age on the x axis\n  geom_density() + # summarise age as a smoothed density plot\n  scale_x_continuous(name = \"Age\") +\n  scale_y_continuous(name = \"Density\") + \n  theme_bw()\n\n\n\n\n\n\n\n\n3.4.7 Activity 5 - Apply your plotting skills to a new variable\nBefore we move on to barplots, an important learning step is being able to apply or transfer what you learnt in one scenario to something new.\nIn the data set, there is a variable for The Authentic Happiness Inventory (AHI): ahiTotal. Plot the new variable and try to recreate the customisation layers before checking the solution below. It might take some trial-and-error to get some features right, so do not worry if it does not immediately look the same.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow me the solution code\n\n\n\n\n\nTo recreate the plot, this is the code:\n\n# Plot the variable ahi total from summarydata\nggplot(summarydata, aes(x = ahiTotal)) +  # Plot ahi total on the x axis\n  geom_histogram(bins = 10) + \n  scale_x_continuous(name = \"Authentic Happiness Inventory (AHI)\") +\n  scale_y_continuous(name = \"Frequency\") + \n  theme_classic()\n\nWe were a little sneaky with using the classic theme to get you exploring."
  },
  {
    "objectID": "04-wrangling-1.html",
    "href": "04-wrangling-1.html",
    "title": "4  Data wrangling 1: Join, select, and mutate",
    "section": "",
    "text": "4.1 Chapter preparation",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data wrangling 1: Join, select, and mutate</span>"
    ]
  },
  {
    "objectID": "04-wrangling-1.html#chapter-preparation",
    "href": "04-wrangling-1.html#chapter-preparation",
    "title": "4  Data wrangling 1: Join, select, and mutate",
    "section": "\n4.1 Chapter preparation",
    "text": "4.1 Chapter preparation\n\n4.1.1 Introduction to the data set\nFor this chapter, we are using open data from Woodworth et al. (2018) one more time. In the last two chapters, we asked you to trust us and copy some code until we reached data wrangling, and now is the time to fill in those gaps. If you need a reminder, the abstract of their article is:\n\nWe present two datasets. The first dataset comprises 992 point-in-time records of self-reported happiness and depression in 295 participants, each assigned to one of four intervention groups, in a study of the effect of web-based positive-psychology interventions. Each point-in-time measurement consists of a participant’s responses to the 24 items of the Authentic Happiness Inventory and to the 20 items of the Center for Epidemiological Studies Depression (CES-D) scale. Measurements were sought at the time of each participant’s enrolment in the study and on five subsequent occasions, the last being approximately 189 days after enrolment. The second dataset contains basic demographic information about each participant.\n\nIn summary, we have one data set containing demographic information about participants and a second data set containing measurements of two scales on happiness and depression.\n\n4.1.2 Organising your files and project for the chapter\nBefore we can get started, you need to organise your files and project for the chapter, so your working directory is in order.\n\nIn your folder for research methods and the book ResearchMethods1_2/Quant_Fundamentals, create a new folder called Chapter_04_06_datawrangling. As we are spending three chapters on data wrangling, we will work within one folder. Within Chapter_04_06_datawrangling, create two new folders called data and figures.\nCreate an R Project for Chapter_04_06_datawrangling as an existing directory for your chapter folder. This should now be your working directory.\nWe will work within one folder, but create a new R Markdown for each chapter. Create a new R Markdown document and give it a sensible title describing the chapter, such as 04 Data Wrangling 1. Delete everything below line 10 so you have a blank file to work with and save the file in your Chapter_04_06_datawrangling folder.\nIf you already have the two files from chapter 3, copy and paste them into the data/ folder. If you need to download them again, the links are data file one (ahi-cesd.csv) and data file two (participant-info.csv). Right click the links and select “save link as”, or clicking the links will save the files to your Downloads. Make sure that both files are saved as “.csv”. Save or copy the file to your data/ folder within Chapter_04_06_datawrangling.\n\nYou are now ready to start working on the chapter!\n\n\n\n\n\n\nReminder of file management if you use the online server\n\n\n\n\n\nIf we support you to use the online University of Glasgow R Server, working with files is a little different. If you downloaded R / RStudio to your own computer or you are using one of the library/lab computers, please ignore this section.\n\nLog on to the R server using the link we provided to you.\nIn the file pane, click New folder and create the same structure we demonstrated above.\nDownload these two data files which we used in Chapter 3. Data file one: ahi-cesd.csv. Data file two: participant-info.csv. Save the two files into the data folder you created for chapter 3. To download a file from this book, right click the link and select “save link as”. Make sure that both files are saved as “.csv”. Do not open them on your machine as often other software like Excel can change setting and ruin the files.\nNow that the files are stored on your computer, go to RStudio on the server and click Upload then Browse and choose the folder for the chapter you are working on.\nClick Choose file and go and find the data you want to upload.\n\n\n\n\n\n4.1.3 Activity 1 - Load tidyverse and read the data files\nAs the first activity, try and test yourself by loading tidyverse and reading the two data files. As a prompt, save the data files to these two object names to be consistent with the activities below, but you can check your answer below if you are stuck.\n\n# Load the tidyverse package below\n?\n  \n# Load the two data files\n# This should be the ahi-cesd.csv file \ndat &lt;- ?\n\n# This should be the participant-info.csv file\npinfo &lt;- ?\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# Load the tidyverse package below\nlibrary(tidyverse)\n\n# Load the two data files\n# This should be the ahi-cesd.csv file \ndat &lt;- read_csv(\"data/ahi-cesd.csv\")\n\n# This should be the participant-info.csv file\npinfo &lt;- read_csv(\"data/participant-info.csv\")"
  },
  {
    "objectID": "04-wrangling-1.html#joining-two-data-frames-with-_join-functions",
    "href": "04-wrangling-1.html#joining-two-data-frames-with-_join-functions",
    "title": "4  Data wrangling 1: Join, select, and mutate",
    "section": "\n4.3 Joining two data frames with *_join() functions",
    "text": "4.3 Joining two data frames with *_join() functions\nThe first thing we will do is combine data files. We have two files, dat and pinfo, but what we really want is a single file that has both the happiness and depression scores and the demographic information about the participants as it makes it easier to work with the combined data.\nTo do this, we are going to use the function inner_join(). So far, we have described these types of functions as *_join(). This is because there are a series of functions that join two data sets in slightly different ways. You do not need to memorise these, but it might be useful to refer back to later.\n\n\n\n\n\n\nJoin function\nDescription\n\n\n\ninner_join()\nKeep observations in data set x that has a matching key in data set y\n\n\nleft_join()\nKeep all observations in data set x\n\n\nright_join()\nKeep all observations in data set y\n\n\nfull_join()\nKeep all observations in both data set x and y\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nAs these functions join data sets in different ways, they will produce different sample sizes depending on the presence of missing data in one or both data sets. For example, inner_join() will be the strictest as you must have matching observations in each data set. On the other hand, full_join() will be the least strict, as you retain observations that may not exist in one data set or the other.\n\n\n\n4.3.1 Activity 2 - Join the files together\nWe are going to join dat and pinfo by common identifiers. When we use inner_join(), this means we want to keep all the observations in dat that also has a corresponding identifier in pinfo. This is known as an inner-join, where you would exclude participants if they did not have a matching observation in one of the data sets.\nThe code below will create a new object, called all_dat, that combines the data from both dat and pinfo using the columns id and intervention to match the participants’ data across the two sets of data. id is a code or number for each unique participant and will be the most common approach you see for creating an identifier. intervention is the group the participant was placed in for the study by Woodworth et al. (2018).\nType and run the code in a new code chunk to inner join the two sets of data.\n\nall_dat &lt;- inner_join(x = dat, \n                      y = pinfo, \n                      by = c(\"id\", \"intervention\"))\n\nTo break down what this code is doing:\n\nall_dat is the new object you created with the joined data.\nx is the first argument and it should be the first data set / object you want to combine.\ny is the second argument and it should be the second data set / object you want to combine.\nby is the third argument and it lists the identifier as the name(s) of the column(s) you want to combine the data by in quote marks. In this scenario, there are two identifiers common to each data set. They both contain columns called “id” and “intervention”. We have to wrap them in c() to say that there is more than one column to combine by. If there was only one common identifier, you would write by = \"id\".\n\n\n\n\n\n\n\nWhy does my data include .x and .y columns?\n\n\n\nIf your data sets have more than one common column, you must enter them all in the by argument. This tells R there are matching columns and values across the data sets. If you do not enter all the common columns, then R will add on a .x and .y when it adds them together, to label which come from each data set.\nFor example, try and run this code and look at the columns in all_dat2. You will see it has an extra column compared to all_dat as there is both “intervention.x” and “intervention.y”.\n\nall_dat2 &lt;- inner_join(x = dat, \n                      y = pinfo, \n                      by = \"id\")\n\n\n\n\n4.3.2 Activity 3 - Explore your data objects\nOnce you have run this code, you should now see the new all_dat object in the environment pane. Remember to get into the habit of exploring your data and objects as you make changes, to check your wrangling is working as intended.\nThere are two main ways you can do this:\n\nClick on the data object in the Environment pane. This will open it up as a tab in RStudio, and you will be able to scroll through the rows and columns (Figure 4.1).\n\n\n\n\n\n\n\nWhy do I not see all my columns?\n\n\n\nOne common source of confusion is not seeing all your columns when you open up a data object as a tab. This is because RStudio shows you a maximum of 50 columns at a time. If you have more than 50 columns, to see more, you must use the arrows at the top of the tab where it says “Cols:”. For example in all_dat, it will say 1-50, if you click the right arrow, it will then say 5-54 so you can see the final 4 columns.\n\n\n\n\n\n\nFigure 4.1: Exploring a data object in RStudio by opening it as a tab. You can navigate around the columns and rows without opening it up in something like Excel. If there are more than 50 columns, you can click the arrows next to Cols.\n\n\n\n\nUse the glimpse() function to see an overview of the data objects.\n\nWe explored this in chapter 3, but glimpse() tells you how many rows and columns your data have, plus an overview of responses per column. Note: you will see a preview of all 54 columns, but we have shortened the preview to 10 columns to take up less space in the book.\n\nglimpse(all_dat)\n\n\n\nRows: 992\nColumns: 10\n$ id           &lt;dbl&gt; 12, 162, 162, 267, 126, 289, 113, 8, 185, 185, 246, 185, …\n$ occasion     &lt;dbl&gt; 5, 2, 3, 0, 5, 0, 2, 2, 2, 4, 4, 0, 4, 0, 1, 4, 0, 5, 4, …\n$ elapsed.days &lt;dbl&gt; 182.025139, 14.191806, 33.033831, 0.000000, 202.096887, 0…\n$ intervention &lt;dbl&gt; 2, 3, 3, 4, 2, 1, 1, 2, 3, 3, 3, 3, 1, 2, 2, 2, 3, 2, 2, …\n$ ahi01        &lt;dbl&gt; 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, …\n$ ahi02        &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, …\n$ ahi03        &lt;dbl&gt; 2, 1, 1, 2, 2, 4, 1, 1, 4, 4, 4, 4, 3, 3, 3, 2, 2, 2, 3, …\n$ ahi04        &lt;dbl&gt; 1, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, …\n$ ahi05        &lt;dbl&gt; 1, 2, 2, 2, 2, 1, 1, 1, 3, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ ahi06        &lt;dbl&gt; 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, …\n\n\n\n\n\n\n\n\nTry this\n\n\n\nNow you have explored all_dat, try and use one or both of these methods to explore the original dat and pinfo objects to see how they changed. Notice how the number of rows/observations and columns change from the original objects to when you join them."
  },
  {
    "objectID": "04-wrangling-1.html#selecting-variables-of-interest-with-select",
    "href": "04-wrangling-1.html#selecting-variables-of-interest-with-select",
    "title": "4  Data wrangling 1: Join, select, and mutate",
    "section": "\n4.4 Selecting variables of interest with select()\n",
    "text": "4.4 Selecting variables of interest with select()\n\nData sets often have a lot of variables we do not need and it can be easier to focus on just the columns we do need. In all_dat, we have 54 variables which takes ages to scroll through and it can be harder to find what you are looking for.\nFor the two scales on happiness and depression, we have all their items, as well as their total scores. We can create a data set that only includes the key variables and ignores all the individual items using the select() function. There are two ways you can use select: by selecting the variables you want to include, or by selecting the variables you want to ignore.\n\n4.4.1 Activity 4 - Selecting variables you want to include\nIf there are a smaller number of variables you want to include, then it will be more efficient to specify which variables you want to include. Returning to the data wrangling from chapter 3, we can select the columns from all_dat that we want to keep.\n\nsummarydata &lt;- select(.data = all_dat, # First argument as the data object\n                      id, # Stating variables we want to include\n                      occasion, \n                      elapsed.days,\n                      intervention,\n                      ahiTotal, \n                      cesdTotal, \n                      sex, \n                      age, \n                      educ, \n                      income)\n\nTo break down this code:\n\nWe are creating a new object called summarydata.\nFrom all_dat, we are selecting 10 columns we want to keep, which we list one by one.\n\n\n\n\n\n\n\nNote\n\n\n\nIn this example, the variables are in the same order as they were all_dat, but they do not need to be. You can use select() to create a new variable order if that helps you see all the important variables first. You can also rename variables as you select or reorder them, using the form new_name = old_name.\n\n\nKeep in mind it is important you select variables and assign them to a new object, or overwrite the old object. Both work, but think about if you need the original object later in your analysis and you do not want to go back and rerun code to recreate it. If you just use the select function on it’s own, it does not do anything to the object, R just shows you the variables you selected:\n\nselect(.data = all_dat, # First argument as the data object\n       id, # Stating variables we want to include\n       occasion, \n       elapsed.days,\n       intervention,\n       ahiTotal, \n       cesdTotal, \n       sex, \n       age, \n       educ, \n       income)\n\nIf you have several variables in order that you want to select, you can use a shortcut to avoid typing out every single name. When you select variables, you can use the format firstcolumn:lastcolumn to select all the variables from the first column you specify until the last column.\nFor example, if we wanted to isolate the individual items, we could use the following code:\n\nscaleitems &lt;- select(all_dat, # First argument as the data object\n                     ahi01:cesd20) # Range of variables to select\n\nYou can also pair this with individual variable selection:\n\nscaleitems &lt;- select(all_dat, # First argument as the data object\n                     id, # Individual variable to include\n                     ahi01:cesd20) # Range of variables to select\n\n\n\n\n\n\n\nTry this\n\n\n\nIf you wanted to select all the variables from id to intervention, plus all the variables from ahiTotal to income, how could you use this shortcut format? Try and complete the following code to recreate summarydata. Check your answer below when you have tried on your own.\n\nsummarydata2 &lt;- ?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nInstead of typing all 10 variables, you can select them using two ranges to ignore the scale items in the middle:\n\nsummarydata2 &lt;- select(all_dat, # First argument as the data object\n                      id:intervention, # variable range 1\n                      ahiTotal:income) # variable range 2\n\n\n\n\n\n4.4.2 Activity 5 - Selecting variables you want to ignore\nAlternatively, you can also state which variables you do not want to keep. This is really handy if you want to keep many columns and only remove one or two.\nFor example, if we wanted to remove two variables, you add a dash (-) before the variable name:\n\nall_dat_reduced2 &lt;- select(all_dat, \n                           -occasion, # Remove occasion\n                           -elapsed.days) # Remove elapsed.days\n\nThis also works using the range method, but you must add the dash before the first and last column in the range you want to remove. For example, we can recreate summarydata one more time by removing the scale items in the middle:\n\nsummarydata3 &lt;- select(all_dat, # \n                       -ahi01:-cesd20) # Remove range of variables\n\n\n\n\n\n\n\nTip\n\n\n\nYou can see there were at least three different ways of creating summarydata to keep the 10 variables we want to focus on. This is an important lesson as there is often not just one unique way of completing a task in R.\nWhen you first start coding, you might begin with the long way that makes sense to you. As you practice more, you recognise ways to simplify your code."
  },
  {
    "objectID": "04-wrangling-1.html#arranging-variables-of-interest-with-arrange",
    "href": "04-wrangling-1.html#arranging-variables-of-interest-with-arrange",
    "title": "4  Data wrangling 1: Join, select, and mutate",
    "section": "\n4.5 Arranging variables of interest with arrange()\n",
    "text": "4.5 Arranging variables of interest with arrange()\n\nAnother handy skill is being able to change the order of observations within columns in your data set. The function arrange() will sort the rows/observations by one or more columns. This can be useful for exploring your data set and answering basic questions, such as: who was the youngest or oldest participant?\n\n4.5.1 Activity 6 - Arranging in ascending order\nUsing summarydata, we can order the participants’ ages in ascending order:\n\nage_ascend &lt;- arrange(summarydata,\n                    age)\n\nTo break down the code,\n\nWe create a new object called age_ascend.\nWe apply the function arrange() to the summarydata object.\nWe order the observations by age, which is by default in ascending order from smallest to largest.\n\nIf you look in age_ascend, we organised the data in ascending order based on age and can see the youngest participant was 18 years old.\n\n4.5.2 Activity 7 - Arranging in descending order\nBy default, arrange() sorts observations in ascending order from the smallest to largest value, or alphabetical order from A to Z. If you want to arrange observations in descending order, you can wrap the name of the variable in the desc() function.\nFor example, we can order participants from oldest to youngest:\n\nage_descend &lt;- arrange(summarydata, \n                     desc(age)) # descending order of age\n\nThis time, we can see the oldest participant was 83 years old.\n\n4.5.3 Activity 8 - Sorting by multiple columns\nFinally, you can also sort by more than one column and a combination of ascending and descending columns. Unlike select(), you might not need to save your sorted observations as a new object, you could use arrange() more as a tool to explore your data.\nFor example, we could look for the oldest female participant. Note: your code will show all 992 observations you could scroll through, but we show the first 10 to save space.\n\narrange(summarydata, \n        sex, # order by sex first\n        desc(age)) # then descending age\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\noccasion\nelapsed.days\nintervention\nahiTotal\ncesdTotal\nsex\nage\neduc\nincome\n\n\n\n51\n4\n94.905451\n2\n86\n15\n1\n83\n2\n2\n\n\n51\n3\n32.644595\n2\n87\n7\n1\n83\n2\n2\n\n\n51\n0\n0.000000\n2\n90\n5\n1\n83\n2\n2\n\n\n51\n2\n15.764178\n2\n90\n4\n1\n83\n2\n2\n\n\n51\n5\n185.852778\n2\n91\n10\n1\n83\n2\n2\n\n\n244\n0\n0.000000\n2\n64\n33\n1\n77\n3\n2\n\n\n244\n1\n7.238877\n2\n70\n37\n1\n77\n3\n2\n\n\n244\n2\n16.900289\n2\n71\n16\n1\n77\n3\n2\n\n\n244\n3\n31.251377\n2\n75\n22\n1\n77\n3\n2\n\n\n215\n0\n0.000000\n4\n76\n1\n1\n75\n3\n2\n\n\n\n\n\n\n\n\n\n\n\n\nTry this\n\n\n\nUsing summarydata and arrange(), sort the data to answer the following questions:\n\nHow old is the participant with the highest total happiness score (ahiTotal)? \nWhat is the highest total depression score (cesdTotal) in a female participant (remember 1 = female, 2 = male)? \n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nWe only need to arrange by ahiTotal in descending order to find the highest value, then look at the age column.\n\n\narrange(summarydata, \n        desc(ahiTotal)) # descending ahiTotal\n\n\nWe first order by sex in ascending order so 1s are first, then descending order of cesdTotal for the highest value.\n\n\narrange(summarydata, \n        sex, # order by sex first\n        desc(cesdTotal)) # Descending depression total"
  },
  {
    "objectID": "04-wrangling-1.html#creating-or-modifying-variables-with-mutate",
    "href": "04-wrangling-1.html#creating-or-modifying-variables-with-mutate",
    "title": "4  Data wrangling 1: Join, select, and mutate",
    "section": "\n4.6 Creating or modifying variables with mutate()\n",
    "text": "4.6 Creating or modifying variables with mutate()"
  },
  {
    "objectID": "04-wrangling-1.html#end-of-chapter",
    "href": "04-wrangling-1.html#end-of-chapter",
    "title": "4  Data wrangling 1: Join, select, and mutate",
    "section": "\n4.9 End of Chapter",
    "text": "4.9 End of Chapter\nExcellent work so far! Data wrangling is a critical skill and being able to clean and prepare your data using code will save you time in the long run. Manually tidying data might seem quicker now when you are unfamilar with these functions, but it is open to errors which may not have a paper trail as you edit files. By reproducibly wrangling your data, you can still make mistakes, but they are reproducible mistakes you can fix.\nIn the next chapter, we start by recapping the key functions from this chapter on a new data set, then introduce you to more data wrangling functions from dplyr to expand your toolkit.\n\n\n\n\nDasu, T., & Johnson, T. (2003). Exploratory data mining and data cleaning. Wiley-Interscience.\n\n\nWickham, H. (2017). Tidyverse: Easily install and load the ’tidyverse’. https://CRAN.R-project.org/package=tidyverse\n\n\nWoodworth, R. J., O’Brien-Malone, A., Diamond, M. R., & Schüz, B. (2018). Data from, “Web-based Positive Psychology Interventions: A Reexamination of Effectiveness.” Journal of Open Psychology Data, 6(1), 1. https://doi.org/10.5334/jopd.35"
  },
  {
    "objectID": "04-wrangling-1.html#tidyverse-and-the-dplyr-package",
    "href": "04-wrangling-1.html#tidyverse-and-the-dplyr-package",
    "title": "4  Data wrangling 1: Join, select, and mutate",
    "section": "\n4.2 Tidyverse and the dplyr package",
    "text": "4.2 Tidyverse and the dplyr package\nSo far, we have loaded a package called tidyverse in every chapter and it is going to be at the core of all the data skills you develop. The tidyverse (https://www.tidyverse.org/, Wickham (2017) is an ecosystem containing six core packages: dplyr, tidyr, readr, purrr, ggplot2, and tibble. Within these six core packages, you have access to functions that will pretty much cover everything you need to wrangle and visualise your data.\nIn chapter 3, we introduced you to the package ggplot2 for data visualisation. In this chapter, we focus on functions from the dplyr package, which the authors describe as a grammar of data manipulation (in the wrangling sense, not deviously making up data).\nThe dplyr package contains several key functions based on common English verbs to help you understand what the code is doing. For an overview, we will introduce you to the following functions:\n\n\nFunction\nDescription\n\n\n\n*_join()\nAdd columns from two data sets by matching observations\n\n\nselect()\nInclude or exclude certain variables (columns)\n\n\nmutate()\nCreate new variables (columns)\n\n\narrange()\nChange the order of observations (rows)\n\n\nfilter()\nInclude or exclude certain observations (rows)\n\n\ngroup_by()\nOrganize the observations (rows) into groups\n\n\nsummarise()\nCreate summary variables for groups of observations\n\n\n\nJust looking at the names gives you some idea of what the functions do. For example, select() selects columns and arrange() orders observations. You will be surprised by how far you can get with data wrangling using just these functions. There will always be unique problems to solve, but these functions cover the most common that apply to almost every data set.\nIn this chapter, we focus on the *_join() series of functions, select(), arrange(), and mutate()."
  },
  {
    "objectID": "04-wrangling-1.html#modifying-or-creating-variables-with-mutate",
    "href": "04-wrangling-1.html#modifying-or-creating-variables-with-mutate",
    "title": "4  Data wrangling 1: Join, select, and mutate",
    "section": "\n4.6 Modifying or creating variables with mutate()\n",
    "text": "4.6 Modifying or creating variables with mutate()\n\nIn the final data wrangling function for this chapter, we can use the function mutate() to modify existing variables or create new variables. This is an extremely powerful and flexible function. We will not be able to cover everything you can do with it in this chapter but we will introduce you to some common tasks you might want to apply.\n\n4.6.1 Activity 9 - Modifying existing variables\nIf you remember back to chapter 3, we had a problem where R interpreted variables like sex, educ, and income as numeric, but ideally we wanted to treat them as distinct categories or factors. We used mutate() to convert the three columns to factors:\n\n# Overwrite summary data \nsummarydata &lt;- mutate(summarydata, # mutate to change columns \n         sex = as.factor(sex), # save sex as a factor\n         educ = as.factor(educ),\n         income = as.factor(income))\n\nTo break down the code:\n\nWe overwrite summarydata by assigning the function to an existing object name.\nWe use the mutate() function on the old summarydata data by using it as the first argument.\nWe can add one or more arguments to modify or create variables. Here, we modify an existing variable sex, use an equals sign (=), then how we want to modify the variable. In this example, we convert sex to a factor by using the function as.factor(sex).\n\nYou might not just want to turn a variable into a factor, you might want to completely recode what it’s values represent. For this, there is a function called case_match() which you can use within mutate(). For example, if we wanted to make sex easier to interpret, we could overwrite it’s values from 1 and 2:\n\nsex_recode &lt;- mutate(summarydata,\n                     sex = case_match(sex, # overwrite existing\n                                      \"1\" ~ \"Female\", # old to new\n                                      \"2\" ~ \"Male\")) # old to new\n\nTo break down this code,\n\nWe create a new object sex_recode by mutating the summarydata object.\nWe modify an existing variable sex by applying case_match() to sex.\nWithin case_match(), the value on the left is the existing value in the data you want to recode. The value on the right is the new value you want to overwrite it to. So, we want to change all the 1s in the data to Female. We then add a new line for every old value we want to change.\n\n\n\n\n\n\n\nError mode\n\n\n\nIn the previous exercise, we already converted sex to a factor. So, we had to add quote marks around the old values (\"1\") as they are no longer considered numeric. If you do not add the quote marks, you will get an error like Can't convert \"..1 (left)\" &lt;double&gt; to &lt;factor&gt;.\nIf you applied this step before converting sex to a factor, then 1 ~ \"Female\" would work. This shows why it is important to keep data types in mind as R might not know what you mean if you state one data type when it is expecting another.\n\n\n\n\n\n\n\n\nTry this\n\n\n\nUsing what you just learnt about using mutate and case_match(), recode the variable income and complete the code below. These are what the numeric values mean as labels:\n1 = Below average\n2 = Average\n3 = Above average\n\nincome_recode &lt;- mutate(summarydata,\n                     income = ?\n                       )\n\nCheck your code against the solution when you have attempted yourself first.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nFollowing the same format as sex, we add a new label for each of the three levels of income.\n\nincome_recode &lt;- mutate(summarydata,\n                     income = case_match(income, # overwrite existing\n                                      \"1\" ~ \"Below average\", # old to new\n                                      \"2\" ~ \"Average\", # old to new\n                                      \"3\" ~ \"Above average\")) # old to new\n\n\n\n\n\n4.6.2 Activity 10 - Creating new variables\nYou can also create new variables using mutate(). There are many possibilities here, so we will demonstrate a few key principles for inspiration and you will learn how to tackle unique problems as you come to them.\nIn it’s simplest application, you can use mutate() to add a single value to all rows. For example, you might want to label a data set before joining with another data set so you can identify their origin. Instead of overwriting an existing variable, we specify a new variable name and the value we want to assign:\n\nsummarydata &lt;- mutate(summarydata,\n                      study = \"Woodworth et al. (2018)\")\n\nUsing a similar kind of logic to case_match() we introduced you to earlier, there is an extremely flexible function called case_when() to help create new variables. Before we explain how it works, we will jump straight into an example to give you something concrete to work with.\nWoodworth et al. (2018) includes scores from the Center for Epidemiological Studies Depression (CES-D) scale. Scores range from 0 to 60, with scores of 16 or more considered a cut-off for being at risk of clinical depression. We have the scores, so we can use case_when() to label whether participants are at risk or not.\n\nsummarydata &lt;- mutate(summarydata,\n                      depression_risk = case_when(\n                        cesdTotal &lt; 16 ~ \"Not at risk\",\n                        cesdTotal &gt; 15 ~ \"At risk\"))\n\nTo break down the code:\n\nWe overwrite summarydata by mutating the existing summarydata object.\nWe create a new variable called depression_risk by applying the case_when() function to the variable cesdTotal.\nWe apply two comparisons to label responses as either “Not at risk” or “At risk”. If cesdTotal is less than 16 (i.e., 15 or smaller), then it receives the value “Not at risk”. If cesdTotal is more than 15 (i.e., 16 or higher), then it receives the value “At risk”.\n\nThe function case_when() applies these criteria line by line as it works through your rows. Depending on which criteria your observation meet, it receives the label “Not at risk” or “At risk”. You can also set the argument .default to assign one value for anything that does not pass any criteria you give it.\nThe comparisons use something called a Boolean expression. These are logical expressions which can return the values of TRUE or FALSE. To demonstrate the idea, imagine we were applying the logic manually to scores in the data. The first value is 50, so we could apply our criteria to see which one it meets:\n\n50 &lt; 16\n50 &gt; 15\n\n[1] FALSE\n[1] TRUE\n\n\nR evaluates the first comparison as FALSE as 50 is not smaller than 16, but it evaluates the second comparison as TRUE as 50 is larger than 15. So, case_when() would apply the label “At risk” as the second statement evaluates to TRUE.\n\n\n\n\n\n\nTry this\n\n\n\nTry and pick a few more cesdTotal scores from the data and apply the criteria to see if they are evaluated as TRUE OR FALSE. It can be tricky moving from imagining what you want to do to being able to express it in code, so the more practice the better.\n\n\nWe have only used less than or greater than, but there are several options for expressing Boolean logic, the most common of which are:\n\n\nOperator\nName\nis TRUE if and only if\n\n\n\nA &lt; B\nless than\nA is less than B\n\n\nA &lt;= B\nless than or equal\nA is less than or equal to B\n\n\nA &gt; B\ngreater than\nA is greater than B\n\n\nA &gt;= B\ngreater than or equal\nA is greater than or equal to B\n\n\nA == B\nequivalence\nA exactly equals B\n\n\nA != B\nnot equal\nA does not exactly equal B\n\n\nA %in% B\nin\nA is an element of vector B\n\n\n\nBoolean expressions will come up again in chapter 5 when it comes to filter(), so there will be plenty more practice as you apply your understanding to different data sets and use cases.\n\n\n\n\n\n\nTry this\n\n\n\nUsing what you just learnt about using mutate and case_when(), create a new variable called happy using the ahiTotal variable and complete the code below.\nThe Authentic Happiness Inventory (AHI) does not have official cutoffs, but let us pretend scores of 65 or more are “happy” and scores of less than 65 are “unhappy”.\n\nsummarydata &lt;- mutate(summarydata,\n                     happy = ?\n                       )\n\nCheck your code against the solution when you have attempted it yourself first.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nFollowing the same format as depression_risk and cesdTotal, we add a new comparison for each criterion we want to use as a Boolean expression:\n\nsummarydata &lt;- mutate(summarydata,\n                      happy = case_when(\n                        ahiTotal &lt; 65 ~ \"Unhappy\",\n                        ahiTotal &gt; 64 ~ \"Happy\"))\n\nIf you looked at the table of Boolean operators, you could also express 65 or more as:\n\nsummarydata &lt;- mutate(summarydata,\n                      happy = case_when(\n                        ahiTotal &lt; 65 ~ \"Unhappy\",\n                        ahiTotal &gt;= 65 ~ \"Happy\"))"
  },
  {
    "objectID": "05-wrangling-2.html#chapter-preparation",
    "href": "05-wrangling-2.html#chapter-preparation",
    "title": "5  Data wrangling 2: Filter and summarise",
    "section": "\n5.1 Chapter preparation",
    "text": "5.1 Chapter preparation\n\n5.1.1 Introduction to the data set\nFor this chapter, we are using open data from Witt et al. (2018). The abstract of their article is:\n\nCan one’s ability to perform an action, such as hitting a softball, influence one’s perception? According to the action-specific account, perception of spatial layout is influenced by the perceiver’s abilities to perform an intended action. Alternative accounts posit that purported effects are instead due to nonperceptual processes, such as response bias. Despite much confirmatory research on both sides of the debate, researchers who promote a response-bias account have never used the Pong task, which has yielded one of the most robust action-specific effects. Conversely, researchers who promote a perceptual account have rarely used the opposition’s preferred test for response bias, namely, the postexperiment survey. The current experiments rectified this. We found that even for people naive to the experiment’s hypothesis, the ability to block a moving ball affected the ball’s perceived speed. Moreover, when participants were explicitly told the hypothesis and instructed to resist the influence of their ability to block the ball, their ability still affected their perception of the ball’s speed.\n\nTo summarise, their research question was: does your ability to perform an action influence your perception? For instance, does your ability to hit a tennis ball influence how fast you perceive the ball to be moving? Or to phrase another way, do expert tennis players perceive the ball moving slower than novice tennis players?\nThis experiment does not use tennis players, instead they used the Pong task like the classic retro arcade game. Participants aimed to block moving balls with various sizes of paddles. Participants tend to estimate the balls as moving faster when they have to block it with a smaller paddle as opposed to when they have a bigger paddle. In this chapter, we will wrangle their data to reinforce skills from Chapter 4, and add more dplyr functions to your toolkit.\n\n5.1.2 Organising your files and project for the chapter\nBefore we can get started, you need to organise your files and project for the chapter, so your working directory is in order.\n\nIn your folder for research methods and the book ResearchMethods1_2/Quant_Fundamentals, you should have a folder from chapter 4 called Chapter_04_06_datawrangling where you created an R Project.\nCreate a new R Markdown document and give it a sensible title describing the chapter, such as 05 Data Wrangling 2. Delete everything below line 10 so you have a blank file to work with and save the file in your Chapter_04_06_datawrangling folder.\nWe are working with a new data set, so please save the following data file: witt_2018.csv. Right click the link and select “save link as”, or clicking the link will save the files to your Downloads. Make sure that you save the file as “.csv”. Save or copy the file to your data/ folder within Chapter_04_06_datawrangling.\n\nYou are now ready to start working on the chapter!"
  },
  {
    "objectID": "05-wrangling-2.html#join-select-and-mutate-recap",
    "href": "05-wrangling-2.html#join-select-and-mutate-recap",
    "title": "5  Data wrangling 2: Filter, summarise, and pipes",
    "section": "\n5.2 Join, select, and mutate recap",
    "text": "5.2 Join, select, and mutate recap\n\nlibrary(\"tidyverse\")\npong_data &lt;- read_csv(\"data/witt_2018.csv\")\nsummary(pong_data)\n\nRemember:  We use the read_csv() function to load in data, and the data filename must be a) in quotation marks and b) spelt exactly as the filename states, including spaces and the file extension (in this case .csv)\nIf you have done this task correctly you should see the following output:\n\n\n  Participant     JudgedSpeed      PaddleLength   BallSpeed    TrialNumber    \n Min.   : 1.00   Min.   :0.0000   Min.   : 50   Min.   :2.0   Min.   :  1.00  \n 1st Qu.: 4.75   1st Qu.:0.0000   1st Qu.: 50   1st Qu.:3.0   1st Qu.: 72.75  \n Median : 8.50   Median :1.0000   Median :150   Median :4.5   Median :144.50  \n Mean   : 8.50   Mean   :0.5471   Mean   :150   Mean   :4.5   Mean   :144.50  \n 3rd Qu.:12.25   3rd Qu.:1.0000   3rd Qu.:250   3rd Qu.:6.0   3rd Qu.:216.25  \n Max.   :16.00   Max.   :1.0000   Max.   :250   Max.   :7.0   Max.   :288.00  \n BackgroundColor      HitOrMiss       BlockNumber   \n Length:4608        Min.   :0.0000   Min.   : 1.00  \n Class :character   1st Qu.:0.0000   1st Qu.: 3.75  \n Mode  :character   Median :1.0000   Median : 6.50  \n                    Mean   :0.6866   Mean   : 6.50  \n                    3rd Qu.:1.0000   3rd Qu.: 9.25  \n                    Max.   :1.0000   Max.   :12.00  \n\n\nsummary(), from the base package - the default packages automatically installed - provides a quick overview of the variables in your dataset and can be useful as a quick check that you have indeed imported the correct data. It will also provide some basic descriptive statistics and some information on whether the data is character (text) data which can also be useful to check.\nAn alternative approach for looking at data types would be to use the glimpse() function, from the dplyr package, loaded in with tidyverse. Try the following in your console window:\n\nglimpse(pong_data)\n\nAnd you will see:\n\n\nRows: 4,608\nColumns: 8\n$ Participant     &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ JudgedSpeed     &lt;dbl&gt; 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, …\n$ PaddleLength    &lt;dbl&gt; 50, 250, 50, 250, 250, 50, 250, 50, 250, 50, 50, 250, …\n$ BallSpeed       &lt;dbl&gt; 5, 3, 4, 3, 7, 5, 6, 2, 4, 4, 7, 7, 3, 6, 5, 7, 2, 5, …\n$ TrialNumber     &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,…\n$ BackgroundColor &lt;chr&gt; \"red\", \"blue\", \"red\", \"red\", \"blue\", \"blue\", \"red\", \"r…\n$ HitOrMiss       &lt;dbl&gt; 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, …\n$ BlockNumber     &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n\n\nAnd if you look at that table you can see the eight column names followed by &lt;dbl&gt;, short for double, or &lt;chr&gt; short for character. Again, this might not mean that much to you but as you progress you will become very adept at recognising the type of data you are working with, as the type of data changes what you can do to the data.\n\n5.2.1 Activity 2: Look at your data\nGreat! Now that we have the data loaded in, let’s have a look at the pong_data and see how it is organized. Again you can do this various ways, but today, click on pong_data in your environment pane.\nIn the dataset you will see that each row (observation) represents one trial per participant and that there were 288 trials for each of the 16 participants. The columns (variables) we have in the dataset are as follows:\n\n\n\n\n\n\n\nVariable\nType\nDescription\n\n\n\nParticipant\ndouble\nparticipant number\n\n\nJudgedSpeed\ndouble\nspeed judgement (1 = fast, 0 = slow)\n\n\nPaddleLength\ndouble\npaddle length (pixels)\n\n\nBallSpeed\ndouble\nball speed (2 pixels/4ms)\n\n\nTrialNumber\ndouble\ntrial number\n\n\nBackgroundColor\ncharacter\nbackground display colour\n\n\nHitOrMiss\ndouble\nhit ball = 1, missed ball = 0\n\n\nBlockNumber\ndouble\nblock number (out of 12 blocks)\n\n\n\nJust as we saw with glimpse(), some of the data is double - i.e. numbers - and some of the data is character - i.e. text. We will use this data to master our skills of the Wickham Six verbs, taking each verb in turn. You should refer to the explanations and example code in the previous chapter to help you complete these. Remember the six main functions were:\n\n\nFunction\nDescription\n\n\n\nselect()\nInclude or exclude certain variables (columns)\n\n\nfilter()\nInclude or exclude certain observations (rows)\n\n\nmutate()\nCreate new variables (columns)\n\n\narrange()\nChange the order of observations (rows)\n\n\ngroup_by()\nOrganize the observations (rows) into groups\n\n\nsummarise()\nCreate summary variables for groups of observations\n\n\n\nNow, let’s do some wrangling!!! And don’t forget, it can help to take a new code chunk on each activity and write yourself some notes between the code chunks!\n\n5.2.2 Activity 3: select()\n\nWe are going to start with some selections!\n\nEither by inclusion (stating all the variables you want to keep) or exclusion (stating all the variables you want to drop), select only the Participant, PaddleLength, TrialNumber, BackgroundColor and HitOrMiss columns from pong_data and store it in a new object named select_dat.\n\n5.2.3 Activity 4: Reorder the variables\nGood work! Now, we previously mentioned that select() can also be used to reorder the columns in a tibble, as the new tibble will display the variables in the order that you entered them.\n\nUse select() to keep only the columns Participant, JudgedSpeed, BallSpeed, TrialNumber, and HitOrMiss from pong_data but have them display in alphabetical order, left to right. Save this tibble in a new object named reorder_dat.\n\n5.2.4 Activity 5: arrange()\n\nWe are now master of selections!!! Let’s move on to a different skill and test our ability to change the order of the data in the rows.\n\nArrange the data by the following two variables: HitOrMiss (putting hits - 1 - first), and JudgedSpeed (putting fast judgement - 1 - first) and store this in an object named arrange_dat.\n\n5.2.5 Activity 6: filter()\n\nGreat! But what about keeping and removing some of the rows with filter()! You may need to refer back to the different boolean operations to complete this activity!\nUse filter() to extract all Participants in the original pong_data that had:\n\na fast speed judgement;\nfor speeds 2, 4, 5, and 7;\nbut missed the ball.\n\nStore this remaining data in a new object called pong_fast_miss\n\n\nHelpful Hint\n\n\nThere are three parts to this filter so it is best to think about them individually and then combine them.\n\nFilter all fast speed judgements (JudgedSpeed)\nFilter for the speeds 2, 4, 5 and 7 (BallSpeed)\nFilter for all Misses (HitOrMiss)\n\nYou could do this in three filters where each one uses the output of the preceding one, or remember that filter functions can take more than one argument. You may also need to use == instead of just =.\n\n\n\n\n\n\nThe filter function is very useful but if used wrongly can give you very misleading findings. This is why it is very important to always check your data after you perform an action. Let’s say you are working in comparative psychology and have run a study looking at how cats, dogs and horses perceive emotion. Let’s say the data is all stored in the tibble animal_data and there is a column called animals that tells you what type of animal your participant was. Imagine you wanted all the data from just cats:\n\n\nfilter(animal_data, animals == “cat”)\n\n\nExactly! But what if you wanted cats and dogs?\n\n\nfilter(animal_data, animals == “cat”, animals == “dog”)\n\n\nRight? Wrong! This actually says “give me everything that is a cat and a dog”. But nothing is a cat and a dog, that would be weird - like a dat or a cog. In fact you want everything that is either a cat or a dog, so you could do:\n\n\nfilter(animal_data, animals == “cat”| animals == “dog”)\n\n\nOr you could do:\n\n\nfilter(animal_data, animals %in% c(“cat”, “dog”))\n\n\nYou used this last approach, using %in%, when producing your own graph of babynames. It is a very helpful function so don’t forget it exists!\n\n\n\n\n5.2.6 Activity 7: mutate()\n\nBrilliant work on getting this far! You really are starting to get the hang of wrangling! Now, let’s test our skills on mutate() but first we want to introduce a new function to help understand what we can do with mutate().\nPreviously you learned how the mutate() function lets us create a new variable in our dataset. However, it also has another useful function in that it can be combined with recode() to create new columns with recoded values - where you change how different categories in a variable are represented. For example, the code below adds a new column to pong_data in which the judged speed is converted into a text label where 1 will become Fast, and 0 will become “Slow”. Run the code and look at the output!\n\npong_data_mut1 &lt;- mutate(pong_data, \n                    JudgedSpeedLabel = recode(JudgedSpeed, \n                                                    \"1\" = \"Fast\", \n                                                    \"0\" = \"Slow\"))\n\nThe code here is a bit complicated but we will explain:\n\n\nJudgedSpeedLabel is the name of your new column,\n\nJudgedSpeed is the name of the old column and the one to take information from\n\nNote that if you gave the recoded variable the same name as the original it would overwrite it.\n\n\nFast and Slow are the new codings of 1 and 0 respectively in the new column\n\nThe mutate() function is also handy for making some calculations on or across columns in your data. For example, say you realise you made a mistake in your experiment where your participant numbers should be 1 higher for every participant, i.e. Participant 1 should actually be numbered as Participant 2, etc. You could do something like:\n\npong_data_mut2 &lt;- mutate(pong_data, \n                         Participant = Participant + 1)\n\nNote here, in this second example, you are giving the new column the same name as the old column Participant. Again, happens here is that you are overwriting the old data with the new data! So watch out, mutate can create a new column or overwrite an existing column, depending on what you tell it to do!\nOk great! Now, imagine you realise that there is a mistake in your dataset and that all your trial numbers are wrong. The first trial (trial number 1) was a practice so should be excluded and your experiment actually started on trial 2. Your turn! You can either do this following activity in two separate steps and create a new object each time, or you can uses pipes %&gt;% and do it it one line of code. The final tibble should be stored in an object called pong_data_renumbered.\n\nFilter out all trials with the number 1 (TrialNumber column) from pong_data.\nThen use the mutate() function to renumber all the remaining trial numbers, starting them at one again instead of two, overwriting the values that were in the TrialNumber column.\n\n\n\nHelpful Hint\n\n\n\nStep 1. filter(TrialNumber does not equal 1). Remember to store this output in a variable if you are not using pipes.\nStep 2. mutate(TrialNumber = TrialNumber minus 1)\n\n\n\n\n5.2.7 Activity 8: Summarising data\nExcellent! And now that we have done some wrangling we want to calculate some descriptive statistics for the data using summarise(). summarise() has a range of internal functions that make life really easy, e.g. mean, sum, max, min, etc. See the dplyr cheatsheet for more examples. And additional one that we will use from time-to-time is na.rm = TRUE which we can add when calculating descriptive statistics to say what to do if there are missing values. Missing values often appear as NA and the job of na.rm is to say whether to remove (rm) the NAs (na.rm = TRUE) or not (na.rm = FALSE). If you try to calculate values from data that have NAs, such as the mean, it would return NA as the result because it doesn’t know how to average nothing. This dataset has no missing values but we will show you how to use it here and try to remember this argument exists, as you will use it often and it save you a lot of time!\nBack to the activity. Here, using the data in pong_data_renumbered we will calculate:\n\nThe total (sum) number of hits for each combination of background colour and paddle length.\nThe mean number of hits for each combination of background colour and paddle length\n\nRemember though, because we want to produce descriptive statistics by groups (background colour and paddle length), there are two steps:\n\nFirst we group the data by BackgroundColor and PaddleLength using group_by().\nThen, we use summarise() to calculate the total and mean number of hits (HitOrMiss) using the grouped data\n\nWe will do this activity using pipes to reduce the amount of code we write. Remember to try and read the code out loud and to pronounce %&gt;% as ‘and then’. Copy and paste the below code into a new code chunk and run the code.\n\npong_data_hits &lt;- pong_data_renumbered %&gt;% \n  group_by(BackgroundColor, \n           PaddleLength) %&gt;% \n  summarise(total_hits = sum(HitOrMiss, \n                             na.rm = TRUE),\n            meanhits = mean(HitOrMiss, \n                            na.rm = TRUE))\n\n`summarise()` has grouped output by 'BackgroundColor'. You can override using\nthe `.groups` argument.\n\n\n\n\n\nRemember, if you get what looks like an error that says “summarise() has grouped output by ‘BackgroundColor’. You can override using the .groups argument.”, don’t worry, this isn’t an error it’s just the code telling you how the final object is grouped.\n\n\n\n\nView pong_data_hits and answer the following questions to see if you have completed the task correctly.\n\n\nWhat was the total number of hits made with the small paddle (50) and the blue colour background?\n\n10595275161057\n\n\n\n\nTo three decimal places, what was the mean number of hits made with the small paddle (50) and the blue colour background?\n\n0.920.4590.4510.922\n\n\n\nNote:\n\nThe name of the column within pong_data_hits is total_hits; this is what you called it in the above code. You could have called it anything you wanted but always try to use something sensible.\nMake sure to call your variables something you (and anyone looking at your code) will understand and recognize later (i.e. not variable1, variable2, variable3. etc.), and avoid spaces (use_underscores_never_spaces)."
  },
  {
    "objectID": "05-wrangling-2.html#select-arrange-and-mutate-recap",
    "href": "05-wrangling-2.html#select-arrange-and-mutate-recap",
    "title": "5  Data wrangling 2: Filter and summarise",
    "section": "\n5.2 Select, arrange, and mutate recap",
    "text": "5.2 Select, arrange, and mutate recap\nBefore we introduce you to new functions, we will recap data wrangling functions from Chapter 4 to select, arrange, and mutate. Following along is one thing but being able to transfer your understanding to a new data set is a key sign of your skill development. Feel free to use Chapter 4 to help you, but try and complete the recap activities independently before checking the solutions. This will help prepare you as we move from the chapters, to the data analysis journeys, to the assessments, and to your future career.\n\n5.2.1 Activity 1 - Load tidyverse and read the data file\nAs the first activity, try and test yourself by loading tidyverse and reading the data file. As a prompt, save the data file to this object name to be consistent with the activities below, but you can check your answer below if you are stuck.\n\n# Load the tidyverse package below\n?\n  \n# Load the data file\n# This should be the witt_2018.csv file \npong_data &lt;- ?\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# Load the tidyverse package below\nlibrary(tidyverse)\n\n# Load the data file\n# This should be the witt_2018.csv file \npong_data &lt;- read_csv(\"data/witt_2018.csv\")\n\n\n\n\n\n5.2.2 Activity 2 - Explore pong_data\n\nRemember the first critical step when you come across any new data is exploring to see how many columns you are working with, how many rows/observations there are, and what the values look like. For example, you can click on pong_data in the environment and scroll around it as a tab. You can also get a preview of your data by using the glimpse() function.\n\nglimpse(pong_data)\n\nRows: 4,608\nColumns: 8\n$ Participant     &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ JudgedSpeed     &lt;dbl&gt; 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, …\n$ PaddleLength    &lt;dbl&gt; 50, 250, 50, 250, 250, 50, 250, 50, 250, 50, 50, 250, …\n$ BallSpeed       &lt;dbl&gt; 5, 3, 4, 3, 7, 5, 6, 2, 4, 4, 7, 7, 3, 6, 5, 7, 2, 5, …\n$ TrialNumber     &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,…\n$ BackgroundColor &lt;chr&gt; \"red\", \"blue\", \"red\", \"red\", \"blue\", \"blue\", \"red\", \"r…\n$ HitOrMiss       &lt;dbl&gt; 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, …\n$ BlockNumber     &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n\n\nIf you look at that table, you can see there are 8 columns and 4608 rows. Seven of the column names are &lt;dbl&gt;, short for double, and one is &lt;chr&gt;, short for character. We will need to keep the data types in mind as we wrangle the data.\n\n5.2.3 Data types in R\nWe try and balance developing your data skills in a practical way while slowly introducing some of the underlying technical points. In the last chapter, we warned about honoring data types so R knew how to handle numbers/doubles vs factors. Now we have explored a few data sets, it is time to clarify some key differences between data types in R.\nWe often store data in two-dimensional tables, either called data frames, tables, or tibbles. There are other ways of storing data that you will discover in time but in this book, we will be using data frame or tibbles (a special type of data frame in the tidyverse). A data frame is really just a table of data with columns and rows of information. Within the cells of the data frame - a cell being where a row and a column meet - you get different types of data, including double, integer, character and factor. To summarise:\n\n\n\n\n\n\nType of Data\nDescription\n\n\n\nDouble\nNumbers that can take decimals\n\n\nInteger\nNumbers that cannot take decimals\n\n\nCharacter\nTends to contain letters or be words\n\n\nFactor\nNominal (categorical). Can be words or numbers (e.g., animal or human, 1 or 2)\n\n\n\nDouble and integer can both be referred to as numeric data, and you will see this word from time to time. For clarity, we will use double as a term for any number that can take a decimal (e.g. 3.14) and integer as a term for any whole number (no decimal, e.g. 3).\nSomewhat confusingly, double data might not have decimal places in it. For instance, the value of 1 could be double as well as integer. However, the value of 1.1 could only be double and never integer. Integers cannot have decimal places. The more you work with data the more this will make sense, but it highlights the importance of looking at your data and checking what type it is as the type determines what you can do with the data.\nIn pong_data, each row (observation) represents one trial per participant and there are 288 trials for each of the 16 participants. Most of the data is a double (i.e., numbers) and one column is a character (i.e., text). The columns (variables) we have in the data set are:\n\n\n\n\n\n\n\nVariable\nType\nDescription\n\n\n\nParticipant\ndouble\nparticipant number\n\n\nJudgedSpeed\ndouble\nspeed judgement (1 = fast, 0 = slow)\n\n\nPaddleLength\ndouble\npaddle length (pixels)\n\n\nBallSpeed\ndouble\nball speed (2 pixels/4ms)\n\n\nTrialNumber\ndouble\ntrial number\n\n\nBackgroundColor\ncharacter\nbackground display colour\n\n\nHitOrMiss\ndouble\nhit ball = 1, missed ball = 0\n\n\nBlockNumber\ndouble\nblock number (out of 12 blocks)\n\n\n\n5.2.4 Activity 3 - select() a range of columns\nEither by inclusion (stating all the variables you want to keep) or exclusion (stating all the variables you want to drop), create a new object named select_dat and select the following columns from pong_data:\n\nParticipant\nPaddleLength\nTrialNumber\nBackgroundColor\nHitOrMiss\n\n\n# select 5 variables from pong_data\nselect_dat &lt;- ?\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# select 5 variables from pong_data\nselect_dat &lt;- select(pong_data,\n                     Participant,\n                     PaddleLength,\n                     TrialNumber,\n                     BackgroundColor,\n                     HitOrMiss)\n\nor\n\n# remove 3 variables from pong_data\nselect_dat &lt;- select(pong_data,\n                     -JudgedSpeed,\n                     -BallSpeed,\n                     -BlockNumber)\n\n\n\n\n\n5.2.5 Activity 4 - Reorder the variables using select()\n\nWe can also use select() to reorder your columns, as the new data object will display the variables in the order that you entered them.\nUse select() to keep only the columns Participant, JudgedSpeed, BallSpeed, TrialNumber, and HitOrMiss from pong_data but this time, display them in ascending alphabetical order. Save this tibble in a new object named reorder_dat.\n\n# reorder the 5 variables from pong_data\nreorder_dat &lt;- ?\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# reorder the 5 variables from pong_data\nreorder_dat &lt;- select(pong_data, # original data\n                     BallSpeed,\n                     HitOrMiss,\n                     JudgedSpeed,\n                     Participant,\n                     TrialNumber)\n\n\n\n\n\n5.2.6 Activity 5 - Reorder observations using arrange()\n\nReorder observations in the data using the following two variables: HitOrMiss (putting hits (1) first) and JudgedSpeed (putting fast judgement (1) first). Store this in an object named arrange_dat.\n\n# arrange pong_data by HitOrMiss and JudgedSpeed\narrange_dat &lt;- ?\n\nNow try and answer the following questions about the data.\n\nWhat is the trial number (TrialNumber) in the 1st row? \nWhat is the background colour (BackgroundColor) in the 10th row? \n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou needed to include desc() to change it from running smallest-to-largest to largest-to-smallest as the values are 0 and 1. You should have the following in a code chunk:\n\n# arrange pong_data by HitOrMiss and JudgedSpeed\narrange_dat &lt;- arrange(pong_data, # original data\n                     desc(HitOrMiss),\n                     desc(JudgedSpeed))\n\n\n\n\n\n5.2.7 Activity 6 - Modifying or creating variables using mutate()\n\nSome of these values could be a little easier to understand. They are represented in the data by 0s and 1s, but it might not be immediately obvious what they mean.\nCreate a new variable called JudgedSpeedLabel by mutating the original pong_data object. Change the values in JudgedSpeed using the following labels:\n0 = Slow\n1 = Fast\n\n# mutate pong_data and recode values into a new variable\npong_data &lt;- ?\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# mutate pong_data and recode values into a new variable\npong_data &lt;- mutate(pong_data, \n                    JudgedSpeedLabel = case_match(JudgedSpeed, \n                                                  0 ~ \"Slow\",\n                                                  1 ~ \"Fast\"))"
  },
  {
    "objectID": "05-wrangling-2.html#removing-or-retaining-observations-using-filter",
    "href": "05-wrangling-2.html#removing-or-retaining-observations-using-filter",
    "title": "5  Data wrangling 2: Filter and summarise",
    "section": "\n5.3 Removing or retaining observations using filter()\n",
    "text": "5.3 Removing or retaining observations using filter()\n\nNow we have revisited key data wrangling functions from Chapter 4 to select, arrange, and mutate, it is time to add some new functions from dplyr to your toolkit.\nUsing select, we could remove columns, but there are many situations where you want to include or exclude certain observations/rows. The function filter() will possibly be one of your most used for data wrangling. For example, imagine you want to only analyse participants who provided informed consent and exclude participants who did not. Similarly, you might want to focus your analyses only on participants who are under the age of 21.\n\n5.3.1 Activity 7 - Filter using one criterion\nWe will jump straight into an example. Imagine that you realised you made a mistake creating your experiment and all your trial numbers are wrong. The first trial (trial number 1) was a practice, so you should exclude it and your experiment actually started on trial 2.\n\npong_data_filter &lt;- filter(pong_data,\n                           TrialNumber &gt; 1)\n\nTo break down the code:\n\nWe create a new object called pong_data_filter by applying the filter function to pong_data.\nWe add the Boolean expression TrialNumber &gt; 1 to keep all responses higher than 1 (i.e., 2 or higher).\n\nThe filter() function uses our old friends the Boolean expressions we introduced you to in Chapter 4. You can add one or more logical expressions to filter observations. The function retains observations when they are evaluated to TRUE and ignores observations when they are evaluated to FALSE. Remember, when you are working out how to express your ideas in code, test them out. For example, we can see what the expression would do to different trial numbers:\n\n1 &gt; 1\n2 &gt; 1\n\n[1] FALSE\n[1] TRUE\n\n\n1 is not larger than 1, so it’s evaluated to FALSE and would be ignored. 2 is larger than 2, so it’s evaluated to TRUE and would be retained. Explore the two data sets pong_data and pong_data_filter and the number of rows they have to see the effects of applying the function.\nAs a reminder from Chapter 4, the most common Boolean expressions are:\n\n\nOperator\nName\nis TRUE if and only if\n\n\n\nA &lt; B\nless than\nA is less than B\n\n\nA &lt;= B\nless than or equal\nA is less than or equal to B\n\n\nA &gt; B\ngreater than\nA is greater than B\n\n\nA &gt;= B\ngreater than or equal\nA is greater than or equal to B\n\n\nA == B\nequivalence\nA exactly equals B\n\n\nA != B\nnot equal\nA does not exactly equal B\n\n\nA %in% B\nin\nA is an element of vector B\n\n\n\n\n\n\n\n\n\nTry this\n\n\n\nUsing the filter() example and the table above, imagine we wanted to only keep trials where participants judged the speed to be “Fast”. Use the pong_data_filter after removing trial number 1 and assign it to a new object pong_data_fast. You could use the JudgedSpeed or JudgedSpeedLabel variable to do this.\nFor a hint, you want to keep responses when they are equivalent to “Fast” or 1 depending on the variable you use.\n\n# Retain fast judged speed trials\npong_data_fast &lt;- filter(pong_data_filter,\n                         ?)\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nYou were looking for the equivalence Boolean operator (==) to retain responses which were equal to “Fast” or 1. If you used JudgedSpeedLabel, you should have:\n\n# Retain fast judged speed trials\npong_data_fast &lt;- filter(pong_data_filter,\n                         JudgedSpeedLabel == \"Fast\")\n\nIf you used JudgedSpeed, you should have:\n\n# Retain fast judged speed trials\npong_data_fast &lt;- filter(pong_data_filter,\n                         JudgedSpeedLabel == 1)\n\nNote we use a double equals == and not a single equals = for the Boolean operator. We also must honour the data type for the expression we set.\n\n\n\n\n5.3.2 Activity 8 - Filter using two or more criteria\nYou explored using one criterion to filter out or retain observations/rows, but you can make the expressions arbitrarily more complicated by adding two or more criteria to evaluate against. Just note the more criteria you add, the more selective you are being. You are probably going to be excluding more and more observations, so think about what you want to achieve.\nFocusing on one variable, you can specify multiple values to compare against. For example, you might want to only keep responses which had a ball speed of 2 or 4:\n\npong_data_BallSpeed &lt;- filter(pong_data_filter,\n                              BallSpeed == 2 | BallSpeed == 4)\n\nTo break down the code:\n\nWe create a new object called pong_data_BallSpeed by applying the filter function to pong_data_filter.\nWe add the Boolean expression BallSpeed == 2, the vertical line symbol (|), then a second expression BallSpeed == 4. The vertical line symbol (|) means “or”, so our expression is retain BallSpeed responses which equal 2 OR 4, and ignore all the others.\n\nFor two values, this is pretty straightforward, but it could get out of hand when you have four or five values to evaluate against. There is a super handy shortcut from the Boolean expressions table for “in” which we can apply if we wanted to keep ball speeds of 2, 4, 5, and 7:\n\npong_data_BallSpeed &lt;- filter(pong_data_filter,\n                              BallSpeed %in% c(2, 4, 5, 7))\n\nYou can read the expression here as: for each observation/row, check whether the value of BallSpeed is in the vector of numbers 2, 4, 5, 7. Remember filter() works by whether the expression is evaluted to TRUE or FALSE, so you can see how it works by testing some numbers:\n\n1 %in% c(2, 4, 5, 7)\n2 %in% c(2, 4, 5, 7)\n\n[1] FALSE\n[1] TRUE\n\n\n1 is not present in c(2, 4, 5, 7), so it is evaluated to FALSE and would be ignored. 2 is presented in c(2, 4, 5, 7), so it is evaluated to TRUE and would be retained.\nYou can also add two or more expressions including multiple variables by adding them to the function separated by commas. For example, imagine we wanted to retain observations/rows which had a “Fast” speed judgement with ball speeds of 2, 4, 5, and 7:\n\npong_fast_BallSpeed &lt;- filter(pong_data_filter, \n                         JudgedSpeedLabel == \"Fast\", \n                         BallSpeed %in% c(\"2\", \"4\", \"5\", \"7\"))\n\nIn the first expression, we only want to keep observations/rows which have a JudgedSpeedLabel of “Fast”. In the second expression, we only want to keep observations/rows which have a BallSpeed of 2, 4, 5, or 7. In other words, retain “Fast” observations AND those with a ball speed of 2, 4, 5, or 7. Adding more expressions makes your criteria more selective as rows must pass both conditions to be retained in the data.\n\n\n\n\n\n\nTry this\n\n\n\nUsing the examples above, imagine we wanted to only keep trials where:\n\nThe PaddleLength is 50.\nThe BackgroundColor is red.\nThe HitOrMiss is 1.\n\nUse the pong_data_filter object and assign it to a new object pong_data_three_criteria.\n\n# apply three criteria to filter pong_data_filter\npong_data_three_criteria &lt;- filter(pong_data_filter,\n                                   ?)\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# apply three criteria to filter pong_data_filter\npong_data_three_criteria &lt;- filter(pong_data_filter,\n                                   PaddleLength == 50,\n                                   BackgroundColor == \"red\",\n                                   HitOrMiss == 1)"
  },
  {
    "objectID": "05-wrangling-2.html#counting-observations-using-count",
    "href": "05-wrangling-2.html#counting-observations-using-count",
    "title": "5  Data wrangling 2: Filter and summarise",
    "section": "\n5.4 Counting observations using count()\n",
    "text": "5.4 Counting observations using count()\n\nAs we work from wrangling data towards analysing your data to produce numerical summaries, we can start introducing different ways of summarising your data set.\nIn it’s simplest sense, we can look at different ways of counting your observations. Often, it is helpful to know how many observations you have, either in total, or broken down by groups. This can help you spot if something has gone wrong in a calculation, e.g., if you have done something with the code and your mean or median is only being calculated using a subset of the values you intended. Alternatively, it can be useful for reporting descriptive statistics, such as how many participants were in your study or how many people were in each group.\n\n5.4.1 Activity 9 - Counting observations\nTo count observations, you have the function count(). Without any additional arguments, you can use the function to report how many observations are in your data set:\n\ncount(pong_data_filter)\n\n\n\n\nn\n\n\n4592\n\n\n\n\n\nThis corresponds nicely with the number of observations you can see in the data environment window and from when we have used glimpse() for a summary of the object.\nYou can then add one or more variables to the function to count the number of observations within each variable and across the combination of variables when you supply two or more. For example, we could count the number of observations within BackgroundColor:\n\ncount(pong_data_filter,\n      BackgroundColor) # count observations within variable 1\n\nAnd it would give the answer of:\n\n\n\n\n\nBackgroundColor\nn\n\n\n\nblue\n2304\n\n\nred\n2304\n\n\n\n\n\n\nWe can see there are an equal number of blue and red backgrounds across all the observations.\n\n\n\n\n\n\nTry this\n\n\n\nOne way of sense checking your data and making sure there is not a sneaky error is checking how many observations there are per unique participant and ensuring that matches up with what you understand about the study.\nUse the count() function on the pong_data_filter object to answer the following questions about the data:\n\nHow many observations do we have for each unique Participant in the data? \nHitOrMiss codes for whether the Participant hit or missed the ball in the trial. If you count the number of HitOrMiss per Participant, participant number 3 made  hits and  misses.\n\n\n# count observations per Participant\ncount(pong_data_filter,\n      ?)\n\n# count observations of HitOrMiss per Participant\n# Hint: you can add multiple variables with a comma. \ncount(pong_data_filter,\n      ?)\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nTo answer question 1, we only need to add Participant as an argument after the data pong_data_filter.\n\n# count observations per Participant\ncount(pong_data_filter,\n      Participant)\n\nTo answer question 2, we need both Participant and HitOrMiss as arguments after the data pong_data_filter, as we want the number of hits and misses per participant.\n\n# count observations of HitOrMiss per Participant\ncount(pong_data_filter,\n      Participant,\n      HitOrMiss)"
  },
  {
    "objectID": "05-wrangling-2.html#getting-summary-statistics-using-summarise-and-group_by",
    "href": "05-wrangling-2.html#getting-summary-statistics-using-summarise-and-group_by",
    "title": "5  Data wrangling 2: Filter and summarise",
    "section": "\n5.5 Getting summary statistics using summarise() and group_by()\n",
    "text": "5.5 Getting summary statistics using summarise() and group_by()\n\nExcellent! And now that we have done some wrangling we want to calculate some descriptive statistics for the data using summarise(). summarise() has a range of internal functions that make life really easy, e.g. mean, sum, max, min, etc. See the dplyr cheatsheet for more examples. And additional one that we will use from time-to-time is na.rm = TRUE which we can add when calculating descriptive statistics to say what to do if there are missing values. Missing values often appear as NA and the job of na.rm is to say whether to remove (rm) the NAs (na.rm = TRUE) or not (na.rm = FALSE). If you try to calculate values from data that have NAs, such as the mean, it would return NA as the result because it doesn’t know how to average nothing. This dataset has no missing values but we will show you how to use it here and try to remember this argument exists, as you will use it often and it save you a lot of time!\nBack to the activity. Here, using the data in pong_data_renumbered we will calculate:\n\nThe total (sum) number of hits for each combination of background colour and paddle length.\nThe mean number of hits for each combination of background colour and paddle length\n\nRemember though, because we want to produce descriptive statistics by groups (background colour and paddle length), there are two steps:\n\nFirst we group the data by BackgroundColor and PaddleLength using group_by().\nThen, we use summarise() to calculate the total and mean number of hits (HitOrMiss) using the grouped data\n\nWe will do this activity using pipes to reduce the amount of code we write. Remember to try and read the code out loud and to pronounce %&gt;% as ‘and then’. Copy and paste the below code into a new code chunk and run the code.\n\npong_data_hits &lt;- pong_data_renumbered %&gt;% \n  group_by(BackgroundColor, \n           PaddleLength) %&gt;% \n  summarise(total_hits = sum(HitOrMiss, \n                             na.rm = TRUE),\n            meanhits = mean(HitOrMiss, \n                            na.rm = TRUE))\n\n`summarise()` has grouped output by 'BackgroundColor'. You can override using\nthe `.groups` argument.\n\n\n\n\n\nRemember, if you get what looks like an error that says “summarise() has grouped output by ‘BackgroundColor’. You can override using the .groups argument.”, don’t worry, this isn’t an error it’s just the code telling you how the final object is grouped.\n\n\n\n\nView pong_data_hits and answer the following questions to see if you have completed the task correctly.\n\n\nWhat was the total number of hits made with the small paddle (50) and the blue colour background?\n\n10595161057527\n\n\n\n\nTo three decimal places, what was the mean number of hits made with the small paddle (50) and the blue colour background?\n\n0.4510.920.4590.922\n\n\n\nNote:\n\nThe name of the column within pong_data_hits is total_hits; this is what you called it in the above code. You could have called it anything you wanted but always try to use something sensible.\nMake sure to call your variables something you (and anyone looking at your code) will understand and recognize later (i.e. not variable1, variable2, variable3. etc.), and avoid spaces (use_underscores_never_spaces).\n\n\n5.5.1 Counting data\n\n5.5.2 Ungrouping data\nAfter grouping data together using the group_by() function and then performing a task on it, e.g. filter(), it can be very good practice to ungroup the data before performing another function - by piping it into the ungroup() function - this is related to what the warnings about summarise() mean as they are changing the groupings so removing all groupings can be good to do. Forgetting to ungroup the dataset won’t always affect further processing, but can really mess up other things. Again just a good reminder to always check the data you are getting out of a function a) makes sense and b) is what you expect.\nThis is an example of how you might use the function:\n\npong_data_ungroup &lt;- pong_data %&gt;%\n  group_by(BackgroundColor, \n           PaddleLength) %&gt;%\n  summarise(total_hits = sum(HitOrMiss)) %&gt;%\n  ungroup"
  },
  {
    "objectID": "05-wrangling-2.html#combining-functions-using-the-pipe",
    "href": "05-wrangling-2.html#combining-functions-using-the-pipe",
    "title": "5  Data wrangling 2: Filter, summarise, and pipes",
    "section": "\n5.6 Combining functions using the pipe",
    "text": "5.6 Combining functions using the pipe"
  },
  {
    "objectID": "05-wrangling-2.html#test-yourself",
    "href": "05-wrangling-2.html#test-yourself",
    "title": "5  Data wrangling 2: Filter and summarise",
    "section": "\n5.6 Test yourself",
    "text": "5.6 Test yourself\nTo end the chapter, we have some knowledge check questions to test your understanding of the concepts we covered in the chapter. We then have some error mode tasks to see if you can find the solution to some common errors in the concepts we covered in this chapter.\n\n5.6.1 Knowledge check\nQuestion 1. What type of data would these most likely be:\n\nMale = \nInteger\nDouble\nCharacter\n7.15 = \nDouble\nCharacter\nInteger\n137 = \nDouble\nInteger\nCharacter\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nThere are several different types of data as well as different levels of measurement and it takes a while to recognise the nuanced differences. It is important to try to remember which is which because you can only do certain types of analyses on certain types of data and certain types of measurements. For instance, you cannot take the average of characters or categorical data. Likewise, you can do any maths on double data, just like you can on interval and ratio data. Integer data is funny in that sometimes it is ordinal and sometimes it is interval, sometimes you should take the median, sometimes you should take the mean. The main point is to always know what type of data you are using and to think about what you can and cannot do with them.\nNote: in the last answer, 137 could also be double as it is not clear if it could take a decimal or not.\n\n\n\nQuestion 2. Which of the dplyr functions would you use to count the number of observations in your data set or variables?\n\nselectfiltercountmutategroup_by\n\nQuestion 3. Which of the dplyr functions would you use to calculate the mean of a column?\n\nfiltergroup_bymutatesummariseselect\n\nQuestion 4. Which of the dplyr functions would you use to remove certain observations (e.g., remove all males)?\n\nselectcountsummarisemutatefiltergroup_by\n\nQuestion 5. Which of the dplyr functions would you use to subset summary statistics by?\n\nfiltercountmutatesummarisegroup_byselect\n\n\n5.6.2 Error mode\nThe following questions are designed to introduce you to making and fixing errors. For this topic, we focus on data wrangling using the functions filter(), count(), and group_by() and summarise(). Remember to keep a note of what kind of error messages you receive and how you fixed them, so you have a bank of solutions when you tackle errors independently.\nCreate and save a new R Markdown file for these activities. Delete the example code, so your file is blank from line 10. Create a new code chunk to load tidyverse and the data file:\n\n# Load the tidyverse package below\nlibrary(tidyverse)\n\n# Load the data file\npong_data &lt;- read_csv(\"data/witt_2018.csv\")\n\nBelow, we have several variations of a code chunk error or misspecification. Copy and paste them into your R Markdown file below the code chunk to load tidyverse and the data. Once you have copied the activities, click knit and look at the error message you receive. See if you can fix the error and get it working before checking the answer.\nQuestion 6. Copy the following code chunk into your R Markdown file and press knit. We want to filter data to only include a paddle length of 50. You should receive the error starting with Error in \"filter()\" ! We detected a named input.\n\n```{r}\n# filter pong_data to retain PaddleLength of 50\npong_data_filter &lt;- filter(pong_data,\n                           PaddleLength = 50)\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nIn the code, we use a single equals sign (=) rather than the Boolean operator a double equals sign (==). With a single equals, R is interpreting this as “PaddleLength is equal to 50” like you were saving an object or setting an argument. The error message below line two tries to help and suggests you might need to include == instead.\n\n# filter pong_data to retain PaddleLength of 50\npong_data_filter &lt;- filter(pong_data,\n                           PaddleLength == 50)\n\n\n\n\nQuestion 7. Copy the following code chunk into your R Markdown file and press knit. We want to count the number of trials per block (BlockNumber). This…works, but if you look at the output, have we counted the number of trials?\n```{r}\n# Count block numbers from pong_data\ncount_blocknumbers &lt;- summarise(pong_data,\n                                N_blocks = sum(BlockNumber))\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nThe mistake is using sum() to count the number of trials per block. sum() would only work when you have 0s and 1s. Here, it just adds up all the numbers, totalling 29952. There are two options here. In every other scenario, you need to either count():\n\n# Count block numbers from pong_data\ncount_blocknumbers &lt;- count(pong_data,\n                            BlockNumber)\n\nor group_by() and `n():\n\n# Group by block number\ngroup_blocks &lt;- group_by(pong_data,\n                         BlockNumber)\n# Then calculate the number of trials per block\ncount_blocknumbers &lt;- summarise(group_blocks,\n                                N_blocks = n())\n\n\n\n\nQuestion 8. Copy the following code chunk into your R Markdown file and press knit. Here, we want the proportion of fast judgements per paddle length by taking the mean of JudgedSpeed. This code… works, but do we have a proportion of fast judgements per paddle length?\n```{r}\n# Mean judged speed for the proportion of fast judgements\nhits_by_background &lt;- summarise(pong_data,\n                                prop_fast = mean(JudgedSpeed))\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nWe wanted the mean proportion of fast judgements, but we forgot to add a group by! We only got one value, so we need to add an initial step to group the responses by PaddleLength first, before we then calculate the mean proportion.\n\n# Group pong_data by paddle length\npong_data_paddle &lt;- group_by(pong_data,\n                                 PaddleLength)\n\n# Mean judged speed for the proportion of fast judgements\nhits_by_background &lt;- summarise(pong_data_paddle,\n                                 prop_fast = mean(JudgedSpeed))"
  },
  {
    "objectID": "05-wrangling-2.html#end-of-chapter",
    "href": "05-wrangling-2.html#end-of-chapter",
    "title": "5  Data wrangling 2: Filter and summarise",
    "section": "\n5.8 End of chapter",
    "text": "5.8 End of chapter\nBrilliant work again! You have another handful of functions added to your data wrangling toolkit and we are almost ready to tackle more advanced plotting techniques and inferential statistics.\nIn the next chapter, we finish the key data wrangling functions. For example, showing you how you can pipe together multiple functions to streamline your code. We will also demonstrate how to pivot your data wider from long form where there are multiple observations per participant to wide form where there is one row per participant, and vice versa.\n\n\n\n\nWitt, J. K., Tenhundfeld, N. L., & Tymoski, M. J. (2018). Is there a chastity belt on perception? Psychological Science, 29(1), 139–146."
  },
  {
    "objectID": "05-wrangling-2.html#summarising-data-using-summarise-and-group_by",
    "href": "05-wrangling-2.html#summarising-data-using-summarise-and-group_by",
    "title": "5  Data wrangling 2: Filter and summarise",
    "section": "\n5.5 Summarising data using summarise() and group_by()\n",
    "text": "5.5 Summarising data using summarise() and group_by()\n\nCounting data is useful, but it might not be the only way of summarising data that you want. A more flexible function is summarise() which you can use to calculate summary statistics across your whole data frame, or grouped by additional variables.\n\n5.5.1 Activity 10 - Summarising all the observations\nTo start with something familiar, we can use summarise() to count observations. The function works in a similar format to mutate() where you enter a variable name and tell R what function you want applying to the data frame or variable. For example, we can use the n() function to calculate the number of observations in pong_data_filter:\n\nN_observations &lt;- summarise(pong_data_filter,\n                            N_observations = n())\n\nTo break down the code:\n\nWe create a new object N_observations by applying the summarise() function to pong_data_filter.\nWe create a new variable name called N_observations, add an equals for what that new variable represents, and add our desired function n(). You do not need to add any further arguments, it calculates the number of observations in the object you give it.\n\nThis creates a new object as a data frame with 1 observation and 1 column to produce a single number:\n\n\n\n\n\nN_observations\n\n\n4592\n\n\n\n\n\nReassuringly, this is exactly the same as we received for count(). If you only want the number of observations, then count() will be more efficient. However, if you want to produce the number of observations in addition to other summary statistics, then summarise() is going to be more useful.\nTo demonstrate the flexibility of summarise(), we can add another summary statistic for the mean hit rate. When binary outcomes like a hit or a miss are coded as 0 and 1, taking the mean provides the proportion of hits (or whatever is coded as 1).\n\nsummarise(pong_data_filter,\n          N_observations = n(),\n          hit_proportion = mean(HitOrMiss, \n                                na.rm = TRUE))\n\n\n\n\nN_observations\nhit_proportion\n\n\n4592\n0.6879355\n\n\n\n\n\nIn this example, we have not saved the summarise() output to a new object, just printed it’s result. We can see we get the number of observations as before, but we also get the mean value for the hit rate. The proportion of hits across all observations was 0.688 or 68.8%.\n\n\n\n\n\n\nWhy is my mean NA?\n\n\n\nWhen you use the mean() function, you might find the result is NA. This is likely due to the presence of an NA or missing value in your variable. NAs are contagious as if you try and calculate the mean of a set of numbers containing one or more NA values, the overall mean will also be an NA.\nSo, the mean() function has an additional argument na.rm = TRUE which tells R what to do if there are missing values. The job of na.rm is to say whether to remove (rm) the NAs (na.rm = TRUE) or not (na.rm = FALSE).\nThis data set has no missing values but we showed you how to use it here so you can try to remember it exists in future. You do not need to use it all the time and you should think carefully about whether you should ignore NAs, but the option is there if you need it.\n\n\n\n\n\n\n\n\nTry this\n\n\n\nUsing what you learnt above, apply the summarise() function to calculate the mean value of JudgedSpeed using the pong_data_filter object and fill in the blanks below. Remember, calculating the mean of a binary outcome of 0s and 1s tells you the proportion, so the mean here would be the proportion of responses judged to be fast.\nRounded to 3 decimal places, the mean proportion of fast responses is  or rounded to 1 decimal place %.\n\n# mean value of JudgedSpeed for the proportion\nsummarise(pong_data_filter,\n          ?)\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nYou only needed to add one argument to calculate the mean of the JudgedSpeed variable. We called the new variable fast_proportion, but this was not important for the answer. Just make sure you call your variables something sensible, so you could understand what it means later.\n\n# mean value of JudgedSpeed for the proportion\nsummarise(pong_data_filter,\n          fast_proportion = mean(JudgedSpeed))\n\n\n\n\n\n5.5.2 Activity 11 - Grouping your summary statistics\nSummarising your whole data set is great, but there will often be times you want separate summary statistics for different groups in your data. The group_by() function takes an existing data frame or tibble and creates a grouped data frame. As a data frame, this does not look much different, but it adds a kind of hidden property which functions like summarise() detects and uses.\nAs an example, let us see how the summary statistics compare between each level of judged speed. For the initial step, we need to apply the group_by() function:\n\n# Group pong_data_filter by JudgedSpeedLabel\npong_data_grouped &lt;- group_by(pong_data_filter,\n                              JudgedSpeedLabel)\n\nTo break down the code:\n\nWe create a new object pong_data_grouped by applying the group_by() function to pong_data_filter.\nWe add one or more variables we want to group any summary statistics by. In this case, we group by JudgedSpeedLabel so we will get separate values for fast and slow.\n\nIf you open pong_data_grouped as a tab, it does not look any different. Remember, group_by() adds a kind of hidden property. To check this, we can run the str() function on the data object which will show us the structure of an object:\n\n# Show the structure of the data object pong_data_grouped\nstr(pong_data_grouped)\n\ngropd_df [4,592 × 9] (S3: grouped_df/tbl_df/tbl/data.frame)\n $ Participant     : num [1:4592] 1 1 1 1 1 1 1 1 1 1 ...\n $ JudgedSpeed     : num [1:4592] 0 1 0 1 0 1 0 0 0 1 ...\n $ PaddleLength    : num [1:4592] 250 50 250 250 50 250 50 250 50 50 ...\n $ BallSpeed       : num [1:4592] 3 4 3 7 5 6 2 4 4 7 ...\n $ TrialNumber     : num [1:4592] 2 3 4 5 6 7 8 9 10 11 ...\n $ BackgroundColor : chr [1:4592] \"blue\" \"red\" \"red\" \"blue\" ...\n $ HitOrMiss       : num [1:4592] 1 0 1 1 1 1 1 1 1 0 ...\n $ BlockNumber     : num [1:4592] 1 1 1 1 1 1 1 1 1 1 ...\n $ JudgedSpeedLabel: chr [1:4592] \"Slow\" \"Fast\" \"Slow\" \"Fast\" ...\n - attr(*, \"groups\")= tibble [2 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ JudgedSpeedLabel: chr [1:2] \"Fast\" \"Slow\"\n  ..$ .rows           : list&lt;int&gt; [1:2] \n  .. ..$ : int [1:2512] 2 4 6 10 11 13 15 17 19 22 ...\n  .. ..$ : int [1:2080] 1 3 5 7 8 9 12 14 16 18 ...\n  .. ..@ ptype: int(0) \n  ..- attr(*, \".drop\")= logi TRUE\n\n\nThe two key elements here are in the first line (gropd_df [4,592 × 9] (S3: grouped_df/tbl_df/tbl/data.frame)) and below the variables (- attr(*, \"groups\")... ..$ JudgedSpeedLabel: chr [1:2] \"Fast\" \"Slow\"). The first line confirms we now have a grouped data frame and the two lines below the variables show the values we group by.\nThe next step is applying the summarise() function as before. Here, we will calculate the total and mean number of hits by whether the participants judged the speed to be fast or slow:\n\n# Sum hits for the number of hits \n# Mean hits for the proportion of hits\nhits_by_judgedspeed &lt;- summarise(pong_data_grouped,\n                                 sum_hits = sum(HitOrMiss),\n                                 prop_hits = mean(HitOrMiss))\n\nCalling the object shows we now get two rows per summary statistic:\n\nhits_by_judgedspeed\n\n\n\n\nJudgedSpeedLabel\nsum_hits\nprop_hits\n\n\n\nFast\n1651\n0.6572452\n\n\nSlow\n1508\n0.7250000\n\n\n\n\n\n\nAlthough there were more hits in the fast judged speed, the proportion of hits to misses was lower. Participants hit .657 (65.7%) of trials they judged to be fast but .725 (72.5%) of trials they judged to be slow.\n\n\n\n\n\n\nTry this\n\n\n\nUsing what you learnt above, apply the group_by() and summarise() functions to calculate the sum and mean value of HitOrMiss depending on whether BackgroundColor was blue or red. In your group_by() object, make sure you use the pong_data_filter object. After writing the code and checking the new object, answer the following questions:\n\nRounded to 2 decimal places, the mean proportion of hits to the blue background was  or rounded to 0 decimal places %.\nRounded to 3 decimal places, the mean proportion of hits to the red background was  or rounded to 1 decimal place %.\n\n\n# Group pong_data_filter by BackgroundColor\npong_data_background &lt;- ?\n\n# Sum hits for the number of hits \n# Mean hits for the proportion of hits\nhits_by_background &lt;- ?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThere are two steps here to follow the previous example. The main difference is using BackgroundColor in group_by(), and then the summarise() element is largely the same.\n\n# Group pong_data_filter by BackgroundColor\npong_data_background &lt;- group_by(pong_data_filter,\n                                 BackgroundColor)\n\n# Sum hits for the number of hits \n# Mean hits for the proportion of hits\nhits_by_background &lt;- summarise(pong_data_background,\n                                 sum_hits = sum(HitOrMiss),\n                                 prop_hits = mean(HitOrMiss))\n\n\n\n\n\n\n\n\n\n\nR Markdown tip of the chapter: Create pretty tables\n\n\n\nAfter we introduced you to R Markdown to create reproducible documents in Chapter 2, we are going to add a tip in every chapter to demonstrate extra functionality.\nR Markdown is great for embedding plots and statistics in reproducible documents, but tables can be a little tricky. If you only call objects like hits_by_background, the output does not look super professional and it is not consistent with APA formatting guidelines.\nThere are a few options available to you. One of the packages that helps create R Markdown - knitr - can create tables from objects you create. There is a function called kable() which can create tables with no further arguments, but you will need to edit the object to make sure it has headers and labels consistent with APA. The following code creates a simple table if you have knitr installed:\n\nknitr::kable(hits_by_judgedspeed)\n\nYou will need to knit your document to see what it looks like, but it should look similar to Figure 5.1. The row labels are fine, but you would need to tidy up the headers and round prop_hits to three decimals (see the function round()).\n\n\n\n\nFigure 5.1: Example of using kable() to create tables in R Markdown.\n\n\n\nSee The R Markdown Cookbook for a guide on creating tables using kable().\nAlternatively, there is a package called gt which can also create tables with plenty of formatting options. See their documentation https://gt.rstudio.com/ online for further information.\n\n\n\n5.5.3 Ungrouping data\nFor a final word of warning, there is an additional function which removes a group from a data frame. For example, if you wanted to use objects like pong_data_grouped for additional wrangling, visualisation, or analysis, it can create problems if you leave the group property. If you only use these objects to create summary tables like hits_by_judgedspeed, then there is no issue.\nIt is good practice to ungroup the data before performing another function using the ungroup() function:\n\npong_data_grouped &lt;- ungroup(pong_data_grouped)\n\nIf you run str(pong_data_grouped) again, you will see we removed the grouping property. Remember, you only need to apply this if you are using the object in further steps. We will demonstrate in the next chapter how you can add this in a more streamlined way."
  },
  {
    "objectID": "06-wrangling-3.html#chapter-preparation",
    "href": "06-wrangling-3.html#chapter-preparation",
    "title": "6  Data Wrangling 3: Pivots and Pipes",
    "section": "\n6.1 Chapter preparation",
    "text": "6.1 Chapter preparation\n\n6.1.1 Introduction to the data set\nFor this chapter, we are using open data from Alter et al. (2024). The abstract of their article is:\n\nThe biggest difference in statistical training from previous decades is the increased use of software. However, little research examines how software impacts learning statistics. Assessing the value of software to statistical learning demands appropriate, valid, and reliable measures. The present study expands the arsenal of tools by reporting on the psychometric properties of the Value of Software to Statistical Learning (VSSL) scale in an undergraduate student sample. We propose a brief measure with strong psychometric support to assess students’ perceived value of software in an educational setting. We provide data from a course using SPSS, given its wide use and popularity in the social sciences. However, the VSSL is adaptable to any statistical software, and we provide instructions for customizing it to suit alternative packages. Recommendations for administering, scoring, and interpreting the VSSL are provided to aid statistics instructors and education researchers understand how software influences students’ statistical learning.\n\nTo summarise, they developed a new scale to measure students’ perceived value of software to learning statistics - Value of Software to Statistical Learning (VSSL). The authors wanted to develop this scale in a way that could be adapted to different software, from SPSS in their article (which some of you may have used in the past), to perhaps R in future. Alongside data from their new scale, they collected data from other scales measuring a similar kind of construct (e.g., Students’ Attitudes toward Statistics and Technology) and related constructs (e.g., Quantitative Attitudes).\nIn this chapter, we will wrangle their data to reinforce skills from Chapter 4 and 5. Scale data is extremely common to work with in psychology and there is a high likelihood you will use one or more in your dissertation or future careers. After recapping skills from the past two chapters on this new data set, we will add more data wrangling functions to your toolkit.\n\n6.1.2 Organising your files and project for the chapter\nBefore we can get started, you need to organise your files and project for the chapter, so your working directory is in order.\n\nIn your folder for research methods and the book ResearchMethods1_2/Quant_Fundamentals, you should have a folder from chapter 4 called Chapter_04_06_datawrangling where you created an R Project.\nCreate a new R Markdown document and give it a sensible title describing the chapter, such as 06 Data Wrangling 3. Delete everything below line 10 so you have a blank file to work with and save the file in your Chapter_04_06_datawrangling folder.\nWe are working with a new data set separated into two files. The links are data file one (Alter_2024_demographics.csv) and data file two (Alter_2024_scales.csv). Right click the links and select “save link as”, or clicking the links will save the files to your Downloads. Make sure that both files are saved as “.csv”. Save or copy the file to your data/ folder within Chapter_04_06_datawrangling.\n\nYou are now ready to start working on the chapter!"
  },
  {
    "objectID": "06-wrangling-3.html#recapping-all-the-previous-dplyr-functions",
    "href": "06-wrangling-3.html#recapping-all-the-previous-dplyr-functions",
    "title": "6  Data Wrangling 3: Pivots and Pipes",
    "section": "\n6.2 Recapping all the previous dplyr functions",
    "text": "6.2 Recapping all the previous dplyr functions\nIn this first section, we will prepare the data for some analysis later by practicing the data wrangling skills you learnt in Chapters 4 and 5 on this new data set.\n\n6.2.1 Activity 1 - Load tidyverse and read the data files\nAs the first activity, load tidyverse and read the two data files. As a prompt, save the data files to these object names to be consistent with the activities below, but you can check your answer below if you are stuck.\n\n# Load the tidyverse package below\n?\n\n# Load the data files\n# This should be the Alter_2024_demographics.csv file \ndemog &lt;- ?\n\n# This should be the Alter_2024_scales.csv file \nscales &lt;- ?\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# Load the tidyverse package below\nlibrary(tidyverse)\n\n# Load the data files\n# This should be the Alter_2024_demographics.csv file \ndemog &lt;- read_csv(\"data/Alter_2024_demographics.csv\")\n\n# This should be the Alter_2024_scales.csv file \nscales &lt;- read_csv(\"data/Alter_2024_scales.csv\")\n\n\n\n\n\n6.2.2 Activity 2 - Explore demog and scales\n\nThe data from Alter et al. (2024) is split into two data files. In demog, we have the participant ID (StudentIDE) and several demographic variables. The columns (variables) we have in the data set are:\n\n\n\n\n\n\n\nVariable\nType\nDescription\n\n\n\nStudentIDE\ndouble\nParticipant number\n\n\nGenderE\ndouble\nGender: 1 = Female, 2 = Male, 3 = Non-Binary\n\n\nRaceEthE\ndouble\nRace: 1 = Black/African American, 2 = Hispanic/Other Latinx, 3 = White, 4 = Multiracial, 5 = Asian/Pacific Islander, 6 = Native American/Alaska Native, 7 = South/Central American\n\n\nGradeE\ncharacter\nExpected grade: 1 = A, 2 = B, 3 = C, 4 = D, 5 = F\n\n\nStuStaE\ncharacter\nStudent status: 1 = Freshman, 2 = Sophomore, 3 = Junior, 4 = Senior or Higher\n\n\nGPAE\ncharacter\nExpected Grade Point Average (GPA)\n\n\nMajorE\ncharacter\nDegree major\n\n\nAgeE\ndouble\nAge in years\n\n\n\nIn scales, we then have the participant ID (StudentIDE) and all the individual scale items. The columns (variables) we have in the data set are:\n\n\n\n\n\n\n\nVariable\nType\nDescription\n\n\n\nStudentIDE\ndouble\nParticipant number\n\n\nMA1E to MA8E\ndouble\n\nEnjoyment of Mathematics and statistics, not analysed in this study.\n\n\nQANX1E to QANX4E\ndouble\n\nQuantitative anxiety: four items scored on a 5-point Likert scale ranging from 1 (Not at all Anxious) to 5 (Extremely Anxious)\n\n\nQINFL1E to QINFL7E\ndouble\n\nQuantitative attitudes: seven items scored on a 5-point Likert scale ranging from 1 (Strongly Disagree) to 5 (Strongly Agree)\n\n\nQSF1E to QSF4E\ndouble\n\nStudy motivation, not analysed in this study.\n\n\nQHIND1E to QHIND5E\ndouble\n\nQuantitative hindrances: five items scored on a 5-point Likert scale ranging from 1 (Strongly Disagree) to 5 (Strongly Agree)\n\n\nQSC1E to QSC4E\ndouble\n\nMathematical self-efficacy, not analysed in this study.\n\n\nQSE1E to QSE6E\ndouble\n\nMathematical ability, not analysed in this study.\n\n\nSPSS1E to SPSS10E\ndouble\n\nVSSL scale on SPSS: 10 items scored on a 5-point Likert scale ranging from 1 (Never True) to 5 (Always True)\n\n\n\n\n\n\n\n\n\nTry this\n\n\n\nNow we have introduced the two data sets, explore them using different methods we introduced. For example, opening the data objects as a tab to scroll around, explore with glimpse(), or even try plotting some of the variables to see what they look like using visualisation skills from Chapter 3.\n\n\n\n6.2.3 Activity 3 - Joining the two data sets using inner_join()\n\nAt the moment, we have two separate data sets, but it will make things easier to join them together so we have both demographic information and the participants’ responses to the scales.\nWe did not recap joining data sets in the last chapter, so you might need to revisit Chapter 4 - Joining two data frames - for a recap.\nCreate a new data object called full_data and see if you can spot a common variable between both data sets that you can use an identifier.\n\n# join demog and scales by a common identifier \nfull_data &lt;- ?\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# join demog and scales by a common identifier \nfull_data &lt;- inner_join(x = demog,\n                        y = scales,\n                        by = \"StudentIDE\")\n\n\n\n\n\n6.2.4 Activity 4 - Selecting a range of columns using select()\n\nThere are some scales in the data that Alter et al. (2024) did not analyse, so we can get rid of them to declutter. Furthermore, the purpose of their study was to validate the new VSSL scale and they found some items did not make the cut. Create a new object called full_data_select and retain the following variables from your new full_data object:\n\nStudentIDE\nGenderE\nRaceEthE\nAgeE\nQANX1E to QINFL7E\nQHIND1E to QHIND5E\nSPSS1E, SPSS4E, SPSS5E, SPSS6E, SPSS7E, SPSS8E, SPSS9E.\n\nRemember: you can select variables either by retaining the variables you want to keep, or removing the variables you want to remove. You should have 27 columns remaining.\n\n# select the key variables listed above\nfull_data_select &lt;- ?\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk if you chose to retain:\n\n# select the key variables listed above\nfull_data_select &lt;- select(full_data,\n                           StudentIDE, \n                           GenderE,\n                           RaceEthE, \n                           AgeE, \n                           QANX1E:QINFL7E, \n                           QHIND1E:QHIND5E, \n                           SPSS1E, SPSS4E, SPSS5E, SPSS6E, SPSS7E, SPSS8E, SPSS9E)\n\nor the following if you chose to remove:\n\n# select the key variables listed above\nfull_data_select &lt;- select(full_data,\n                           -GradeE, \n                           -StuStaE, \n                           -GPAE, \n                           -MajorE, \n                           -MA1E:-MA8E,\n                           -QSF1E:-QSF4E,\n                           -QSC1E:-QSE6E,\n                           -SPSS2E, -SPSS3E, -SPSS10E)\n\nThere are a similar number to retain or remove, so there is no real time saving one way or the other.\n\n\n\n\n6.2.5 Activity 5 - Reorder observations using arrange()\n\nFor a quick check of the data, order the values of AgeE using the object full_data_select and answer the following questions:\n\nThe youngest participant is  years old.\nThe old participant is  years old.\n\n\n# youngest participants\n?\n\n# oldest participants\n?\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# youngest participants\narrange(full_data_select, \n        AgeE)\n\n# oldest participants\narrange(full_data_select, \n        desc(AgeE))\n\n\n\n\n\n6.2.6 Activity 6 - Modifying or creating variables using mutate()\n\nAt the moment, we have categorical variables such gender (GenderE) and race (RaceEthE) which have numerical codes. When it comes to summarising or plotting later, this would not be the easiest to understand.\nUsing the full_data_select object, use mutate() to recode these two existing variables and replace the numbers with labels and create a new object full_data_mutate. As a reminder of what each number refers to:\nGenderE\n\n1 = Female\n2 = Male\n3 = Non-binary\n\nRaceEthE\n\n1 = Black/African American\n2 = Hispanic/Other Latinx\n3 = White\n4 = Multiracial\n5 = Asian/Pacific Islander\n6 = Native American/Alaska Native\n7 = South/Central American\n\n\n# recode gender and race to labels\nfull_data_mutate &lt;- ?\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk (some lines wrap due to being quite long, but it will look right if you copy and paste it to your RStudio):\n\n# recode gender and race to labels\nfull_data_mutate &lt;- mutate(full_data_select,\n                           GenderE = case_match(GenderE,\n                                                1 ~ \"Female\",\n                                                2 ~ \"Male\",\n                                                3 ~ \"Non-binary\"),\n                           RaceEthE = case_match(RaceEthE,\n                                                 1 ~ \"Black/African American\",\n                                                 2 ~ \"Hispanic/Other Latinx\",\n                                                 3 ~ \"White\",\n                                                 4 ~ \"Multiracial\",\n                                                 5 ~ \"Asian/Pacific Islander\",\n                                                 6 ~ \"Native American/Alaska Native\",\n                                                 7 ~ \"South/Central American\"))\n\n\n\n\n\n6.2.6.1 Bonus activity - reverse coding scales\nFor a bonus activity, we want to demonstrate a super common task when working with scale data. Often, scales will reverse code some items to express the same idea in opposite ways: one positive and one negative. If the scale is measuring a consistent construct, the responses should be more positive in one and more negative in the other. If you analysed this immediately, you would get two opposing answers, so a key data wrangling step is reverse coding some items so all the numbers mean a similar thing.\nIn Alter et al. (2024), the three VSSL items we removed were the ones which needed to be reverse coded, but it is a good excuse to practice. Using the scales object, what function could you use to recode existing responses? Hint: we want to recode 1 to 5, 2 to 4, etc.\n\n# recode items 2, 3, and 10\nscales_reverse &lt;- mutate(scales,\n                         SPSS2_R = ?,\n                         SPSS3_R = ?,\n                         SPSS10_R = ?)\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nBased on what we covered before, we expect you will have completed a perfectly accurate but long process of recoding each item one by one:\n\n# recode items 2, 3, and 10\nscales_reverse &lt;- mutate(scales,\n                         SPSS2_R = case_match(SPSS2E,\n                                              1 ~ 5,\n                                              2 ~ 4,\n                                              3 ~ 3,\n                                              4 ~ 2,\n                                              5 ~ 1),\n                         SPSS3_R = case_match(SPSS3E,\n                                              1 ~ 5,\n                                              2 ~ 4,\n                                              3 ~ 3,\n                                              4 ~ 2,\n                                              5 ~ 1),\n                         SPSS10_R = case_match(SPSS10E,\n                                              1 ~ 5,\n                                              2 ~ 4,\n                                              3 ~ 3,\n                                              4 ~ 2,\n                                              5 ~ 1))\n\nHowever, there is a neat shortcut where you can subtract the response from the biggest scale unit plus 1. For example, if you have a 5-point scale, you would subtract the response from 6, if you have a 7-point scale, from 8 etc.\n\n# Reverse code by subtracting responses from 6\nscales_reverse &lt;- mutate(scales,\n                         SPSS2_R = 6 - SPSS2E,\n                         SPSS3_R = 6 - SPSS3E,\n                         SPSS10_R = 6 - SPSS10E)\n\nExplore your new data object to see what the new reverse coded variables look like.\n\n\n\n\n6.2.7 Activity 7 - Removing or retaining observations using filter()\n\nTo practice filtering data to retain specific participants, imagine we wanted to focus on two specific groups of people.\nFirst, we just want to explore the data of “Non-binary” participants. Second, we want to explore the data of “Female”, “Asian/Pacific Islander” participants. Use filter() on the full_data_mutate object to create two objects: NB_participants and F_asian_participants.\n\n# non-binary participants\nNB_participants &lt;- ?\n\n# female, Asian/Pacific Islander participants\nF_asian_participants &lt;- ?\n\nAfter creating the objects, answer the following questions:\n\nWe have  non-binary participant(s) in the data set.\nWe have  female, Asian/Pacific Islander participant(s) in the data set.\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# non-binary participants\nNB_participants &lt;- filter(full_data_mutate,\n                          GenderE == \"Non-binary\")\n\n# female, Asian/Pacific Islander participants\nF_asian_participants &lt;- filter(full_data_mutate,\n                          GenderE == \"Female\",\n                          RaceEthE == \"Asian/Pacific Islander\")\n\n\n\n\n\n6.2.7.1 Bonus activity - Removing NAs with drop_na()\n\nOne concept we will spend more time on in Chapter 11 - Screening Data - is removing participants who do not provide an answer. We delve more into the decision making in the course materials, but there is a handy function in tidyr called drop_na(). You could do this using filter, but the standalone function streamlines things. If you run the function on your whole data set, it will remove observations with one or more NAs in all their variables:\n\n# remove observations with any NAs\nno_NAs &lt;- drop_na(full_data_mutate)\n\nHowever, often you do not want to remove all variables with an NA as there might be valuable information elsewhere. You can add one or more variables to ask drop_na() to only remove NAs present in those specific variables:\n\n# remove observations with any NAs\nage_NAs &lt;- drop_na(full_data_mutate,\n                   AgeE)\n\nThis impacts the number of participants we remove as we had 171 when we removed all NAs, but 179 when we only removed NAs in age.\n\n6.2.8 Activity 8 - Summarising data using count() and summarise()\n\n\n6.2.8.1 Counting observations\nAs the final recap activity, it is time to calculate some summary statistics to understand our data set. First, use count() on the full_data_mutate object to answer the following questions:\n\nHow many observations do we have of each gender?  males,  females, and  non-binary.\nHow many observations do we have of each race?  white,  Black/African American, and  NA with missing data.\n\n\n# count each group in GenderE\n?\n\n# count each group in RaceE\n?\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# count each group in GenderE\ncount(full_data_mutate,\n      GenderE)\n\n# count each group in RaceE\ncount(full_data_mutate,\n      RaceEthE)\n\n\n\n\n\n6.2.8.2 Summarising observations\nOne useful demographic summary is the mean and standard deviation (SD) of participant ages. We have covered the function for the mean (mean()) several times, but a key part of coding is knowing what you want, but not the function to do it. So, in the process of the next answer, try and find the function for the standard deviation on your own. If you are really stuck though, you can see the hint below.\n\n\n\n\n\n\nGive me a hint for the SD function\n\n\n\n\n\n\n# Function for the standard deviation\nsd()\n\n\n\n\n\n# Mean and SD age\nmean_age &lt;- summarise(full_data_mutate,\n                      mean_age = ?,\n                      SD_age = ?)\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# Mean and SD age\nmean_age &lt;- summarise(full_data_mutate,\n                      mean_age = mean(AgeE, na.rm = TRUE),\n                      SD_age = sd(AgeE, na.rm = TRUE))\n\nRemember, if there are NAs present in the data like this, you need to add na.rm = TRUE or handle NAs prior to applying the function.\n\n\n\n\n\n\n\n\n\nError mode\n\n\n\nAs a transition point to restructuring data, imagine we wanted to calculate the sum score of the items to calculate a number for the whole scale per participant. Based on how we have used mutate() or summarise() before, you might try:\n\nsum_VSSL &lt;- mutate(full_data_mutate,\n                      VSSL = sum(c(SPSS1E, SPSS4E, SPSS5E, SPSS6E, SPSS7E, SPSS8E, SPSS9E), na.rm = TRUE))\n\nHowever, if you look at the object, the VSSL column is the same for every participant (4413) which does not look right? This is due to how functions work within mutate(). It is essentially applying the sum() function to all the columns first and adding them together, rather than summing the values of each column within each participant.\nWe can fix this problem by restructuring the data."
  },
  {
    "objectID": "06-wrangling-3.html#manipulating-data-between-longer-and-wider-using-pivot_longer-and-pivot_wider",
    "href": "06-wrangling-3.html#manipulating-data-between-longer-and-wider-using-pivot_longer-and-pivot_wider",
    "title": "6  Data Wrangling 3: Pivots and Pipes",
    "section": "\n6.3 Manipulating data between longer and wider using pivot_longer() and pivot_wider()\n",
    "text": "6.3 Manipulating data between longer and wider using pivot_longer() and pivot_wider()\n\n\n6.3.1 Tidy data\nBut first a little more on data structure and organisation.For most of this book, we will use a type of data organisation known as tidy data. Any data in this format is easily processed through the tidyverse package. However, the data you work with will not always start formatted in the most efficient way possible. If that happens then our first step is to put it into Tidy Data format. There are two fundamental principles defining Tidy Data:\n\nEach variable must have its own column.\nEach observation must have its own row.\n\nTidy Data (Wickham, 2014) adds the following principle:\n\nEach type of observation unit forms a table.\n\nAnd Grolemund and Wickham (2017) restate this third principle as:\n\nEach value must have its own cell (i.e. no grouping two variables together, e.g. time/date in one cell).\n\nWhere a cell is where any specific row and column meet; a single data point in a tibble is a cell for example. The Grolemund and Wickham (2017) book is a very useful read and it is free, but browsing the chapter on Tidy Data will help you visualise how you want to arrange data. Try to keep the principles in mind whilst doing so.\n\n\n\nIf you’ve worked with any kind of data before, particularly if you’ve used Excel, it’s very likely that you will have used wide format or long format data. In wide format, each participant’s data is all in one row with multiple columns for different data points. This means that the data set tends to be very wide and you will have as many rows as you have participants.\n\n\nLong format is where each row is a single observation, typically a single trial in an experiment or a response to a single item on a questionnaire. When you have multiple trials per participant, you will have multiple rows for the same participant. To identify participants, you would need a variable with some kind of participant id, which can be as simple as a distinct integer value for each participant. In addition to the participant identifier, you would have any measurements taken during each observation (e.g., response time) and what experimental condition the observation was taken under.\n\n\nIn wide format data, each row corresponds to a single participant, with multiple observations for that participant spread across columns. So for instance, with survey data, you would have a separate column for each survey question.\n\n\nTidy is a mix of both of these approachs and most functions in the tidyverse assume the tidy format, so typically the first thing you need to do when you get data, particularly wide-format data, is to reshape it through wrangling. Which is why we teach these really important skills.\n\n\nThere is more information about tidy data available here.\n\n\n\nWe now have all the data we need loaded in, but in order to make it easier for us to get the AQ score for each participant, we need to change the layout of the responses tibble to Tidy Data.\n\n6.3.2 Activity 4: Gathering with pivot_longer()\nThe first step is to use the function pivot_longer() to transform the data. The pivot functions can be easier to show than tell - you may find it a useful exercise to run the below code and compare the tibble in the newly created object rlong with the tibble in the original object, respones, before reading on.\n\nrlong &lt;- pivot_longer(data = responses,\n                      cols = Q1:Q10,\n                      names_to = \"Question\", \n                      values_to = \"Response\")\n\nTo break this code down a little to help you understand it more:\n\nAs with the other tidyverse functions, the first argument specifies the dataset to use as the base, in this case responses.\n\nAnd remember the more experienced and confident you get you do not have to write the argument names, e.g. data =.\n\n\nThe second argument, cols specifies all the columns you want to transform. The easiest way to visualise this is to think about which columns would be the same in the new long-form dataset and which will change. In this case, we only have a single column Id that will remain constant and we will transform all the the other columns that contain participant’s responses to each question.\n\nThe colon notation first_column:last_column is used to select all variables from the first column specified to the second column specified. So in our code, cols specifies that the columns we want to transform are Q1 to Q10.\nNote that “Gathering” of columns is based on position in the tibble. If the order of columns in the tibble was Q1 then Q10, the above code would only gather those two columns. As it is, in our tibble, the order, is Q1, Q2, Q3, … Q10, and therefore the code gathers all the columns between Q1 and Q10.\n\n\nThe third and fourth arguments are the names of the new columns we are creating.\n\n\nnames_to specifies the names of the new columns that will be created.\nFinally, values_to names the new column that will contain the measurements, in this case we’ll call it Response.\nThese new column names are put in quotes because they do not already exist in the tibble. This is not always the case but is the case for this function.\nNote also that these names could have been anything but by using these names the code makes more sense.\nLastly, you do need to write names_to = … and values_to = … otherwise the columns won’t be created correctly.\n\n\n\nAnd now that we have run the code and explained it a bit, you may find it helpful to go back and compare rlong and responses again to see how each argument matches up with the output of the table."
  },
  {
    "objectID": "06-wrangling-3.html#combining-several-functions-with-pipes",
    "href": "06-wrangling-3.html#combining-several-functions-with-pipes",
    "title": "6  Data Wrangling 3: Pivots and Pipes",
    "section": "\n6.4 Combining several functions with pipes",
    "text": "6.4 Combining several functions with pipes\nIn this final section on data wrangling, we are not covering new functions, but a new way of working. So far, we have created lots of new objects by applying individual tidyverse functions, but there is a way to string together several functions and streamline your code. We wanted to introduce you to the individual functions first to develop your fundamentals skills and understanding of what the functions do, but now we can be a little more efficient.\nInstead of creating several objects, you can use pipes. We write pipes as %&gt;% and you can read them as “and then”. Pipes allow you to string together ‘sentences’ of code into ‘paragraphs’ so that you do not need to create intermediary objects.\nThis is another one of those concepts that is initially easier to show than tell:\n\n# Create an object starting with demog \nfull_data_pipe &lt;-  demog %&gt;%\n  # Join with scales\n  inner_join(y = scales,\n             by = \"StudentIDE\") %&gt;%\n  # Select key columns\n  select(StudentIDE, \n         GenderE,\n         RaceEthE, \n         AgeE, \n         QANX1E:QINFL7E, \n         QHIND1E:QHIND5E, \n         SPSS1E, SPSS4E, SPSS5E, SPSS6E, SPSS7E, SPSS8E, SPSS9E) %&gt;% \n  # Recode variables with labels\n  mutate(GenderE = case_match(GenderE,\n                              1 ~ \"Female\",\n                              2 ~ \"Male\",\n                              3 ~ \"Non-binary\"),\n         RaceEthE = case_match(RaceEthE,\n                               1 ~ \"Black/African American\",\n                               2 ~ \"Hispanic/Other Latinx\",\n                               3 ~ \"White\",\n                               4 ~ \"Multiracial\",\n                               5 ~ \"Asian/Pacific Islander\",\n                               6 ~ \"Native American/Alaska Native\",\n                               7 ~ \"South/Central American\"))\n\nInstead of creating all the intermediary objects, we go straight from joining the two data sets to recoding the variables in mutate, all in one object. Side by side, you can see the difference in the process we had to go through:\n\n\nCreating separate objects\nCombining functions using pipes\n\n\n\n\n# join demog and scales by a common identifier \nfull_data &lt;- inner_join(x = demog,\n                        y = scales,\n                        by = \"StudentIDE\")\n\n# select the key variables listed above\nfull_data_select &lt;- select(full_data,\n                           StudentIDE, \n                           GenderE,\n                           RaceEthE, \n                           AgeE, \n                           QANX1E:QINFL7E, \n                           QHIND1E:QHIND5E, \n                           SPSS1E, SPSS4E:SPSS9E)\n\n# recode gender and race to labels\nfull_data_mutate &lt;- mutate(full_data_select,\n                           GenderE = case_match(GenderE,\n                                                1 ~ \"Female\",\n                                                2 ~ \"Male\",\n                                                3 ~ \"Non-binary\"),\n                           RaceEthE = case_match(RaceEthE,\n                                                 1 ~ \"Black...\",\n                                                 2 ~ \"Hispanic...\",\n                                                 3 ~ \"White\",\n                                                 4 ~ \"Multiracial\",\n                                                 5 ~ \"Asian...\",\n                                                 6 ~ \"Native American...\",\n                                                 7 ~ \"South...\"))\n\n\n\n\n# Create an object starting with demog \nfull_data_pipe &lt;-  demog %&gt;%\n  # Join with scales\n  inner_join(y = scales,\n             by = \"StudentIDE\") %&gt;%\n  # Select key columns\n  select(StudentIDE, \n         GenderE,\n         RaceEthE, \n         AgeE, \n         QANX1E:QINFL7E, \n         QHIND1E:QHIND5E, \n         SPSS1E, SPSS4E:SPSS9E) %&gt;% \n  # Recode variables with labels\n  mutate(GenderE = case_match(GenderE,\n                              1 ~ \"Female\",\n                              2 ~ \"Male\",\n                              3 ~ \"Non-binary\"),\n         RaceEthE = case_match(RaceEthE,\n                               1 ~ \"Black...\",\n                               2 ~ \"Hispanic...\",\n                               3 ~ \"White\",\n                               4 ~ \"Multiracial\",\n                               5 ~ \"Asian...\",\n                               6 ~ \"Native American...\",\n                               7 ~ \"South...\"))\n\n\n\n\nAs you get used to using pipes, remember you can interpret them as “and then”. So, we could explain the function of the code to ourselves as:\n\nCreate full_data_pipe by starting with demog data, and then\nJoin with the scales data using StudentIDE as an identifier, and then,\nSelect our key columns, and then\nMutate to recode gender and race.\n\nIt can be tricky at first to understand what pipes are doing from a conceptual point of view, but it is well worth learning to use them. When your code starts getting longer, they are much more efficient and you write less code which is always a good thing to debug and find errors. You also have fewer objects in your environment as we created one object instead of three, tidying your workspace.\n\n\n\n\n\n\nError mode\n\n\n\nOne key difference that can trip people up is we no longer specify the data object as the first argument in each function. The reason that this function - the %&gt;% - is called a pipe is because it ‘pipes’ the data through to the next function. When you wrote the code previously, the first argument of each function was the dataset you wanted to work on. When you use pipes, it will automatically take the data from the previous line of code so you do not need to specify it again.\nFor example, if we tried to specify demog again in select(), we would just receive an error.\n\n# Create an object starting with demog \nfull_data_pipe &lt;-  demog %&gt;%\n  # Join with scales\n  inner_join(y = scales,\n             by = \"StudentIDE\") %&gt;%\n  # Select key columns\n  select(.data = demog,\n         StudentIDE, \n         GenderE,\n         RaceEthE, \n         AgeE, \n         QANX1E:QINFL7E, \n         QHIND1E:QHIND5E, \n         SPSS1E, SPSS4E:SPSS9E)\n\n\n\n\n\n\n\n\n\nTry this\n\n\n\nPipes also work with other functions like filter(), group_by() and summarise(). If you start with the object full_data_mutate, try and express the following instructions in code:\n\nCreate a new object age_groups using full_data_mutate as your starting point, and then\nFilter to only include “White” and “Black/African American” participants using RaceEthE, and then,\nGroup the observations by RaceEthE, and then,\nSummarise the data to calculate the mean and standard deviation AgeE.\n\nCheck your attempt with the solution below when you have tried on your own.\n\n# create age_groups by filtering, grouping, and summarising\nage_groups &lt;- full_data_mutate %&gt;% \n  ?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe complete this task in three steps. First, we filter full_data_mutate to just focus on White and Black/African American participants. Second, we group the data by RaceEthE so our summary statistics are split into two groups. Third, we calculate the mean and SD age.\n\n# create age_groups by filtering, grouping, and summarising\nage_groups &lt;- full_data_mutate %&gt;% \n  filter(RaceEthE %in% c(\"White\", \"Black/African American\")) %&gt;% \n  group_by(RaceEthE) %&gt;% \n  summarise(mean_age = mean(AgeE, na.rm = TRUE),\n            SD_age = sd(AgeE, na.rm = TRUE))"
  },
  {
    "objectID": "06-wrangling-3.html#test-yourself",
    "href": "06-wrangling-3.html#test-yourself",
    "title": "6  Data Wrangling 3: Pivots and Pipes",
    "section": "\n6.5 Test yourself",
    "text": "6.5 Test yourself\nTo end the chapter, we have some knowledge check questions to test your understanding of the concepts we covered in the chapter. We then have some error mode tasks to see if you can find the solution to some common errors in the concepts we covered in this chapter.\n\n6.5.1 Knowledge check\nWhich function(s) would you use to approach each of the following problems?\nQuestion 1. We have a data set of 400 adults but we want to remove anyone with an age of 50 years or more. To do this, we could use:\n\nsummarise()filter()select()mutate()group_by()arrange()\n\nQuestion 2. We are interested in overall summary statistics for our data, such as the mean and total number of observations for a variable. To do this, we could use:\n\narrange()select()filter()summarise()group_by()mutate()\n\nQuestion 3. Our data set has a column with the number of cats a person has and a column with the number of dogs. We want to calculate a new column which contains the total number of pets each participant has. To do this, we could use:\n\nselect()group_by()filter()mutate()summarise()arrange()\n\nQuestion 4. We want to calculate the mean value of a column for several groups in our data set. To do this, we could use:\n\nfilter() and select()group_by() and summarise()group_by() and arrange()arrange() and mutate()\n\nQuestion 5. If we wanted to apply the following wrangling steps with pipes, which series of functions would work? With the object wide_data, select several columns and then, pivot three columns longer and then, group by a participant ID and then, calculate the sum of responses.\n\nselect() %&gt;% pivot_longer() %&gt;% group_by() %&gt;% summarise() %&gt;% wide_datawide_data %&gt;% pivot_longer() %&gt;% select() %&gt;% summarise() %&gt;% group_by()long_data %&gt;% select() %&gt;% pivot__longer_wider() %&gt;% group_by() %&gt;% summarise()wide_data %&gt;% select() %&gt;% pivot_longer() %&gt;% group_by() %&gt;% summarise()\n\n\n6.5.2 Error mode\nThe following questions are designed to introduce you to making and fixing errors. For this topic, we focus on data wrangling using past functions, pivot_longer(), and pipes (%&gt;%). Remember to keep a note of what kind of error messages you receive and how you fixed them, so you have a bank of solutions when you tackle errors independently.\nCreate and save a new R Markdown file for these activities. Delete the example code, so your file is blank from line 10. Create a new code chunk to load tidyverse and the data files:\n\n# Load the tidyverse package below\nlibrary(tidyverse)\n\n# Load the data files\n# This should be the Alter_2024_demographics.csv file \ndemog &lt;- read_csv(\"data/Alter_2024_demographics.csv\")\n\n# This should be the Alter_2024_scales.csv file \nscales &lt;- read_csv(\"data/Alter_2024_scales.csv\")\n\nBelow, we have several variations of a code chunk error or misspecification. Copy and paste them into your R Markdown file below the code chunk to load tidyverse and the data files. Once you have copied the activities, click knit and look at the error message you receive. See if you can fix the error and get it working before checking the answer.\nQuestion 6. Copy the following code chunk into your R Markdown file and press knit. In this code chunk, we want to calculate the mean and SD age of all participants using demog. There are two errors/omissions here to try and fix:\n\nOne causes the document not to knit. You should receive an error like Caused by error in \"SD()\": ! could not find function \"SD\".\nThe other looks like we just get NA values?\n\n```{r}\n# calculate the mean and SD age\ndemog %&gt;% \n  summarise(mean_age = mean(AgeE),\n            SD_age = SD(AgeE))\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nThe first error is using the wrong function name for SD. Because we always abbreviate standard deviation to SD, it is tempting to try and use that as the function name. However, the function is lowercase: sd().\nThe second error is not including the na.rm = TRUE argument. There are NAs in the data, so you either need to address them before running the function, or ignoring the NAs with na.rm = TRUE.\n\n# calculate the mean and SD age\ndemog %&gt;% \n  summarise(mean_age = mean(AgeE, na.rm = TRUE),\n            SD_age = sd(AgeE, na.rm = TRUE))\n\n\n\n\nQuestion 7. Copy the following code chunk into your R Markdown file and press knit. We want to calculate the sum of the five quantitative hindrances items per participant. This code… works, but does it look like it fits in the possible 5-25 range?\n```{r}\n# sum quant hindrances items per participant\nsum_quant_hindrance &lt;- scales %&gt;% \n  mutate(sum_quant_hindrance = sum(c(QHIND1E, QHIND2E, QHIND3E, QHIND4E, QHIND5E), na.rm = TRUE))\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nThis is the main of warning we flagged in the opening section to pivot_longer(). Intuitively, it is the right idea to try and calculate the sum in a new column. However, in mutate(), it sums all the columns, not the observations for each participant.\nInstead, we can pivot longer focusing on the quantitative hindrance items, group by participant ID, and summarise.\n\n# sum quant hindrances items per participant\nsum_quant_hindrance &lt;- scales %&gt;% \n  # pivot longer on 5 quant hindrances items\n  pivot_longer(cols = QHIND1E:QHIND5E,\n               names_to = \"Question\",\n               values_to = \"Response\") %&gt;% \n  # group by student ID\n  group_by(StudentIDE) %&gt;% \n  # summarise for sum of new long column \n  summarise(sum_quant_hindrance = sum(Response, na.rm = TRUE))\n\n\n\n\nQuestion 8. Copy the following code chunk into your R Markdown file and press knit. We want to filter demog to focus on female participant and calculate the mean age of the female participants. You should receive an error containing Caused by error:! \"..1$StudentIDE\" must be a logical vector, not a double vector which is not the most helpful error for diagnosing the problem.\n```{r}\n# filter for females then calculate mean age\ndemog %&gt;% \n  filter(.data = demog, \n         GenderE == 2) %&gt;% \n  summarise(.data = demog,\n            mean_age = mean(AgeE, na.rm = TRUE))\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nWe are using pipes but we tried adding in the .data argument in each line. Remember %&gt;% “pipes” the previous line into the next line, so you do not need to specify an object for it to work with. If you try and specify the .data argument with pipes, it thinks you are trying to set the next argument in the list.\n\n# filter for females then calculate mean age\ndemog %&gt;% \n  filter(GenderE == 2) %&gt;% \n  summarise(mean_age = mean(AgeE, na.rm = TRUE))"
  },
  {
    "objectID": "06-wrangling-3.html#end-of-chapter",
    "href": "06-wrangling-3.html#end-of-chapter",
    "title": "6  Data Wrangling 3: Pivots and Pipes",
    "section": "\n6.7 End of chapter",
    "text": "6.7 End of chapter\nBrilliant work again! You recapped data wrangling functions from the past two chapters to a new data set, and added two more concepts to your arsenal: pivots and pipes. There really is no substitute for practicing on new data to transfer your knowledge and understanding. As you work with more and more data, you will see how far these data wrangling functions take you. They will your foundational skills for any new data set and give you the confidence to search for new functions when there is a new problem to solve.\nThis is a key milestone, so remember to go over anything you are unsure of. If you have any questions about data wrangling, please post them on Teams, visit the GTA support sessions, or pop into office hours.\nAt this point, we direct you to the first data analysis journey chapter: Analysis Journey 1: Data Wrangling. This is a bridge between the structured learning in these chapters and your assessments. We present you with a new data set, show you what the end product should look like, and see if you can apply your data wrangling skills to get there. If you get stuck, we have a range of hints and steps you can unhide, then the solution to check your attempts against.\nIn the next core chapter though, we turn to more advanced data visualisation to demonstrate how to create scatterplots, boxplots, and violin-boxplots.\n\n\n\n\nAlter, U., Dang, C., Kunicki, Z. J., & Counsell, A. (2024). The VSSL scale: A brief instructor tool for assessing students’ perceived value of software to learning statistics. Teaching Statistics, 46(3). https://doi.org/10.1111/test.12374\n\n\nWickham, H. (2014). Tidy Data. Journal of Statistical Software, 59, 1–23. https://doi.org/10.18637/jss.v059.i10"
  },
  {
    "objectID": "04-wrangling-1.html#04-joins",
    "href": "04-wrangling-1.html#04-joins",
    "title": "4  Data wrangling 1: Join, select, and mutate",
    "section": "\n4.3 Joining two data frames with *_join() functions",
    "text": "4.3 Joining two data frames with *_join() functions\nThe first thing we will do is combine data files. We have two files, dat and pinfo, but what we really want is a single file that has both the happiness and depression scores and the demographic information about the participants as it makes it easier to work with the combined data.\nTo do this, we are going to use the function inner_join(). So far, we have described these types of functions as *_join(). This is because there are a series of functions that join two data sets in slightly different ways. You do not need to memorise these, but it might be useful to refer back to later.\n\n\n\n\n\n\nJoin function\nDescription\n\n\n\ninner_join()\nKeep observations in data set x that has a matching key in data set y\n\n\nleft_join()\nKeep all observations in data set x\n\n\nright_join()\nKeep all observations in data set y\n\n\nfull_join()\nKeep all observations in both data set x and y\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nAs these functions join data sets in different ways, they will produce different sample sizes depending on the presence of missing data in one or both data sets. For example, inner_join() will be the strictest as you must have matching observations in each data set. On the other hand, full_join() will be the least strict, as you retain observations that may not exist in one data set or the other.\n\n\n\n4.3.1 Activity 2 - Join the files together\nWe are going to join dat and pinfo by common identifiers. When we use inner_join(), this means we want to keep all the observations in dat that also has a corresponding identifier in pinfo. This is known as an inner-join, where you would exclude participants if they did not have a matching observation in one of the data sets.\nThe code below will create a new object, called all_dat, that combines the data from both dat and pinfo using the columns id and intervention to match the participants’ data across the two sets of data. id is a code or number for each unique participant and will be the most common approach you see for creating an identifier. intervention is the group the participant was placed in for the study by Woodworth et al. (2018).\nType and run the code in a new code chunk to inner join the two sets of data.\n\nall_dat &lt;- inner_join(x = dat, \n                      y = pinfo, \n                      by = c(\"id\", \"intervention\"))\n\nTo break down what this code is doing:\n\nall_dat is the new object you created with the joined data.\nx is the first argument and it should be the first data set / object you want to combine.\ny is the second argument and it should be the second data set / object you want to combine.\nby is the third argument and it lists the identifier as the name(s) of the column(s) you want to combine the data by in quote marks. In this scenario, there are two identifiers common to each data set. They both contain columns called “id” and “intervention”. We have to wrap them in c() to say that there is more than one column to combine by. If there was only one common identifier, you would write by = \"id\".\n\n\n\n\n\n\n\nWhy does my data include .x and .y columns?\n\n\n\nIf your data sets have more than one common column, you must enter them all in the by argument. This tells R there are matching columns and values across the data sets. If you do not enter all the common columns, then R will add on a .x and .y when it adds them together, to label which come from each data set.\nFor example, try and run this code and look at the columns in all_dat2. You will see it has an extra column compared to all_dat as there is both “intervention.x” and “intervention.y”.\n\nall_dat2 &lt;- inner_join(x = dat, \n                      y = pinfo, \n                      by = \"id\")\n\n\n\n\n4.3.2 Activity 3 - Explore your data objects\nOnce you have run this code, you should now see the new all_dat object in the environment pane. Remember to get into the habit of exploring your data and objects as you make changes, to check your wrangling is working as intended.\nThere are two main ways you can do this:\n\nClick on the data object in the Environment pane. This will open it up as a tab in RStudio, and you will be able to scroll through the rows and columns (Figure 4.1).\n\n\n\n\n\n\n\nWhy do I not see all my columns?\n\n\n\nOne common source of confusion is not seeing all your columns when you open up a data object as a tab. This is because RStudio shows you a maximum of 50 columns at a time. If you have more than 50 columns, to see more, you must use the arrows at the top of the tab where it says “Cols:”. For example in all_dat, it will say 1-50, if you click the right arrow, it will then say 5-54 so you can see the final 4 columns.\n\n\n\n\n\n\nFigure 4.1: Exploring a data object in RStudio by opening it as a tab. You can navigate around the columns and rows without opening it up in something like Excel. If there are more than 50 columns, you can click the arrows next to Cols.\n\n\n\n\nUse the glimpse() function to see an overview of the data objects.\n\nWe explored this in chapter 3, but glimpse() tells you how many rows and columns your data have, plus an overview of responses per column. Note: you will see a preview of all 54 columns, but we have shortened the preview to 10 columns to take up less space in the book.\n\nglimpse(all_dat)\n\n\n\nRows: 992\nColumns: 10\n$ id           &lt;dbl&gt; 12, 162, 162, 267, 126, 289, 113, 8, 185, 185, 246, 185, …\n$ occasion     &lt;dbl&gt; 5, 2, 3, 0, 5, 0, 2, 2, 2, 4, 4, 0, 4, 0, 1, 4, 0, 5, 4, …\n$ elapsed.days &lt;dbl&gt; 182.025139, 14.191806, 33.033831, 0.000000, 202.096887, 0…\n$ intervention &lt;dbl&gt; 2, 3, 3, 4, 2, 1, 1, 2, 3, 3, 3, 3, 1, 2, 2, 2, 3, 2, 2, …\n$ ahi01        &lt;dbl&gt; 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, …\n$ ahi02        &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, …\n$ ahi03        &lt;dbl&gt; 2, 1, 1, 2, 2, 4, 1, 1, 4, 4, 4, 4, 3, 3, 3, 2, 2, 2, 3, …\n$ ahi04        &lt;dbl&gt; 1, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, …\n$ ahi05        &lt;dbl&gt; 1, 2, 2, 2, 2, 1, 1, 1, 3, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ ahi06        &lt;dbl&gt; 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, …\n\n\n\n\n\n\n\n\nTry this\n\n\n\nNow you have explored all_dat, try and use one or both of these methods to explore the original dat and pinfo objects to see how they changed. Notice how the number of rows/observations and columns change from the original objects to when you join them."
  },
  {
    "objectID": "06-wrangling-3.html#restructuring-data-using-pivot_longer-and-pivot_wider",
    "href": "06-wrangling-3.html#restructuring-data-using-pivot_longer-and-pivot_wider",
    "title": "6  Data Wrangling 3: Pivots and Pipes",
    "section": "\n6.3 Restructuring data using pivot_longer() and pivot_wider()\n",
    "text": "6.3 Restructuring data using pivot_longer() and pivot_wider()\n\nApart from joining two data sets, we have pretty much just worked with the data files as they come to us where each row represents one observation/participant and each column represents one variable. That is great but there are scenarios where you get data sets in messier formats that do not follow this pattern. Furthermore, you might need to restructure your data to perform certain functions, like taking the mean/sum of many columns per participant or visualising multiple elements. Before we work on the data wrangling side, we need a brief explanation of data formats.\n\n6.3.1 Tidy data\nFor most of this book, we use a type of data organisation known as tidy data. Any data in this format is easily processed through the tidyverse family of packages. However, the data you work with will not always be formatted in the most efficient way possible. If that happens, then our first step is to put it into a tidy data format. There are two fundamental principles defining tidy data:\n\nEach variable must have its own column.\nEach observation must have its own row.\n\nWickham (2014) adds the following principle:\n\nEach type of observation unit forms a table.\n\nGrolemund and Wickham (2023) restate this third principle as: “Each value must have its own cell (i.e. no grouping two variables together, e.g. time/date in one cell)” where a cell is where any specific row and column meet. A single data point in a data frame / tibble is a cell for example. The Grolemund and Wickham (2023) book is a very useful source for further reading and it is free, but browsing the chapter on tidy data will help you visualise how you want to arrange data.\n\n\n\n\n\n\nNote\n\n\n\nIf you have worked with any kind of data before, particularly if you have used Excel, it is likely that you will have used wide format or long format data. In wide format, each participant’s data is all in one row with multiple columns for different data points. This means that the data set tends to be very wide and you will have as many rows as you have participants.\nLong format is where each row is a single observation, typically a single trial in an experiment or a response to a single item on a questionnaire. When you have multiple trials per participant, you will have multiple rows for the same participant. To identify participants, you would need a variable with some kind of participant id, which can be as simple as a distinct integer value for each participant. In addition to the participant identifier, you would have any measurements taken during each observation (e.g., response time) and what experimental condition the observation was taken under.\nIn wide format data, each row corresponds to a single participant, with multiple observations for that participant spread across columns. So for instance, with survey data, you would have a separate column for each survey question.\nTidy data is a mix of both of these approaches and most functions in the tidyverse assume the tidy format, so typically the first thing you need to do when you get data is think about what format you need your data to perform the functions and analyses you want. For some functions, you need your data in wide format, and in others you need your data in long format. This means being able to quickly restructure your data is a key skill.\n\n\n\n6.3.2 Activity 9: Gathering with pivot_longer()\n\nIn it’s current format, we have wide data where each row is a separate participant and each column is a separate variable. We can use the function pivot_longer() from the tidyr package within tidyverse.\nThe pivot functions can be easier to show than explain first, so type and run the following code using the full_data_mutate object:\n\nfull_data_long &lt;- pivot_longer(data = full_data_mutate,\n                      cols = SPSS1E:SPSS9E,\n                      names_to = \"Question\", \n                      values_to = \"Response\")\n\nTo break down the code:\n\nWe create a new data object called full_data_long by applying the pivot_longer() function to full_data_mutate.\nIn the cols argument, we specify the columns we want to gather. We use the colon method here like select() to choose the 7 columns for the VSSL items. If the columns are not in order, you could use the c() method instead (e.g., cols = c(SPSS1E, SPSS9E)).\nThe names_to argument is what your first new column will be called. All the column names you selected in cols will be pivoted into this new column, so call it something sensible you will remember later. Here, we call the new column “Question”.\nThe values_to argument is what your second new column will be called. For all the columns you gather, the response of each participant will be in one column stacked on top of each other next to its label in “Question”. You also need to call this something memorable, like “Response” here.\n\nNow, explore the new full_data_long object you just created and compare it to full_data_mutate. Instead of 181 rows, we now have 1267 rows. Instead of 27 variables, we now have 22 variables. We have 181 participants who responded to 7 VSSL items, so we pivot the data into long format to get 181 * 7 = 1267 rows.\nVisually, you can see the difference with a preview of just the participant ID and VSSL items here:\n\n\nOriginal wide format\nNew long format\n\n\n\n\n\n\n\n\nStudentIDE\nSPSS1E\nSPSS4E\nSPSS5E\nSPSS6E\nSPSS7E\nSPSS8E\nSPSS9E\n\n\n\n1\n4\n3\n3\n3\n4\n4\n4\n\n\n2\n4\n4\n4\n4\n4\n4\n4\n\n\n3\n3\n2\n3\n2\n2\n3\n3\n\n\n4\n2\n2\n2\n2\n2\n2\n2\n\n\n5\n4\n3\n4\n4\n3\n4\n3\n\n\n6\n2\n3\n2\n1\n3\n3\n3\n\n\n7\n4\n2\n4\n4\n2\n3\n2\n\n\n8\n2\n3\n3\n3\n3\n3\n2\n\n\n9\n3\n3\n3\n1\n4\n3\n2\n\n\n10\n4\n4\n3\n5\n4\n2\n4\n\n\n\n\n\n\n\n\n\n\n\n\n\nStudentIDE\nQuestion\nResponse\n\n\n\n1\nSPSS1E\n4\n\n\n1\nSPSS4E\n3\n\n\n1\nSPSS5E\n3\n\n\n1\nSPSS6E\n3\n\n\n1\nSPSS7E\n4\n\n\n1\nSPSS8E\n4\n\n\n1\nSPSS9E\n4\n\n\n2\nSPSS1E\n4\n\n\n2\nSPSS4E\n4\n\n\n2\nSPSS5E\n4\n\n\n\n\n\n\n\n\n\nNow we have our data in long form, we can calculate summary statistics for participants using group_by() and summarise(). First, we group the data by the participant ID, as we want one value per participant:\n\n# group full_data_long by StudentIDE\nlongdata_grouped &lt;- group_by(full_data_long, \n                             StudentIDE)\n\nSecond, we create a new variable using summarise() to take the sum of all the items. This will create the VSSL scale score consistent with Alter et al. (2024):\n\n# Calculate the sum of VSSL items by taking the sum of Response\nVSSL_sum &lt;- summarise(longdata_grouped,\n                      VSSL_sum = sum(Response))\n\nOur new object goes from 1267 rows back to 181 as we grouped by the participant ID and took the sum of Response. This means we apply the function we provide summarise() to all the rows we want to group by, in this case across all 7 VSSL items. Your new object has just two columns: StudentIDE and VSSL_sum and should look like the following extract:\n\n\n\n\n\nStudentIDE\nVSSL_sum\n\n\n\n1\n25\n\n\n2\n28\n\n\n3\n18\n\n\n4\n14\n\n\n5\n25\n\n\n6\n17\n\n\n\n\n\n\nAt this point, you could join the object to full_data_mutate to add the scale score to all the other variables.\n\n\n\n\n\n\nTry this\n\n\n\nWe calculated the VSSL scale score by pivoting longer, grouping the data, and taking the sum of the 7 items. To test your understanding, complete the same steps to calculate the scale score of Quantitative anxiety using the four columns QANX1E to QANX4E. The scale score here also involves taking the sum of the columns. Use the full_data_mutate object as your starting point for the data.\nCheck your attempt with the solution below when you have tried on your own.\n\n# gather the four quant anxiety items to long form\nquant_anxiety_long &lt;- ?\n\n# group the long data by participant ID\nquant_anxiety_group &lt;- ?\n\n# calculate the sum quant anxiety per participant\nsum_quant_anxiety &lt;- ?\n\nTo check your answers:\n\nParticipant 1 has a sum quantitative anxiety score of \nParticipant 5 has a sum quantitative anxiety score of \n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe complete the task in three steps. First, we pivot longer using the four columns QANX1E to QANX4E to create the new quant_anxiety_long object. Second, we group that new long data object by the participant ID. Third, we calculate the sum quantitative anxiety score by taking the sum of the responses per participant ID.\n\n# gather the four quant anxiety items to long form\nquant_anxiety_long &lt;- pivot_longer(data = full_data_mutate,\n                                   cols = QANX1E:QANX4E,\n                                   names_to = \"Question\",\n                                   values_to = \"Response\")\n\n# group the long data by participant ID\nquant_anxiety_group &lt;- group_by(quant_anxiety_long, \n                                StudentIDE)\n\n# calculate the sum quant anxiety per participant\nsum_quant_anxiety &lt;- summarise(quant_anxiety_group,\n                               sum_quant_anxiety = sum(Response))\n\n\n\n\n\n6.3.3 Spreading with pivot_wider()\n\nYou might also find yourself in situations where you must restructure data in the opposite direction: from long to wide. There is a complementary function called pivot_wider() where you can spread values from one column to multiple columns. You need two columns in your long form data set, one for the variable names which will be your new column names, then one for the responses which will be the values in each cell.\nTo demonstrate this function, we will transform full_data_long back to wide format so we have 7 columns of VSSL items:\n\nfull_data_wide &lt;- pivot_wider(data = full_data_long,\n                              names_from = \"Question\",\n                              values_from = \"Response\")\n\nTo break down the code:\n\nWe create a new object full_data_wide by applying the function pivot_wider() to full_data_long.\nIn the names_from argument, we add the column name “Question” which contains the names of the variables you want as your new column names.\nIn the values_from argument, we add the column name “Response” which contains the values of the variables which will be the cells of your data frame.\n\nThe new object full_data_wide should now look exactly the same as the full_data_mutate object we started with.\n\n\n\n\n\n\nDo I need to add quotes to the column names?\n\n\n\nYou might have noticed we added quotes around the column names to specify the names_from and values_from arguments. When we specify columns in tidyverse functions, we do not need to add the quotes, we can just type the name and it will work (names_from = \"Question\" and names_from = Question would both work here). However, in other functions outside the tidyverse, you normally need to add the quotes around column names. When to add quotes or not can take a while to get used to, so this is just a note to highlight you might try one method and it does not work, but you can try the other method if you get an error.\n\n\n\n\n\n\n\n\nTry this\n\n\n\nIn the pivot_longer() section, you should have created a new object quant_anxiety_long if you completed the “Try this” activity. To test your understanding of pivot_wider(), spread the four items and responses of Quantitative anxiety back to wide format. Use the quant_anxiety_long object as your starting point and create a new object called quant_anxiety_wide.\nCheck your attempt with the solution below when you have tried on your own.\n\n# spread the quant anxiety items back to wide form\nquant_anxiety_wide &lt;- ?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThis task follows the exact format as full_data_wide if you named your variables the same as ours. It is just important the names_from and values_from columns are the same as those you used in quant_anxiety_long.\n\n# spread the quant anxiety items back to wide form\nquant_anxiety_wide &lt;- pivot_wider(quant_anxiety_long, \n                                  names_from = \"Question\",\n                                  values_from = \"Response\")"
  },
  {
    "objectID": "06-wrangling-3.html",
    "href": "06-wrangling-3.html",
    "title": "6  Data Wrangling 3: Pivots and Pipes",
    "section": "",
    "text": "6.1 Chapter preparation",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Wrangling 3: Pivots and Pipes</span>"
    ]
  },
  {
    "objectID": "17-analysis-journey-1.html#task-preparation",
    "href": "17-analysis-journey-1.html#task-preparation",
    "title": "15  Analysis Journey 1: Data Wrangling",
    "section": "\n15.1 Task preparation",
    "text": "15.1 Task preparation\n\n15.1.1 Introduction to the data set\nFor this task, we are using open data from Bartlett et al. (2022). The abstract of their article is:\n\nBoth daily and non-daily smokers find it difficult to quit smoking long-term. One factor associated with addictive behaviour is attentional bias, but previous research in daily and non-daily smokers found inconsistent results and did not report the reliability of their cognitive tasks. Using an online sample, we compared daily (n = 106) and non-daily (n = 60) smokers in their attentional bias towards smoking pictures. Participants completed a visual probe task with two picture presentation times: 200ms and 500ms. In confirmatory analyses, there were no significant effects of interest, and in exploratory analyses, equivalence testing showed the effects were statistically equivalent to zero. The reliability of the visual probe task was poor, meaning it should not be used for repeated testing or investigating individual differences. The results can be interpreted in line with contemporary theories of attentional bias where there are unlikely to be stable trait-like differences between smoking groups. Future research in attentional bias should focus on state-level differences using more reliable measures than the visual probe task.\n\nTo summarise, they compared two daily and non-daily smokers on something called attentional bias. This is the idea that when people use drugs often, things associated with those drugs grab people’s attention.\nTo measure attentional bias, participants completed a dot probe task. This is a computer task where participants see two pictures side-by-side: one related to smoking like someone holding a cigarette and one unrelated to smoking like someone holding a fork. Both the images disappear and a small dot appears in the location of one of the images. Participants must press left or right on the keyboard to identify where the dot appeared. This process is repeated many times for different images, different locations of the dot, and different durations of showing the images. The idea is if smoking images grab people’s attention, they will be able to identify the dot location faster on average when it appears in the location of the smoking images compared to when it appears in the location of the the non-smoking images.\nResponse time tasks like this are incredibly common in psychology and cognitive neuroscience, and being able to wrangle hundreds of trials is a great demonstration of your new data skills. After setting up your files and project for the chapter, we will outline the kind of problems you are trying to solve.\n\n15.1.2 Organising your files and project for the task\nBefore we can get started, you need to organise your files and project for the task, so your working directory is in order.\n\nIn your folder for research methods and the book ResearchMethods1_2/Quant_Fundamentals, create a new folder for the data analysis journey called Journey_01_wrangling. Within Journey_01_wrangling, create two new folders called data and figures.\nCreate an R Project for Journey_01_wrangling as an existing directory for your chapter folder. This should now be your working directory.\nCreate a new R Markdown document and give it a sensible title describing the chapter, such as Analysis Journey 1 - Data Wrangling. Delete everything below line 10 so you have a blank file to work with and save the file in your Journey_01_wrangling folder.\nWe are working with data separated into two files. The links are data file one (Bartlett_demographics.csv) and data file two (Bartlett_trials.csv). Right click the links and select “save link as”, or clicking the links will save the files to your Downloads. Make sure that both files are saved as “.csv”. Save or copy the file to your data/ folder within Journey_01_wrangling.\n\nYou are now ready to start working on the task!"
  },
  {
    "objectID": "17-analysis-journey-1.html#overview",
    "href": "17-analysis-journey-1.html#overview",
    "title": "15  Analysis Journey 1: Data Wrangling",
    "section": "\n15.2 Overview",
    "text": "15.2 Overview\n\n15.2.1 Load tidyverse and read the data files\nBefore we explore what wrangling we need to do, load tidyverse and read the two data files. As a prompt, save the data files to these object names to be consistent with the activities below, but you can check the solution if you are stuck.\n\n# Load the tidyverse package below\nlibrary(tidyverse)\n\n# Load the data files\n# This should be the Bartlett_demographics.csv file \ndemog &lt;- ?\n\n# This should be the Bartlett_trials.csv file \ntrials &lt;- ?\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# Load the tidyverse package below\nlibrary(tidyverse)\n\n# Load the data files\n# This should be the Bartlett_demographics.csv file \ndemog &lt;- read_csv(\"data/Bartlett_demographics.csv\")\n\n# This should be the Bartlett_trials.csv file \ntrials &lt;- read_csv(\"data/Bartlett_trials.csv\")\n\n\n\n\n\n15.2.2 Explore demog and trials\n\nThe data from Bartlett et al. (2022) is split into two data files. In demog, we have the participant ID (participant_private_id) and several demographic variables.\n\n\nRows: 205\nColumns: 20\n$ participant_private_id &lt;dbl&gt; 631737, 631738, 631741, 631739, 631749, 631746,…\n$ consent_given          &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ age                    &lt;dbl&gt; 46, 54, 23, 34, 38, 19, 25, 21, 28, 35, 47, 45,…\n$ cigarettes_per_week    &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"…\n$ smoke_everyday         &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"…\n$ past_four_weeks        &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"…\n$ age_started_smoking    &lt;chr&gt; \"12\", \"17\", \"17\", \"16\", \"15\", \"16\", \"22\", \"11\",…\n$ country_of_origin      &lt;chr&gt; \"United Kingdom\", \"Germany\", \"Poland\", \"Austral…\n$ cpd                    &lt;chr&gt; \"6\", \"5\", \"10\", \"20\", \"10\", \"1\", \"6\", \"15\", \"12…\n$ ethnicity              &lt;chr&gt; \"White / Caucasian\", \"White / Caucasian\", \"Mixe…\n$ gender                 &lt;chr&gt; \"Female\", \"Female\", \"Male\", \"Female\", \"Female\",…\n$ last_cigarette         &lt;chr&gt; \"60\", \"780\", \"90\", \"5\", \"60\", \"720\", \"10\", \"10\"…\n$ level_education        &lt;chr&gt; \"Graduated University / College\", \"Graduated Un…\n$ technical_issues       &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\",…\n$ FTND_1                 &lt;dbl&gt; 2, 0, 0, 3, 3, 0, 1, 2, 1, 3, 2, 2, 2, 1, 2, 0,…\n$ FTND_2                 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,…\n$ FTND_3                 &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0,…\n$ FTND_4                 &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1,…\n$ FTND_5                 &lt;dbl&gt; 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0,…\n$ FTND_6                 &lt;dbl&gt; 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0,…\n\n\nThe columns (variables) we have in the data set are:\n\n\n\n\n\n\n\nVariable\nType\nDescription\n\n\n\nparticipant_private_id\ndouble\nParticipant number.\n\n\nconsent_given\ndouble\n1 = informed consent, 2 = no consent.\n\n\nage\ndouble\nAge in Years.\n\n\ncigarettes_per_week\ncharacter\nDo you smoke every week? Yes or No.\n\n\nsmoke_everyday\ncharacter\nDo you smoke everyday? Yes or No.\n\n\npast_four_weeks\ncharacter\nHave you smoked in the past four weeks? Yes or No.\n\n\nage_started_smoking\ncharacter\nAge started smoking in years.\n\n\ncountry_of_origin\ncharacter\nCountry of origin.\n\n\ncpd\ncharacter\nHow many cigarettes do you smoke per day?\n\n\nethnicity\ncharacter\nWhat is your ethniciity?\n\n\ngender\ncharacter\nWhat is your gender?\n\n\nlast_cigarette\ncharacter\nHow long in minutes since your last cigarette?\n\n\nlevel_education\ncharacter\nWhat is your highest level of education?\n\n\ntechnical_issues\ncharacter\nDid you experience any technical issues? Yes or No\n\n\nFTND_1 to FTND_6\ndouble\nSix items of the Fagerstrom Test for Nicotine Dependence\n\n\n\nIn trials, we then have the participant ID (participant_private_id) and trial-by-trial information from the software Gorilla (an online experiment service). This is probably the biggest data set you have come across so far as we have hundreds of trials per participant.\n\n\nRows: 244,847\nColumns: 15\n$ participant_private_id &lt;dbl&gt; 631737, 631737, 631737, 631737, 631737, 631737,…\n$ trial_number           &lt;chr&gt; \"BEGIN TASK\", \"1\", \"1\", \"1\", \"1\", \"2\", \"2\", \"2\"…\n$ reaction_time          &lt;dbl&gt; NA, 8007.015, 249.823, 199.765, 1999.671, 249.8…\n$ response               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ correct                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ display                &lt;chr&gt; NA, \"instructions\", \"practice\", \"practice\", \"pr…\n$ answer                 &lt;chr&gt; NA, NA, \"right\", \"right\", \"right\", \"left\", \"lef…\n$ soa                    &lt;dbl&gt; NA, NA, 200, 200, 200, 200, 200, 200, 500, 500,…\n$ screen_name            &lt;chr&gt; NA, \"instructions_continue\", \"Screen 1\", \"Scree…\n$ image_left             &lt;chr&gt; NA, NA, \"p1.jpg\", \"p1.jpg\", \"p1.jpg\", \"p1.jpg\",…\n$ image_right            &lt;chr&gt; NA, NA, \"p2.jpg\", \"p2.jpg\", \"p2.jpg\", \"p2.jpg\",…\n$ dot_left               &lt;chr&gt; NA, NA, \"nodot.jpg\", \"nodot.jpg\", \"nodot.jpg\", …\n$ dot_right              &lt;chr&gt; NA, NA, \"dot.jpg\", \"dot.jpg\", \"dot.jpg\", \"nodot…\n$ trial_type             &lt;chr&gt; NA, NA, \"practice\", \"practice\", \"practice\", \"pr…\n$ block                  &lt;dbl&gt; NA, NA, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n\n\nThe columns (variables) we have in the data set are:\n\n\n\n\n\n\n\nVariable\nType\nDescription\n\n\n\nparticipant_private_id\ndouble\nParticipant number.\n\n\ntrial_number\ncharacter\nTrial number as an integer, plus start and end task.\n\n\nreaction_time\ndouble\nParticipant response time in milliseconds (ms)\n\n\nresponse\ncharacter\nKeyboard response from participant. Left or Right.\n\n\ncorrect\ndouble\nWas the response correct? 1 = correct, 0 = incorrect.\n\n\ndisplay\ncharacter\nTrial display: e.g., practice, trials, instructions, breaks.\n\n\nanswer\ncharacter\nWhat is the correct answer? Left or Right.\n\n\nsoa\ndouble\nStimulus onset asynchrony. How long the images were shown for: 200ms or 500ms.\n\n\nscreen_name\ncharacter\nName of the screen: e.g., screen 1, fixation, stimuli, response.\n\n\nimage_left\ncharacter\nName of the image file in the left area.\n\n\nimage_right\ncharacter\nName of the image file in the right area.\n\n\ndot_left\ncharacter\nName of the dot image file in the left area.\n\n\ndot_right\ncharacter\nName of the dot image file in the right area.\n\n\ntrial_type\ncharacter\nCategory of the trial: practice, neutral, nonsmoking, smoking.\n\n\nblock\ndouble\nNumber of the trial block.\n\n\n\n\n\n\n\n\n\nTry this\n\n\n\nNow we have introduced the two data sets, explore them using different methods we introduced. For example, opening the data objects as a tab to scroll around, explore with glimpse(), or even try plotting some of the variables to see what they look like using visualisation skills from Chapter 3.\nDo you notice any variables that look the wrong type? Can you see any responses in there that are going to cause problems?"
  },
  {
    "objectID": "17-analysis-journey-1.html#wrangling-demographics",
    "href": "17-analysis-journey-1.html#wrangling-demographics",
    "title": "15  Analysis Journey 1: Data Wrangling",
    "section": "\n15.3 Wrangling demographics",
    "text": "15.3 Wrangling demographics\nFor this kind of data, we recommend wrangling each file first, before joining them together. Starting with the demographics file, there are a few wrangling steps before the data are ready to summarise. We are going to show you a preview of the starting data set and the end product we are aiming for.\n\n\nRaw data\nWrangled data\n\n\n\n\n\nRows: 205\nColumns: 20\n$ participant_private_id &lt;dbl&gt; 631737, 631738, 631741, 631739, 631749, 631746,…\n$ consent_given          &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ age                    &lt;dbl&gt; 46, 54, 23, 34, 38, 19, 25, 21, 28, 35, 47, 45,…\n$ cigarettes_per_week    &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"…\n$ smoke_everyday         &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"…\n$ past_four_weeks        &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"…\n$ age_started_smoking    &lt;chr&gt; \"12\", \"17\", \"17\", \"16\", \"15\", \"16\", \"22\", \"11\",…\n$ country_of_origin      &lt;chr&gt; \"United Kingdom\", \"Germany\", \"Poland\", \"Austral…\n$ cpd                    &lt;chr&gt; \"6\", \"5\", \"10\", \"20\", \"10\", \"1\", \"6\", \"15\", \"12…\n$ ethnicity              &lt;chr&gt; \"White / Caucasian\", \"White / Caucasian\", \"Mixe…\n$ gender                 &lt;chr&gt; \"Female\", \"Female\", \"Male\", \"Female\", \"Female\",…\n$ last_cigarette         &lt;chr&gt; \"60\", \"780\", \"90\", \"5\", \"60\", \"720\", \"10\", \"10\"…\n$ level_education        &lt;chr&gt; \"Graduated University / College\", \"Graduated Un…\n$ technical_issues       &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\",…\n$ FTND_1                 &lt;dbl&gt; 2, 0, 0, 3, 3, 0, 1, 2, 1, 3, 2, 2, 2, 1, 2, 0,…\n$ FTND_2                 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,…\n$ FTND_3                 &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0,…\n$ FTND_4                 &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1,…\n$ FTND_5                 &lt;dbl&gt; 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0,…\n$ FTND_6                 &lt;dbl&gt; 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0,…\n\n\n\n\n\n\nRows: 205\nColumns: 22\n$ participant_private_id &lt;dbl&gt; 631737, 631738, 631741, 631739, 631749, 631746,…\n$ consent_given          &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ age                    &lt;dbl&gt; 46, 54, 23, 34, 38, 19, 25, 21, 28, 35, 47, 45,…\n$ cigarettes_per_week    &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"…\n$ smoke_everyday         &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"…\n$ past_four_weeks        &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"…\n$ age_started_smoking    &lt;int&gt; 12, 17, 17, 16, 15, 16, 22, 11, 18, 15, 18, 19,…\n$ country_of_origin      &lt;fct&gt; United Kingdom, Germany, Poland, Australia, Spa…\n$ cpd                    &lt;int&gt; 6, 5, 10, 20, 10, 1, 6, 15, 12, 20, 20, 15, 20,…\n$ ethnicity              &lt;fct&gt; White / Caucasian, White / Caucasian, Mixed / m…\n$ gender                 &lt;fct&gt; Female, Female, Male, Female, Female, Male, Fem…\n$ last_cigarette         &lt;dbl&gt; 60, 780, 90, 5, 60, 720, 10, 10, 30, 0, 10, 30,…\n$ level_education        &lt;fct&gt; Graduated University / College, Graduated Unive…\n$ technical_issues       &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\",…\n$ FTND_1                 &lt;dbl&gt; 2, 0, 0, 3, 3, 0, 1, 2, 1, 3, 2, 2, 2, 1, 2, 0,…\n$ FTND_2                 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,…\n$ FTND_3                 &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0,…\n$ FTND_4                 &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1,…\n$ FTND_5                 &lt;dbl&gt; 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0,…\n$ FTND_6                 &lt;dbl&gt; 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0,…\n$ daily_smoker           &lt;fct&gt; Daily Smoker, Daily Smoker, Daily Smoker, Daily…\n$ FTND_sum               &lt;dbl&gt; 3, 0, 2, 7, 5, 3, 3, 5, 4, 6, 7, 5, 6, 3, 4, 1,…\n\n\n\n\n\n\n\n\n\n\n\nTry this\n\n\n\nBefore we give you a task list, try and switch between the raw data and the wrangled data. Make a list of all the differences you can see between the two data objects.\n\nWhat type is each variable? Has it changed from the raw data?\nDo we have any new variables? How could you create these from the variables available to you?\n\nFor the variable daily_smoker, this has two levels which you cannot see in the preview: “Daily Smoker” and “Non-daily Smoker”. Which variable could this be based on?\nTry and wrangle the data based on all the differences you notice to create a new object demog_tidy.\nWhen you get as far as you can, check the task list which explains all the steps we applied, but not how to do them. Then, you can check the solution for our code.\n\n\n\n15.3.1 Task list\n\n\n\n\n\n\nShow me the task list\n\n\n\n\n\nThese are all the steps we applied to create the wrangled data object:\n\nConvert age_started_smoking to an integer (as age is a round number).\nConvert cpd to an integer (as cigarettes per day is a round number). You will notice a warning about introducing an NA as some nonsense responses cannot be converted to a number.\nConvert country_of_origin to a factor (as we have distinct categories).\nConvert ethnicity to a factor (as we have distinct categories).\nConvert gender to a factor (as we have distinct categories).\nConvert last_cigarette to an integer (as time since last cigarette in minutes is a round number). You will notice a warning about introducing an NA as some nonsense responses cannot be converted to a number.\nConvert level_education to a factor (as we have distinct categories).\nCreate a new variable daily_smoker by recoding an existing variable. The new variable should have two levels: “Daily Smoker” and “Non-daily Smoker”. In the process, convert daily_smoker to a factor (as we have distinct categories).\nCreate a new variable FTND_sum by taking the sum of the six items FTND_1 to FTND_6 per participant.\n\nFor some advice, think of everything we covered in Chapters 4 to 6. How could you complete these steps as efficiently as possible? Could you string together functions using pipes, or do you need some intermediary objects? If it’s easier for you to complete steps with longer but accurate code, there is nothing wrong with that. You recognise ways to make your code more efficient over time.\n\n\n\n\n15.3.2 Solution\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThis is the code we used to create the new object demog_tidy using the original object demog. As long as you get the same end result, the exact code is not important. In coding, there are multiple ways of getting to the same end result. Maybe you found a more efficient way to complete some of the steps compared to us. Maybe your code was a little longer. As long as it worked, that is the most important thing.\n\n# Using demog, create a new object demog_tidy\n# apply mutate to convert or create variables\ndemog_tidy &lt;- demog %&gt;% \n  mutate(age_started_smoking = as.integer(age_started_smoking),\n         cpd = as.integer(cpd),\n         country_of_origin = as.factor(country_of_origin),\n         ethnicity = as.factor(ethnicity),\n         gender = as.factor(gender),\n         last_cigarette = as.integer(last_cigarette),\n         level_education = as.factor(level_education),\n         # we used smoke_everyday to create our daily_smoker variable\n         daily_smoker = as.factor(case_match(smoke_everyday,\n                                             \"Yes\" ~ \"Daily Smoker\",\n                                             \"No\" ~ \"Non-daily Smoker\")))\n# To calculate the sum of the 6 FTND items, \n# pivot longer, group by ID, then sum responses. \nFTND_sum &lt;- demog_tidy %&gt;% \n  pivot_longer(cols = FTND_1:FTND_6,\n               names_to = \"Item\",\n               values_to = \"Response\") %&gt;% \n  group_by(participant_private_id) %&gt;% \n  summarise(FTND_sum = sum(Response))\n\n# Join this new column back to demog_tidy\ndemog_tidy &lt;- demog_tidy %&gt;% \n  inner_join(y = FTND_sum,\n             by = \"participant_private_id\")"
  },
  {
    "objectID": "17-analysis-journey-1.html#wrangling-trials",
    "href": "17-analysis-journey-1.html#wrangling-trials",
    "title": "15  Analysis Journey 1: Data Wrangling",
    "section": "\n15.4 Wrangling trials",
    "text": "15.4 Wrangling trials\nTurning to the trials file, there are a few wrangling steps and you will probably need the task list more for this part than you did for demographics. Some of the steps might not be as obvious but it is still important to compare the objects and see if you can identify the changes. We are going to show you a preview of the starting data set, and the end product we are aiming for in step 3.\n\n\nOriginal raw data\nStep 1\nStep 2\nStep 3\n\n\n\n\n\nRows: 244,847\nColumns: 15\n$ participant_private_id &lt;dbl&gt; 631737, 631737, 631737, 631737, 631737, 631737,…\n$ trial_number           &lt;chr&gt; \"BEGIN TASK\", \"1\", \"1\", \"1\", \"1\", \"2\", \"2\", \"2\"…\n$ reaction_time          &lt;dbl&gt; NA, 8007.015, 249.823, 199.765, 1999.671, 249.8…\n$ response               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ correct                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ display                &lt;chr&gt; NA, \"instructions\", \"practice\", \"practice\", \"pr…\n$ answer                 &lt;chr&gt; NA, NA, \"right\", \"right\", \"right\", \"left\", \"lef…\n$ soa                    &lt;dbl&gt; NA, NA, 200, 200, 200, 200, 200, 200, 500, 500,…\n$ screen_name            &lt;chr&gt; NA, \"instructions_continue\", \"Screen 1\", \"Scree…\n$ image_left             &lt;chr&gt; NA, NA, \"p1.jpg\", \"p1.jpg\", \"p1.jpg\", \"p1.jpg\",…\n$ image_right            &lt;chr&gt; NA, NA, \"p2.jpg\", \"p2.jpg\", \"p2.jpg\", \"p2.jpg\",…\n$ dot_left               &lt;chr&gt; NA, NA, \"nodot.jpg\", \"nodot.jpg\", \"nodot.jpg\", …\n$ dot_right              &lt;chr&gt; NA, NA, \"dot.jpg\", \"dot.jpg\", \"dot.jpg\", \"nodot…\n$ trial_type             &lt;chr&gt; NA, NA, \"practice\", \"practice\", \"practice\", \"pr…\n$ block                  &lt;dbl&gt; NA, NA, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n\n\n\n\n\n\nRows: 50,510\nColumns: 15\n$ participant_private_id &lt;dbl&gt; 631737, 631737, 631737, 631737, 631737, 631737,…\n$ trial_number           &lt;chr&gt; \"1\", \"2\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"11\", \"…\n$ reaction_time          &lt;dbl&gt; 1486.850, 720.640, 739.635, 668.730, 578.015, 5…\n$ response               &lt;chr&gt; \"right\", \"left\", \"right\", \"right\", \"left\", \"lef…\n$ correct                &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ display                &lt;chr&gt; \"trials\", \"trials\", \"trials\", \"trials\", \"trials…\n$ answer                 &lt;chr&gt; \"right\", \"left\", \"right\", \"right\", \"left\", \"lef…\n$ soa                    &lt;dbl&gt; 200, 500, 500, 200, 200, 200, 200, 200, 500, 50…\n$ screen_name            &lt;chr&gt; \"response\", \"response\", \"response\", \"response\",…\n$ image_left             &lt;chr&gt; \"N14.jpg\", \"F14.jpg\", \"F14.jpg\", \"N4.jpg\", \"N19…\n$ image_right            &lt;chr&gt; \"F14.jpg\", \"N14.jpg\", \"N14.jpg\", \"F4.jpg\", \"F19…\n$ dot_left               &lt;chr&gt; \"nodot.jpg\", \"dot.jpg\", \"nodot.jpg\", \"nodot.jpg…\n$ dot_right              &lt;chr&gt; \"dot.jpg\", \"nodot.jpg\", \"dot.jpg\", \"dot.jpg\", \"…\n$ trial_type             &lt;chr&gt; \"smoking\", \"smoking\", \"nonsmoking\", \"smoking\", …\n$ block                  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n\n\n\n\n\n\nRows: 820\nColumns: 5\n$ participant_private_id &lt;dbl&gt; 631737, 631737, 631737, 631737, 631738, 631738,…\n$ soa                    &lt;dbl&gt; 200, 200, 500, 500, 200, 200, 500, 500, 200, 20…\n$ trial_type             &lt;chr&gt; \"nonsmoking\", \"smoking\", \"nonsmoking\", \"smoking…\n$ median_RT              &lt;dbl&gt; 444.6275, 452.8675, 456.8900, 449.6650, 638.000…\n$ condition              &lt;chr&gt; \"nonsmoking200\", \"smoking200\", \"nonsmoking500\",…\n\n\n\n\n\n\nRows: 205\nColumns: 5\n$ participant_private_id &lt;dbl&gt; 631737, 631738, 631739, 631741, 631746, 631748,…\n$ nonsmoking200          &lt;dbl&gt; 444.6275, 638.0000, 516.5375, 410.8250, 375.272…\n$ smoking200             &lt;dbl&gt; 452.8675, 703.5000, 529.1300, 433.3175, 367.365…\n$ nonsmoking500          &lt;dbl&gt; 456.8900, 700.0000, 517.4775, 427.4100, 363.195…\n$ smoking500             &lt;dbl&gt; 449.6650, 725.0000, 514.5050, 421.2250, 355.777…\n\n\n\n\n\n\n\n\n\n\n\nTry this\n\n\n\nBefore we give you a task list, try and switch between the raw data and the three steps we took for wrangling the data. Make a list of all the differences you can see across the steps.\nThis part of the data wrangling is quite difficult if you are unfamiliar with dealing with response time tasks as you need to know what the end product should look like to work with later. Essentially, we want the median response time per participant per condition (across trial type and soa). There are rows we do not need, variables to create, and data to restructure. So, it takes all your wrangling skills you have learnt so far.\n\nIn step 1, how many observations do we have compared to the raw data? Knowing the design is important here, so look at the columns correct, screen_name, and trial_type. What function might reduce the number of observations like this?\nIn step 2, how many observations do we have compared to step 1? How many observations do we have per participant ID? What new variables do we have and how could you make them? Hint: for condition, we have not covered this, so look up a function called paste0().\nIn step 3, how many observations do we have compared to step 2? Have we removed any columns compared to step 2? Have the data been restructured?\n\nTry and wrangle the data based on all the differences you notice to create a new object RT_wide shown in step 3.\nWhen you get as far as you can, check the task list which explains all the steps we applied, but not how to do them. Then, you can check the solution for our code.\n\n\n\n15.4.1 Task list\nFor this part, we will separate the task list into the three steps in case you want to test yourself at each stage.\n\n\n\n\n\n\nShow me the step 1 task list\n\n\n\n\n\nThese are all the steps we applied to create the wrangled data object:\n\nCreate an object trials_tidy using the original trials data.\n\nFilter observations using three variables:\n\nscreen_name should only include “response”.\ntrial_type should only include “nonsmoking” and “smoking”.\ncorrect should only include 1 (correct responses).\n\n\n\n\n\n\n\n\n\n\n\n\nShow me the step 2 task list\n\n\n\n\n\nThese are all the steps we applied to create the wrangled data object:\n\nCreate an object average_trials using the trials_tidy object from step 1.\nGroup observations by three variables: participant_private_id, soa, and trial_type.\nSummarise the data to create a new variable median_RT by calculating the median reaction_time.\nCreate a new variable called condition by combining the names of the trial_type and soa columns. Hint: this is a new concept, so try this paste0(trial_type, soa). There are a few ways of dealing with this problem, but we are trying to avoid turning soa into variable names, as R does not like having variable names start with or be completely numbers.\nUngroup to avoid the groups carrying over into future objects.\n\n\n\n\n\n\n\n\n\n\nShow me the step 3 task list\n\n\n\n\n\nThese are all the steps we applied to create the wrangled data object:\n\nCreate an object RT_wide using the average_trials object from step 2.\nRemove the variables soa and trial_type to avoid problems with restructuring. You could use the argument,\nRestructure the data so your condition variable is spread across columns.\n\n\n\n\n\n15.4.2 Solution\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThis is the code we used to create the new object RT_wide by following three steps. You could do it in two to combine the first two steps, but we wanted to make the change between filtering and grouping/summarising more obvious before showing you the task list.\nRemember: As long as you get the same end result, the exact code is not important. In coding, there are multiple ways of getting to the same end result.\n\n# filter trials to focus on correct responses and key trials\ntrials_tidy &lt;- trials %&gt;% \n  filter(screen_name == \"response\",\n         trial_type %in% c(\"nonsmoking\", \"smoking\"),\n         correct == 1)\n\n# Calculate median RT per ID, SOA, and trial type\naverage_trials &lt;- trials_tidy %&gt;% \n  group_by(participant_private_id, soa, trial_type) %&gt;% \n  summarise(median_RT = median(reaction_time)) %&gt;% \n  mutate(condition = paste0(trial_type, soa)) %&gt;% \n  ungroup() # ungroup to avoid it carrying over\n\n# Create wide data by making a new condition variable\n# remove soa and trial type\n# pivot wider for four columns per participant\nRT_wide &lt;- average_trials %&gt;% \n  select(-soa, -trial_type) %&gt;% \n  pivot_wider(names_from = condition,\n              values_from = median_RT)"
  },
  {
    "objectID": "17-analysis-journey-1.html#summarising",
    "href": "17-analysis-journey-1.html#summarising",
    "title": "16  Analysis Journey 1: Data Wrangling",
    "section": "\n16.5 Summarising",
    "text": "16.5 Summarising",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Analysis Journey 1: Data Wrangling</span>"
    ]
  },
  {
    "objectID": "17-analysis-journey-1.html#conclusion",
    "href": "17-analysis-journey-1.html#conclusion",
    "title": "15  Analysis Journey 1: Data Wrangling",
    "section": "\n15.7 Conclusion",
    "text": "15.7 Conclusion\nWell done! Hopefully you recognised how far your skills have come to be able to do this independently, regardless of how many hints you needed.\nThese are real skills people use in research. If you are curious, Bartlett et al. (2022) shared their code as a reproducible manuscrupt, so you can see all the wrangling steps they completed by looking at this file on the Open Science Framework. We did not include all of them here as there are concepts like outliers we had not covered by Chapter 6.\n\n\n\n\nBartlett, J. E., Jenks, R., & Wilson, N. (2022). No Meaningful Difference in Attentional Bias Between Daily and Non-Daily Smokers. Journal of Trial & Error. https://doi.org/10.36850/e11"
  },
  {
    "objectID": "17-analysis-journey-1.html#combining-objects-and-exclusion-criteria",
    "href": "17-analysis-journey-1.html#combining-objects-and-exclusion-criteria",
    "title": "15  Analysis Journey 1: Data Wrangling",
    "section": "\n15.5 Combining objects and exclusion criteria",
    "text": "15.5 Combining objects and exclusion criteria\nGreat work so far! You should now have two wrangled objects: demog_tidy and RT_wide. The next step is combining them and applying exclusion criteria from the study.\nWe are going to give you the task list immediately for this as you need to understand the methods to know what criteria to use. We still challenge you to complete the tasks though, before checking your answers against the code we used.\n\n\n\n\n\n\nTask list\n\n\n\nComplete the following tasks to apply the final data wrangling steps:\n\nCreate a new object called full_data by joining your two data objectsdemog_tidy and RT_wide using a common identifier.\n\nFilter observations using the following criteria:\n\nconsent_given should only include 1. We only want people who consented.\nage range only between 18 and 60. We do not want people younger or older than this range.\npast_four_weeks should only include “Yes”. We do not want people who have not smoked in the past four weeks.\ntechnical_issues should only include “No”. We do not want people who experienced technical issues during the study.\n\n\n\n\n\n\n15.5.1 Solution\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThis is the code we used to create the new object full_data by joining demog_tidy and RT_wide, and filtering observations based on our four criteria.\nAs long as you get the same end result, the exact code is not important. In coding, there are multiple ways of getting to the same end result.\n\n# create full_data by joining the two objects\n# filter data by four criteria\nfull_data &lt;- demog_tidy %&gt;% \n  inner_join(y = RT_wide,\n             by = \"participant_private_id\") %&gt;% \n  filter(consent_given == 1,\n         age &gt;= 18 & age &lt;= 60,\n         past_four_weeks == \"Yes\",\n         technical_issues == \"No\")"
  },
  {
    "objectID": "17-analysis-journey-1.html#summarisingvisualising-your-data",
    "href": "17-analysis-journey-1.html#summarisingvisualising-your-data",
    "title": "15  Analysis Journey 1: Data Wrangling",
    "section": "\n15.6 Summarising/visualising your data",
    "text": "15.6 Summarising/visualising your data\nThat is all the wrangling complete! Hopefully, this reinforces the role of reproducibility and data skills. If you did this in other software like Excel, you might not have a paper trail of all the steps. Like this, you have the full code to apply all the wrangling steps from raw data which you can run every time you need to, and edit it if you found a mistake or wanted to add something new. You can also come back to the file later to add more code (such as after Chapter 7 to plot more of the data, or Chapter 13 for some inferential statistics).\nTo finish the journey, we have some practice tasks for summarising and visualising the data. The whole purpose of Bartlett et al. (2022) was to compare daily and non-daily smokers, so we will explore some of the key variables.\nAll of the questions are based on the final full_data object. If your answers differ, check the wrangling steps above. If you are really struggling to identify the difference, or you just wanted to complete these tasks, you can download a spreadsheet version of full_data here: Bartlett_full_data.csv.\n\n15.6.1 Demographics\n\nHow many daily and non-daily smokers were there? There were  daily smokers and  non-daily smokers.\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\n\nfull_data %&gt;% \n  count(daily_smoker)\n\n\n\n\ndaily_smoker\nn\n\n\n\nDaily Smoker\n115\n\n\nNon-daily Smoker\n63\n\n\n\n\n\n\n\n\n\n\nTo 2 decimal places, the mean age of all the participants was  (SD = ).\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\n\nfull_data %&gt;% \n  summarise(mean_age = round(mean(age), 2),\n            sd_age = round(sd(age), 2))\n\n\n\n\nmean_age\nsd_age\n\n\n31.07\n9.22\n\n\n\n\n\n\n\n\n\nA histogram of all the participants’ ages looks like:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\n\nfull_data %&gt;% \n  ggplot(aes(x = age)) + \n  geom_histogram() + \n  scale_x_continuous(name = \"Age\") + \n  scale_y_continuous(name = \"Frequency\") + \n  theme_classic()\n\n\n\n\n\nA bar plot of the gender breakdown of the sample would look like:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\n\nfull_data %&gt;% \n  ggplot(aes(x = gender)) + \n  geom_bar() +\n  scale_x_discrete(name = \"Gender\") + \n  scale_y_continuous(name = \"Frequency\") + \n  theme_classic()\n\n\n\n\n\n15.6.2 Measures of smoking dependence\n\nTo 2 decimal places, for daily smokers the mean number of cigarettes per day was  (SD = ) and for non-daily smokers the mean number of cigarettes per day was  (SD = ).\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\n\nfull_data %&gt;% \n  group_by(daily_smoker) %&gt;% \n  summarise(mean_cpd = round(mean(cpd, na.rm = TRUE), 2),\n            sd_cpd = round(sd(cpd, na.rm = TRUE), 2))\n\n\n\n\ndaily_smoker\nmean_cpd\nsd_cpd\n\n\n\nDaily Smoker\n8.85\n6.51\n\n\nNon-daily Smoker\n2.32\n2.69\n\n\n\n\n\n\n\n\n\n\nTo 2 decimal places, for daily smokers the mean FTND sum score was  (SD = ) and for non-daily smokers the mean number of cigarettes per day was  (SD = ).\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\n\nfull_data %&gt;% \n  group_by(daily_smoker) %&gt;% \n  summarise(mean_FTND = round(mean(FTND_sum, na.rm = TRUE), 2),\n            sd_FTND = round(sd(FTND_sum, na.rm = TRUE), 2))\n\n\n\n\ndaily_smoker\nmean_FTND\nsd_FTND\n\n\n\nDaily Smoker\n2.61\n2.20\n\n\nNon-daily Smoker\n0.49\n1.28\n\n\n\n\n\n\n\n\n\n\n15.6.3 Attentional bias\n\n\nBefore answering the following questions, complete one extra data wrangling step to create difference scores where positive values mean attentional bias towards smoking images (faster responses to smoking compared to non-smoking stimuli):\n\nCreate a new variable called difference_200 by calculating nonsmoking200 - smoking200.\nCreate a new variable called difference_500 by by calculating nonsmoking500 - smoking500.\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\n\nfull_data &lt;- full_data %&gt;% \n  mutate(difference_200 = nonsmoking200 - smoking200,\n         difference_500 = nonsmoking500 - smoking500)\n\n\n\n\n\nTo 2 decimal places, the mean difference in attentional bias in the 200ms condition was  (SD = ) for daily smokers and  (SD = ) for non-daily smokers.\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\n\nfull_data %&gt;% \n  group_by(daily_smoker) %&gt;% \n  summarise(mean_bias_200 = round(mean(difference_200, na.rm = TRUE), 2),\n            sd_bias_200 = round(sd(difference_200, na.rm = TRUE), 2))\n\n\n\n\ndaily_smoker\nmean_bias_200\nsd_bias_200\n\n\n\nDaily Smoker\n1.25\n23.91\n\n\nNon-daily Smoker\n-2.74\n21.27\n\n\n\n\n\n\n\n\n\n\nTo 2 decimal places, the mean difference in attentional bias in the 500ms condition was  (SD = ) for daily smokers and  (SD = ) for non-daily smokers.\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\n\nfull_data %&gt;% \n  group_by(daily_smoker) %&gt;% \n  summarise(mean_bias_500 = round(mean(difference_500, na.rm = TRUE), 2),\n            sd_bias_500 = round(sd(difference_500, na.rm = TRUE), 2))\n\n\n\n\ndaily_smoker\nmean_bias_500\nsd_bias_500\n\n\n\nDaily Smoker\n0.76\n21.66\n\n\nNon-daily Smoker\n-1.19\n14.51\n\n\n\n\n\n\n\n\n\nIf you are currently completing this after Chapter 6, we have not covered visualising continuous data or inferential statistics yet. Try coming back to these tasks to compare these measures when you have finished Chapter 7 for more advanced visualisation and Chapter 13 for factorial ANOVA.\nA difference score of 0 means no bias towards smoking or non-smoking images. So, you can see the paper did not find either group showed much attentional bias towards smoking images nor much difference between the groups, hence why it was published in the Journal of Trial and Error."
  },
  {
    "objectID": "07-more-visualisation.html#chapter-preparation",
    "href": "07-more-visualisation.html#chapter-preparation",
    "title": "7  Scatterplots, boxplots, and violin-boxplots",
    "section": "\n7.1 Chapter preparation",
    "text": "7.1 Chapter preparation\n\n7.1.1 Introduction to the data set\nFor this chapter, we are using open data from Zhang et al. (2014). The abstract of their article is:\n\nAlthough documenting everyday activities may seem trivial, four studies reveal that creating records of the present generates unexpected benefits by allowing future rediscoveries. In Study 1, we used a time-capsule paradigm to show that individuals underestimate the extent to which rediscovering experiences from the past will be curiosity provoking and interesting in the future. In Studies 2 and 3, we found that people are particularly likely to underestimate the pleasure of rediscovering ordinary, mundane experiences, as opposed to extraordinary experiences. Finally, Study 4 demonstrates that underestimating the pleasure of rediscovery leads to time-inconsistent choices: Individuals forgo opportunities to document the present but then prefer rediscovering those moments in the future to engaging in an alternative fun activity. Underestimating the value of rediscovery is linked to people’s erroneous faith in their memory of everyday events. By documenting the present, people provide themselves with the opportunity to rediscover mundane moments that may otherwise have been forgotten.\n\nIn summary, they were interested in whether people could predict how interested they would be in rediscovering past experiences. They call it a “time capsule” effect, where people store photos or messages to remind themselves of past events in the future.\nAt the start of the study (time 1), participants in a romantic relationship wrote about two kinds of experiences. An “extraordinary” experience with their partner on Valentine’s day and an “ordinary” experience one week before. They were then asked how enjoyable, interesting, and meaningful they predict they will find these recollections in three months time (time 2). Three months later, Zhang et al. randomised participants into one of two groups. In the “extraordinary” group, they reread the extraordinary recollection. In the “ordinary” group, they reread the ordinary recollection. All the participants completed measures on how enjoyable, interesting, and meaningful they found the experience, but this time what they actually felt, rather than what they predict they will feel.\nThey predicted participants in the ordinary group would underestimate their future feelings (i.e., there would be a bigger difference between time 1 and time 2 measures) compared to participants in the extraordinary group. In this chapter, we focus on a composite measure which took the mean of items on interest, meaningfulness, and enjoyment.\n\n7.1.2 Organising your files and project for the chapter\nBefore we can get started, you need to organise your files and project for the chapter, so your working directory is in order.\n\nIn your folder for research methods and the book ResearchMethods1_2/Quant_Fundamentals, create a new folder called Chapter_07_dataviz. Within Chapter_07_dataviz, create two new folders called data and figures.\nCreate an R Project for Chapter_07_dataviz as an existing directory for your chapter folder. This should now be your working directory.\nCreate a new R Markdown document and give it a sensible title describing the chapter, such as 07 Scatterplots Boxplots Violins. Delete everything below line 10 so you have a blank file to work with and save the file in your Chapter_07_dataviz folder.\nWe are working with a new data set, so please save the following data file: Zhang_2014.csv. Right click the link and select “save link as”, or clicking the link will save the files to your Downloads. Make sure that you save the file as “.csv”. Save or copy the file to your data/ folder within Chapter_07_dataviz.\n\nYou are now ready to start working on the chapter!\n\n7.1.3 Activity 1 - Read and wrangle the data\nAs the first activity, try and test yourself by completing the following task list to practice your data wrangling skills. Create an object called zhang_data to be consistent with the tasks below. If you want to focus on data visualisation, then you can just type the code in the solution.\n\n\n\n\n\n\nTry this\n\n\n\nTo wrangle the data, complete the following tasks:\n\nLoad the tidyverse package.\nRead the data file data/Zhang_2014.csv.\n\nSelect the following columns:\n\nGender\nAge\nCondition\nT1_Predicted_Interest_Composite renamed to time1_interest\nT2_Actual_Interest_Composite renamed to time2_interest.\n\n\nThere is currently no identifier, so create a new variable called participant_ID. Hint: try participant_ID = row_number().\n\nRecode two variables to be easier to understand and visualise:\n\nGender: 1 = “Male”, 2 = “Female”.\nCondition: 1 = “Ordinary”, 2 = “Extraordinary”.\n\n\n\nYour data should now be in wide format and ready to create a scatterplot.\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# Load the tidyverse package below\nlibrary(tidyverse)\n\n# Load the data file\n# This should be the Zhang_2014.csv file \nzhang_data &lt;- read_csv(\"data/Zhang_2014.csv\")\n\n# Wrangle the data for plotting. \n# select and rename key variables\n# mutate to add participant ID and recode\nzhang_data &lt;- zhang_data %&gt;%\n  select(Gender, \n         Age, \n         Condition, \n         time1_interest = T1_Predicted_Interest_Composite, \n         time2_interest = T2_Actual_Interest_Composite) %&gt;%\n  mutate(participant_ID = row_number(),\n         Condition = case_match(Condition, \n                            1 ~ \"Ordinary\", \n                            2 ~ \"Extraordinary\"),\n         Gender = case_match(Gender,\n                             1 ~ \"Male\",\n                             2 ~ \"Female\")) \n\n\n\n\n\n7.1.4 Activity 2 - Explore the data\n\n\n\n\n\n\nTry this\n\n\n\nAfter the wrangling steps, try and explore zhang_data to see what variables you are working with. For example, opening the data object as a tab to scroll around, explore with glimpse(), or try plotting some of the individual variables to see what they look like using visualisation skills from Chapter 3.\n\n\nIn zhang_data, we have the following variables:\n\n\n\n\n\n\n\nVariable\nType\nDescription\n\n\n\nGender\ncharacter\nParticipant gender: Male (1) or Female (2)\n\n\nAge\ndouble\nParticipant age in years.\n\n\nCondition\ncharacter\nCondition participant was randomly allocated into: Ordinary (1) or Extraordinary (2).\n\n\ntime1_interest\ndouble\nHow interested they predict they will find the recollection on a 1 (not at all) to 7 (extremely) scale. This measure is the mean of enjoyment, interest, and meaningfulness.\n\n\ntime2_interest\ndouble\nHow interested they actually found the recollection on a 1 (not at all) to 7 (extremely) scale. This measure is the mean of enjoyment, interest, and meaningfulness.\n\n\nparticipant_ID\ninteger\nOur new participant ID as an integer from 1 to 130.\n\n\n\nWe will use this data set to demonstrate different ways of visualising continuous variables, either combining multiple continuous variables in a scatterplot or splitting continuous variables into categories in a boxplot or violin-boxplot."
  },
  {
    "objectID": "07-more-visualisation.html#test-yourself",
    "href": "07-more-visualisation.html#test-yourself",
    "title": "7  Scatterplots, boxplots, and violin-boxplots",
    "section": "\n7.5 Test yourself",
    "text": "7.5 Test yourself\nTo end the chapter, we have some knowledge check questions to test your understanding of the concepts we covered in the chapter. We then have some error mode tasks to see if you can find the solution to some common errors in the concepts we covered in this chapter.\n\n7.5.1 Knowledge check\nQuestion 1. You want to plot several summary statistics including the median for your outcome, which ggplot2 layer could you use?\n\ngeom_boxplot()geom_point()geom_violin()\n\nQuestion 2. You want to create a scatterplot to show the correlation between two continuous variables, which ggplot2 layer could you use?\n\ngeom_point()geom_boxplot()geom_violin()\n\nQuestion 3. You want to show the density of values in your outcome, which ggplot2 layer could you use?\n\ngeom_boxplot()geom_point()geom_violin()\n\nQuestion 4. To separate a scatterplot into different groups, you could specify a grouping variable using the fill argument to change the colour of the points? \nTRUE\nFALSE\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nThis was a sneaky one, but relates to the error mode warning within the chapter. There are two ways to add a grouping variable for separate colours: colour and fill. In this scenario, colour would change the colour of the points, whereas fill would only change the colour of the regression line and its 95% confidence interval ribbon. Sometimes you need to play around with the settings to produce the effects you want.\n\n\n\nQuestion 5. The order of layers is important in ggplot2. Which order of layers would show individual data points on top of a boxplot?\n\ndata + ggplot() + geom_boxplot() + geom_jitter()data %&gt;% ggplot() + geom_jitter() + geom_boxplot()data + ggplot() + geom_jitter() + geom_boxplot()data %&gt;% ggplot() + geom_boxplot() + geom_jitter()\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nIn addition to the layer order, we also added an error mode feature to recognise when you need to use the pipe %&gt;% vs the +.\n\ndata %&gt;% ggplot() + geom_boxplot() + geom_jitter() was the correct answer as we add data point after the boxplot.\ndata + ggplot() + geom_boxplot() + geom_jitter() had the right order, but we used + instead of the pipe between the data and the initial ggplot() function.\ndata + ggplot() + geom_jitter() + geom_boxplot() and data %&gt;% ggplot() + geom_jitter() + geom_boxplot() both had the wrong layer order as the boxplot would overlay the points.\n\n\n\n\n\n7.5.2 Error mode\nThe following questions are designed to introduce you to making and fixing errors. For this topic, we focus on the new types of data visualisation. Remember to keep a note of what kind of error messages you receive and how you fixed them, so you have a bank of solutions when you tackle errors independently.\nCreate and save a new R Markdown file for these activities. Delete the example code, so your file is blank from line 10. Create a new code chunk to load tidyverse and wrangle the data files:\n\n# Load the tidyverse package below\nlibrary(tidyverse)\n\n# Load the data file\n# This should be the Zhang_2014.csv file \nzhang_data &lt;- read_csv(\"data/Zhang_2014.csv\")\n\n# Wrangle the data for plotting. \n# select and rename key variables\n# mutate to add participant ID and recode\nzhang_data &lt;- zhang_data %&gt;%\n  select(Gender, \n         Age, \n         Condition, \n         time1_interest = T1_Predicted_Interest_Composite, \n         time2_interest = T2_Actual_Interest_Composite) %&gt;%\n  mutate(participant_ID = row_number(),\n         Condition = case_match(Condition, \n                            1 ~ \"Ordinary\", \n                            2 ~ \"Extraordinary\"),\n         Gender = case_match(Gender,\n                             1 ~ \"Male\",\n                             2 ~ \"Female\")) \n\n# gather the data to convert to long format\nzhang_data_long &lt;- zhang_data %&gt;% \n  pivot_longer(cols = time1_interest:time2_interest,\n               names_to = \"Time\",\n               values_to = \"Interest\")\n\nBelow, we have several variations of a code chunk error or misspecification. Copy and paste them into your R Markdown file below the code chunk to load tidyverse and the data files. Once you have copied the activities, click knit and look at the error message you receive. See if you can fix the error and get it working before checking the answer.\nQuestion 6. Copy the following code chunk into your R Markdown file and press knit. This code… works, but it does not look quite right? Why are the tick marks not displaying properly?\n```{r}\nzhang_data %&gt;%  \n  ggplot(aes(x = time1_interest, y = time2_interest)) +\n  geom_point() +\n  theme_classic() + \n  scale_x_discrete(name = \"Time 1 interest score (1-7)\", \n                     breaks = c(1:7)) + # tick marks from 1 to 7\n  scale_y_discrete(name = \"Time 2 interest score (1-7)\", \n                     breaks = c(1:7)) + # tick marks from 1 to 7\n  geom_smooth(method = \"lm\")\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nIn this example, we used the wrong function for continuous variables. We used scale_x_discrete and scale_y_discrete, instead of scale_x_continuous and scale_y_continuous. We must honour the variable type when we customise the plot, so think about what type of variable is on each axis and which function lets you edit it.\n\nzhang_data %&gt;%  \n  ggplot(aes(x = time1_interest, y = time2_interest)) +\n  geom_point() +\n  theme_classic() + \n  scale_x_continuous(name = \"Time 1 interest score (1-7)\", \n                     breaks = c(1:7)) + # tick marks from 1 to 7\n  scale_y_continuous(name = \"Time 2 interest score (1-7)\", \n                     breaks = c(1:7)) + # tick marks from 1 to 7\n  geom_smooth(method = \"lm\")\n\n\n\n\nQuestion 7. Copy the following code chunk into your R Markdown file and press knit. You should receive an error like Error in \"fortify()\":! \"data\" must be a &lt;data.frame&gt;, or an object coercible by \"fortify()\" which is a little cryptic.\n```{r}\nzhang_data_long + \n  ggplot(aes(y = Interest, x = Condition, fill = Condition)) +\n  geom_boxplot() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7)) + \n  scale_fill_viridis_d(option = \"E\", \n                       alpha = 0.6) + \n  guides(fill = FALSE)\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nOnce we start using a mixture of tidyverse functions, it is important to remember which uses a pipe %&gt;% between layers, and which uses +. Here, we tried using the + between the data object and the initial ggplot() layer. We need a pipe here or it thinks you are trying to set the data argument using aes().\n\nzhang_data_long %&gt;% \n  ggplot(aes(y = Interest, x = Condition, fill = Condition)) +\n  geom_boxplot() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7)) + \n  scale_fill_viridis_d(option = \"E\", \n                       alpha = 0.6) + \n  guides(fill = FALSE)\n\n\n\n\nQuestion 8. Copy the following code chunk into your R Markdown file and press knit. We want to change the order of the categories to present males then female. This code…works, but is it doing what we think it is doing?\n```{r}\nzhang_data_long %&gt;% \n  drop_na(Gender) %&gt;% \n  ggplot(aes(y = Interest, x = Gender)) +\n  geom_violin() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7)) + \n  scale_x_discrete(labels = c(\"Male\", \"Female\"))\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nWe have introduced this error several times, but we see it so often it is worth reinforcing. When we change the labels, this is really just to tidy things up. The underlying data does not change, we are just trying to communicate it clearer. If we want to change the order of categories, we must change the underlying order of the data as a factor or R will default to alphabetical/numerical. So, we mutate Gender as a factorm, then pipe to ggplot2.\n\nzhang_data_long %&gt;% \n  mutate(Gender = factor(Gender,\n                         levels = (c(\"Male\", \"Female\")))) %&gt;% \n  drop_na(Gender) %&gt;% \n  ggplot(aes(y = Interest, x = Gender)) +\n  geom_violin() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7))"
  },
  {
    "objectID": "07-more-visualisation.html#words-from-this-chapter",
    "href": "07-more-visualisation.html#words-from-this-chapter",
    "title": "7  Scatterplots, boxplots, and violin-boxplots",
    "section": "\n7.6 Words from this Chapter",
    "text": "7.6 Words from this Chapter\nBelow you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the PsyTeachR Glossary. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter.\n\n\n\n\nterm\ndefinition\n\n\n\nboxplot\nVisualising a continuous variable by five summary statistics: the median centre line, the first and third quartile, and 1.5 times the first and third quartiles.\n\n\nscatterplot\nPlotting two variables on the x- and y-axis to show the correlation/relationship between the variables.\n\n\nviolin-boxplots\nA combination of a violin plot to show the density of data points and a boxplot to show summary statistics of distribution."
  },
  {
    "objectID": "07-more-visualisation.html#end-of-chapter",
    "href": "07-more-visualisation.html#end-of-chapter",
    "title": "7  Scatterplots, boxplots, and violin-boxplots",
    "section": "\n7.7 End of chapter",
    "text": "7.7 End of chapter\nWell done, you have completed the second chapter dedicated to data visualisation! This is a key area for psychology research and helping to communicate your findings to your audience. Data visualisation also comes with a lot of responsibility. There are lots of design choices to make and help communicate your findings as effectively and transparently as possible. We could dedicate a whole book to data visualisation possibilities in R and ggplot2, so we have added a range of further reading sources in the Additional Resources appendix.\nIn the next chapter, we start on inferential statistics introducing you to the concept of regression by focusing on one continuous predictor variable.\n\n\n\n\nZhang, T., Kim, T., Brooks, A. W., Gino, F., & Norton, M. I. (2014). A “Present” for the Future: The Unexpected Value of Rediscovery. Psychological Science, 25(10), 1851–1860. https://doi.org/10.1177/0956797614542274"
  },
  {
    "objectID": "07-more-visualisation.html",
    "href": "07-more-visualisation.html",
    "title": "7  Scatterplots, boxplots, and violin-boxplots",
    "section": "",
    "text": "7.1 Chapter preparation",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Scatterplots, boxplots, and violin-boxplots</span>"
    ]
  },
  {
    "objectID": "08-lm-continuous.html#chapter-preparation",
    "href": "08-lm-continuous.html#chapter-preparation",
    "title": "\n8  Regression with one continuous predictor\n",
    "section": "\n8.1 Chapter preparation",
    "text": "8.1 Chapter preparation\n\n8.1.1 Introduction to the data set\nFor this chapter, we are using open data from Dawtry et al. (2015). The abstract of their article is:\n\nThe present studies provide evidence that social-sampling processes lead wealthier people to oppose redistribution policies. In samples of American Internet users, wealthier participants reported higher levels of wealth in their social circles (Studies 1a and 1b). This was associated, in turn, with estimates of higher mean wealth in the wider U.S. population, greater perceived fairness of the economic status quo, and opposition to redistribution policies. Furthermore, results from a large-scale, nationally representative New Zealand survey revealed that low levels of neighborhood-level socioeconomic deprivation?an objective index of wealth within participants’ social circles mediated the relation between income and satisfaction with the economic status quo (Study 2). These findings held controlling for relevant variables, including political orientation and perceived self-interest. Social-structural inequalities appear to combine with social-sampling processes to shape the different political attitudes of wealthier and poorer people.\n\nIn summary, the authors investigated why people with more money tend to oppose wealth redistribution policies like higher taxes for higher incomes to decrease inequality in society. We are using data from Study 1A where 305 people completed measures on household income, predicted population income, their predicted social circle income, in addition to measures on support for wealth redistribution and fairness and satisfaction with the current system.\nThey predicted people with higher incomes have social circles with higher incomes, so they are more satisfied with the current system of wealth redistribution and less interested in changing it. In essence, poorer people and richer people have different experiences of how rich and equal their country is. In this chapter, we will explore the relationship between a range of these variables.\n\n8.1.2 Organising your files and project for the chapter\nBefore we can get started, you need to organise your files and project for the chapter, so your working directory is in order.\n\nIn your folder for research methods and the book ResearchMethods1_2/Quant_Fundamentals, create a new folder called Chapter_08_regression_continuous. Within Chapter_08_regression_continuous, create two new folders called data and figures.\nCreate an R Project for Chapter_08_regression_continuous as an existing directory for your chapter folder. This should now be your working directory.\nCreate a new R Markdown document and give it a sensible title describing the chapter, such as 08 Correlations and Regression. Delete everything below line 10 so you have a blank file to work with and save the file in your Chapter_08_regression_continuous folder.\nWe are working with a new data set, so please save the following data file: Dawtry_2015.csv. Right click the link and select “save link as”, or clicking the link will save the files to your Downloads. Make sure that you save the file as “.csv”. Save or copy the file to your data/ folder within Chapter_08_regression_continuous.\n\nYou are now ready to start working on the chapter!\n\n8.1.3 Activity 1 - Read and wrangle the data\nAs the first activity, try and test yourself by completing the following task list to practice your data wrangling skills. Create a final object called dawtry_clean to be consistent with the tasks below. If you want to focus on correlations and regression, then you can just type the code in the solution.\n\n\n\n\n\n\nTry this\n\n\n\nTo wrangle the data, complete the following tasks:\n\n\nLoad the following packages (three of these are new, so revisit Chapter 1 if you need a refresher of installing R packages, but remember not to install packages on the university computers / online server):\n\ntidyverse\neffectsize\ncorrelation\nperformance\n\n\nRead the data file data/Dawtry_2015.csv to the object name dawtry_data.\nReverse code two items: redist2 and redist4 to create two new variables redist2_R and redist4_R. See the codebook below, but they are on a 1-6 scale.\nSummarise the data to calculate the mean fairness_satisfaction score, by taking the mean of two items: fairness and satisfaction.\nSummarise the data to calculate the mean redistribution score, by taking the mean of four items: redist1, redist2_R, redist3, and redist4_R.\nCreate a new object called dawtry_clean by joining dawtry_data with your two new variables fairness_satisfaction and redistribution.\nDecrease the number of columns in dawtry_clean by selecting PS, all the columns between Household_Income and redistribution, but removing the two reverse coded items redist2_R and redist4_R.\n\nYour data should look like this to be ready to analyse:\n\n\nRows: 305\nColumns: 11\n$ PS                                  &lt;dbl&gt; 233, 157, 275, 111, 52, 11, 76, 90…\n$ Household_Income                    &lt;dbl&gt; NA, 20.00, 100.00, 150.00, 500.00,…\n$ Political_Preference                &lt;dbl&gt; 5, 5, 5, 8, 5, 3, 4, 3, 2, 3, NA, …\n$ age                                 &lt;dbl&gt; 40, 59, 41, 59, 35, 34, 36, 39, 40…\n$ gender                              &lt;dbl&gt; 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, NA, …\n$ Population_Inequality_Gini_Index    &lt;dbl&gt; 38.78294, 37.21451, 20.75000, 35.3…\n$ Population_Mean_Income              &lt;dbl&gt; 29715, 123630, 60000, 59355, 15360…\n$ Social_Circle_Inequality_Gini_Index &lt;dbl&gt; 28.056738, 24.323388, 14.442577, 2…\n$ Social_Circle_Mean_Income           &lt;dbl&gt; 21150, 65355, 107100, 86640, 56850…\n$ fairness_satisfaction               &lt;dbl&gt; 1.0, 3.5, 5.0, 7.0, 4.5, 2.5, 3.0,…\n$ redistribution                      &lt;dbl&gt; 5.50, 3.25, 3.75, 2.75, 3.00, 3.75…\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# Load the packages below\nlibrary(tidyverse)\nlibrary(effectsize)\nlibrary(correlation)\nlibrary(performance)\n\n# Load the data file\n# This should be the Dawtry_2015.csv file \ndawtry_data &lt;- read_csv(\"data/Dawtry_2015.csv\")\n\n# Reverse code redist2 and redist4\ndawtry_data &lt;- dawtry_data %&gt;%\n  mutate(redist2_R = 7 - redist2,\n         redist4_R = 7 - redist4)\n\n# calculate mean fairness and satisfaction score  \nfairness_satisfaction &lt;- dawtry_data %&gt;% \n  pivot_longer(cols = fairness:satisfaction, \n               names_to = \"Items\", \n               values_to = \"Response\") %&gt;% \n  group_by(PS) %&gt;% \n  summarise(fairness_satisfaction = mean(Response)) %&gt;% \n  ungroup()\n\n# calculate mean wealth redistribution score  \nredistribution &lt;- dawtry_data %&gt;% \n  pivot_longer(cols = c(redist1, redist2_R, redist3, redist4_R), \n               names_to = \"Items\", \n               values_to = \"Response\") %&gt;% \n  group_by(PS) %&gt;% \n  summarise(redistribution = mean(Response)) %&gt;% \n  ungroup()\n\n# join data and select columns for focus\ndawtry_clean &lt;- dawtry_data %&gt;% \n  inner_join(fairness_satisfaction, by = \"PS\") %&gt;% \n  inner_join(redistribution, by = \"PS\") %&gt;% \n  select(PS, Household_Income:redistribution, -redist2_R, -redist4_R)\n\n\n\n\n\n8.1.4 Activity 2 - Explore the data\n\n\n\n\n\n\nTry this\n\n\n\nAfter the wrangling steps, try and explore dawtry_clean to see what variables you are working with. For example, opening the data object as a tab to scroll around, explore with glimpse(), or try plotting some of the individual variables using a histogram.\n\n\nIn dawtry_clean, we have the following variables:\n\n\n\n\n\n\n\nVariable\nType\nDescription\n\n\n\nPS\ndouble\nParticipant ID number.\n\n\nHousehold_Income\ndouble\nHousehold income in US Dollars ($).\n\n\nPolitical_Preference\ndouble\nPolitical attitudes: 1 = very liberal/very left-wing/strong Democrat to 7 = very conservative/very right-wing/strong Republican.\n\n\nage\ndouble\nAge in years.\n\n\ngender\ndouble\n1 = “Male”, 2 = “Female.\n\n\nPopulation_Inequality_Gini_Index\ndouble\nMeasure of income inequality from 0 (perfect equality) to 100 (perfect inequality), here where participants estimated population in equality.\n\n\nPopulation_Mean_Income\ndouble\nParticipant estimate of the mean household income in the population ($).\n\n\nSocial_Circle_Inequality_Gini_Index\ndouble\nMeasure of income inequality from 0 (perfect equality) to 100 (perfect inequality), here where participants estimated inequality in their social circle.\n\n\nSocial_Circle_Mean_Income\ndouble\nParticipant estimate of the mean household income in their social circle ($).\n\n\nfairness_satisfaction\ndouble\nPerceived fairness and satisfaction about the current system of wealth redistribution: Mean of two items (1 extremely fair – 9 extremely unfair)\n\n\nredistribution\ndouble\nSupport for wealth distribution: Mean of four items (1 strongly disagree – 6 strongly agree).\n\n\n\nWe will use this data set to demonstrate correlations and regression when you have one continuous predictor."
  },
  {
    "objectID": "08-lm-continuous.html#section",
    "href": "08-lm-continuous.html#section",
    "title": "\n8  Regression with one continuous predictor\n",
    "section": "\n8.2 ",
    "text": "8.2"
  },
  {
    "objectID": "08-lm-continuous.html#end-of-chapter",
    "href": "08-lm-continuous.html#end-of-chapter",
    "title": "\n8  Regression with one continuous predictor\n",
    "section": "\n8.8 End of chapter",
    "text": "8.8 End of chapter\nGreat work, that was your first chapter working on inferential statistics!\nWe have spent so long developing your data wrangling and visualisation skills that the code for statistical models is pretty short. Hopefully, you now believe us when we said almost all the work goes into wrangling your data into a format you can analyse. Once it comes to inferential statistics, it shifts from wrangling the data being the most difficult to being able to express your research question/design and interpret the outcome being the most difficult.\nIn the next chapter, we reinforce most of the content by applying simple linear regression to a categorical predictor. This is when you want to test for differences between two groups on your outcome instead of testing the relationship between two continuous variables.\n\n\n\n\nDawtry, R. J., Sutton, R. M., & Sibley, C. G. (2015). Why Wealthier People Think People Are Wealthier, and Why It Matters: From Social Sampling to Attitudes to Redistribution. Psychological Science, 26(9), 1389–1400. https://doi.org/10.1177/0956797615586560"
  },
  {
    "objectID": "08-lm-continuous.html#correlation",
    "href": "08-lm-continuous.html#correlation",
    "title": "\n8  Regression with one continuous predictor\n",
    "section": "\n8.2 Correlation",
    "text": "8.2 Correlation\nBefore we cover regression as a more flexible framework for inferential statistics, we think it is useful to start with correlation to get a feel for how we can capture the relationship between two variables. As a reminder from the course materials, correlations are standardised to range from -1 (a perfect negative correlation) to 1 (a perfect positive correlation). A value of 0 would mean there is no correlation between your variables.\n\n8.2.1 Activity 3 - Visualise the relationship\nTo explore the relationship between two variables, it is useful to create a scatterplot early for yourself, then provide a more professional looking version to help communicate your results. For most of the demonstrations in this chapter, we will try and answer the research question: “Is there a relationship between support for wealth redistribution and fairness and satisfaction with the current system?”\n\n\n\n\n\n\nTry this\n\n\n\nUsing your data visualisation skills from Chapter 7, recreate the scatterplot below using the variables fairness_satisfaction and redistribution from dawtry_clean.\n\n\n\n\n\n\n\n\nLooking at the graph, we can describe the relationship as \npositive\nlittle to no correlation\nnegative.\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThe scatterplot shows a negative correlation between the two variables. You need to be careful interpreting fairness and satisfaction as it is coded a little counterintuitive. Higher values mean great dissatisfaction.\nAs support for wealth redistribution increases to be more positive, perceived fairness and satisfaction tends to decrease. This makes sense as people who are more dissatisfied with the current system think there should be more wealth redistribution strategies.\nYou should have the following in a code chunk:\n\ndawtry_clean %&gt;% \n  ggplot(aes(x = fairness_satisfaction, y = redistribution)) + \n  geom_point() + \n  geom_smooth(method = \"lm\") + \n  scale_x_continuous(name = \"Perceived Fairness and Satisfaction\", \n                     breaks = c(1:9)) + \n  scale_y_continuous(name = \"Support for Wealth Redistribution\", \n                     breaks = c(1:6))\n\n\n\n\n\n8.2.2 Activity 4 - Calculate the correlation coefficient\nVisualising the relationship between two variables is great for our understanding, but it does not tell us anything about the inferential statistics for what we can learn from our sample in hypothesis testing and measures of effect size.\nA correlation is a specific application of the general linear model. We want to capture the covariation between two variables. If you are interested, see the Handy Workbook (McAleer, 2023) for the calculations behind different types of correlation and how it represents the covariance of two variables compared to their total variability. They are not the only methods, but the two most common versions of a correlation are:\n\nPearson’s product-moment correlation (often shortened to the Pearson correlation) and symbolised by r.\nSpearman’s rank correlation coefficient (often shortened to the Spearman correlation) and symbolised by \\(r_s\\) or sometimes the Greek letter rho \\(\\rho\\).\n\nThere is a function built into R (cor.test()) to calculate the correlation between two variables, but we tend to use the correlation() function from the correlation package as it has more consistent reporting features. The correlation() function requires:\n\nThe name of the data set you are using.\nThe name of the first variable you want to select for the correlation.\nThe name of the second variable you want to select for the correlation.\nThe type of correlation you want to run: e.g. pearson, spearman.\n\nFor our dawtry_clean data, we would run the following code for a two-tailed Pearson correlation:\n\ncorrelation(data = dawtry_clean, \n            select = \"fairness_satisfaction\", \n            select2 = \"redistribution\",  \n            method = \"pearson\", \n            alternative = \"two.sided\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\nCI\nCI_low\nCI_high\nt\ndf_error\np\nMethod\nn_Obs\n\n\nfairness_satisfaction\nredistribution\n-0.70034\n0.95\n-0.7533907\n-0.6382316\n-17.07843\n303\n&lt; .001\nPearson correlation\n305\n\n\n\n\n\nYour output will look a little different due to how our book renders tables, but you should get the same information. For the three key concepts of inferential statistics, we get\n\nHypothesis testing: p &lt; .001, suggesting we can reject the null hypothesis assuming \\(\\alpha\\) = .05.\nEffect size: r = -.70, suggesting a strong negative correlation.\nConfidence interval: [-0.75, -0.64], showing the precision around the effect size estimate.\n\nTo summarise: a Pearson correlation showed there was a strong, negative, statistically significant relationship between attitudes on wealth redistribution and perceived fairness and satisfaction, r (303) = -0.70, p &lt; .001, 95% CI = [-0.75, -0.64].\nIf we had reason to use a Spearman correlation instead, all we need to do is change the method argument.\n\ncorrelation(data = dawtry_clean, \n            select = \"fairness_satisfaction\", \n            select2 = \"redistribution\",  \n            method = \"spearman\", \n            alternative = \"two.sided\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nrho\nCI\nCI_low\nCI_high\nS\np\nMethod\nn_Obs\n\n\nfairness_satisfaction\nredistribution\n-0.6806667\n0.95\n-0.738182\n-0.6133274\n7947402\n&lt; .001\nSpearman correlation\n305\n\n\n\n\n\nSimilarly, we could report the results as: a Spearman correlation showed there was a strong, negative, statistically significant relationship between attitudes on wealth redistribution and perceived fairness and satisfaction, \\(r_s\\) (303) = -0.68, p &lt; .001, 95% CI = [-0.74, -0.61].\n\n\n\n\n\n\nTry this\n\n\n\nGreat work following along so far, but now it is time to test your understanding on a new set of variables. Use the variables age and redistribution from dawtry_clean. We can ask the question: “What is the relationship between age and attitudes on wealth redistribution?”\n\nCreate a scatterplot to visualise the relationship between age and redistribution from dawtry_clean.\n\nApply the Pearson correlation to get your inferential statistics and answer the following questions:\n\nHypothesis testing: Assuming \\(\\alpha\\) = .05, the relationship between age and wealth redistribution is \nstatistically significant\nnot statistically significant.\nEffect size: Rounded to 2 decimals, the value for Pearson’s correlation coefficient is \n-0.14\n-0.03\n0.08\n-0.49.\nConfidence interval: Rounded to 2 decimals, the lower bound is \n-0.14\n-0.03\n0.08\n-0.49 and the upper bound is \n-0.14\n-0.03\n0.08\n-0.49.\n\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThe scatterplot shows very little correlation between the two variables. The regression line is almost flat and there does not appear to be a clear pattern to the data points.\n\ndawtry_clean %&gt;% \n  ggplot(aes(x = age, y = redistribution)) + \n  geom_point() + \n  geom_smooth(method = \"lm\") + \n  scale_y_continuous(name = \"Attitudes on Wealth Distribution\", \n                     breaks = c(1:6))\n\n\n\n\n\n\n\nFor our inferential statistics, the relationship is not statistically significant and the Pearson correlation coefficient is very weak, r (302) = -0.03, p = .625, 95% CI = [-0.14, 0.08]. Note there is a missing value for age, so we have one few participant / degrees of freedom.\n\ncorrelation(data = dawtry_clean, \n            select = \"age\", \n            select2 = \"redistribution\",  \n            method = \"pearson\", \n            alternative = \"two.sided\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\nCI\nCI_low\nCI_high\nt\ndf_error\np\nMethod\nn_Obs\n\n\nage\nredistribution\n-0.0281749\n0.95\n-0.1402227\n0.0845855\n-0.4898215\n302\n0.6246159\nPearson correlation\n304"
  },
  {
    "objectID": "08-lm-continuous.html#simple-linear-regression",
    "href": "08-lm-continuous.html#simple-linear-regression",
    "title": "\n8  Regression with one continuous predictor\n",
    "section": "\n8.3 Simple linear regression",
    "text": "8.3 Simple linear regression\n\n8.3.1 Descriptive statistics\n\n8.3.2 Modelling\n\n8.3.3 Effect sizes and confidence intervals\n\n8.3.4 Centering predictors\n\n8.3.5 Visualising model estimates"
  },
  {
    "objectID": "08-lm-continuous.html#checking-assumptions",
    "href": "08-lm-continuous.html#checking-assumptions",
    "title": "\n8  Regression with one continuous predictor\n",
    "section": "\n8.4 Checking assumptions",
    "text": "8.4 Checking assumptions\nFor the inferential statistics to work as intended, the model makes certain assumptions about the data you are putting into it and the accuracy of the inferences depends on how sensible these assumption are. Remember these functions will always work even if the numbers you enter are nonsense, so it’s important for you as the researcher to recognise when it’s appropriate to use these techniques and when it is not.\n\n8.4.1 Activity 9 - Diagnostic plots for linear regression\nAs a reminder, the assumptions for simple linear regression are:\n\nThe outcome is interval/ratio level data.\nThe predictor variable is interval/ratio or categorical (with two levels at a time).\nAll values of the outcome variable are independent (i.e., each score should come from a different participant/observation).\nThe predictors have non-zero variance.\nThe relationship between the outcome and predictor is linear.\nThe residuals should be normally distributed.\nThere should be homoscedasticity.\n\nAssumptions 1-4 are pretty straight forward as they relate to your understanding of the design or a simple check on the data for non-zero variance (the responses are not all the exact same value).\nAssumptions 5-7 require diagnostic checks on the residuals from the model. The residuals are the difference between your observed values in the data and the values your model predicts given it’s assumptions. If you remember back, we highlighted the model output mentioned Residuals: and they are saved within the model object.\n\n# head shows the first 6 values \nhead(lm_redistribution$residuals)\n\n         1          2          3          4          5          6 \n 0.5806764 -0.6754769  0.4208311  0.2159084 -0.5279383 -0.5730156 \n\n\n\n\n\n\n\n\nWhat does the $ symbol mean?\n\n\n\nWe have not used this symbol in the book yet, but it is a base R operator for extracting information. You use it to access specific components within a data frame or object.\nTry the following in the console to see what it does:\n\ndawtry_clean$age\nlm_redistribution$coefficients\n\nIf you type an object name into the console and add the $, you will see all the components appear to auto complete.\n\n\nIn your reading, you might see individual statistical tests to check these assumptions, but they have more limitations than benefits. The best way to check the assumptions is through diagnostic plots which express the model residuals in different ways. We want to walk through this longer way of checking assumptions to develop a solid understanding before showing you a shortcut to see them all below.\nIn the code below, we use a format you will be less familiar with as all these functions come from base R. If you just run the code for the diagnostic plots plot(lm_redistribution), each one gets individually printed to your Plots window. Here, we create a 2x2 panel to show them all together.\n\n# Change the panel layout to 2 x 2\npar(mfrow=c(2,2))\n\n# plot the diagnostic plots \nplot(lm_redistribution)\n\n\n\n\n\n\n\nFor more information on each of these plots, see this great resource by Kim (2015) via the University of Virginia, but we will break the key ones down below.\n\n8.4.2 Checking linearity\nTo isolate each plot, we can use the which argument. Plot 1 is a residuals vs fitted plot and helps us check linearity by showing the residuals on the y-axis and the fitted (predicted) values on the x-axis.\n\nplot(lm_redistribution, \n     which = 1)\n\n\n\n\n\n\n\nHere, you are looking out for a roughly flat horizontal red line. Common patterns to look out for if there is a problem are when the line has an obvious curve to look like a hump or several bends to look like an S.\nThe only downside to using diagnostic plots is it takes experience to recognise when there is nothing wrong with a regression model compared to when it violates the assumptions. It is easy to see a little deviation and think there is some drastically wrong. Our advice is if you squint and it looks fine, it is probably fine. You are looking for clear and obvious deviations from what you expect and all the models we use in Chapters 8 and 9 are intentionally fine to develop foundational skills. In Chapter 11, we then introduce you to more problematic cases and what your options are.\n\n\n\n\n\n\nError mode\n\n\n\nIf you want to save these plots to add into a report, you might try using ggsave() like we have covered in the data visualisation chapters. However, it will not work as these plots have not been created by ggplot2.\nTo save these plots, you can either right click and choose save as to save on your computer. Alternatively, if they open in the Plots window, you can click on Export and save them as an image or PDF to insert into your documents.\n\n\n\n8.4.3 Checking normality\nPlot 2 is a qq-plot (quantile-quantile plot) and helps us check the normality of the model residuals by showing the standardised residuals on the y-axis and the theoretical quantiles on the x-axis. A common misconception is your variables should all be normally distributed, but it is actually the model residuals which should be normal.\n\nplot(lm_redistribution, \n     which = 2)\n\n\n\n\n\n\n\nIn this plot, you are looking for the data points to roughly follow the dashed line. The idea is there should be a linear relationship between the residuals and the values we would expect under a normal distribution.\nLike the other diagnostic plots, it is tempting to think there are problems where there are none. The vast majority of the points here follow the line nicely, but tail off a little at the extremes. It flags the points with the largest deviations but there do not appear to be any obvious problems.\nWhen there are problems with normality, you are looking for obvious deviations, like the points curving around in a banana shape, or snaking around like an S.\n\n8.4.4 Checking homoscedasticity\nPlot 3 is a scale-location plot and helps us check homoscedasticity by showing the square root of the standardised residuals on the y-axis and the fitted values on the x-axis. Homoscedasticity is where the variance of the residuals is approximately equal across the range of your predictor(s).\n\nplot(lm_redistribution, \n     which = 3)\n\n\n\n\n\n\n\nIn this plot, you are looking out for a roughly random spread of points as you move from one end of the x-axis to the other. The red line should be roughly flat and horizontal.\nWhen there is heteroscedasticity, the characteristic patterns to look out for are a kind of arrow shape where there is a wide spread of points at one end and decreases to a denser range at the other end, or a bow tie where there is a wide spread of points at each end and dense in the middle.\n\n8.4.5 Checking influential cases\nFinally, there are two main plots to help us identify influential cases. You might have heard of the term outlier before and this is one way of classifying data points that are different enough to the rest of the data in a regression model. It is not strictly an assumption of linear regression, but it can affect the other assumptions. Identifying outliers is a complex decision and we will explore your options in the course materials and Chapter 11 on data screening.\nIf you only run plot(lm_redistribution) and cycle through the plots, you do not see this version. This plot shows values of Cook’s distance for each observation in your data along the x-axis. Cook’s distance measures the influence of deleting a given observation, where higher values mean deleting that observation results in a larger change to the model estimates. There are different thresholds in the literature, but estimates range from 1, 0.5, to 4/n. We explore the decision making around this and your options in Chapter 11.\n\nplot(lm_redistribution, \n     which = 4)\n\n\n\n\n\n\n\nFinally, we get a residuals vs leverage plot to show influential cases in a slightly different way. Instead of just the Cook’s distance value of each observation, it plots the standardised residuals against leverage values.\n\nplot(lm_redistribution, \n     which = 5)\n\n\n\n\n\n\n\nInfluential points and potential outliers would have high leverage values and the plot will show a threshold of Cook’s distance as red dashed lines. In this plot, they are not visible as there is no value with a big enough leverage value, but you would be looking for data points outside this threshold to identify influential values.\n\n8.4.6 Checking all the assumptions\nNow we have covered the individual diagnostic plots, there is a handy function called check_model() from the performance package. This function reports all the diagnostic checks from plot(), but tidies up the presentation and has some useful reminders of what you are looking for.\n\ncheck_model(lm_redistribution)\n\n\n\n\n\n\n\nThe key difference is you get a posterior predictive check (essentially comparing values you observe compared to what your model predicts) and the qq-plot for normality of residuals looks a little different. Instead of a kind of angled line, the residuals are expressed as deviations instead, so the points should be close to a flat horizontal line. This version can make smaller deviations look worse, so keep in mind again you are looking for clear deviations in the overall pattern.\n\n\n\n\n\n\nNote\n\n\n\nThe performance version of the diagnostic plots are actually created using ggplot2, so the function ggsave() would work here if you need to save the plot to add into your report.\n\n\n\n\n\n\n\n\nTry this\n\n\n\nIn activity 7, you should have calculated the relationship between age and support for redistribution for your independent task. Using the model object lm_age, work through assumptions for simple linear regression and make a note of whether you think it meets the assumptions, or there might be any problems. Some of the assumptions you consider what you know about the design, while others you need the diagnostic plots.\n\nThe outcome is interval/ratio level data.\nThe predictor variable is interval/ratio or categorical (with two levels at a time).\nAll values of the outcome variable are independent (i.e., each score should come from a different participant/observation).\nThe predictors have non-zero variance.\nThe relationship between the outcome and predictor is linear.\nThe residuals should be normally distributed.\nThere should be homoscedasticity.\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\n\nThe outcome is interval/ratio level data.\n\nThere is a debate here we cover in the course materials, but there is an argument you can treat the average of multiple Likert items as interval, but you need to be careful.\n\nThe predictor variable is interval/ratio or categorical (with two levels at a time).\n\nOur predictor age is nicely ratio.\n\nAll values of the outcome variable are independent (i.e., each score should come from a different participant/observation).\n\nYou need to know this from the design / data collection, but it appears to be the case in this study.\n\nThe predictors have non-zero variance.\n\nThere are a range of ages in the data.\n\nThe relationship between the outcome and predictor is linear.\n\nLooking at the first plot, the red line is pretty flat and horizontal, so we are happy with this.\n\nplot(lm_age, which = 1)\n\n\n\n\n\n\n\n\nThe residuals should be normally distributed.\n\nThe qq-plot is fine for the vast majority of the range. We just have a few deviations in the extreme ends of the x-axis, but this is a byproduct of using a scale score as our outcome as responses cannot go beyond 1-6.\n\nplot(lm_age, which = 2)\n\n\n\n\n\n\n\n\nThere should be homoscedasticity.\n\nThe red line is pretty flat and it looks like there is a fairly even range of values across the x-axis range.\n\nplot(lm_age, which = 3)\n\n\n\n\n\n\n\nAll in all, there do not appear to be any issues with the assumptions here."
  },
  {
    "objectID": "08-lm-continuous.html#reporting-your-results",
    "href": "08-lm-continuous.html#reporting-your-results",
    "title": "\n8  Regression with one continuous predictor\n",
    "section": "\n8.5 Reporting your results",
    "text": "8.5 Reporting your results\nNow we have some results to go with, there are a few recommendations on how to communicate that information. In psychology (and other disciplines), we tend to follow the American Psychological Association (APA) formatting guidelines as they provide a comprehensive standardised style to make sure information is being reported as easily digestible and consistent as possible. You can see this PDF online for a little cheat sheet for numbers and statistics, but we will outline some key principles to ensure you provide your reader with enough information.\n\nExplain to the reader what your linear regression model was. For example, what was your outcome and predictor variable?\nReport descriptive statistics to help contextualise your findings. For example, the mean/standard deviation for your outcome and continuous predictor.\nProvide an appropriate data visualisation to help communciate key patterns to the reader. For example, a scatterplot for the relationship between your outcome and predictor.\nReport all three key inferential statistics concepts for the coefficient: the slope, the confidence interval around your slope, and the p-value for hypothesis testing. When you have one predictor in simple linear regression, you typically focus on the slope as your key effect size that helps address your research question and hypothesis. APA style rounds numbers to 2 decimal places when numbers can be bigger than 1, and 3 decimals with no leading zero when it cannot be bigger than 1. When you report the unstandardised slope, you use the symbol \\(b_1\\) but for the standardised slope, you use Beta instead \\(\\beta_1\\).\nProvide an overview of the model fit statistics for whether your model explained a significant amount of variance in your outcome. Remember: the p-value for your model will be the same as for the slope in simple linear regression.\n\nFor our main example, we could summarise the findings as:\n“Our research question was: is there a relationship between support for wealth redistribution and fairness and satisfaction with the current system? To test this, we applied simple linear regression using fairness and satisfaction as a predictor and support for wealth redistribution as our outcome. Figure 1 shows a scatterplot of the relationship.\n\n\n\n\n\n\n\n\nOur model explained a statistically significant amount of variance in our outcome (adjusted \\(R^2\\) = .489, F(1, 303) = 291.70, p &lt; .001). Fairness and satisfaction was a negative predictor, where for every 1-unit increase we expect support for redistribution to decrease by 0.40 (\\(b_1 = -0.40\\), 95% CI = [-0.44, -0.35], p &lt; .001).”\nNote: we have not included an APA formatted Figure title here as it is not easy to format in our book, so refer to the course materials for guidance."
  },
  {
    "objectID": "08-lm-continuous.html#linear-regression-with-one-continuous-predictor",
    "href": "08-lm-continuous.html#linear-regression-with-one-continuous-predictor",
    "title": "\n8  Regression with one continuous predictor\n",
    "section": "\n8.3 Linear regression with one continuous predictor",
    "text": "8.3 Linear regression with one continuous predictor\nNow you know how to calculate a correlation in R, we can turn to simple linear regression as a more flexible tool for modelling the relationship between variables.\nIn Research Methods 1, we focus on just two variables, before scaling up to more complicated models in Research Methods 2. In this chapter, we focus the relationship between a continuous outcome and one continuous predictor, before extending the framework to one categorical predictor in Chapter 9. There is also a chapter in the Handy Workbook (McAleer, 2023) dedicated to manually calculating simple linear regression.\n\n8.3.1 Activity 5- Calculating descriptive statistics\nFor all the information we want to include in a report, calculating descriptive statistics is helpful for the reader to show the context behind the results you present. Here, we can report the mean and standard deviation of our two variables.\n\ndawtry_clean %&gt;% \n  # pivot longer to avoid repeating yourself\n  pivot_longer(cols = fairness_satisfaction:redistribution,\n               names_to = \"Variable\", \n               values_to = \"Value\") %&gt;% \n  # group by Variable to get one value per variable\n  group_by(Variable) %&gt;% \n  # mean and SD, rounded to 2 decimals\n  summarise(mean_variable = round(mean(Value), 2),\n            sd_variable = round(sd(Value), 2))\n\n\n\n\nVariable\nmean_variable\nsd_variable\n\n\n\nfairness_satisfaction\n3.54\n2.02\n\n\nredistribution\n3.91\n1.15\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you want some reinforcement of how these skills apply to published research, look at Table 1 in Dawtry et al. (2015). The means and standard deviations here (and the correlation in Activity 4) exactly reproduce the values they report.\n\n\nIf other types of descriptive statistic would be more suitable to your data, then you can just replace the functions you use within summarise().\n\n8.3.2 Activity 6 - Using the lm() function\nFor our research question of “is there a relationship between support for wealth redistribution and fairness and satisfaction”, we can address it with simple linear regression.\nInstead of a standardised correlation coefficient, we can frame it as whether knowing fairness and satisfaction can predict values of support for wealth redistribution. The design is still correlational, so it does not tell us anything about a causal relationship in isolation. We use the word predict in the statistical sense, where we can ask whether knowing values of one variable help us predict values of another variable with a degree of error.\nThe first step is to create an object (lm_redistribution) for the linear model.\n\nlm_redistribution &lt;- lm(redistribution ~ fairness_satisfaction,\n                        data = dawtry_clean)\n\nThe function lm() is built into R and is incredibly flexible for creating linear regression models.\n\nThe first argument is to specify a formula which defines our model. The first component (redistribution) is our outcome variable for what we are interested in modelling.\nThe tilde (~) separates the equation, where everything on the right is your predictor variable(s). In simple linear regression, we just have one predictor, which is fairness_satisfaction in our model here. This is saying we want to predict redistribution as our outcome from fairness_satisfaction as our predictor.\nWe then specify the data frame we want to use.\n\n\n\n\n\n\n\nNote\n\n\n\nIn some resources, you might see people enter the same model as redistribution ~ 1 + fairness_satisfaction. The 1 + component explicitly tells R to fit an intercept, plus a slope from fairness_satisfaction. R includes an intercept by default, so you do not need to add it, but some people like to include it for clarity.\n\n\nWhen you create this object, it stores a bunch of information, but does not really tell us all the statistics we expect. If you simply print the object in the console, it will tell you the intercept and coefficient(s), but none of the model fitting nor hypothesis testing values. If you look at the object in the R environment, you will see it is a list containing several elements. It stores things like the model, the residuals, and other information you can use.\n\nlm_redistribution\n\n\nCall:\nlm(formula = redistribution ~ fairness_satisfaction, data = dawtry_clean)\n\nCoefficients:\n          (Intercept)  fairness_satisfaction  \n               5.3169                -0.3975  \n\n\nTo get that extra information, we need to call the summary() function around the linear model object to explore it’s properties like estimates and model fit.\n\nsummary(lm_redistribution)\n\n\nCall:\nlm(formula = redistribution ~ fairness_satisfaction, data = dawtry_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9193 -0.5279  0.0233  0.4782  3.3634 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)            5.31686    0.09488   56.04   &lt;2e-16 ***\nfairness_satisfaction -0.39754    0.02328  -17.08   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8218 on 303 degrees of freedom\nMultiple R-squared:  0.4905,    Adjusted R-squared:  0.4888 \nF-statistic: 291.7 on 1 and 303 DF,  p-value: &lt; 2.2e-16\n\n\nTo walk through the output, Call: summarises the model you specified. Residuals: provides a summary of the model residuals which we will come back to later. Coefficients: provides our model output, this time with inferential statistics. The two key lines are:\n\n\n(Intercept) - This is the value of the outcome when our predictor is set to 0. For a fairness and satisfaction value of 0, we would expect a value of 5.32 for redistribution. You get a p-value for this, but in isolation it is not too useful. It just compares the intercept estimate to 0 which typically you are not interested in.\n\n\n\nfairness_satisfaction - This is the regression slope or coefficient. This is the change in the outcome for every 1 unit change in the predictor. So, for every 1 unit increase in fairness and satisfaction, we expect support for wealth redistribution to decrease (as we have a negative value) by 0.40 units. This is consistent with the correlation as we have a negative relationship between the two variables. Looking at the p-value, this is statistically significant (p &lt; .001), suggesting we can reject the null hypothesis and conclude there is an effect here.\n\n\n\n\n\n\n\nDoes it matter if the slope is positive or negative?\n\n\n\nWhen you have a continuous predictor, the sign is important to keep in mind. A positive slope would mean an increase in the predictor is associated with increased values of your outcome. A negative slope would mean an increase in the predictor is associated with decreased values of your outcome. This is crucial for interpreting the coefficient.\n\n\nAt the bottom of the model output, you then get the fit statistics. Multiple \\(R^2\\) tells you how much variance in your outcome your predictor(s) explain. Adjusted \\(R^2\\) tends to be more conservative as it adjusts for the number of predictors in the model (something we will not cover until Chapter 14), but they will be very similar when you have one predictor. Adjusted \\(R^2\\) is .49, suggesting fairness and satisfaction explains 49% of the variance in support for wealth redistribution.\nFinally, we have the model fit statistics to tell us whether the model explains a significant amount of variance in the outcome. With one predictor, the p-value next to the coefficient and next to the model fit will be identical, as one predictor is the whole model. The F-statistic is 291.7, the model degrees of freedom is 1, the residual degrees of freedom is 303, and the p-value is p &lt; .001.\n\n\n\n\n\n\nWhat does 2e-16 mean?\n\n\n\nFor the p-value here, the output looks a little weird. R reports very small or very large numbers using scientific notation to save space. We normally report p-values to three decimals, so we report anything smaller as p &lt; .001 to say it is smaller than this.\nIf you want to see the real number, you can use the following function which shows just how small the p-value is:\n\nformat(2e-16, scientific = FALSE)\n\n[1] \"0.0000000000000002\"\n\n\n\n\n\n\n\n\n\n\nHow are correlation and regression the same?\n\n\n\n\n\nIf you are interested in the relationship between the two concepts, we said correlation was a specific application of the general linear model. It describes the - standardised - covariation between two variables compared to their total variability. For values of -1 and 1, knowing the value of one variable perfectly correlates to the value of your other variable. As you approach 0, the relationship between the variables is less perfect, meaning there is more variability left over compared to the covariance.\nIn regression, we frame it as how much variance you explain compared to the total amount of variance. The more variance your predictor explains, the less unexplained variance there is left over. We no longer calculate r, we calculate \\(R^2\\) as the proportion of variance in your outcome explained by your model. A value of 0 would be you explain no variance and a value of 1 means you explain all the variance.\nYou can see the connection between the two by comparing the value of Pearson’s r from Activity 4 (-.70) to the value of \\(R^2\\) = .4905. If you take the square root to get r (sqrt(.4905)), you get .70, which is exactly the same absolute value since \\(R^2\\) can only be positive.\nSo, when you have a single continuous predictor, it is the exact same process as correlation, just expressed slightly different.\n\n\n\n\n8.3.3 Activity 7 - Calculating confidence intervals\nIn the standard lm() and summary() output, we get most of the key values we need for our inferential statistics, but the one thing missing is confidence intervals around our estimates. Fortunately, R has a built-in function called confint() for calculating confidence intervals using your linear model object.\n\nconfint(lm_redistribution)\n\n                           2.5 %     97.5 %\n(Intercept)            5.1301581  5.5035664\nfairness_satisfaction -0.4433442 -0.3517332\n\n\nNormally, you focus on the confidence interval around your slope estimate as the intercept is not usually super useful for interpreting your findings when you have a continuous predictor. Now, we can summarise the three key concepts of inferential statistics as:\n\nHypothesis testing: p &lt; .001, suggesting we can reject the null hypothesis assuming \\(\\alpha\\) = .05. Fairness and satisfaction is a significant predictor of support for wealth redistribution.\nEffect size: \\(b_1\\) = -0.40, suggesting fairness and satisfaction is a negative predictor.\nConfidence interval: [-0.44, -0.35], showing the precision around the slope estimate.\n\n\n\n\n\n\n\nTry this\n\n\n\nGreat work following along so far, but now it is time to test your understanding on a new set of variables. This time, use redistribution as your outcome, age as your predictor, and use dawtry_clean as your data. We can ask the same question as before: “What is the relationship between age and attitudes on wealth redistribution?”.\nApply simple linear regression to get your inferential statistics and answer the following questions:\n\nHypothesis testing: Assuming \\(\\alpha\\) = .05, age is a \nstatistically significant\nnon-significant predictor of support for wealth redistribution.\nEffect size: Rounded to 2 decimals, the age coefficient is \n4.01\n-0.003\n0.005\n0.22.\nConfidence interval: Rounded to 2 decimals, the lower bound of the age coefficient is \n3.59\n-0.01\n4.44\n0.01 and the upper bound is \n3.59\n-0.01\n4.44\n0.01.\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThe conclusions are the same as when we calculated the correlation where age is not a statistically significant predictor of support for wealth redistribution. As a regression model, we get the same conclusions expressed in a slightly different way. Age is negative, but the size of the slope is very small (-0.003) and non-significant (p = .625). We explain pretty much no variance in support for wealth redistribution (\\(R^2\\) = .0008), so age is not very informative as a predictor.\n\n# Create lm object for age as a predictor\nlm_age &lt;- lm(redistribution ~ age,\n             data = dawtry_clean)\n\n# summary of the model object\nsummary(lm_age)\n\n# confidence intervals around estimates\nconfint(lm_age)\n\n\nCall:\nlm(formula = redistribution ~ age, data = dawtry_clean)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.93382 -0.69527  0.08099  0.84379  2.13621 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  4.011931   0.216042   18.57   &lt;2e-16 ***\nage         -0.002693   0.005499   -0.49    0.625    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.153 on 302 degrees of freedom\n  (1 observation deleted due to missingness)\nMultiple R-squared:  0.0007938, Adjusted R-squared:  -0.002515 \nF-statistic: 0.2399 on 1 and 302 DF,  p-value: 0.6246\n\n                  2.5 %     97.5 %\n(Intercept)  3.58679351 4.43706821\nage         -0.01351424 0.00812738\n\n\n\n\n\n\n8.3.4 Activity 8 - Centering and standardising predictors\nSo far, we have covered specifying your outcome and predictor variables as their raw values in the data. However, there are two variations that are useful to understand: centering and standardising predictors. These do not change the model fitting or p-values, but change how you interpret the intercept and/or slope.\n\n8.3.4.1 Centering predictors\nCentering predictors is where you change the values of your predictor, but not their scale. Typically, this means substracting the mean of your predictor from each observation. This changes how you interpret the intercept of your regression model.\nRemember the interpretation of the intercept is the predicted value of your outcome when your predictor is set to 0. If 0 is not present in your data or a value of 0 would be uninformative, the intercept can be difficult to interpret. When you center your predictor, 0 becomes the mean value of your predictor. So, the intercept is now the predicted value of your outcome for the mean value of your predictor, but the slope itself does not change. You can see the impact of this by plotting the data side by side in Figure 8.1.\n\ndawtry_clean &lt;- dawtry_clean %&gt;% \n  # subtract fairness values from mean of fairness\n  mutate(fairness_center = fairness_satisfaction - mean(fairness_satisfaction))\n\n\n\n\n\nFigure 8.1: Top: The relationship between wealth redistribution and perceived fairness and satisfaction using raw values. Bottom: The relationship after centering perceived fairness and satisfaction values.\n\n\n\nThe relationship between the two variables is exactly the same, but the values of fairness and satisfaction shifted so the mean is 0. If you create a new linear model object, you can see the difference this makes to the output.\n\nlm_center &lt;- lm(redistribution ~ fairness_center, \n                data = dawtry_clean)\n\nsummary(lm_center)\n\n\nCall:\nlm(formula = redistribution ~ fairness_center, data = dawtry_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9193 -0.5279  0.0233  0.4782  3.3634 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      3.90984    0.04706   83.09   &lt;2e-16 ***\nfairness_center -0.39754    0.02328  -17.08   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8218 on 303 degrees of freedom\nMultiple R-squared:  0.4905,    Adjusted R-squared:  0.4888 \nF-statistic: 291.7 on 1 and 303 DF,  p-value: &lt; 2.2e-16\n\n\nEvery single one of the values remains the same apart from the intercept. Now, we can interpret it as the predicted value of redistribution when fairness and satisfaction is set to 0, i.e., the mean value. So, for the mean value of fairness and satisfaction, we would predict a value of 3.91 for redistribution.\n\n8.3.4.2 Standardising predictors\nStandardising predictors is where you first convert your values to z-scores. This means you interpret the values as standard deviations rather than your original units. This is more useful in multiple regression (Chapter 14) to compare the magnitude of predictors, but it is useful to get used to now when you only have one predictor to focus on.\nThe first step is to standardise all your variables, not just the predictor this time. This involves subtracting the mean of your variable from each value, and dividing by the standard deviation of the variable. They now have a mean of 0 and a standard deviation of 1.\n\n# Be careful with the bracket placement to subtract the mean first\ndawtry_clean &lt;- dawtry_clean %&gt;% \n  mutate(redistribution_std = (redistribution - mean(redistribution)) / sd(redistribution),\n         fairness_std = (fairness_satisfaction - mean(fairness_satisfaction)) / sd(fairness_satisfaction))\n\nOnce we enter them into the model, we no longer have values in the original units of measurement, we now have them expressed as standard deviations.\n\nlm_standardised &lt;- lm(redistribution_std ~ fairness_std, \n                      data = dawtry_clean)\n\nsummary(lm_standardised)\n\n\nCall:\nlm(formula = redistribution_std ~ fairness_std, data = dawtry_clean)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.53979 -0.45930  0.02026  0.41604  2.92617 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -1.603e-16  4.094e-02    0.00        1    \nfairness_std -7.003e-01  4.101e-02  -17.08   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.715 on 303 degrees of freedom\nMultiple R-squared:  0.4905,    Adjusted R-squared:  0.4888 \nF-statistic: 291.7 on 1 and 303 DF,  p-value: &lt; 2.2e-16\n\n\nLike centering, the model fit and p-values do not change again, apart from the intercept. The relationship between the variables is exactly the same, but we changed their units. The intercept is tiny and close enough to zero that the p-value is 1.\nMore importantly, the slope is now expressed in standard deviations. Annoyingly, R prints the values in scientific notation, so this can be awkward to read (remember the format() function). Now, for every 1 standard deviation increase in our predictor, we predict the outcome to decrease by 0.70 standard deviations.\n\n\n\n\n\n\nTip\n\n\n\nIt is important to demonstrate the underlying concepts first but if you want a shortcut without needing to standardise all your variables, the effectsize package has a handy function called standardize_parameters() which you can apply to your initial lm() object.\n\nstandardize_parameters(lm_redistribution)\n\n\n\n\nParameter\nStd_Coefficient\nCI\nCI_low\nCI_high\n\n\n\n(Intercept)\n0.00000\n0.95\n-0.0805627\n0.0805627\n\n\nfairness_satisfaction\n-0.70034\n0.95\n-0.7810351\n-0.6196449"
  },
  {
    "objectID": "09-lm-categorical.html#chapter-preparation",
    "href": "09-lm-categorical.html#chapter-preparation",
    "title": "\n9  Regression with one categorical predictor\n",
    "section": "\n9.1 Chapter preparation",
    "text": "9.1 Chapter preparation\n\n9.1.1 Introduction to the data set\nFor most of this chapter, we are using open data from Lopez et al. (2023). The abstract of their article is:\n\nImagine a bowl of soup that never emptied, no matter how many spoonfuls you ate—when and how would you know to stop eating? Satiation can play a role in regulating eating behavior, but research suggests visual cues may be just as important. In a seminal study by Wansink et al. (2005), researchers used self-refilling bowls to assess how visual cues of portion size would influence intake. The study found that participants who unknowingly ate from self-refilling bowls ate more soup than did participants eating from normal (not self-refilling) bowls. Despite consuming 73% more soup, however, participants in the self-refilling condition did not believe they had consumed more soup, nor did they perceive themselves as more satiated than did participants eating from normal bowls. Given recent concerns regarding the validity of research from the Wansink lab, we conducted a preregistered direct replication study of Wansink et al. (2005) with a more highly powered sample (N = 464 vs. 54 in the original study). We found that most results replicated, albeit with half the effect size (d = 0.45 instead of 0.84), with participants in the self-refilling bowl condition eating significantly more soup than those in the control condition. Like the original study, participants in the selfrefilling condition did not believe they had consumed any more soup than participants in the control condition. These results suggest that eating can be strongly controlled by visual cues, which can even override satiation.\n\nIn summary, they replicated an (in)famous experiment that won the Ig-Nobel prize. Participants engaged in a intricate setting (seriously, go and look at the diagrams in the article) where they ate soup from bowls on a table. In the control group, participants could eat as much soup as they wanted and could ask for a top-up from the researchers. In the experimental group, the soup bowls automatically topped up through a series of hidden tubes under the table. The idea behind the control group is they get an accurate visual cue by the soup bowl reducing, and the experimental group get an inaccurate visual cue by the soup bowl seemingly never reducing. So, the inaccurate visual cue would interfere with natural signs of getting full and lead to people eating more.\nIn the original article, participants in the experimental group ate more soup than participants in the control group, but the main author was involved in a series of research misconduct cases. Lopez et al. (2023) wanted to see if the result would replicate in an independent study, so they predicted they would find the same results. In this chapter, we will explore the difference between the control and experimental groups on several variables in their data set.\n\n9.1.2 Organising your files and project for the chapter\nBefore we can get started, you need to organise your files and project for the chapter, so your working directory is in order.\n\nIn your folder for research methods and the book ResearchMethods1_2/Quant_Fundamentals, create a new folder called Chapter_09_regression_categorical. Within Chapter_09_regression_categorical, create two new folders called data and figures.\nCreate an R Project for Chapter_09_regression_categorical as an existing directory for your chapter folder. This should now be your working directory.\nCreate a new R Markdown document and give it a sensible title describing the chapter, such as 09 t-tests and Regression. Delete everything below line 10 so you have a blank file to work with and save the file in your Chapter_09_regression_categorical folder.\nWe are working with a new data set, so please save the following data file: Lopez_2023.csv. Right click the link and select “save link as”, or clicking the link will save the files to your Downloads. Make sure that you save the file as “.csv”. Save or copy the file to your data/ folder within Chapter_09_regression_categorical.\n\nYou are now ready to start working on the chapter!\n\n9.1.3 Activity 1 - Read and wrangle the data\nAs the first activity, try and test yourself by completing the following task list to practice your data wrangling skills. In this example, there is not loads to do, you just need to tidy up some variables. Create a final object called lopez_clean to be consistent with the tasks below. If you want to focus on t-tests and regression, then you can just type the code in the solution.\n\n\n\n\n\n\nTry this\n\n\n\nTo wrangle the data, complete the following tasks:\n\n\nLoad the following packages:\n\ntidyverse\neffectsize\nperformance\n\n\nRead the data file data/Lopez_2023.csv to the object name lopez_data.\n\nCreate a new object called lopez_clean based on lopez_data:\n\nModify the variable Condition to turn it into a factor.\nCreate a new variable called Condition_label by recoding Condition. “0” is the “Control” group and “1” is the “Experimental” group.\n\n\n\nYour data should look like this to be ready to analyse:\n\n\nRows: 464\nColumns: 10\n$ ParticipantID      &lt;dbl&gt; 1002, 1004, 1007, 1016, 1018, 1021, 1022, 1024, 102…\n$ Sex                &lt;dbl&gt; 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, …\n$ Age                &lt;dbl&gt; 18, 19, 19, 21, 20, 20, 21, 21, 19, 20, 21, 20, 21,…\n$ Ethnicity          &lt;dbl&gt; 7, 3, 3, 4, 1, 3, 1, 6, 4, 7, 1, 3, 3, 4, 7, 2, 3, …\n$ OzEstimate         &lt;dbl&gt; 3.0, 2.0, 1.0, 3.0, 5.0, 1.0, 1.0, 3.0, 4.0, 1.0, 4…\n$ CalEstimate        &lt;dbl&gt; 65, 10, 20, 25, 50, 5, 20, 180, 470, 50, 130, 100, …\n$ M_postsoup         &lt;dbl&gt; 3.3, 3.1, 43.4, 5.5, 6.0, 0.8, 3.8, 4.5, 7.9, 8.1, …\n$ F_CaloriesConsumed &lt;dbl&gt; 73.19441, 68.75839, 962.61743, 121.99069, 133.08075…\n$ Condition          &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Condition_label    &lt;chr&gt; \"Control\", \"Control\", \"Control\", \"Control\", \"Contro…\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# load the relevant packages\nlibrary(effectsize)\nlibrary(performance)\nlibrary(tidyverse)\n\n# Read the Lopez_2023.csv file \nlopez_data &lt;- read_csv(\"data/Lopez_2023.csv\")\n\n# turn condition into a factor and recode\nlopez_clean &lt;- lopez_data %&gt;% \n  mutate(Condition = as.factor(Condition),\n         Condition_label = case_match(Condition,\n                                      \"0\" ~ \"Control\",\n                                      \"1\" ~ \"Experimental\"))\n\n\n\n\n\n9.1.4 Activity 2 - Explore the data\n\n\n\n\n\n\nTry this\n\n\n\nAfter the wrangling steps, try and explore lopez_clean to see what variables you are working with. For example, opening the data object as a tab to scroll around, explore with glimpse(), or try plotting some of the individual variables.\n\n\nIn lopez_clean, we have the following variables:\n\n\n\n\n\n\n\nVariable\nType\nDescription\n\n\n\nParticipantID\ndouble\nParticipant ID number.\n\n\nSex\ndouble\nParticipant sex.\n\n\nAge\ndouble\nParticipant age in years.\n\n\nEthnicity\ndouble\nParticipant ethnicity.\n\n\nOzEstimate\ndouble\nEstimated soup consumption in ounces (Oz).\n\n\nCalEstimate\ndouble\nEstimated soup consumption in calories (kcals).\n\n\nM_postsoup\ndouble\nActual soup consumption in ounces (Oz).\n\n\nF_CaloriesConsumed\ndouble\nActual soup consumption in calories (kcals).\n\n\nCondition\ninteger\nCondition labelled numerically as 0 (Control) and 1 (Experimental).\n\n\nCondition_label\ncharacter\nCondition as a direct label: Control and Experimental.\n\n\n\nWe will use this data set to demonstrate t-tests and regression when you have one categorical predictor."
  },
  {
    "objectID": "09-lm-categorical.html#comparing-differences-using-the-t-test",
    "href": "09-lm-categorical.html#comparing-differences-using-the-t-test",
    "title": "\n9  Regression with one categorical predictor\n",
    "section": "\n9.2 Comparing differences using the t-test",
    "text": "9.2 Comparing differences using the t-test\nLike correlations are a specific application of the general linear model for the relationship between two continuous variables, t-tests are a specific application for the difference between two groups. Before we demonstrate how you can express this kind of design as a regression model, we cover t-tests so you know how to calculate and interpret them when you come across them in your research.\n\n9.2.1 Activity 3 - Visualising the difference\nTo visualise the difference between two groups, it is useful to create something like a boxplot early for yourself, then provide a more professional looking violin-boxplot to help communicate your results. For most of the demonstrations in this chapter, we will try and answer the research question: “Is there a difference in actual calories consumed between the control and experimental groups?”\n\n\n\n\n\n\nTry this\n\n\n\nUsing your data visualisation skills from Chapter 7, recreate the violin-boxplot below using the variables F_CaloriesConsumed and Condition_label from lopez_clean.\n\n\n\n\n\n\n\n\nLooking at the graph, the \nControl\nExperimental group consumed more calories on average.\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThe violin-boxplot shows the experimental group who had the biased visual cues consumed more soup in calories than the control group who had the accurate visual cues.\nYou should have the following in a code chunk:\n\nlopez_clean %&gt;% \n  ggplot(aes(y = F_CaloriesConsumed, x = Condition_label, fill = Condition_label)) +\n  geom_violin(alpha = 0.5) + \n  geom_boxplot(width = 0.2, \n               fatten = NULL) + \n  stat_summary(fun = \"mean\", \n               geom = \"point\") +\n  stat_summary(fun.data = \"mean_cl_boot\", # confidence interval\n               geom = \"errorbar\", \n               width = 0.1) +\n  scale_fill_viridis_d(option = \"E\") + \n  scale_y_continuous(name = \"Actual Calories Consumed (kcals)\") +\n  scale_x_discrete(name = \"Study Condition\") + \n  guides(fill = FALSE) + \n  theme_classic()\n\n\n\n\n\n9.2.2 Activity 4 - Using the t.test() function\nA t-test is a specific application of the general linear model. In this test, we express the difference in an outcome between two groups as a kind of standardised mean difference. If you are interested, see the Handy Workbook (McAleer, 2023) for the calculations behind the Student and Welch t-test. Conceptually, a t-test is the difference between two groups divided by the standard error of the difference. There are two main versions of a t-test:\n\nStudent t-test\nWelch t-test\n\nThere is a function built into R to calculate the t-test: t.test(). The function requires:\n\nA formula like lm() where you specify the outcome/dependent variable and the predictor/independent variable in the form outcome ~ predictor.\nThe data set you want to use.\n\nFor our lopez_clean data, we would run the following code for a two-tailed Welch t-test:\n\nt.test(formula = F_CaloriesConsumed ~ Condition_label, \n       data = lopez_clean)\n\n\n    Welch Two Sample t-test\n\ndata:  F_CaloriesConsumed by Condition_label\nt = -4.8578, df = 453.45, p-value = 1.638e-06\nalternative hypothesis: true difference in means between group Control and group Experimental is not equal to 0\n95 percent confidence interval:\n -88.55610 -37.54289\nsample estimates:\n     mean in group Control mean in group Experimental \n                  196.6818                   259.7313 \n\n\nFor the three key concepts of inferential statistics, we get\n\n\nHypothesis testing: p &lt; .001, suggesting we can reject the null hypothesis assuming \\(\\alpha\\) = .05.\n\n\n\n\n\n\n\nWhat does 1.638e-06 mean?\n\n\n\nRemember: R reports very small or very large numbers using scientific notation to save space. We normally report p-values to three decimals, so we report anything smaller as p &lt; .001 to say it is smaller than this.\nIf you want to see the real number, you can use the following function which shows just how small the p-value is:\n\nformat(1.638e-06, scientific = FALSE)\n\n[1] \"0.000001638\"\n\n\n\n\n\n\nEffect size: Somewhat annoyingly, we do not directly get the mean difference between groups as a raw/unstandardised mean difference. We must manually calculate it by subtracting the means of each group (196.6818 - 259.7313 = -63.05). So, those in the experimental group ate on average 63 more calories of soup than the control group.\n\n\n\n\n\n\n\nDoes it matter whether the difference is positive or negative?\n\n\n\nFor effect sizes describing the difference between two groups, it is the absolute difference which is important, providing it is consistent with your predictions (if applicable). If you entered the groups the other way around, the mean difference would become 259.7313 - 196.6818 = 63.05. The same applies when we calculate a standardised mean difference like Cohen’s d later.\n\n\n\n\nConfidence interval: [-88.56, -37.54], although we do not get the mean difference, we get the confidence interval around the mean difference.\n\nTo summarise: A Welch t-test showed participants in the experimental group ate significantly more calories of soup than participants in the control group, t (453.45) = -4.86, p &lt; .001. On average, those in the experimental group ate 63.05 (95% CI = [37.54, 88.56]) more calories than those in the control group.\nWhen you have statistics software like R to do the heavy lifting for you, there is not really a scenario where you would use the Student t-test anymore, but if you did, you can use the var.equal argument to say you assume there are equal variances in each group:\n\nt.test(formula = F_CaloriesConsumed ~ Condition_label, \n       data = lopez_clean, \n       var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  F_CaloriesConsumed by Condition_label\nt = -4.8625, df = 462, p-value = 1.591e-06\nalternative hypothesis: true difference in means between group Control and group Experimental is not equal to 0\n95 percent confidence interval:\n -88.52983 -37.56915\nsample estimates:\n     mean in group Control mean in group Experimental \n                  196.6818                   259.7313 \n\n\nYou can see the main difference between the two versions is the Welch t-test Student corrects the degrees of freedom, so they are a decimal. While the Student t-test does not correct the degrees of freedom, so they are predictably N - 2.\nTo summarise: A Student t-test showed participants in the experimental group ate significantly more calories of soup than participants in the control group, t (462) = -4.86, p &lt; .001. On average, those in the experimental group ate 63.05 (95% CI = [37.57, 88.53]) more calories than those in the control group.\nOne further useful argument is specifying a one-tailed test if you have a specific prediction. The only downside to using linear models later is there is not a simple argument to apply a one-tailed test.\n\nt.test(formula = F_CaloriesConsumed ~ Condition_label, \n       data = lopez_clean, \n       alternative = \"less\")\n\n\n    Welch Two Sample t-test\n\ndata:  F_CaloriesConsumed by Condition_label\nt = -4.8578, df = 453.45, p-value = 8.188e-07\nalternative hypothesis: true difference in means between group Control and group Experimental is less than 0\n95 percent confidence interval:\n     -Inf -41.6571\nsample estimates:\n     mean in group Control mean in group Experimental \n                  196.6818                   259.7313 \n\n\nThe difference here is specifying the alternative argument. You can use “less” or “greater” depending if you predict a negative (group A &lt; group B) or positive difference (group A &gt; group B).\n\n9.2.3 Activity 5 - Calculating Cohen’s d\nRaw/unstandardised effect sizes are great for putting results in context, particularly when the units are comparable across studies. For our outcome in this study, differences in calories are easy to put in context.\nAlternatively, it can be useful to calculate standardised effect sizes. This helps for power analyses (more on that in Chapter 10) and when you want to compare across comparable studies with slightly different measurement scales.\nThere are different formulas for calculating Cohen’s d, but if you know the t-value and degrees of freedom, you can calculate Cohen’s d through:\n\\(d = \\frac{2t}{\\sqrt{df}} = \\frac{-9.725}{21.49} = -0.45\\)\nIt is important to know the concepts before you use shortcuts, but there is the cohens_d() function from the effectsize package which uses the same format as t.test().\n\ncohens_d(F_CaloriesConsumed ~ Condition_label, \n         data = lopez_clean)\n\n\n\n\nCohens_d\nCI\nCI_low\nCI_high\n\n\n-0.4523004\n0.95\n-0.6366884\n-0.2674345\n\n\n\n\n\n\n\n\n\n\n\nTry this\n\n\n\nGreat work following along so far, but now it is time to test your understanding on a new set of variables. Use the variables CalEstimate and Condition_label from lopez_clean. We can ask the question: “What is the difference in estimated calories consumed between the experimental and control groups?”\n\nCreate a violin-boxplot to visualise the difference between CalEstimate and Condition_label from lopez_clean.\n\nApply the Welch t-test to get your inferential statistics and answer the following questions:\n\nHypothesis testing: Assuming \\(\\alpha\\) = .05, the difference between the experimental and control groups on estimated calories consumed was \nstatistically significant\nnot statistically significant.\nEffect size: Rounded to 2 decimals, the raw effect size was an average difference of  estimates calories between the two groups. Expressed as a standardised effect size, this difference equates to Cohen’s d = .\nConfidence interval: Rounded to 2 decimals, the 95% confidence interval for the mean difference is \n-4.08\n-0.03\n39.85\n0.33 to \n-4.08\n-0.03\n39.85\n0.33. The 95% confidence interval for Cohen’s d is \n-4.08\n-0.03\n39.85\n0.33 to \n-4.08\n-0.03\n39.85\n0.33.\n\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThe violin-boxplot shows little difference between the two groups on estimated calories consumed.\n\nlopez_clean %&gt;% \n  ggplot(aes(y = CalEstimate, x = Condition_label, fill = Condition_label)) +\n  geom_violin(alpha = 0.5) + \n  geom_boxplot(width = 0.2, \n               fatten = NULL) + \n  stat_summary(fun = \"mean\", \n               geom = \"point\") +\n  stat_summary(fun.data = \"mean_cl_boot\", # confidence interval\n               geom = \"errorbar\", \n               width = 0.1) +\n  scale_fill_viridis_d(option = \"E\") + \n  scale_y_continuous(name = \"Estimated Calories Consumed (kcals)\") +\n  scale_x_discrete(name = \"Study Condition\") + \n  guides(fill = FALSE) + \n  theme_classic()\n\n\n\n\n\n\n\nFor our inferential statistics, a Welch t-test showed the difference is not statistically significant, t (455.06) = 1.60, p = .110.\n\nt.test(formula = CalEstimate ~ Condition_label, \n       data = lopez_clean)\n\n\n    Welch Two Sample t-test\n\ndata:  CalEstimate by Condition_label\nt = 1.6001, df = 455.06, p-value = 0.1103\nalternative hypothesis: true difference in means between group Control and group Experimental is not equal to 0\n95 percent confidence interval:\n -4.080399 39.846433\nsample estimates:\n     mean in group Control mean in group Experimental \n                  133.0328                   115.1498 \n\n\nThe control group estimated they consumed 17.88 (95% CI = [-4.08, 39.85]) more calories than the experimental group, but the difference was not significant. Expressed as a standardised effect size, this equates to Cohen’s d = 0.15 (95% CI = [-0.03, 0.33]).\n\ncohens_d(CalEstimate ~ Condition_label, \n         data = lopez_clean)\n\n\n\n\nCohens_d\nCI\nCI_low\nCI_high\n\n\n0.1490887\n0.95\n-0.0341294\n0.332145"
  },
  {
    "objectID": "09-lm-categorical.html#linear-regression-with-one-categorical-predictor",
    "href": "09-lm-categorical.html#linear-regression-with-one-categorical-predictor",
    "title": "\n9  Regression with one categorical predictor\n",
    "section": "\n9.3 Linear regression with one categorical predictor",
    "text": "9.3 Linear regression with one categorical predictor\nNow you know how to calculate a t-test in R, we can turn to simple linear regression as a more flexible tool for modelling the difference between two groups. As a reminder, there is a chapter in the Handy Workbook (McAleer, 2023) dedicated to manually calculating simple linear regression if you want to work through what the functions are doing behind the scenes.\n\n9.3.1 Activity 6 - Descriptive statistics\nFor all the information we want to include in a report, calculating descriptive statistics is helpful for the reader to show the context behind the results you present. Here, we can report the mean and standard deviation of our outcome per group.\n\nlopez_clean %&gt;% \n  group_by(Condition_label) %&gt;% \n  summarise(mean_cals = round(mean(F_CaloriesConsumed), 2), \n            sd_cals = round(mean(F_CaloriesConsumed), 2))\n\n\n\n\nCondition_label\nmean_cals\nsd_cals\n\n\n\nControl\n196.68\n196.68\n\n\nExperimental\n259.73\n259.73\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you want some reinforcement of how these skills apply to published research, look at Table 1 in Lopez et al. (2023). The means and standard deviations here (and Cohen’s d from Activity 5) exactly reproduce the values they report, apart from the SD for the control group (maybe there is a typo in their article).\n\n\n\n9.3.2 Activity 7 - Using the lm() function\nFor our research question of “is there a difference in actual calories consumed between the control and experimental group?”, we can address it with simple linear regression. In this study, we can make causal conclusions as it was an experiment to randomly allocate people into one of two groups, but you can also use regression to compare two self-selecting groups when you cannot make a causal conclusion in isolation. Think carefully about what you can conclude from your design.\nLike Chapter 8, we start by defining our regression model with a formula in the pattern outcome ~ predictor and specify the data frame you want to use. We must then use the summary() function around your model object to get all the statistics you need.\nThere are two ways you can use a categorical predictor. First, we can code groups numerically which people called dummy coding. You code your first group 0 and you code your second group as 1, which maps on directly to how the regression model works. Let’s look at the output.\n\n# Condition as a factor containing 0 and 1\nlm_cals_numbers &lt;- lm(formula = F_CaloriesConsumed ~ Condition, \n                      data = lopez_clean)\n\nsummary(lm_cals_numbers)\n\n\nCall:\nlm(formula = F_CaloriesConsumed ~ Condition, data = lopez_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-230.90  -99.09  -24.15   62.83  828.04 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  196.682      8.888  22.130  &lt; 2e-16 ***\nCondition1    63.049     12.966   4.863 1.59e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 139.4 on 462 degrees of freedom\nMultiple R-squared:  0.04869,   Adjusted R-squared:  0.04663 \nF-statistic: 23.64 on 1 and 462 DF,  p-value: 1.591e-06\n\n\nCompared to when we had a continuous predictor in Chapter 8, the output is identical. We just need to remember what the key numbers represent. The intercept is the predicted value of your outcome when your predictor is set to 0. When we have two groups coded as 0 and 1, this means the intercept is essentially the mean value of group 0 (here, the control group). We call this the reference group. You can confirm this by comparing the intercept estimate 196.68 to the mean value of the control group we calculated in Activity 6.\nThe slope estimate then represents how we predict the outcome to change for every 1-unit increase in the predictor. Since we coded the predictor 0 and 1, this just represents the shift from group 1 to group 2. We call the group we code as 1 the target group. You see the target group appended to the variable name, which is Condition1 here. So, for a categorical predictor, the slope represents the mean difference between the reference group (0) and the target group (1): 63.05. In contrast to the t-test, this is our raw/unstandardised effect size for the mean difference we do not need to manually calculate.\n\n\n\n\n\n\nDoes it matter if the slope is positive or negative?\n\n\n\nWhen you have a categorical predictor, the sign is only important for interpreting which group is bigger or smaller. The absolute size is relevant for the effect size where a larger absolute value indicates a larger effect. Whether the slope is positive or negative depends on the order of the groups and which has a larger mean. If the reference is larger than the target, you will get a negative slope. If the target is larger than the reference, you will get a positive slope.\n\n\nLike the continuous predictor, we get values for \\(R^2\\) and adjusted \\(R^2\\), showing we explain .046 (in other words, 4.6%) variance in the outcome through our condition manipulation. We then get the model fit statistics, but with a single predictor, the p-value is identifical to the slope.\nAlternatively, you can use character labels for your categorical predictor and it will still work. This time, we use Condition_label. By default, it will set the order of the reference and target groups alphabetically, but you can manually specify the order by setting factor levels.\n\n# Condition_label as characters\nlm_cals_labels &lt;- lm(formula = F_CaloriesConsumed ~ Condition_label, \n                     data = lopez_clean)\n\nsummary(lm_cals_labels)\n\n\nCall:\nlm(formula = F_CaloriesConsumed ~ Condition_label, data = lopez_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-230.90  -99.09  -24.15   62.83  828.04 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                  196.682      8.888  22.130  &lt; 2e-16 ***\nCondition_labelExperimental   63.049     12.966   4.863 1.59e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 139.4 on 462 degrees of freedom\nMultiple R-squared:  0.04869,   Adjusted R-squared:  0.04663 \nF-statistic: 23.64 on 1 and 462 DF,  p-value: 1.591e-06\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you want to test specifying the factor order to see how it affects the output, try running this code prior to the regression model:\n\n# Specify group order of Experimental then Control\nlopez_clean &lt;- lopez_clean %&gt;% \n  mutate(Condition_label = factor(Condition_label, \n                                  levels = c(\"Experimental\", \"Control\")))\n\n\n\n\n\n\n\n\n\nHow are t-tests and regression the same?\n\n\n\n\n\nIf you are interested in the relationship between the two concepts, we said a t-test was a specific application of the general linear model. In the t-test calculations, it expresses the mean difference between groups by the standard error of the difference. In essence, it describes the difference in standard errors, which we can describe with a t-distribution to calculate p-values.\nIn regression, we frame the model as how much variance you explain compared to the total amount of variance. The more variance your predictor explains, the less unexplained variance there is left over. For the slope estimate though, this is identical to the t-test as we estimate the mean difference between groups plus the standard error around the mean difference. We calculate a p-value for the slope from a t-distribution, so you get a t-value in the output.\nYou can see the process is identical by comparing the key values from the regression output to the Student t-test. We can recreate the mean difference to compare to the slope, the t-value is the same, the p-value is the same, the degrees of freedom are the same, and the 95% confidence intervals below are the same.\nSo, when you have a single categorical predictor, it is the exact same process as the Student t-test, just expressed slightly different. The only downside to this procedure is it is much more difficult to recreate the Welch t-test.\n\n\n\n\n9.3.3 Activity 8 - Calculating confidence intervals\nThe only thing we are missing is our confidence intervals around the estimates which we can calculate through the confint() function.\n\nconfint(lm_cals_numbers)\n\n                2.5 %    97.5 %\n(Intercept) 179.21657 214.14704\nCondition1   37.56915  88.52983\n\n\nNow, we can summarise the three key concepts of inferential statistics as:\n\nHypothesis testing: p &lt; .001, suggesting we can reject the null hypothesis assuming \\(\\alpha\\) = .05. The experimental group ate significantly more calories of soup than the control group.\nEffect size: \\(b_1\\) = 63.05, suggesting the experimental group ate on average 63 more calories than the control group.\nConfidence interval: [37.57, 88.53], showing the precision around the slope estimate.\n\n\n\n\n\n\n\nTry this\n\n\n\nNow it is time to test your understanding on a new set of variables. This time, use CalEstimate as your outcome, Condition_label as your predictor, and use lopez_clean as your data. We can ask the same question as Activity 5: “What is the difference in estimated calories consumed between the experimental and control groups?”.\nApply simple linear regression to get your inferential statistics and answer the following questions:\n\nHypothesis testing: Assuming \\(\\alpha\\) = .05, Condition is a \nstatistically significant\nnon-significant predictor of estimates calories consumed.\nEffect size: Rounded to 2 decimals, the Condition slope coefficient means there was a mean difference of \n133.03\n7.68\n-17.88\n11.19.\nConfidence interval: Rounded to 2 decimals, the lower bound of the slope is \n117.94\n-39.88\n148.12\n4.11 and the upper bound is \n117.94\n-39.88\n148.12\n4.11.\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThe conclusions are the same as when we calculated the t-test, where condition is not a statistically significant predictor of estimated calories consumed. As a regression model, we get the same conclusions expressed in a slightly different way. Condition is a negative but non-significant predictor (p = .111). The control group ate 17.88 (\\(b_1\\) = -17.88, 95% CI = [-39.88, 4.11]) more calories than the experimental group. We explain very little variance in estimated calories consumed (adjusted \\(R^2\\) = .003), so the condition manipulation had little effect.\n\n# Create lm object for condiiton label as a predictor\nlm_cal_est &lt;- lm(CalEstimate ~ Condition_label, \n                 data = lopez_clean)\n\n# summary of the model object\nsummary(lm_cal_est)\n\n# confidence intervals around estimates\nconfint(lm_cal_est)\n\n\nCall:\nlm(formula = CalEstimate ~ Condition_label, data = lopez_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-130.03  -83.03  -33.03   44.85  666.97 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                  133.033      7.679  17.324   &lt;2e-16 ***\nCondition_labelExperimental  -17.883     11.192  -1.598    0.111    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 119.9 on 459 degrees of freedom\n  (3 observations deleted due to missingness)\nMultiple R-squared:  0.005531,  Adjusted R-squared:  0.003365 \nF-statistic: 2.553 on 1 and 459 DF,  p-value: 0.1108\n\n                                2.5 %     97.5 %\n(Intercept)                 117.94256 148.123015\nCondition_labelExperimental -39.87763   4.111599\n\n\n\n\n\n\n9.3.4 Activity 9 - Standardising predictors\nFor simple linear regression with two levels of a categorical predictor, centering the variable does not help, but we can standardise our outcome to express the estimate in standard deviations rather than the raw units. This is analogous to calculating Cohen’s d as we express the standardised mean difference. In contrast to continuous predictors, we only need to standardise the outcome, rather than both the outcome and predictor(s). We then use the standardised variable as our outcome.\n\n# Be careful with the bracket placement to subtract the mean first\nlopez_clean &lt;-lopez_clean %&gt;% \n  mutate(actual_calories_std = (F_CaloriesConsumed - mean(F_CaloriesConsumed)) / sd(F_CaloriesConsumed))\n\n# Condition as a factor containing 0 and 1\nlm_cals_std &lt;- lm(formula = actual_calories_std ~ Condition, \n                      data = lopez_clean)\n\nsummary(lm_cals_std)\n\n\nCall:\nlm(formula = actual_calories_std ~ Condition, data = lopez_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.6173 -0.6941 -0.1692  0.4401  5.8000 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.20749    0.06225  -3.333 0.000928 ***\nCondition1   0.44163    0.09082   4.863 1.59e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9764 on 462 degrees of freedom\nMultiple R-squared:  0.04869,   Adjusted R-squared:  0.04663 \nF-statistic: 23.64 on 1 and 462 DF,  p-value: 1.591e-06\n\n\nNote, the estimate may be slightly different to directly calculating Cohen’s d as there are a few formulas. If you compare to Activity 5, we got d = 0.45 there and 0.44 here. Between the estimate and 95% confidence intervals, they are off by .02, so it does not have a material impact on the results.\n\n\n\n\n\n\nTip\n\n\n\nAs before, once you know how it works conceptually, there is a shortcut where you do not need to standardise all your variables first. The effectsize package has a handy function called standardize_parameters() which you can apply to your initial lm() object.\n\nstandardize_parameters(lm_cals_numbers)\n\n\n\n\nParameter\nStd_Coefficient\nCI\nCI_low\nCI_high\n\n\n\n(Intercept)\n-0.2074898\n0.95\n-0.3298249\n-0.0851547\n\n\nCondition1\n0.4416297\n0.95\n0.2631529\n0.6201065"
  },
  {
    "objectID": "09-lm-categorical.html#checking-assumptions",
    "href": "09-lm-categorical.html#checking-assumptions",
    "title": "\n9  Regression with one categorical predictor\n",
    "section": "\n9.4 Checking assumptions",
    "text": "9.4 Checking assumptions\nFor the inferential statistics to work as intended, the model makes certain assumptions about the data you are putting into it and the accuracy of the inferences depends on how sensible these assumption are.\n\n9.4.1 Activity 10 - Diagnostic plots for linear regression\nWe have the same assumptions for simple linear regression now we have a categorical predictor:\n\nThe outcome is interval/ratio level data.\nThe predictor variable is interval/ratio or categorical (with two levels at a time).\nAll values of the outcome variable are independent (i.e., each score should come from a different participant/observation).\nThe predictors have non-zero variance.\nThe relationship between the outcome and predictor is linear.\nThe residuals should be normally distributed.\nThere should be homoscedasticity.\n\nAssumptions 1-4 are pretty straight forward as they relate to your understanding of the design or a simple check on the data for non-zero variance (the responses are not all the exact same value).\nAssumptions 5-7 require diagnostic checks on the residuals from the model. In contrast to continuous predictors, they are a little harder to identify patterns in. As we only have two values on the x-axis (0 and 1), all the residuals will be organised into vertical lines and the trend lines to help spot patterns do not look quite right.\n\n9.4.2 Checking linearity\nWhen you have a categorical predictor with two levels, you meet linearity by default, so you do not need to check this assumption directly. When you have two levels, you can only fit a straight line between the values.\n\nplot(lm_cals_numbers, \n     which = 1)\n\n\n\n\n\n\n\n\n9.4.3 Checking normality\nThe qq-plot is still the same to interpret. Now, this example presents a useful case of decision making in data analysis we explore more in Chapter 11. The plot here is approaching signs of violating normality as there is a clear curve to the data points with 3 and 118 the largest deviations (you can see these on the violin-boxplot as the two highest values in the control group). For this chapter, we are sticking with it and it would be consistent with how the original authors analysed the data, but note this would be a key decision to make and justify when reporting the analysis.\n\nplot(lm_cals_numbers, \n     which = 2)\n\n\n\n\n\n\n\n\n9.4.4 Checking homoscedasticity\nThe scale-location plot is harder to interpret when you have a categorical predictor. Like linearity, the points are all arranged in two vertical lines as we only have two levels. You are looking out for the spread of the two lines to be roughly similar. They look fine here, just points 118 and 3 separated a little from the other points.\n\nplot(lm_cals_numbers, \n     which = 3)\n\n\n\n\n\n\n\n\n9.4.5 Checking influential cases\nFinally, we have our plots for identifying influential cases. First, we get Cook’s distance for all the observations in your data. We see points 3 and 118 come up yet again, but although they are the largest deviations, they do not necessarily have worrying Cook’s distance values. There are different thresholds in the literature, but estimates range from 1, 0.5, to 4/n. It would only be under this final most conservative estimate (0.009) we would highlight several observations for further inspection.\n\nplot(lm_cals_numbers, \n     which = 4)\n\n\n\n\n\n\n\nFinally, the fifth plot shows residual values against leverage. Like Chapter 8, we cannot see the Cook’s distance threshold it uses in the plot as none of the points are a large enough deviation, despite 3 and 188 sticking out again.\n\nplot(lm_cals_numbers, \n     which = 5)\n\n\n\n\n\n\n\n\n9.4.6 Checking all the assumptions\nNow we have covered the individual diagnostic plots, there is a handy function called check_model() from the performance package. Like the plot() function, the output for linearity, homoscedasticity, and influential observations does not plot right as we only have two values for the predictor and the plot lines do not really work. Do not worry, you have not done anything wrong.\n\ncheck_model(lm_cals_numbers)\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat might explain the funky normality?\n\n\n\n\n\nIf you are interested, the posterior predictive check here provides an insight into why we get potential problems with normality. The outcome is ratio but cannot be smaller than 0 as we cannot have negative calories. So, in the green line for the observed data, the data are a little skewed as it drops off prior to 0. However, the model does not know that and it happily predicts normally distributed values which go below 0, creating a mismatch between what the model predicts and the values we enter into it.\nRemember the models will work regardless of the data you put into them, it is important to keep your role in mind to recognise when you need to be cautious about what you can learn from the model.\n\n\n\n\n\n\n\n\n\nTry this\n\n\n\nIn activity 8, you should have calculated the effect of condition (Condition_label) on estimated calories consumed (CalEstimate) for your independent task. Using the model object lm_cal_est, work through assumptions for simple linear regression and make a note of whether you think it meets the assumptions, or there might be any problems. Some of the assumptions you consider what you know about the design, while others you need the diagnostic plots.\n\nThe outcome is interval/ratio level data.\nThe predictor variable is interval/ratio or categorical (with two levels at a time).\nAll values of the outcome variable are independent (i.e., each score should come from a different participant/observation).\nThe predictors have non-zero variance.\nThe relationship between the outcome and predictor is linear.\nThe residuals should be normally distributed.\nThere should be homoscedasticity.\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\n\nThe outcome is interval/ratio level data.\n\nThe outcome is nicely ratio as estimated calories have a logical 0 point (no calories) and the units are in equal measurements..\n\nThe predictor variable is interval/ratio or categorical (with two levels at a time).\n\nOur predictor is categorical with two levels.\n\nAll values of the outcome variable are independent (i.e., each score should come from a different participant/observation).\n\nThe short answer is this appears to be the case in this study. The longer answer is there might have been an issue with the participants apparently completing the study in groups of 3. It is not entirely clear in the data how they recorded this, but grouped data collection does present a potential problem with independence we do not tackle in this course and the original authors did not seem to address it.\n\nThe predictors have non-zero variance.\n\nWe have observations from both levels of the predictor.\n\nThe relationship between the outcome and predictor is linear.\n\nWe meet linearity by default with two levels, so we do not need the plot here.\n\nThe residuals should be normally distributed.\n\nLike the actual calories consumed, this is firmly a clear deviation from what we expect and provides a good example of when it does not look right. If we were to analyse the data fully, we would explore the impact of this and alternative models, but for this chapter, we are going to note our concern and remember the authors analysed the data like this.\n\nplot(lm_cal_est, \n     which = 2)\n\n\n\n\n\n\n\n\nThere should be homoscedasticity.\n\nLooking at the spread of each group, it looks fine with a similar range until both groups are more sparsely distributed above 1.\n\nplot(lm_cal_est, \n     which = 3)\n\n\n\n\n\n\n\nIn summary, normality is a clear concern and something we will return to for your options in Chapter 11 and the course materials. For now, we will stick with the model but recognise we should be cautious."
  },
  {
    "objectID": "09-lm-categorical.html#reporting-your-results",
    "href": "09-lm-categorical.html#reporting-your-results",
    "title": "\n9  Regression with one categorical predictor\n",
    "section": "\n9.5 Reporting your results",
    "text": "9.5 Reporting your results\nNow we have some results to go with, there are a few recommendations on how to communicate that information. If you need a reminder of APA style for formatting numbers, you can see this PDF online for a little cheat sheet for numbers and statistics.\n\nExplain to the reader what your linear regression model was. For example, what was your outcome and predictor variable?\nReport descriptive statistics to help contextualise your findings. For example, the mean/standard deviation for your outcome per group.\nProvide an appropriate data visualisation to help communciate key patterns to the reader. For example, a violin-boxplot for how each group responded on your outcome.\nReport all three key inferential statistics concepts for the coefficient: the slope, the confidence interval around your slope, and the p-value for hypothesis testing. When you have one predictor in simple linear regression, you typically focus on the slope as your key effect size that helps address your research question and hypothesis. APA style rounds numbers to 2 decimal places when numbers can be bigger than 1, and 3 decimals with no leading zero when it cannot be bigger than 1. When you report the unstandardised slope, you use the symbol \\(b_1\\) but for the standardised slope, you use Beta instead \\(\\beta_1\\).\nProvide an overview of the model fit statistics for whether your model explained a significant amount of variance in your outcome. Remember: the p-value for your model will be the same as for the slope in simple linear regression.\n\nFor our main example, we could summarise the findings as:\n“Our research question was: is there a difference in actual calories consumed between the control and experimental group? To test this, we applied simple linear regression using condition as a predictor with two levels (control and experimental) and actual calories consumed as our outcome. Figure 1 shows a violin-boxplot of the difference between the control and experimental groups.\n\n\n\n\n\n\n\n\nOur model explained a statistically significant amount of variance in our outcome (adjusted \\(R^2\\) = .047, F(1, 462) = 23.64, p &lt; .001). Condition was a positive predictor, where the experimental group consumed on average 63 more calories than the control group (\\(b_1\\) = 63.05, 95% CI = [37.57, 88.53], p &lt; .001). Expressed as a standardised effect size, the experimental group consumed 0.44 (95% CI = [0.26, 0.62]) more standard deviations than the control group.”\nNote: we have not included an APA formatted Figure title here as it is not easy to format in our book, so refer to the course materials for guidance."
  },
  {
    "objectID": "09-lm-categorical.html#one--and-paired-sample-tests",
    "href": "09-lm-categorical.html#one--and-paired-sample-tests",
    "title": "\n9  Regression with one categorical predictor\n",
    "section": "\n9.6 One- and paired-sample tests",
    "text": "9.6 One- and paired-sample tests"
  },
  {
    "objectID": "09-lm-categorical.html#test-yourself",
    "href": "09-lm-categorical.html#test-yourself",
    "title": "\n9  Regression with one categorical predictor\n",
    "section": "\n9.7 Test Yourself",
    "text": "9.7 Test Yourself\nTo end the chapter, we have some knowledge check questions to test your understanding of the concepts we covered in the chapter. We then have some error mode tasks to see if you can find the solution to some common errors in the concepts we covered in this chapter.\n\n9.7.1 Knowledge check\nFor this chapter’s knowledge check section, we have something a little different. Instead of purely conceptual questions about functions, we have another example of linear regression from X. Feel free to create this model yourself, but we will show you some output and ask you questions based on it.\nFor this model…\nQuestion 1.\nQuestion 2.\nQuestion 3.\nQuestion 4.\nQuestion 5.\n\n9.7.2 Error mode\nThe following questions are designed to introduce you to making and fixing errors. For this topic, we focus on simple linear regression between two continuous variables. There are not many outright errors that people make here, more misspecifications that are not doing what you think they are doing.\nCreate and save a new R Markdown file for these activities. Delete the example code, so your file is blank from line 10. Create a new code chunk to load tidyverse and wrangle the data files:\nBelow, we have several variations of a misspecification. Copy and paste them into your R Markdown file below the code chunk to wrangle the data. Once you have copied the activities, click knit and look at the output you receive. See if you can identify the mistake and fix it before checking the answer.\nQuestion 6.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regression with one categorical predictor</span>"
    ]
  },
  {
    "objectID": "09-lm-categorical.html#end-of-chapter",
    "href": "09-lm-categorical.html#end-of-chapter",
    "title": "\n9  Regression with one categorical predictor\n",
    "section": "\n9.9 End of chapter",
    "text": "9.9 End of chapter\nWell done, you have now completed the first core set of chapters for inferential statistics!\nAt this point, you can now address a range of research questions by applying variations of the general linear model. As a researcher, the most important thing is starting with your research question (and where applicable, your hypothesis), designing a study to address that research question, and using an appropriate statistical model for your design and research question. But, before you can identify an appropriate statistical model, you need to know what they look like! This is everything we cover in Research Methods 1 to focus on a select range of foundational skills. You will then build on these modelling techniques in Chapters 12-14 for Research Methods 2.\nYou are now ready to complete the second data analysis journey chapter: Simple Linear Regression. This is where you can test your new skills in a slightly less structured way, from wrangling data, to answering a research question.\nIn the next core chapter, we turn to statistical power and work on how you can conduct a power analysis in R/RStudio.\n\n\n\n\nBem, D. J. (2011). Feeling the future: Experimental evidence for anomalous retroactive influences on cognition and affect. Journal of Personality and Social Psychology, 100(3), 407–425. https://doi.org/10.1037/a0021524\n\n\nLopez, A., Choi, A. K., Dellawar, N. C., Cullen, B. C., Avila Contreras, S., Rosenfeld, D. L., & Tomiyama, A. J. (2023). Visual cues and food intake: A preregistered replication of Wansink et al (2005). Journal of Experimental Psychology: General. https://doi.org/10.1037/xge0001503.supp"
  },
  {
    "objectID": "09-lm-categorical.html#bonus-section---one--and-paired-sample-tests",
    "href": "09-lm-categorical.html#bonus-section---one--and-paired-sample-tests",
    "title": "\n9  Regression with one categorical predictor\n",
    "section": "\n9.6 Bonus section - One- and paired-sample tests",
    "text": "9.6 Bonus section - One- and paired-sample tests\nIn this course, we focus on correlational and between-subjects designs, but you might find yourself in a situation where you want to test a continuous variable against a fixed value or compare conditions in the same participants. This is a bonus section if you have time, so you can skip to the Test Yourself section to finish the chapter if you do not.\nFor this demonstration, we will use data from experiment 1 of Bem (2011), an (in)famous study that almost single-handedly started the replication crisis in psychology. Briefly, participants completed a computer task adapted from priming experiments where they could select one of two windows. They had to guess which window had an image hidden behind it and the images contained different stimuli like erotic or neutral/control images. Across many trials of the participants guessing the location, Bem calculated the proportion of successful trials which could range between 0 (never correct), 50 (50%, chance), and 100 (always correct). The headline finding was participants demonstrated precognition - or the ability to see into the future - to guess above chance levels, but what does the data look like?\nWe are working with a new data set, so please save the following data file: Bem_2011.csv. Right click the link and select “save link as”, or clicking the link will save the files to your Downloads. Make sure that you save the file as “.csv”. Save or copy the file to your data/ folder within Chapter_09_regression_categorical. Read in the data file to the object bem_data to be consistent with the tasks below.\n\n9.6.1 One-sample comparing against a fixed value\nThere are scenarios where you want to compare a single continuous variable against a fixed value. For example, do your participants respond significantly above or below chance?\n\n9.6.1.1 Expressed as a t-test\nAs a t-test, we need to specify two arguments:\n\nx - This is the continuous variable you want to analyse and compare the mean value of. We have to use the base R operator $ to specify the column from your data.\nmu - This is the fixed value you want to test your variable against.\n\nIn this scenario, we want to compare the hit rate to erotic images against a value of 50. This will tell us if the hit rate is significantly above or below chance.\n\nt.test(x = bem_data$Erotic.Hits.PC,\n       mu = 50)\n\n\n    One Sample t-test\n\ndata:  bem_data$Erotic.Hits.PC\nt = 2.5133, df = 99, p-value = 0.01358\nalternative hypothesis: true mean is not equal to 50\n95 percent confidence interval:\n 50.66075 55.61703\nsample estimates:\nmean of x \n 53.13889 \n\n\nThe output is similar to the independent samples t-test. We get the p-value for hypothesis testing, the mean estimate of the variable, and it’s 95% confidence interval. To express it as an effect size, you can subtract 50 from each value. So, participants responded 3.14% above chance, statistically significant, but hardly convincing evidence for precognition.\n\n9.6.1.2 Expressed as a linear model\nWe can also express this as a linear model, but we first must add a small wrangling step. In the one-sample t-test, we can manually enter a fixed value to compare the mean against. In a linear model, we must compare against 0 by subtracting the fixed value from your variable. So, we subtract 50 from all the observations, so they become a kind of deviation from 50.\n\nbem_data &lt;- bem_data %&gt;% \n  mutate(erotic_deviation = Erotic.Hits.PC - 50)\n\nIn contrast to previous linear models, we only add a fixed intercept and do not add a predictor. This recreates the one-sample t-test by estimating the mean value of your outcome.\n\nlm_erotic &lt;- lm(erotic_deviation ~ 1, \n                data = bem_data)\n\nsummary(lm_erotic)\n\n\nCall:\nlm(formula = erotic_deviation ~ 1, data = bem_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-28.139  -8.694   2.417   7.972  30.194 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)    3.139      1.249   2.513   0.0136 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.49 on 99 degrees of freedom\n\n\nThis process has the benefit of directly producing your effect size, as the intercept estimate is the deviation from your fixed value (here, 50). As we calculated manually before, the erotic hit rate is 3.14% above your fixed value. If you remember back to the linear model explanations, this is where the p-value for the intercept is finally useful as it tests against 0.\nIf you compare to the one-sample t-test, all of these values are identical. You also have the option of calculating confidence intervals around the estimate and calculating a standardised effect size by applying the previous linear regression activities.\n\n9.6.2 Paired-samples comparing conditions\nAlternatively, you might want to compare two conditions from the same participants in paired samples/within-subjects design. For example, is the hit-rate significantly higher for erotic images compared to control images?\n\n9.6.2.1 Expressed as a t-test\nTo conduct a paired-samples t-test, we must specify three arguments:\n\nx - This is the first level of your condition as a column. You need your data in wide format, so the condition levels are spread across two columns per participant. We must use the base R operator $ to specify the column from your data.\ny - This is the second level of your condition as a column.\npaired - This instructs R you want a paired-samples t-test to compare conditions within participants.\n\nIn this scenario, we want to compare the hit rate for erotic images to control images.\n\nt.test(x = bem_data$Erotic.Hits.PC,\n       y = bem_data$Control.Hits.PC, \n       paired = TRUE)\n\n\n    Paired t-test\n\ndata:  bem_data$Erotic.Hits.PC and bem_data$Control.Hits.PC\nt = 1.8563, df = 99, p-value = 0.06638\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -0.2277431  6.8388542\nsample estimates:\nmean difference \n       3.305556 \n\n\nThe output is almost identical to the one-sample t-test, but this time the effect size is the mean difference between conditions, not just the mean per condition. Behind the scenes, a paired-samples t-test is actually a one-sample t-test in disguise as it uses the difference between conditions as the outcome.\n\n9.6.2.2 Expressed as a linear model\nFinally, we can express a paired-samples t-test as a linear model. We must apply a small data wrangling step to calculate a difference score between conditions. This is so the linear model compares the estimate against 0 of no difference. So, for this example, we create a variable for the difference between erotic and control images.\n\nbem_data &lt;- bem_data %&gt;% \n  mutate(erotic_control = Erotic.Hits.PC - Control.Hits.PC)\n\nLike the one-sample scenario, we only add a fixed intercept for the new difference variance and do not add a predictor. This recreates the paired-samples t-test by estimating the mean value of your difference score outcome.\n\nlm_paired &lt;- lm(erotic_control ~ 1, \n                data = bem_data)\n\nsummary(lm_paired)\n\n\nCall:\nlm(formula = erotic_control ~ 1, data = bem_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-58.861  -9.556   2.250   9.194  35.583 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)    3.306      1.781   1.856   0.0664 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 17.81 on 99 degrees of freedom\n\n\nThis process directly produces your effect size again, as the intercept estimate is the deviation from 0 for your difference score. As we saw in the paired-samples t-test output, there was a 3.31% higher hit rate for erotic images compared to control (as we calculated erotic - control).\nIf you compare to the paired-samples t-test, all of these values are identical. You also have the option of calculating confidence intervals around the estimate and calculating a standardised effect size by applying the previous linear regression activities.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regression with one categorical predictor</span>"
    ]
  },
  {
    "objectID": "09-lm-categorical.html",
    "href": "09-lm-categorical.html",
    "title": "\n9  Regression with one categorical predictor\n",
    "section": "",
    "text": "9.1 Chapter preparation",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regression with one categorical predictor</span>"
    ]
  },
  {
    "objectID": "08-lm-continuous.html",
    "href": "08-lm-continuous.html",
    "title": "\n8  Regression with one continuous predictor\n",
    "section": "",
    "text": "8.1 Chapter preparation",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression with one continuous predictor</span>"
    ]
  },
  {
    "objectID": "09-lm-categorical.html#09-test",
    "href": "09-lm-categorical.html#09-test",
    "title": "\n9  Regression with one categorical predictor\n",
    "section": "\n9.7 Test Yourself",
    "text": "9.7 Test Yourself\nTo end the chapter, we have some knowledge check questions to test your understanding of the concepts we covered in the chapter. Compared to previous chapters, there are no error mode questions as the content is so similar to Chapter 8. We are just going to test your understanding of the concepts rather than potential errors.\n\n9.7.1 Knowledge check\nFor this chapter’s knowledge check section, we have something a little different. Instead of purely conceptual questions about functions, we have another example of linear regression from Lopez et al. (2023). Feel free to create this model yourself, but we will show you some output and ask you questions based on it.\nFor this model, we focus on ounces of soup consumed (M_postsoup) rather than calories by each Condition group (Condition_label). You might have a good idea about the results based on the chapter, but you will still need to interpret the output accurately.\nQuestion 1. In the violin-boxplot below, the experimental group consumed more soup in ounces than the control group: \nTRUE\nFALSE.\n\n\n\n\n\n\n\n\nQuestion 2 For the next few questions, we have the output from a linear regression model and we would like you to interpret it.\n\n\n\nCall:\nlm(formula = M_postsoup ~ Condition_label, data = lopez_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-10.410  -4.467  -1.089   2.833  37.333 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                   8.8675     0.4007  22.130  &lt; 2e-16 ***\nCondition_labelExperimental   2.8426     0.5846   4.863 1.59e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.285 on 462 degrees of freedom\nMultiple R-squared:  0.04869,   Adjusted R-squared:  0.04663 \nF-statistic: 23.64 on 1 and 462 DF,  p-value: 1.591e-06\n\n\nThe outcome variable in this model is \nActual ounces of soup consumed\nExperimental condition and the predictor variable is \nActual ounces of soup consumed\nExperimental condition.\nQuestion 3 In this model, the reference group is \nControl\nExperimental and the target group is \nControl\nExperimental\nQuestion 4 Rounded to 2 decimals, we predict a value of  for our reference group.\nQuestion 5 The predictor is \nstatistically significant\nnon-significant and \npositive\nnegative.\nQuestion 6 The target group consumed on average  ounces \nless\nmore soup than the reference group."
  },
  {
    "objectID": "09-lm-categorical.html#bonus-section---one--and-paired-samples-tests",
    "href": "09-lm-categorical.html#bonus-section---one--and-paired-samples-tests",
    "title": "\n9  Regression with one categorical predictor\n",
    "section": "\n9.6 Bonus section - One- and paired-samples tests",
    "text": "9.6 Bonus section - One- and paired-samples tests\nIn this course, we focus on correlational and between-subjects designs, but you might find yourself in a situation where you want to test a continuous variable against a fixed value or compare conditions in the same participants. This is a bonus section if you have time, so you can skip to the Test Yourself section to finish the chapter if you do not.\nFor this demonstration, we will use data from experiment 1 of Bem (2011), an (in)famous study that almost single-handedly started the replication crisis in psychology. Briefly, participants completed a computer task adapted from priming experiments where they could select one of two windows. They had to guess which window had an image hidden behind it and the images contained different stimuli like erotic or neutral/control images. Across many trials of the participants guessing the location, Bem calculated the proportion of successful trials which could range between 0 (never correct), 50 (50%, chance), and 100 (always correct). The headline finding was participants demonstrated precognition - or the ability to see into the future - to guess above chance levels, but what does the data look like?\nWe are working with a new data set, so please save the following data file: Bem_2011.csv. Right click the link and select “save link as”, or clicking the link will save the files to your Downloads. Make sure that you save the file as “.csv”. Save or copy the file to your data/ folder within Chapter_09_regression_categorical. Read in the data file to the object bem_data to be consistent with the tasks below.\n\n9.6.1 One-sample comparing against a fixed value\nThere are scenarios where you want to compare a single continuous variable against a fixed value. For example, do your participants respond significantly above or below chance?\n\n9.6.1.1 Expressed as a t-test\nAs a t-test, we need to specify two arguments:\n\nx - This is the continuous variable you want to analyse and compare the mean value of. We must use the base R operator $ to specify the column from your data.\nmu - This is the fixed value you want to test your variable against.\n\nIn this scenario, we want to compare the hit rate to erotic images against a value of 50. This will tell us if the hit rate is significantly above or below chance.\n\nt.test(x = bem_data$Erotic.Hits.PC,\n       mu = 50)\n\n\n    One Sample t-test\n\ndata:  bem_data$Erotic.Hits.PC\nt = 2.5133, df = 99, p-value = 0.01358\nalternative hypothesis: true mean is not equal to 50\n95 percent confidence interval:\n 50.66075 55.61703\nsample estimates:\nmean of x \n 53.13889 \n\n\nThe output is similar to the independent samples t-test. We get the p-value for hypothesis testing, the mean estimate of the variable, and it’s 95% confidence interval. To express it as an effect size, you can subtract 50 from each value. So, participants responded 3.14% above chance, statistically significant, but hardly convincing evidence for precognition.\n\n9.6.1.2 Expressed as a linear model\nWe can also express this as a linear model, but we must first add a small wrangling step. In the one-sample t-test, we can manually enter a fixed value to compare the mean against. In a linear model, we must compare against 0 by subtracting the fixed value from your variable. So, we subtract 50 from all the observations, so they become a kind of deviation from 50.\n\nbem_data &lt;- bem_data %&gt;% \n  mutate(erotic_deviation = Erotic.Hits.PC - 50)\n\nIn contrast to previous linear models, we only add a fixed intercept and do not add a predictor. This recreates the one-sample t-test by estimating the mean value of your outcome.\n\nlm_erotic &lt;- lm(erotic_deviation ~ 1, \n                data = bem_data)\n\nsummary(lm_erotic)\n\n\nCall:\nlm(formula = erotic_deviation ~ 1, data = bem_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-28.139  -8.694   2.417   7.972  30.194 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)    3.139      1.249   2.513   0.0136 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.49 on 99 degrees of freedom\n\n\nThis process has the benefit of directly producing your effect size, as the intercept estimate is the deviation from your fixed value (here, 50). As we calculated manually before, the erotic hit rate is 3.14% above your fixed value. If you remember back to the linear model explanations, this is where the p-value for the intercept is finally useful as it tests against 0.\nIf you compare to the one-sample t-test, all of these values are identical. You also have the option of calculating confidence intervals around the estimate, calculating a standardised effect size, and checking assumptions by applying the previous linear regression activities.\n\n9.6.2 Paired-samples comparing conditions\nAlternatively, you might want to compare two conditions from the same participants in paired samples/within-subjects design. For example, is the hit-rate significantly higher for erotic images compared to control images?\n\n9.6.2.1 Expressed as a t-test\nTo conduct a paired-samples t-test, we must specify three arguments:\n\nx - This is the first level of your condition as a column. You need your data in wide format, so the condition levels are spread across two columns per participant. We must use the base R operator $ to specify the column from your data.\ny - This is the second level of your condition as a column.\npaired - This instructs R you want a paired-samples t-test to compare conditions within participants.\n\nIn this scenario, we want to compare the hit rate for erotic images to control images.\n\nt.test(x = bem_data$Erotic.Hits.PC,\n       y = bem_data$Control.Hits.PC, \n       paired = TRUE)\n\n\n    Paired t-test\n\ndata:  bem_data$Erotic.Hits.PC and bem_data$Control.Hits.PC\nt = 1.8563, df = 99, p-value = 0.06638\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -0.2277431  6.8388542\nsample estimates:\nmean difference \n       3.305556 \n\n\nThe output is almost identical to the one-sample t-test, but this time the effect size is the mean difference between conditions, not just the mean per condition. Behind the scenes, a paired-samples t-test is actually a one-sample t-test in disguise as it uses the difference between conditions as the outcome.\nAs an aside, Bem (2011) reported a significant difference here, but only because he reported a one-tailed test (alternative = \"greater\"). This is an example where you ideally need a strong (ideally pre-registered) prediction as it makes a material impact on the inferences you would make.\n\n9.6.2.2 Expressed as a linear model\nFinally, we can express a paired-samples t-test as a linear model. We must apply a small data wrangling step to calculate a difference score between conditions. This is so the linear model compares the estimate against 0 of no difference. So, for this example, we create a variable for the difference between erotic and control images.\n\nbem_data &lt;- bem_data %&gt;% \n  mutate(erotic_control = Erotic.Hits.PC - Control.Hits.PC)\n\nLike the one-sample scenario, we only add a fixed intercept for the new difference variance and do not add a predictor. This recreates the paired-samples t-test by estimating the mean value of your difference score.\n\nlm_paired &lt;- lm(erotic_control ~ 1, \n                data = bem_data)\n\nsummary(lm_paired)\n\n\nCall:\nlm(formula = erotic_control ~ 1, data = bem_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-58.861  -9.556   2.250   9.194  35.583 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)    3.306      1.781   1.856   0.0664 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 17.81 on 99 degrees of freedom\n\n\nThis process directly produces your effect size again, as the intercept estimate is the deviation from 0 for your difference score. As we saw in the paired-samples t-test output, there was a 3.31% higher hit rate for erotic images compared to control (as we calculated erotic - control).\nIf you compare to the paired-samples t-test, all of these values are identical. You also have the option of calculating confidence intervals around the estimate, calculating a standardised effect size, and checking assumptions by applying the previous linear regression activities."
  },
  {
    "objectID": "18-analysis-journey-2.html#task-preparation",
    "href": "18-analysis-journey-2.html#task-preparation",
    "title": "16  Analysis Journey 2: Simple Linear Regression",
    "section": "\n16.1 Task preparation",
    "text": "16.1 Task preparation\n\n16.1.1 Introduction to the data set\nFor this task, we are using open data from Binfet et al. (2022), where the authors used the data set to write a separate article on repurposing it for statistics education (Evans et al., 2023), inspiring us to use it in the chapter here. The abstract of their article is:\n\nResearchers have claimed that canine-assisted interventions (CAIs) contribute significantly to bolstering participants’ wellbeing, yet the mechanisms within interactions have received little empirical attention. The aim of this study was to assess the impact of client–canine contact on wellbeing outcomes in a sample of 284 undergraduate college students (77% female; 21% male, 2% non-binary). Participants self-selected to participate and were randomly assigned to one of two canine interaction treatment conditions (touch or no touch) or to a handler-only condition with no therapy dog present. To assess self-reports of wellbeing, measures of flourishing, positive and negative affect, social connectedness, happiness, integration into the campus community, stress, homesickness, and loneliness were administered. Exploratory analyses were conducted to assess whether these wellbeing measures could be considered as measuring a unidimensional construct. This included both reliability analysis and exploratory factor analysis. Based on the results of these analyses we created a composite measure using participant scores on a latent factor. We then conducted the tests of the four hypotheses using these factor scores. Results indicate that participants across all conditions experienced enhanced wellbeing on several measures; however, only those in the direct contact condition reported significant improvements on all measures of wellbeing. Additionally, direct interactions with therapy dogs through touch elicited greater wellbeing benefits than did no touch/indirect interactions or interactions with only a dog handler. Similarly, analyses using scores on the wellbeing factor indicated significant improvement in wellbeing across all conditions (handler-only, d=0.18, p=0.041; indirect, d=0.38, p&lt;0.001; direct, d=0.78, p&lt;0.001), with more benefit when a dog was present (d=0.20, p&lt;0.001), and the most benefit coming from physical contact with the dog (d=0.13, p=0.002). The findings hold implications for post-secondary wellbeing programs as well as the organization and delivery of CAIs.\n\nIn summary, they were interested in the effect of therapy dogs on well-being in undergraduate students. Participants were randomly allocated to one of three groups:\n\nCanine interaction touching the dogs (Direct).\nCanine interaction not touching the dogs (Indirect).\nHandler-only with no dogs present (Control).\n\nThey measured 9 outcomes before and after the intervention including social connectedness, stress, and loneliness. For this journey chapter, we will focus on a constrained set of variables and analyses so it does not take forever, but the process would apply to all the outcomes. The authors posed three hypotheses which we will test after some data wrangling:\n\nAll treatment groups would have significantly higher measures of well-being and lower measures of ill-being after treatment.\nThe treatment groups that interact with dogs would have significantly higher measures of well-being and lower measures of ill-being compared to the handler-only treatment.\nDirect contact with a therapy dog would yield greater benefits than indirect contact treatment.\n\n16.1.2 Organising your files and project for the task\nBefore we can get started, you need to organise your files and project for the task, so your working directory is in order.\n\nIn your folder for research methods and the book ResearchMethods1_2/Quant_Fundamentals, create a new folder for the data analysis journey called Journey_02_regression. Within Journey_02_regression, create two new folders called data and figures.\nCreate an R Project for Journey_02_regression as an existing directory for your chapter folder. This should now be your working directory.\nCreate a new R Markdown document and give it a sensible title describing the chapter, such as Analysis Journey 2 - Simple Linear Regression. Delete everything below line 10 so you have a blank file to work with and save the file in your Journey_02_regression folder.\nWe are working with a new data set, so please save the following data file: Evans_2023_raw.csv. Right click the link and select “save link as”, or clicking the link will save the files to your Downloads. Make sure that you save the file as “.csv”. Save or copy the file to your data/ folder within Journey_02_regression.\n\nYou are now ready to start working on the task!"
  },
  {
    "objectID": "18-analysis-journey-2.html#overview",
    "href": "18-analysis-journey-2.html#overview",
    "title": "16  Analysis Journey 2: Simple Linear Regression",
    "section": "\n16.2 Overview",
    "text": "16.2 Overview\n\n16.2.1 Load tidyverse and read the data file\nBefore we explore what wrangling we need to do, complete the following task list and check the solution if you are stuck.\n\n\n\n\n\n\nTry this\n\n\n\nComplete the following steps:\n\nLoad the tidyverse package.\nRead the data file data/Evans_2023_raw.csv to the object name evans_data.\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# load the relevant packages\nlibrary(tidyverse)\n\n# Read the Evans_2023_raw.csv file \nevans_data &lt;- read_csv(\"data/Evans_2023_raw.csv\")\n\n\n\n\n\n16.2.2 Explore evans_data\n\nIn evans_data, we have the participant ID (RID), several demographic variables, and pre- and post-test items for stress, loneliness, and social connectedness. There are 88 variables which would take up loads of space, so we are just showing a preview of the first 20 here. If you use glimpse(), you will see all 88.\n\n\nRows: 284\nColumns: 20\n$ RID             &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,…\n$ GroupAssignment &lt;chr&gt; \"Control\", \"Direct\", \"Indirect\", \"Control\", \"Direct\", …\n$ Age_Yrs         &lt;dbl&gt; 21, 19, 18, 18, 19, 20, 26, 17, 21, 22, 19, 20, 19, 19…\n$ Year_of_Study   &lt;dbl&gt; 3, 1, 1, 1, 1, 2, 2, 1, 3, 4, 2, 2, 2, 2, 3, 1, 1, 1, …\n$ Live_Pets       &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, NA, 2, 2, 1,…\n$ Consumer_BARK   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, …\n$ S1_1            &lt;dbl&gt; 2, 2, 4, 2, 3, 4, 4, 3, 2, 2, 3, 2, 3, 4, 3, 2, 4, 2, …\n$ L1_1            &lt;dbl&gt; 3, 3, 3, 4, 2, 4, 3, 2, 3, 4, 3, 3, 4, 4, 4, 2, 3, 4, …\n$ L1_2            &lt;dbl&gt; 3, 2, 3, 2, 3, 3, 2, 3, 4, 1, 3, 3, 2, 3, 1, 4, 3, 2, …\n$ L1_3            &lt;dbl&gt; 4, 3, 2, 2, 3, 3, 1, 3, 3, 1, 2, 2, 1, 3, 1, 3, 3, 1, …\n$ L1_4            &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 3, 3, 4, 1, 2, 3, 2, 3, 2, 4, 3, 2, …\n$ L1_5            &lt;dbl&gt; 2, 4, 3, 4, 4, 3, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 3, 4, …\n$ L1_6            &lt;dbl&gt; 3, 3, 4, 4, 3, 2, 3, 3, 3, 4, 3, 3, 4, 3, 4, 2, 2, 4, …\n$ L1_7            &lt;dbl&gt; 1, 2, 2, 1, 2, 2, 4, 2, 2, 1, 3, 2, 3, 2, 2, 2, 3, 3, …\n$ L1_8            &lt;dbl&gt; 2, 2, 3, 3, 2, 3, 2, 3, 3, 2, 3, 2, 2, 3, 2, 4, 3, 2, …\n$ L1_9            &lt;dbl&gt; 3, 4, 3, 3, 3, 3, 3, 3, 2, 4, 3, 3, 4, 4, 4, 3, 2, 3, …\n$ L1_10           &lt;dbl&gt; 4, 3, 3, 4, 2, 2, 3, 3, 3, 4, 4, 3, 4, 4, 4, 2, 2, 3, …\n$ L1_11           &lt;dbl&gt; 3, 2, 2, 2, 4, 3, 4, 2, 2, 1, 3, 2, 2, 2, 2, 4, 3, 2, …\n$ L1_12           &lt;dbl&gt; 1, 2, 2, 1, 4, 3, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 3, 1, …\n$ L1_13           &lt;dbl&gt; 3, 1, 2, 2, 4, 3, 3, 3, 4, 1, 3, 4, 2, 2, 2, 4, 3, 2, …\n\n\nThe columns (variables) we have in the data set are:\n\n\n\n\n\n\n\nVariable\nType\nDescription\n\n\n\nRID\ndouble\nParticipant ID number.\n\n\nGroupAssignment\ncharacter\nRandomly allocated study group: Control, Indirect, Direct.\n\n\nAge_Yrs\ndouble\nAge in years.\n\n\nYear_of_Study\ndouble\nParticipant’s year in college: First (1), Second (2), Third (3), Fourth (4), Fifth or more (5).\n\n\nLive_Pets\ndouble\nDoes the participant have a pet back at home: Pet back home (1), no pet back home (2).\n\n\nConsumer_BARK\ndouble\nIs the participant a low (1), medium (2), or high (3) consumer of the BARK program - the therapy dog service.\n\n\nS1_1\ndouble\nStress scale pre-test, 1 item, 1 (not at all stressed) to 5 (very stressed).\n\n\nL1_1 to L1_20\ndouble\nLoneliness scale pre-test, 20 items, 1 (never) to 4 (often).\n\n\nSC1_1 to SC1_20\ndouble\nSocial connectedness scale pre-test, 20 items, 1 (strongly disagree) to 6 (strongly agree).\n\n\nS2_1\ndouble\nStress scale post-test, 1 item.\n\n\nL2_1 to L2_20\ndouble\nLoneliness scale post-test, 20 items.\n\n\nSC2_1 to SC2_20\ndouble\nSocial connectedness scale post-test, 20 items, 1 (strongly disagree) to 6 (strongly agree).\n\n\n\n\n\n\n\n\n\nTry this\n\n\n\nNow we have introduced the data set, explore them using different methods we introduced. For example, opening the data object as a tab to scroll around, explore with glimpse(), or even try plotting some of the individual variables to see what they look like."
  },
  {
    "objectID": "18-analysis-journey-2.html#wrangling",
    "href": "18-analysis-journey-2.html#wrangling",
    "title": "16  Analysis Journey 2: Simple Linear Regression",
    "section": "\n16.3 Wrangling",
    "text": "16.3 Wrangling\nWe are going to show you a preview of the starting data set and the end product we are aiming for. For the raw data, we have limited this to the first 20 rows again just so it does not take up the whole page, but if you use glimpse() you will see all 88 variables.\n\n\nRaw data\nWrangled data\n\n\n\n\n\nRows: 284\nColumns: 20\n$ RID             &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,…\n$ GroupAssignment &lt;chr&gt; \"Control\", \"Direct\", \"Indirect\", \"Control\", \"Direct\", …\n$ Age_Yrs         &lt;dbl&gt; 21, 19, 18, 18, 19, 20, 26, 17, 21, 22, 19, 20, 19, 19…\n$ Year_of_Study   &lt;dbl&gt; 3, 1, 1, 1, 1, 2, 2, 1, 3, 4, 2, 2, 2, 2, 3, 1, 1, 1, …\n$ Live_Pets       &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, NA, 2, 2, 1,…\n$ Consumer_BARK   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, …\n$ S1_1            &lt;dbl&gt; 2, 2, 4, 2, 3, 4, 4, 3, 2, 2, 3, 2, 3, 4, 3, 2, 4, 2, …\n$ L1_1            &lt;dbl&gt; 3, 3, 3, 4, 2, 4, 3, 2, 3, 4, 3, 3, 4, 4, 4, 2, 3, 4, …\n$ L1_2            &lt;dbl&gt; 3, 2, 3, 2, 3, 3, 2, 3, 4, 1, 3, 3, 2, 3, 1, 4, 3, 2, …\n$ L1_3            &lt;dbl&gt; 4, 3, 2, 2, 3, 3, 1, 3, 3, 1, 2, 2, 1, 3, 1, 3, 3, 1, …\n$ L1_4            &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 3, 3, 4, 1, 2, 3, 2, 3, 2, 4, 3, 2, …\n$ L1_5            &lt;dbl&gt; 2, 4, 3, 4, 4, 3, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 3, 4, …\n$ L1_6            &lt;dbl&gt; 3, 3, 4, 4, 3, 2, 3, 3, 3, 4, 3, 3, 4, 3, 4, 2, 2, 4, …\n$ L1_7            &lt;dbl&gt; 1, 2, 2, 1, 2, 2, 4, 2, 2, 1, 3, 2, 3, 2, 2, 2, 3, 3, …\n$ L1_8            &lt;dbl&gt; 2, 2, 3, 3, 2, 3, 2, 3, 3, 2, 3, 2, 2, 3, 2, 4, 3, 2, …\n$ L1_9            &lt;dbl&gt; 3, 4, 3, 3, 3, 3, 3, 3, 2, 4, 3, 3, 4, 4, 4, 3, 2, 3, …\n$ L1_10           &lt;dbl&gt; 4, 3, 3, 4, 2, 2, 3, 3, 3, 4, 4, 3, 4, 4, 4, 2, 2, 3, …\n$ L1_11           &lt;dbl&gt; 3, 2, 2, 2, 4, 3, 4, 2, 2, 1, 3, 2, 2, 2, 2, 4, 3, 2, …\n$ L1_12           &lt;dbl&gt; 1, 2, 2, 1, 4, 3, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 3, 1, …\n$ L1_13           &lt;dbl&gt; 3, 1, 2, 2, 4, 3, 3, 3, 4, 1, 3, 4, 2, 2, 2, 4, 3, 2, …\n\n\n\n\n\n\nRows: 284\nColumns: 12\n$ RID             &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,…\n$ GroupAssignment &lt;chr&gt; \"Control\", \"Direct\", \"Indirect\", \"Control\", \"Direct\", …\n$ Age_Yrs         &lt;dbl&gt; 21, 19, 18, 18, 19, 20, 26, 17, 21, 22, 19, 20, 19, 19…\n$ Year_of_Study   &lt;dbl&gt; 3, 1, 1, 1, 1, 2, 2, 1, 3, 4, 2, 2, 2, 2, 3, 1, 1, 1, …\n$ Live_Pets       &lt;chr&gt; \"Does not have a pet back home\", \"Does not have a pet …\n$ Consumer_BARK   &lt;chr&gt; \"Low\", \"Low\", \"Low\", \"Low\", \"Low\", \"Low\", \"Low\", \"Low\"…\n$ stress_pre      &lt;dbl&gt; 2, 2, 4, 2, 3, 4, 4, 3, 2, 2, 3, 2, 3, 4, 3, 2, 4, 2, …\n$ stress_post     &lt;dbl&gt; 2, 1, 3, 2, 4, 4, 3, 2, 2, 1, 2, 2, 1, 2, 4, 2, 2, 1, …\n$ lonely_pre      &lt;dbl&gt; 2.25, 1.90, 2.25, 1.75, 2.85, 2.70, 2.40, 2.25, 2.55, …\n$ lonely_post     &lt;dbl&gt; 1.70, 1.60, 2.25, 2.05, 2.70, 2.40, 2.25, 2.00, 2.55, …\n$ social_pre      &lt;dbl&gt; 3.90, 5.15, 4.10, 4.65, 3.65, 4.35, 4.75, 4.60, 4.20, …\n$ social_post     &lt;dbl&gt; 3.800000, 5.263158, 4.150000, 5.100000, 3.600000, 4.65…\n\n\n\n\n\n\n\n\n\n\n\nTry this\n\n\n\nBefore we give you a task list, try and switch between the raw data and the wrangled data. Make a list of all the differences you can see between the two data objects.\n\nDo the values of variables change from numbers? How might you recode them using the code book above?\nLooking at the codebook, are some variables the same but renamed?\nLooking at the codebook, have we calculated the mean of all the items for a scale?\n\nTry and wrangle the data based on all the differences you notice to create a new object evans_wide.\nFor one hint, unless you read the original paper, there are a bunch of items that first need reverse coding you would not know about:\n\nLoneliness pre-test: L1_1, L1_5, L1_6, L1_9, L1_10, L1_15, L1_16, L1_19, L1_20.\nLoneliness post-test: L2_1, L2_5, L2_6, L2_9, L2_10, L2_15, L2_16, L2_19, L2_20.\nSocial connectedness pre-test: SC1_3, SC1_6, SC1_7, SC1_9, SC1_11, SC1_13, SC1_15, SC1_17, SC1_18, SC1_20.\nSocial connectedness post-test: SC2_3, SC2_6, SC2_7, SC2_9, SC2_11, SC2_13, SC2_15, SC2_17, SC2_18, SC2_20.\n\nWhen you get as far as you can, check the task list which explains all the steps we applied, but not how to do them. Then, you can check the solution for our code.\n\n\n\n16.3.1 Task list\n\n\n\n\n\n\nShow me the task list\n\n\n\n\n\nThese are all the steps we applied to create the wrangled data object:\n\nRecode Live_Pets to the two labels outlined in the code book.\nRecode Consumer_BARK to the three labels outlined in the code book.\nReverse code the loneliness and social connectedness items outlined above. Think of previous examples where we explained reverse coding for how you can do this efficiently.\n\nAs one extra piece of advice if you do not want to recode 40 variables one by one, there is a more advanced function you can use within mutate(). The function across() lets you apply a function or calculation to several columns at once. For example, if we wanted to reverse score items on a 4-point scale, it would look like the following:\n\nmutate(across(.cols = c(column1, column2...), \n              .fns = ~ 5 - .x))\n\nIn .cols, we enter all the columns we want to apply the function to.\nIn .fns after the =, we add the function we want to apply to all the columns we selected. The code is a little awkward as we have a tilde ~, here the calculation we want to apply, and .x in place of the column name. You could summarise it as: for all the columns I select, subtract each value from 5. Once you get used to the format, across() is really helpful when you want to do the same thing to multiple columns.\n\nAfter reverse coding the items, calculate the subscale mean scores for loneliness and social connectedness. You must do this twice per scale, as we have the 20 items for the pre-test and 20 items for the post-test per scale.\nIf you calculated the subscale mean scores individually, join them back to the evans_clean object you mutated.\n\nSelect the following columns:\n\nRID to Consumer_BARK.\nRename S1_1 to stress_pre.\nRename S2_1 to stress_post.\nSelect your four subscale mean score variables.\n\n\n\nRemember: If it’s easier for you to complete steps with longer but accurate code, there is nothing wrong with that. You recognise ways to make your code more efficient over time.\n\n\n\n\n16.3.2 Solution\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThis is the code we used to create the new object evans_wide using the original object evans_data. As long as you get the same end result, the exact code is not important. In coding, there are multiple ways of getting to the same end result. Maybe you found a more efficient way to complete some of the steps compared to us. Maybe your code was a little longer. As long as it worked, that is the most important thing.\n\n# Initial cleaning step to recode pets and BARK\n# then reverse code a bunch of items \nevans_clean &lt;- evans_data %&gt;% \n  mutate(Live_Pets = case_match(Live_Pets,\n                                1 ~ \"Has a pet back home\",\n                                2 ~ \"Does not have a pet back home\"),\n         Consumer_BARK = case_match(Consumer_BARK,\n                                    1 ~ \"Low\",\n                                    2 ~ \"Medium\",\n                                    3 ~ \"High\"),\n         # across works with mutate to apply the same function to several columns\n         # So, take all the loneliness items to reverse code, then subtract them from 5\n         across(.cols = c(L1_1, L1_5, L1_6, L1_9, L1_10, L1_15, L1_16, L1_19, L1_20,\n                          L2_1, L2_5, L2_6, L2_9, L2_10, L2_15, L2_16, L2_19, L2_20),\n                .fns = ~ 5 - .x),\n         # take all the connectedness items to reverse code, then subtract them from 7\n         across(.cols = c(SC1_3, SC1_6, SC1_7, SC1_9, SC1_11, SC1_13, SC1_15, SC1_17, SC1_18, SC1_20, \n                          SC2_3, SC2_6, SC2_7, SC2_9, SC2_11, SC2_13, SC2_15, SC2_17, SC2_18, SC2_20),\n                .fns = ~ 7 - .x))\n\n# There are more elegant ways around this, but for each set, \n# take the 20 items, group by participant ID, and calculate the mean, ignoring missing values\nlonely_pre &lt;- evans_clean %&gt;% \n  pivot_longer(cols = L1_1:L1_20, \n               names_to = \"Item\", \n               values_to = \"Response\") %&gt;% \n  group_by(RID) %&gt;% \n  summarise(lonely_pre = mean(Response, na.rm = TRUE))\n\n# Same thing for post scores\nlonely_post &lt;- evans_clean %&gt;% \n  pivot_longer(cols = L2_1:L2_20, \n               names_to = \"Item\", \n               values_to = \"Response\") %&gt;% \n  group_by(RID) %&gt;% \n  summarise(lonely_post = mean(Response, na.rm = TRUE))\n\n# take the 20 items, group by participant ID, and calculate the mean, ignoring missing values\nsocial_pre &lt;- evans_clean %&gt;% \n  pivot_longer(cols = SC1_1:SC1_20, \n               names_to = \"Item\", \n               values_to = \"Response\") %&gt;% \n  group_by(RID) %&gt;% \n  summarise(social_pre = mean(Response, na.rm = TRUE))\n\n# Same thing for post scores\nsocial_post &lt;- evans_clean %&gt;% \n  pivot_longer(cols = SC2_1:SC2_20, \n               names_to = \"Item\", \n               values_to = \"Response\") %&gt;% \n  group_by(RID) %&gt;% \n  summarise(social_post = mean(Response, na.rm = TRUE))\n\n# join all four summary values to main data\n# select just the key variables we need\n# rename the two stress items\nevans_wide &lt;- evans_clean %&gt;% \n  inner_join(lonely_pre) %&gt;% \n  inner_join(lonely_post) %&gt;% \n  inner_join(social_pre) %&gt;% \n  inner_join(social_post) %&gt;% \n  select(RID:Consumer_BARK, \n         stress_pre = S1_1, \n         stress_post = S2_1, \n         lonely_pre:social_post)"
  },
  {
    "objectID": "18-analysis-journey-2.html#summarisingvisualising",
    "href": "18-analysis-journey-2.html#summarisingvisualising",
    "title": "16  Analysis Journey 2: Simple Linear Regression",
    "section": "\n16.4 Summarising/visualising",
    "text": "16.4 Summarising/visualising\nYou should now have an object called evans_wide containing 12 variables. If you struggled completing the wrangling steps, you can copy the code from the solution to follow along from this point. In this section, we will calculate some summary statistics and plot the data to see what we can learn. We present you with a list of questions to answer using your wrangling and visualisation skills, interspersed with the solutions to check if you are stuck.\n\n16.4.1 Demographics\nFor demographics, we will recreate some values from Table 1 from Binfet et al. (2022).\n\n\nHow many participants were in each group for GroupAssignment?\n\n Control\n Direct\n Indirect\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThis nicely reproduces their values.\n\nevans_wide %&gt;% \n  count(GroupAssignment)\n\n\n\n\nGroupAssignment\nn\n\n\n\nControl\n94\n\n\nDirect\n95\n\n\nIndirect\n95\n\n\n\n\n\n\n\n\n\n\n\nTo 2 decimals, what was the mean and standard deviation age per group?\n\nControl: M = , SD = .\nDirect: M = , SD = .\nIndirect: M = , SD = .\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nWeirdly, this reproduces the standard deviations from Table 1, but not the means.\n\nevans_wide %&gt;% \n  group_by(GroupAssignment) %&gt;% \n  summarise(mean_age = round(mean(Age_Yrs), 2),\n            sd_age = round(sd(Age_Yrs), 2))\n\n\n\n\nGroupAssignment\nmean_age\nsd_age\n\n\n\nControl\n19.95\n2.89\n\n\nDirect\n19.77\n1.94\n\n\nIndirect\n19.95\n2.23\n\n\n\n\n\n\n\n\n\n\n\nHow many participants in each group have a pet at home?\n\n Control\n Direct\n Indirect\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThis nicely reproduces their values.\n\nevans_wide %&gt;% \n  count(GroupAssignment, Live_Pets)\n\n\n\n\nGroupAssignment\nLive_Pets\nn\n\n\n\nControl\nDoes not have a pet back home\n72\n\n\nControl\nHas a pet back home\n21\n\n\nControl\nNA\n1\n\n\nDirect\nDoes not have a pet back home\n63\n\n\nDirect\nHas a pet back home\n30\n\n\nDirect\nNA\n2\n\n\nIndirect\nDoes not have a pet back home\n60\n\n\nIndirect\nHas a pet back home\n34\n\n\nIndirect\nNA\n1\n\n\n\n\n\n\n\n\n\n\nThis is not part of their article, but one interesting question might be how many people have a pet at home (Live_Pets) against how frequently they use the BARK program (Consumer_BARK). Try and recreate the following bar plot to visualise this as close as possible. We have intentionally used some features we have not covered in the data visualisation chapters to get you problem solving. For one hint though, we used option D for the viridis colour scheme.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThe new features we hoped you found independently were:\n\nSetting the factor order to show Consumer_BARK as low, medium, then high.\nSet position = \"dodge\" to avoid the stacked bar chart.\nEdited the legend title by using the name argument in the scale_fill layer.\n\n\nevans_wide %&gt;% \n  drop_na(Live_Pets, Consumer_BARK) %&gt;% \n  mutate(Consumer_BARK = factor(Consumer_BARK, \n                                levels = c(\"Low\", \"Medium\", \"High\"))) %&gt;% \n  ggplot(aes(x = Live_Pets, fill = Consumer_BARK)) + \n  geom_bar(position = \"dodge\") + \n  labs(x = \"Pets in Home\", \n       y = \"Frequency\") + \n  scale_fill_viridis_d(option = \"D\", \n                       name = \"BARK Program User\") + \n  theme_classic()\n\n\n\n\n\n16.4.2 Wellbeing measures\nFor wellbeing and ill-being measures, we will recreate some values from Table 2 from Binfet et al. (2022).\n\n\nIf you calculate the mean and standard deviation of each variable per group, answer the following questions:\n\nWhich group has the lowest post-test stress value? \nControl\nDirect\nIndirect\nWhich group has the lowest post-test loneliness value? \nIndirect\nDirect\nControl\nWhich group has the lowest post-test social connectedness value? \nIndirect\nControl\nDirect\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThis table calculates the mean and standard score for each variable per group. You can use this to answer the questions above.\n\nevans_wide %&gt;% \n  pivot_longer(cols = stress_pre:social_post, \n               names_to = \"Variable\", \n               values_to = \"Value\") %&gt;% \n  group_by(GroupAssignment, Variable) %&gt;% \n  summarise(mean_score = round(mean(Value), 2), \n            sd_score = round(sd(Value), 2))\n\n`summarise()` has grouped output by 'GroupAssignment'. You can override using\nthe `.groups` argument.\n\n\n\n\n\nGroupAssignment\nVariable\nmean_score\nsd_score\n\n\n\nControl\nlonely_post\n1.96\n0.57\n\n\nControl\nlonely_pre\n2.02\n0.55\n\n\nControl\nsocial_post\n4.49\n0.87\n\n\nControl\nsocial_pre\n4.47\n0.81\n\n\nControl\nstress_post\n2.76\n1.08\n\n\nControl\nstress_pre\n3.27\n1.04\n\n\nDirect\nlonely_post\n1.82\n0.51\n\n\nDirect\nlonely_pre\n2.05\n0.56\n\n\nDirect\nsocial_post\n4.64\n0.79\n\n\nDirect\nsocial_pre\n4.42\n0.88\n\n\nDirect\nstress_post\n1.84\n0.76\n\n\nDirect\nstress_pre\n3.15\n0.98\n\n\nIndirect\nlonely_post\n1.96\n0.52\n\n\nIndirect\nlonely_pre\n2.06\n0.48\n\n\nIndirect\nsocial_post\n4.50\n0.82\n\n\nIndirect\nsocial_pre\n4.37\n0.79\n\n\nIndirect\nstress_post\n2.53\n1.00\n\n\nIndirect\nstress_pre\n3.21\n0.90\n\n\n\n\n\n\n\n\n\n\nCreate a scatterplot of the relationship between post-test social connectedness and loneliness. The relationship between the two variables is \nnegative\npositive, meaning that as social connectedness increases, we expect loneliness to \nincrease\ndecrease.\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThe code here creates a scatterplot for the relationship between post-test social connectedness and loneliness.\n\nevans_wide %&gt;% \n  ggplot(aes(x = lonely_post, y = social_post)) + \n  geom_point() + \n  geom_smooth(method = \"lm\") + \n  theme_classic() + \n  labs(x = \"Loneliness Post-test\", y = \"Social Connectedness Post-test\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\nAs we start to think about inferential statistics, we can plot the difference between pre- and post-test for each group. For this question, try and recreate the boxplot to visualise stress. Hint: think about if you need to restructure the data, and how you can present the conditions in the appropriate order.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThere are two key steps before you can plot the data. First, you need to restructure the data to long form to get one variable for pre- and post-test. Second, post comes before pre due to alphabetical order, so you need to create a factor to specify the order here.\n\nevans_wide %&gt;% \n  pivot_longer(cols = stress_pre:stress_post, \n               names_to = \"Stress\", \n               values_to = \"Value\") %&gt;% \n  mutate(Stress = factor(Stress,\n                         levels = c(\"stress_pre\", \"stress_post\"), \n                         labels = c(\"Pre-test\", \"Post-test\"))) %&gt;% \n  ggplot(aes(x = GroupAssignment, y = Value, fill = Stress)) + \n  geom_boxplot(alpha = 0.7) + \n  labs(x = \"Group Assignment\", y = \"Stress Scale\") + \n  scale_fill_viridis_d(option = \"E\", \n                       name = \"Time\") + \n  theme_classic()\n\n\n\n\n\nTry and recreate the violin-boxplot to visualise loneliness. Hint: remember how to align the different elements from Chapter 7.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThe same hints apply as question 7 as you need to restructure the data and create a new factor order so pre comes before post. As we have two grouping variables, we must specify a constant position dodge value so it does not plot weird.\n\n# specify as an object, so we only change it in one place\ndodge_value &lt;- 0.9\n\nevans_wide %&gt;% \n  pivot_longer(cols = lonely_pre:lonely_post, \n               names_to = \"Lonely\", \n               values_to = \"Value\") %&gt;% \n   mutate(Lonely = factor(Lonely,\n                          levels = c(\"lonely_pre\", \"lonely_post\"), \n                          labels = c(\"Pre-test\", \"Post-test\"))) %&gt;% \n  ggplot(aes(x = GroupAssignment, y = Value, fill = Lonely)) + \n  geom_violin(alpha = 0.5) + \n  geom_boxplot(width = 0.2, \n               alpha = 0.7,\n               fatten = NULL,\n               position = position_dodge(dodge_value)) + \n  stat_summary(fun = \"mean\", \n               geom = \"point\",\n               position = position_dodge(dodge_value)) +\n  stat_summary(fun.data = \"mean_cl_boot\", \n               geom = \"errorbar\", \n               width = .1,\n               position = position_dodge(dodge_value)) +\n  scale_fill_viridis_d(option = \"E\", \n                       name = \"Time\") + \n  labs(x = \"Group Assignment\", y = \"Loneliness Scale\") + \n  theme_classic()"
  },
  {
    "objectID": "18-analysis-journey-2.html#analysing",
    "href": "18-analysis-journey-2.html#analysing",
    "title": "16  Analysis Journey 2: Simple Linear Regression",
    "section": "\n16.5 Analysing",
    "text": "16.5 Analysing\nFinally, we turn to analysis for inferential statistics. In Evans et al. (2023), they organise the analyses from Binfet et al. (2022) into three hypotheses. You have not covered all the skills in Research Methods 1 to reproduce their analyses exactly, so we will work around an adapted set based on what we currently expect of you.\nWe present each analysis as an overview so you can think about what techniques from Chapters 8 and 9 would address it, give you instructions on what analysis we have in mind if you need guidance, then present the solution. We focus on one outcome per hypothesis, but once you are confident you are applying and interpreting the appropriate techniques, why not try the other outcomes yourself?\n\n16.5.1 Hypothesis 1\n\nHypothesis 1 is that each treatment group will increase measures of well-being (social connectedness) and decrease measures of ill-being (stress and loneliness). For this question, we focus on stress, so we expected stress to decrease.\n\n\n\n\n\n\n\nTry this\n\n\n\nThere are two ways you could approach this. Either as the whole sample, or like Evans et al. (2023) present to focus on each group separately. Think about what techniques from Chapters 8 and 9 would let you test the hypothesis that each treatment group will decrease stress at post-test compared to pre-test.\n\n\n\n\n\n\n\n\nShow me the task list\n\n\n\n\n\nFor the solution below, we are focusing on the whole sample to test whether everyone decreased stress in post-test, but you could approach it by separating the data into the three groups and then testing for the difference per group.\nTo test whether an outcome decreases between conditions in the same participants, we need a model suitable for a within-subjects design. In Chapter 9, we covered in the bonus section how to test the difference in conditions either through a paired samples-test or linear model with fixed intercept on the difference score.\n\nCalculate the difference between stress pre- and post-test.\nFit a linear model on the difference score with a fixed intercept and no predictor.\nLook at the intercept, is it positive or negative? If you calculated pre-test minus post-test, you would be looking for a postive difference as we expect lower stress at post-test. For hypothesis testing, is the p-value lower than alpha?\nWhat is the effect size? How much did stress change from pre-test to post-test? What is the confidence interval around the effect size?\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nIn the code below, we first calculate a difference score by substracting stress post-test from stress pre-test.\nWe then fit a linear model on this difference score and add a fixed intercept as we have no predictor.\nConsistent with hypothesis 1, stress was lower at post-test compared to pre-test across all participants. On average, participants decreased their stress score by 0.83 points (\\(b_0\\) = 0.83, 95% CI = [0.72, 0.95], p &lt; .001).\n\nevans_wide &lt;- evans_wide %&gt;% \n  mutate(stress_diff = stress_pre - stress_post)\n\nlm_stress &lt;- lm(stress_diff ~ 1, \n                data = evans_wide)\n\nsummary(lm_stress)\n\nconfint(lm_stress)\n\n\nCall:\nlm(formula = stress_diff ~ 1, data = evans_wide)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.8345 -0.8345  0.1655  0.1655  3.1655 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.83451    0.05657   14.75   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9534 on 283 degrees of freedom\n\n                2.5 %    97.5 %\n(Intercept) 0.7231517 0.9458623\n\n\n\n\n\n\n16.5.2 Hypothesis 2\n\nIn Hypothesis 2, we predict that the direct and indirect contact groups will have higher well-being and lower ill-being measures compared to the control group. For this question, we focus on social connectedness at post-test for a measure of well-being, so we expect higher scores in the direct and indirect groups.\n\n\n\n\n\n\n\nTry this\n\n\n\nThink about what techniques from Chapters 8 and 9 would let you test the hypothesis that the direct and indirect groups both increase social connectedness at post-test compared to the control group. Think of how you could focus on two groups at a time per analysis.\n\n\n\n\n\n\n\n\nShow me the task list\n\n\n\n\n\nFor the solution below, we apply two tests. We focus on the direct and control groups by filtering out indirect, then we focus on indirect and control by filtering out direct.\nTo test the difference between two groups on one outcome, we need a model suitable for a between-subjects design. In Chapter 9, we covered linear regression with one categorical predictor how to test the difference in an outcome between two groups.\n\nFit a linear model on the outcome social connectedness post-test with a categorical predictor of group. You will need to fit two models, one where you filter out the indirect group and one where you filter out the direct group.\nLook at the intercept, what is the predicted value for the reference group? Look at the slope, what is the estimated change to the target group? For hypothesis 2, is the direct/indirect group higher on social connectedness compared to control? For hypothesis testing, is the p-value lower than alpha?\nWhat is the effect size? How much did the two groups differ on social connectedness? What is the confidence interval around the effect size?\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nIn the code below, we first fit a linear model on social connectedness post-test and focus on the direct and control groups. There are different ways you could ignore the indirect group, but here we filter the data as we pass the data to the lm() function.\nThe direct group increased social connectedness post-test on average 0.15 points compared to the control group, but the difference was not statistically significant (\\(b_1\\) = 0.15, 95% CI = [-0.09, 0.39], p = .207).\n\nlm_direct &lt;- lm(social_post ~ GroupAssignment, \n                 data = filter(evans_wide,\n                               GroupAssignment != \"Indirect\"))\n\nsummary(lm_direct)\n\nconfint(lm_direct)\n\n\nCall:\nlm(formula = social_post ~ GroupAssignment, data = filter(evans_wide, \n    GroupAssignment != \"Indirect\"))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.2940 -0.5905  0.1338  0.6560  1.3560 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)            4.49054    0.08596  52.239   &lt;2e-16 ***\nGroupAssignmentDirect  0.15349    0.12125   1.266    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8334 on 187 degrees of freedom\nMultiple R-squared:  0.008497,  Adjusted R-squared:  0.003195 \nF-statistic: 1.603 on 1 and 187 DF,  p-value: 0.2071\n\n                            2.5 %    97.5 %\n(Intercept)            4.32096331 4.6601179\nGroupAssignmentDirect -0.08569829 0.3926749\n\n\nThe indirect group increased social connectedness post-test compared to the control group, but the difference was very small and not statistically significant (\\(b_1\\) = 0.01, 95% CI = [-0.23, 0.25], p = .936).\n\nlm_indirect &lt;- lm(social_post ~ GroupAssignment, \n                 data = filter(evans_wide,\n                               GroupAssignment != \"Direct\"))\n\nsummary(lm_indirect)\n\nconfint(lm_indirect)\n\n\nCall:\nlm(formula = social_post ~ GroupAssignment, data = filter(evans_wide, \n    GroupAssignment != \"Direct\"))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.70037 -0.59054  0.05946  0.64963  1.34963 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)             4.490541   0.087155   51.52   &lt;2e-16 ***\nGroupAssignmentIndirect 0.009833   0.122931    0.08    0.936    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.845 on 187 degrees of freedom\nMultiple R-squared:  3.422e-05, Adjusted R-squared:  -0.005313 \nF-statistic: 0.006398 on 1 and 187 DF,  p-value: 0.9363\n\n                             2.5 %    97.5 %\n(Intercept)              4.3186067 4.6624745\nGroupAssignmentIndirect -0.2326772 0.2523439\n\n\nIn Evans et al. (2023), the direct vs control comparison is significant, but they approached the analysis differently using a technique you will not learn until Research Methods 2. They control for pre-test scores by using it as an additional predictor, but you have not learnt about multiple regression yet.\n\n\n\n\n16.5.3 Hypothesis 3\n\nFinally, the third hypothesis focuses on the difference between the two contact groups. They predict that the direct contact group will lead to higher well-being and lower ill-being compared to the indirect contact group. For this question, we focus on loneliness post-test for a measure of ill-being, so we expect lower scores in the direct group.\n\n\n\n\n\n\n\nTry this\n\n\n\nThink about what techniques from Chapters 8 and 9 would let you test the hypothesis that the direct group decreases loneliness at post-test compared to the indirect group.\n\n\n\n\n\n\n\n\nShow me the task list\n\n\n\n\n\nFor this analysis, we focus on the final combination of groups, this time ignoring the control group.\nTo test the difference between two groups on one outcome, we need a model suitable for a between-subjects design. In Chapter 9, we covered linear regression with one categorical predictor how to test the difference in an outcome between two groups.\n\nFit a linear model on the outcome loneliness post-test with a categorical predictor of group. Filter the data to just focus on the direct and indirect contact groups.\nLook at the intercept, what is the predicted value for the reference group? Look at the slope, what is the estimated change to the target group? For hypothesis 3, is the direct group lower on loneliness compared to indirect? For hypothesis testing, is the p-value lower than alpha?\nWhat is the effect size? How much did the two groups differ on loneliness? What is the confidence interval around the effect size?\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nIn the code below, we first fit a linear model on loneliness post-test and focus on the direct and indirect groups. There are different ways you could ignore the indirect group, but here we filter the data as we pass the data to the lm() function.\nThe direct group decreased loneliness post-test on average 0.14 points compared to the indirect group, but the difference was not statistically significant (\\(b_1\\) = 0.14, 95% CI = [-0.01, 0.29], p = .060).\n\nlm_contact &lt;- lm(lonely_post ~ GroupAssignment, \n                 data = filter(evans_wide,\n                               GroupAssignment != \"Control\"))\n\nsummary(lm_contact)\n\nconfint(lm_contact)\n\n\nCall:\nlm(formula = lonely_post ~ GroupAssignment, data = filter(evans_wide, \n    GroupAssignment != \"Control\"))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.96457 -0.42130 -0.06457  0.32645  1.58543 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              1.82355    0.05267  34.625   &lt;2e-16 ***\nGroupAssignmentIndirect  0.14102    0.07448   1.893   0.0598 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5133 on 188 degrees of freedom\nMultiple R-squared:  0.01871,   Adjusted R-squared:  0.01349 \nF-statistic: 3.585 on 1 and 188 DF,  p-value: 0.05983\n\n                               2.5 %    97.5 %\n(Intercept)              1.719655160 1.9274363\nGroupAssignmentIndirect -0.005898489 0.2879484\n\n\nLike hypothesis 2, Evans et al. (2023) report the direct vs indirect comparison as significant, but they approached the analysis differently using a technique you will not learn until Research Methods 2. They control for pre-test scores by using it as an additional predictor, but you have not learnt about multiple regression yet."
  },
  {
    "objectID": "18-analysis-journey-2.html#conclusion",
    "href": "18-analysis-journey-2.html#conclusion",
    "title": "16  Analysis Journey 2: Simple Linear Regression",
    "section": "\n16.6 Conclusion",
    "text": "16.6 Conclusion\nWell done! Hopefully you recognised how far your skills have come to be able to do this independently, regardless of how many hints you needed. We are really starting to pile the skills up you have learnt so far, from simply using R Markdown files, to wrangling data, to visualising data, to finally applying modelling techniques for your inferential statistics.\nIf you are curious, you can read Evans et al. (2023) to see how they walk through wrangling and analysing the data. Some of the techniques we do not cover in Research Methods 1, but they have some great features like highlighting common student mistakes.\n\n\n\n\nBinfet, J.-T., Green, F. L. L., & Draper, Z. A. (2022). The Importance of Client–Canine Contact in Canine-Assisted Interventions: A Randomized Controlled Trial. Anthrozoös, 35(1), 1–22. https://doi.org/10.1080/08927936.2021.1944558\n\n\nEvans, C., Cipolli, W., Draper, Z. A., & Binfet, J.-T. (2023). Repurposing a Peer-Reviewed Publication to Engage Students in Statistics: An Illustration of Study Design, Data Collection, and Analysis. Journal of Statistics and Data Science Education, 0(0), 1–21. https://doi.org/10.1080/26939169.2023.2238018"
  },
  {
    "objectID": "09-lm-categorical.html#09-categorical",
    "href": "09-lm-categorical.html#09-categorical",
    "title": "\n9  Regression with one categorical predictor\n",
    "section": "\n9.3 Linear regression with one categorical predictor",
    "text": "9.3 Linear regression with one categorical predictor\nNow you know how to calculate a t-test in R, we can turn to simple linear regression as a more flexible tool for modelling the difference between two groups. As a reminder, there is a chapter in the Handy Workbook (McAleer, 2023) dedicated to manually calculating simple linear regression if you want to work through what the functions are doing behind the scenes.\n\n9.3.1 Activity 6 - Descriptive statistics\nFor all the information we want to include in a report, calculating descriptive statistics is helpful for the reader to show the context behind the results you present. Here, we can report the mean and standard deviation of our outcome per group.\n\nlopez_clean %&gt;% \n  group_by(Condition_label) %&gt;% \n  summarise(mean_cals = round(mean(F_CaloriesConsumed), 2), \n            sd_cals = round(mean(F_CaloriesConsumed), 2))\n\n\n\n\nCondition_label\nmean_cals\nsd_cals\n\n\n\nControl\n196.68\n196.68\n\n\nExperimental\n259.73\n259.73\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you want some reinforcement of how these skills apply to published research, look at Table 1 in Lopez et al. (2023). The means and standard deviations here (and Cohen’s d from Activity 5) exactly reproduce the values they report, apart from the SD for the control group (maybe there is a typo in their article).\n\n\n\n9.3.2 Activity 7 - Using the lm() function\nFor our research question of “is there a difference in actual calories consumed between the control and experimental group?”, we can address it with simple linear regression. In this study, we can make causal conclusions as it was an experiment to randomly allocate people into one of two groups, but you can also use regression to compare two self-selecting groups when you cannot make a causal conclusion in isolation. Think carefully about what you can conclude from your design.\nLike Chapter 8, we start by defining our regression model with a formula in the pattern outcome ~ predictor and specify the data frame you want to use. We must then use the summary() function around your model object to get all the statistics you need.\nThere are two ways you can use a categorical predictor. First, we can code groups numerically which people called dummy coding. You code your first group 0 and you code your second group as 1, which maps on directly to how the regression model works. Let’s look at the output.\n\n# Condition as a factor containing 0 and 1\nlm_cals_numbers &lt;- lm(formula = F_CaloriesConsumed ~ Condition, \n                      data = lopez_clean)\n\nsummary(lm_cals_numbers)\n\n\nCall:\nlm(formula = F_CaloriesConsumed ~ Condition, data = lopez_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-230.90  -99.09  -24.15   62.83  828.04 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  196.682      8.888  22.130  &lt; 2e-16 ***\nCondition1    63.049     12.966   4.863 1.59e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 139.4 on 462 degrees of freedom\nMultiple R-squared:  0.04869,   Adjusted R-squared:  0.04663 \nF-statistic: 23.64 on 1 and 462 DF,  p-value: 1.591e-06\n\n\nCompared to when we had a continuous predictor in Chapter 8, the output is identical. We just need to remember what the key numbers represent. The intercept is the predicted value of your outcome when your predictor is set to 0. When we have two groups coded as 0 and 1, this means the intercept is essentially the mean value of group 0 (here, the control group). We call this the reference group. You can confirm this by comparing the intercept estimate 196.68 to the mean value of the control group we calculated in Activity 6.\nThe slope estimate then represents how we predict the outcome to change for every 1-unit increase in the predictor. Since we coded the predictor 0 and 1, this just represents the shift from group 1 to group 2. We call the group we code as 1 the target group. You see the target group appended to the variable name, which is Condition1 here. So, for a categorical predictor, the slope represents the mean difference between the reference group (0) and the target group (1): 63.05. In contrast to the t-test, this is our raw/unstandardised effect size for the mean difference we do not need to manually calculate.\n\n\n\n\n\n\nDoes it matter if the slope is positive or negative?\n\n\n\nWhen you have a categorical predictor, the sign is only important for interpreting which group is bigger or smaller. The absolute size is relevant for the effect size where a larger absolute value indicates a larger effect. Whether the slope is positive or negative depends on the order of the groups and which has a larger mean. If the reference is larger than the target, you will get a negative slope. If the target is larger than the reference, you will get a positive slope.\n\n\nLike the continuous predictor, we get values for \\(R^2\\) and adjusted \\(R^2\\), showing we explain .046 (in other words, 4.6%) variance in the outcome through our condition manipulation. We then get the model fit statistics, but with a single predictor, the p-value is identifical to the slope.\nAlternatively, you can use character labels for your categorical predictor and it will still work. This time, we use Condition_label. By default, it will set the order of the reference and target groups alphabetically, but you can manually specify the order by setting factor levels.\n\n# Condition_label as characters\nlm_cals_labels &lt;- lm(formula = F_CaloriesConsumed ~ Condition_label, \n                     data = lopez_clean)\n\nsummary(lm_cals_labels)\n\n\nCall:\nlm(formula = F_CaloriesConsumed ~ Condition_label, data = lopez_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-230.90  -99.09  -24.15   62.83  828.04 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                  196.682      8.888  22.130  &lt; 2e-16 ***\nCondition_labelExperimental   63.049     12.966   4.863 1.59e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 139.4 on 462 degrees of freedom\nMultiple R-squared:  0.04869,   Adjusted R-squared:  0.04663 \nF-statistic: 23.64 on 1 and 462 DF,  p-value: 1.591e-06\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you want to test specifying the factor order to see how it affects the output, try running this code prior to the regression model:\n\n# Specify group order of Experimental then Control\nlopez_clean &lt;- lopez_clean %&gt;% \n  mutate(Condition_label = factor(Condition_label, \n                                  levels = c(\"Experimental\", \"Control\")))\n\n\n\n\n\n\n\n\n\nHow are t-tests and regression the same?\n\n\n\n\n\nIf you are interested in the relationship between the two concepts, we said a t-test was a specific application of the general linear model. In the t-test calculations, it expresses the mean difference between groups by the standard error of the difference. In essence, it describes the difference in standard errors, which we can describe with a t-distribution to calculate p-values.\nIn regression, we frame the model as how much variance you explain compared to the total amount of variance. The more variance your predictor explains, the less unexplained variance there is left over. For the slope estimate though, this is identical to the t-test as we estimate the mean difference between groups plus the standard error around the mean difference. We calculate a p-value for the slope from a t-distribution, so you get a t-value in the output.\nYou can see the process is identical by comparing the key values from the regression output to the Student t-test. We can recreate the mean difference to compare to the slope, the t-value is the same, the p-value is the same, the degrees of freedom are the same, and the 95% confidence intervals below are the same.\nSo, when you have a single categorical predictor, it is the exact same process as the Student t-test, just expressed slightly different. The only downside to this procedure is it is much more difficult to recreate the Welch t-test.\n\n\n\n\n9.3.3 Activity 8 - Calculating confidence intervals\nThe only thing we are missing is our confidence intervals around the estimates which we can calculate through the confint() function.\n\nconfint(lm_cals_numbers)\n\n                2.5 %    97.5 %\n(Intercept) 179.21657 214.14704\nCondition1   37.56915  88.52983\n\n\nNow, we can summarise the three key concepts of inferential statistics as:\n\nHypothesis testing: p &lt; .001, suggesting we can reject the null hypothesis assuming \\(\\alpha\\) = .05. The experimental group ate significantly more calories of soup than the control group.\nEffect size: \\(b_1\\) = 63.05, suggesting the experimental group ate on average 63 more calories than the control group.\nConfidence interval: [37.57, 88.53], showing the precision around the slope estimate.\n\n\n\n\n\n\n\nTry this\n\n\n\nNow it is time to test your understanding on a new set of variables. This time, use CalEstimate as your outcome, Condition_label as your predictor, and use lopez_clean as your data. We can ask the same question as Activity 5: “What is the difference in estimated calories consumed between the experimental and control groups?”.\nApply simple linear regression to get your inferential statistics and answer the following questions:\n\nHypothesis testing: Assuming \\(\\alpha\\) = .05, Condition is a \nstatistically significant\nnon-significant predictor of estimates calories consumed.\nEffect size: Rounded to 2 decimals, the Condition slope coefficient means there was a mean difference of \n133.03\n7.68\n-17.88\n11.19.\nConfidence interval: Rounded to 2 decimals, the lower bound of the slope is \n117.94\n-39.88\n148.12\n4.11 and the upper bound is \n117.94\n-39.88\n148.12\n4.11.\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThe conclusions are the same as when we calculated the t-test, where condition is not a statistically significant predictor of estimated calories consumed. As a regression model, we get the same conclusions expressed in a slightly different way. Condition is a negative but non-significant predictor (p = .111). The control group ate 17.88 (\\(b_1\\) = -17.88, 95% CI = [-39.88, 4.11]) more calories than the experimental group. We explain very little variance in estimated calories consumed (adjusted \\(R^2\\) = .003), so the condition manipulation had little effect.\n\n# Create lm object for condiiton label as a predictor\nlm_cal_est &lt;- lm(CalEstimate ~ Condition_label, \n                 data = lopez_clean)\n\n# summary of the model object\nsummary(lm_cal_est)\n\n# confidence intervals around estimates\nconfint(lm_cal_est)\n\n\nCall:\nlm(formula = CalEstimate ~ Condition_label, data = lopez_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-130.03  -83.03  -33.03   44.85  666.97 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                  133.033      7.679  17.324   &lt;2e-16 ***\nCondition_labelExperimental  -17.883     11.192  -1.598    0.111    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 119.9 on 459 degrees of freedom\n  (3 observations deleted due to missingness)\nMultiple R-squared:  0.005531,  Adjusted R-squared:  0.003365 \nF-statistic: 2.553 on 1 and 459 DF,  p-value: 0.1108\n\n                                2.5 %     97.5 %\n(Intercept)                 117.94256 148.123015\nCondition_labelExperimental -39.87763   4.111599\n\n\n\n\n\n\n9.3.4 Activity 9 - Standardising predictors\nFor simple linear regression with two levels of a categorical predictor, centering the variable does not help, but we can standardise our outcome to express the estimate in standard deviations rather than the raw units. This is analogous to calculating Cohen’s d as we express the standardised mean difference. In contrast to continuous predictors, we only need to standardise the outcome, rather than both the outcome and predictor(s). We then use the standardised variable as our outcome.\n\n# Be careful with the bracket placement to subtract the mean first\nlopez_clean &lt;-lopez_clean %&gt;% \n  mutate(actual_calories_std = (F_CaloriesConsumed - mean(F_CaloriesConsumed)) / sd(F_CaloriesConsumed))\n\n# Condition as a factor containing 0 and 1\nlm_cals_std &lt;- lm(formula = actual_calories_std ~ Condition, \n                      data = lopez_clean)\n\nsummary(lm_cals_std)\n\n\nCall:\nlm(formula = actual_calories_std ~ Condition, data = lopez_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.6173 -0.6941 -0.1692  0.4401  5.8000 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.20749    0.06225  -3.333 0.000928 ***\nCondition1   0.44163    0.09082   4.863 1.59e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9764 on 462 degrees of freedom\nMultiple R-squared:  0.04869,   Adjusted R-squared:  0.04663 \nF-statistic: 23.64 on 1 and 462 DF,  p-value: 1.591e-06\n\n\nNote, the estimate may be slightly different to directly calculating Cohen’s d as there are a few formulas. If you compare to Activity 5, we got d = 0.45 there and 0.44 here. Between the estimate and 95% confidence intervals, they are off by .02, so it does not have a material impact on the results.\n\n\n\n\n\n\nTip\n\n\n\nAs before, once you know how it works conceptually, there is a shortcut where you do not need to standardise all your variables first. The effectsize package has a handy function called standardize_parameters() which you can apply to your initial lm() object.\n\nstandardize_parameters(lm_cals_numbers)\n\n\n\n\nParameter\nStd_Coefficient\nCI\nCI_low\nCI_high\n\n\n\n(Intercept)\n-0.2074898\n0.95\n-0.3298249\n-0.0851547\n\n\nCondition1\n0.4416297\n0.95\n0.2631529\n0.6201065"
  },
  {
    "objectID": "09-lm-categorical.html#09-bonus",
    "href": "09-lm-categorical.html#09-bonus",
    "title": "\n9  Regression with one categorical predictor\n",
    "section": "\n9.6 Bonus section - One- and paired-samples tests",
    "text": "9.6 Bonus section - One- and paired-samples tests\nIn this course, we focus on correlational and between-subjects designs, but you might find yourself in a situation where you want to test a continuous variable against a fixed value or compare conditions in the same participants. This is a bonus section if you have time, so you can skip to the Test Yourself section to finish the chapter if you do not.\nFor this demonstration, we will use data from experiment 1 of Bem (2011), an (in)famous study that almost single-handedly started the replication crisis in psychology. Briefly, participants completed a computer task adapted from priming experiments where they could select one of two windows. They had to guess which window had an image hidden behind it and the images contained different stimuli like erotic or neutral/control images. Across many trials of the participants guessing the location, Bem calculated the proportion of successful trials which could range between 0 (never correct), 50 (50%, chance), and 100 (always correct). The headline finding was participants demonstrated precognition - or the ability to see into the future - to guess above chance levels, but what does the data look like?\nWe are working with a new data set, so please save the following data file: Bem_2011.csv. Right click the link and select “save link as”, or clicking the link will save the files to your Downloads. Make sure that you save the file as “.csv”. Save or copy the file to your data/ folder within Chapter_09_regression_categorical. Read in the data file to the object bem_data to be consistent with the tasks below.\n\n9.6.1 One-sample comparing against a fixed value\nThere are scenarios where you want to compare a single continuous variable against a fixed value. For example, do your participants respond significantly above or below chance?\n\n9.6.1.1 Expressed as a t-test\nAs a t-test, we need to specify two arguments:\n\nx - This is the continuous variable you want to analyse and compare the mean value of. We must use the base R operator $ to specify the column from your data.\nmu - This is the fixed value you want to test your variable against.\n\nIn this scenario, we want to compare the hit rate to erotic images against a value of 50. This will tell us if the hit rate is significantly above or below chance.\n\nt.test(x = bem_data$Erotic.Hits.PC,\n       mu = 50)\n\n\n    One Sample t-test\n\ndata:  bem_data$Erotic.Hits.PC\nt = 2.5133, df = 99, p-value = 0.01358\nalternative hypothesis: true mean is not equal to 50\n95 percent confidence interval:\n 50.66075 55.61703\nsample estimates:\nmean of x \n 53.13889 \n\n\nThe output is similar to the independent samples t-test. We get the p-value for hypothesis testing, the mean estimate of the variable, and it’s 95% confidence interval. To express it as an effect size, you can subtract 50 from each value. So, participants responded 3.14% above chance, statistically significant, but hardly convincing evidence for precognition.\n\n9.6.1.2 Expressed as a linear model\nWe can also express this as a linear model, but we must first add a small wrangling step. In the one-sample t-test, we can manually enter a fixed value to compare the mean against. In a linear model, we must compare against 0 by subtracting the fixed value from your variable. So, we subtract 50 from all the observations, so they become a kind of deviation from 50.\n\nbem_data &lt;- bem_data %&gt;% \n  mutate(erotic_deviation = Erotic.Hits.PC - 50)\n\nIn contrast to previous linear models, we only add a fixed intercept and do not add a predictor. This recreates the one-sample t-test by estimating the mean value of your outcome.\n\nlm_erotic &lt;- lm(erotic_deviation ~ 1, \n                data = bem_data)\n\nsummary(lm_erotic)\n\n\nCall:\nlm(formula = erotic_deviation ~ 1, data = bem_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-28.139  -8.694   2.417   7.972  30.194 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)    3.139      1.249   2.513   0.0136 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.49 on 99 degrees of freedom\n\n\nThis process has the benefit of directly producing your effect size, as the intercept estimate is the deviation from your fixed value (here, 50). As we calculated manually before, the erotic hit rate is 3.14% above your fixed value. If you remember back to the linear model explanations, this is where the p-value for the intercept is finally useful as it tests against 0.\nIf you compare to the one-sample t-test, all of these values are identical. You also have the option of calculating confidence intervals around the estimate, calculating a standardised effect size, and checking assumptions by applying the previous linear regression activities.\n\n9.6.2 Paired-samples comparing conditions\nAlternatively, you might want to compare two conditions from the same participants in paired samples/within-subjects design. For example, is the hit-rate significantly higher for erotic images compared to control images?\n\n9.6.2.1 Expressed as a t-test\nTo conduct a paired-samples t-test, we must specify three arguments:\n\nx - This is the first level of your condition as a column. You need your data in wide format, so the condition levels are spread across two columns per participant. We must use the base R operator $ to specify the column from your data.\ny - This is the second level of your condition as a column.\npaired - This instructs R you want a paired-samples t-test to compare conditions within participants.\n\nIn this scenario, we want to compare the hit rate for erotic images to control images.\n\nt.test(x = bem_data$Erotic.Hits.PC,\n       y = bem_data$Control.Hits.PC, \n       paired = TRUE)\n\n\n    Paired t-test\n\ndata:  bem_data$Erotic.Hits.PC and bem_data$Control.Hits.PC\nt = 1.8563, df = 99, p-value = 0.06638\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -0.2277431  6.8388542\nsample estimates:\nmean difference \n       3.305556 \n\n\nThe output is almost identical to the one-sample t-test, but this time the effect size is the mean difference between conditions, not just the mean per condition. Behind the scenes, a paired-samples t-test is actually a one-sample t-test in disguise as it uses the difference between conditions as the outcome.\nAs an aside, Bem (2011) reported a significant difference here, but only because he reported a one-tailed test (alternative = \"greater\"). This is an example where you ideally need a strong (ideally pre-registered) prediction as it makes a material impact on the inferences you would make.\n\n9.6.2.2 Expressed as a linear model\nFinally, we can express a paired-samples t-test as a linear model. We must apply a small data wrangling step to calculate a difference score between conditions. This is so the linear model compares the estimate against 0 of no difference. So, for this example, we create a variable for the difference between erotic and control images.\n\nbem_data &lt;- bem_data %&gt;% \n  mutate(erotic_control = Erotic.Hits.PC - Control.Hits.PC)\n\nLike the one-sample scenario, we only add a fixed intercept for the new difference variance and do not add a predictor. This recreates the paired-samples t-test by estimating the mean value of your difference score.\n\nlm_paired &lt;- lm(erotic_control ~ 1, \n                data = bem_data)\n\nsummary(lm_paired)\n\n\nCall:\nlm(formula = erotic_control ~ 1, data = bem_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-58.861  -9.556   2.250   9.194  35.583 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)    3.306      1.781   1.856   0.0664 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 17.81 on 99 degrees of freedom\n\n\nThis process directly produces your effect size again, as the intercept estimate is the deviation from 0 for your difference score. As we saw in the paired-samples t-test output, there was a 3.31% higher hit rate for erotic images compared to control (as we calculated erotic - control).\nIf you compare to the paired-samples t-test, all of these values are identical. You also have the option of calculating confidence intervals around the estimate, calculating a standardised effect size, and checking assumptions by applying the previous linear regression activities."
  },
  {
    "objectID": "12-anova.html#chapter-preparation",
    "href": "12-anova.html#chapter-preparation",
    "title": "\n12  One-way ANOVA\n",
    "section": "\n12.1 Chapter preparation",
    "text": "12.1 Chapter preparation\n\n12.1.1 Introduction to the data set\nFor this chapter, we are using open data from experiment 2 in James et al. (2015). The abstract of their article is:\n\nMemory of a traumatic event becomes consolidated within hours. Intrusive memories can then flash back repeatedly into the mind’s eye and cause distress. We investigated whether reconsolidation - the process during which memories become malleable when recalled - can be blocked using a cognitive task and whether such an approach can reduce these unbidden intrusions. We predicted that reconsolidation of a reactivated visual memory of experimental trauma could be disrupted by engaging in a visuospatial task that would compete for visual working memory resources. We showed that intrusive memories were virtually abolished by playing the computer game Tetris following a memory-reactivation task 24 hr after initial exposure to experimental trauma. Furthermore, both memory reactivation and playing Tetris were required to reduce subsequent intrusions (Experiment 2), consistent with reconsolidation-update mechanisms. A simple, non-invasive cognitive-task procedure administered after emotional memory has already consolidated (i.e., &gt; 24 hours after exposure to experimental trauma) may prevent the recurrence of intrusive memories of those emotional events.\n\nIn summary, they were interested in whether you can reduce intrusive memories associated with a traumatic event. Participants were randomly allocated to one of four groups and watched a video designed to be traumatic:\n\nControl\nReactivation + Tetris\nTetris\nReactivation\n\nThey measured the number of intrusive memories prior to the start of the study, then participants kept a diary to record intrusive memories about the film in the 7 days after watching it. The authors were interested in whether the combination of reactivation and playing Tetris would lead to the largest reduction in intrusive memories. You will recreate their analyses using a one-way ANOVA.\n\n12.1.2 Organising your files and project for the chapter\nBefore we can get started, you need to organise your files and project for the chapter, so your working directory is in order.\n\nIn your folder for research methods and the book ResearchMethods1_2/Quant_Fundamentals, create a new folder called Chapter_12_ANOVA. Within Chapter_12_ANOVA, create two new folders called data and figures.\nCreate an R Project for Chapter_12_ANOVA as an existing directory for your chapter folder. This should now be your working directory.\nCreate a new R Markdown document and give it a sensible title describing the chapter, such as 12 ANOVA. Delete everything below line 10 so you have a blank file to work with and save the file in your Chapter_12_ANOVA folder.\nWe are working with a new data set, so please save the following data file: James_2015.csv. Right click the link and select “save link as”, or clicking the link will save the files to your Downloads. Make sure that you save the file as “.csv”. Save or copy the file to your data/ folder within Chapter_12_ANOVA.\n\nYou are now ready to start working on the chapter!\n\n12.1.3 Activity 1 - Read and wrangle the data\nAs the first activity, try and test yourself by completing the following task list to practice your data wrangling skills. Create a final object called james_data to be consistent with the tasks below.\n\n\n\n\n\n\nTry this\n\n\n\nTo wrangle the data, complete the following tasks:\n\n\nLoad the following packages (several of these are new, so revisit Chapter 1 if you need a refresher of installing R packages, but remember not to install packages on the university computers / online server):\n\npwr\neffectsize\nbroom\nafex\nemmeans\nperformance\ntidyverse\n\n\nRead the data file data/James_2015.csv to the object name james_data.\nCreate a new variable called PID that equals row_number() to act as a participant ID which is currently missing from the data set.\nConvert Condition to a factor.\n\nSelect and rename the following three variables as we do not need the others:\n\nPID\nCondition\nRename Days_One_to_Seven_Image_Based_Intrusions_in_Intrusion_Diary to intrusions.\n\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# Load packages\nlibrary(pwr)\nlibrary(effectsize)\nlibrary(broom)\nlibrary(afex)\nlibrary(emmeans)\nlibrary(performance)\nlibrary(tidyverse)\n\n# Read data and add new column\njames_data &lt;- read_csv(\"data/James_2015.csv\") %&gt;%\n  mutate(PID = row_number(),\n         Condition = as.factor(Condition)) %&gt;% \n  select(PID, \n         Condition, \n         intrusions = Days_One_to_Seven_Image_Based_Intrusions_in_Intrusion_Diary)\n\n\n\n\n\n12.1.4 Activity 2 - Create summary statistics\nNext, we want to calculate some descriptive statistics to see some overall trends in the data. We are really interested in the scores from each experimental group rather than overall.\n\n\n\n\n\n\nTry this\n\n\n\n\nSummarise the data to show the mean, standard deviation, and standard error for the number of intrusive memories (intrusions) grouped by Condition.\nYour table should have four columns, Condition, mean, sd, and se.\n\nHint: You can calculate the standard error through: sd/sqrt(n) or sd/sqrt(length(some_variable_name).\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\njames_data %&gt;%\n  group_by(Condition) %&gt;%\n  summarise(mean = round(mean(intrusions), 2), \n            sd = round(sd(intrusions), 2), \n            se = round(sd/sqrt(length(intrusions)), 2))\n\n\n\n\nCondition\nmean\nsd\nse\n\n\n\n1\n5.11\n4.23\n1.00\n\n\n2\n1.89\n1.75\n0.41\n\n\n3\n3.89\n2.89\n0.68\n\n\n4\n4.83\n3.33\n0.78\n\n\n\n\n\n\n\n\n\n\n12.1.5 Activity 3 - Visualisation\nNow we can visualise the data. In the original paper they use a bar plot, but let’s use a better plot that gives us more information about the data.\n\n\n\n\n\n\nTry this\n\n\n\n\nCreate a violin-boxplot with the number of intrusive memories on the y-axis and condition on the x-axis (See Chapter 7 if you need a reminder).\nChange the labels on the x-axis to something more informative for the condition names.\n\nYour plot should look like this:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\njames_data %&gt;% \n  ggplot(aes(x = Condition, y = intrusions))+\n  geom_violin()+\n  geom_boxplot(width = .2) + \n  scale_y_continuous(name = \"Number of Intrusions\") + \n  scale_x_discrete(labels = c(\"Control\", \"Reactivation + Tetris\", \"Tetris\", \"Reactivation\")) + \n  theme_classic()\n\nWe can see from this plot that there are a few potential outliers in each of the groups. This information is not present in the bar plot, which is why it’s not a good idea to use them for this kind of data."
  },
  {
    "objectID": "12-anova.html#anova-a6",
    "href": "12-anova.html#anova-a6",
    "title": "\n12  One-way ANOVA\n",
    "section": "\n12.2 One-way ANOVA",
    "text": "12.2 One-way ANOVA\nNow we can run the one-way ANOVA using aov_ez() from the afex package and save it to the object mod. As well as running the ANOVA, the aov_ez() function also conducts a Levene’s test for homogeneity of variance so that we can test our final assumption.\n\n12.2.1 Activity 4 - Running a one-way ANOVA using afex\naov_ez() will likely produce some messages that look like errors, do not worry about these, they are just letting you know what it’s done. Run the code below to view the results of the ANOVA.\n\nmod &lt;- aov_ez(id = \"PID\", # the column containing the participant IDs\n              dv = \"intrusions\", # the DV \n              between = \"Condition\", # the between-subject variable\n              es = \"pes\", # sets effect size to partial eta-squared\n              type = 3, # this affects how the sum of squares is calculated, set this to 3\n              include_aov = TRUE,\n              data = james_data)\n\nmod\n\nAnova Table (Type 3 tests)\n\nResponse: intrusions\n     Effect    df   MSE      F  ges p.value\n1 Condition 3, 68 10.09 3.79 * .143    .014\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n\n\nJust like with the t-tests and correlations, we can use tidy() to make the output easier to work with. Run the below code to transform the output. Do not worry about the warning message, it is just telling you it does not know how to automatically rename the columns so it will keep the original names.\n\nmod_output &lt;- mod$anova_table %&gt;% \n  tidy()\n\nWarning in tidy.anova(.): The following column names in ANOVA output were not\nrecognized or transformed: num.Df, den.Df, MSE, ges\n\nmod_output\n\n\n\n\nterm\nnum.Df\nden.Df\nMSE\nstatistic\nges\np.value\n\n\nCondition\n3\n68\n10.08578\n3.794762\n0.1434073\n0.0140858\n\n\n\n\n\n\n\nterm = the IV\n\n\nnum.Df = degrees of freedom effect\n\nden.Df = degrees of freedom residuals\n\nMSE = Mean-squared errors\n\nstatistic = F-statistic\n\nges = effect size\n\n\np.value = p.value\n\nYou should refer to the lecture for more information on what each variable means and how it is calculated.\n\nIs the overall effect of Condition significant? \nYes\nNo\nWhat is the F-statistics to 2 decimal places? \nAccording to the rules of thumb, the effect size is \nSmall\nMedium\nLarge\n\n12.2.2 Activity 5 - Checking assumptions for ANOVA\nTo test the assumptions, we must use the model we created with aov_ez(). For a one-way independent ANOVA, the assumptions are the same as for a Student t-test / regression model with a categorical predictor:\n\nThe DV is interval or ratio data.\nThe observations should be independent.\nThe residuals should be normally distributed.\nThere should be homogeneity of variance between the groups.\n\nWe know that 1 and 2 are met because of the design of our study. To test 3, we can look at the qq-plot of the residuals. Instead of saving just the model object, we must specifically select the aov component and run our diagnostic plots.\n\nplot(mod$aov, \n     which = 2)\n\n\n\nFigure 12.1: qq-plot for model residuals.\n\n\n\nThe qq-plot shows the assumption of normality might not be ideal. Is this a problem? If the sample sizes for each group are equal, then ANOVA is robust to violations of both normality and of homogeneity of variance. If you are interested, there is a good discussion of these issues in Blanca et al. (2018) and Knief & Forstmeier (2021). We can check how many participants are in each condition using count():\n\njames_data %&gt;% \n  count(Condition)\n\n\n\n\nCondition\nn\n\n\n\n1\n18\n\n\n2\n18\n\n\n3\n18\n\n\n4\n18\n\n\n\n\n\n\nThankfully, the sample sizes are equal, so we should be OK to proceed with the ANOVA. It is not clear whether normality was checked in the original paper.\nFor the last assumption, we can test homogeneity of variance by checking the third diagnostic plot for the scale against location.\n\nplot(mod$aov, \n     which = 3)\n\n\n\nFigure 12.2: Diagnostic plot for homogeneity of variance.\n\n\n\nCompared to normality, this assumption looks closer to being supported as the variance of each group is approximately equal. James et al. (2015) suspect there might be issues with this assumption as they mention that the ANOVAs do not assume equal variance, however, the results of the ANOVA that are reported are identical to our results above where no correction has been made although the post-hoc tests are Welch t-tests (you can tell this because the degrees of freedom have been adjusted and are not whole numbers).\nWhile all of this might seem very confusing - we imagine you might be wondering what the point of assumption testing is given that it seems to be ignored - we are showing you this for three reasons:\n\nTo reassure you that sometimes the data can fail to meet the assumptions and it is still ok to use the test. To put this in statistical terms, many tests are robust to mild deviations of normality and unequal variance, particularly with equal sample sizes.\nAs a critical thinking point, to remind you that just because a piece of research has been published does not mean it is perfect and you should always evaluate whether the methods used are appropriate.\nTo reinforce the importance of pre-registration where these decisions could be made in advance, and/or open data and code so that analyses can be reproduced exactly to avoid any ambiguity about exactly what was done. In this example, given the equal sample sizes and the difference in variance between the groups isn’t too extreme, it looks like it is still appropriate to use an ANOVA but the decisions and justification for those decisions could have been more transparent.\n\n\n\n\n\n\n\nNote\n\n\n\nThe check_model() function from performance also works here, so you can see what it looks like if you run:\n\ncheck_model(mod$aov)\n\n\n\n\n12.2.3 Activity 6 - Post-hoc tests\nFor post-hoc comparisons, the paper appears to have computed Welch t-tests but there is no mention of any multiple comparison correction. We could reproduce these results by using t.test() for each of the contrasts.\nFor example, to compare condition 1 (the control group) with condition 2 (the reactivation plus tetris group) we could run:\n\njames_data %&gt;%\n  filter(Condition %in% c(\"1\", \"2\")) %&gt;%\n  droplevels() %&gt;% # ignore unused factor levels\n  t.test(intrusions ~ Condition, \n         data = .)\n\n\n    Welch Two Sample t-test\n\ndata:  intrusions by Condition\nt = 2.9893, df = 22.632, p-value = 0.006627\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n 0.990331 5.454113\nsample estimates:\nmean in group 1 mean in group 2 \n       5.111111        1.888889 \n\n\n\n\n\n\n\n\nImportant\n\n\n\nBecause Condition has four levels, we cannot just specify intrustion ~ Condition because a t-test compares two groups and it would not know which of the four to compare so first we have to filter the data and use a new function droplevels(). It’s important to remember that when it comes to R there are two things to consider, the data you can see and the underlying structure of that data. In the above code we use filter() to select only conditions 1 and 2 so that we can compare them. However, that does not change the fact that R “knows” that Condition has four levels - it does not matter if two of those levels do not have any observations any more, the underlying structure still says there are four groups. droplevels() tells R to remove any unused levels from a factor. Try running the above code but without droplevels() and see what happens.\n\n\nHowever, a quicker and better way of doing this that allows you apply a correction for multiple comparisons easily is to use emmeans() which computes all possible pairwise comparison t-tests and applies a correction to the p-value.\nFirst, we use emmeans() to run the comparisons and then we can pull out the contrasts and use tidy() to make it easier to work with.\nRun the code below. Which conditions are significantly different from each other? Are any of the comparisons different from the ones reported in the paper now that a correction for multiple comparisons has been applied?\n\nmod_pairwise &lt;-emmeans(mod, \n                       pairwise ~ Condition, \n                       adjust = \"bonferroni\")\n\nmod_contrasts &lt;- mod_pairwise$contrasts %&gt;% \n  tidy()\n\nmod_contrasts\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\ncontrast\nnull.value\nestimate\nstd.error\ndf\nstatistic\nadj.p.value\n\n\n\nCondition\nCondition1 - Condition2\n0\n3.2222222\n1.058604\n68\n3.0438406\n0.0199179\n\n\nCondition\nCondition1 - Condition3\n0\n1.2222222\n1.058604\n68\n1.1545602\n1.0000000\n\n\nCondition\nCondition1 - Condition4\n0\n0.2777778\n1.058604\n68\n0.2624001\n1.0000000\n\n\nCondition\nCondition2 - Condition3\n0\n-2.0000000\n1.058604\n68\n-1.8892804\n0.3787128\n\n\nCondition\nCondition2 - Condition4\n0\n-2.9444444\n1.058604\n68\n-2.7814405\n0.0419783\n\n\nCondition\nCondition3 - Condition4\n0\n-0.9444444\n1.058604\n68\n-0.8921602\n1.0000000\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe inquisitive among you may have noticed that mod is a list of 5 and seemingly contains the same thing three times: anova_table, aov and Anova. The reasons behind the differences are too complex to go into detail on this course (see The R Companion website here for more information) but the simple version is that anova_table and Anova use one method of calculating the results (type 3 sum of squares) and aov uses a different method (type 1 sum of squares). What’s important for your purposes is that you need to use anova_table to view the overall results (and replicate the results from papers) and aovto run the follow-up tests and to get access to the residuals (or lm() for factorial ANOVA). As always, precision and attention to detail is key.\n\n\n\n12.2.4 Activity 7 - Power and effect sizes\nFinally, we can replicate their power analysis using pwr.anova.testfrom the pwr package.\n\nOn the basis of the effect size of d = 1.14 from Experiment 1, we assumed a large effect size of f = 0.4. A sample size of 18 per condition was required in order to ensure an 80% power to detect this difference at the 5% significance level.\n\n\npwr.anova.test(k = 4, \n               f = .4, \n               sig.level = .05, \n               power = .8)\n\n\n     Balanced one-way analysis of variance power calculation \n\n              k = 4\n              n = 18.04262\n              f = 0.4\n      sig.level = 0.05\n          power = 0.8\n\nNOTE: n is number in each group\n\n\nWe have already got the effect size for the overall ANOVA, however, we should also really calculate Cohen’s d using cohens_d() from effectsize for each of the pairwise comparisons. This code is a little long because you need to do it separately for each comparison, bind them all together and then add them to mod_contrasts - just make sure your understand which bits of the code you would need to change to run this on different data. As we are binding rows and columns rather than joining, it is critical the comparisons are already in the correct order.\n\n# Calculate Cohen's d for all comparisons\nd_1_2 &lt;- cohens_d(intrusions ~ Condition, \n                 data = filter(james_data, \n                               Condition %in% c(1, 2)) %&gt;% \n                   droplevels())\n\nd_1_3 &lt;- cohens_d(intrusions ~ Condition, \n                 data = filter(james_data, \n                               Condition %in% c(1, 3)) %&gt;% \n                   droplevels()) \n\nd_1_4 &lt;- cohens_d(intrusions ~ Condition, \n                 data = filter(james_data, \n                               Condition %in% c(1, 4)) %&gt;% \n                   droplevels())\n\nd_2_3 &lt;- cohens_d(intrusions ~ Condition, \n                 data = filter(james_data, \n                               Condition %in% c(2, 3)) %&gt;% \n                   droplevels())\n\nd_2_4 &lt;- cohens_d(intrusions ~ Condition, \n                 data = filter(james_data, \n                               Condition %in% c(2, 4)) %&gt;% \n                   droplevels())\n\nd_3_4 &lt;- cohens_d(intrusions ~ Condition, \n                 data = filter(james_data, \n                               Condition %in% c(3, 4)) %&gt;% \n                   droplevels())\n\n# Bind all the comparisons in the order of mod_contrasts\npairwise_ds &lt;- bind_rows(d_1_2, \n                         d_1_3, \n                         d_1_4,\n                         d_2_3, \n                         d_2_4, \n                         d_3_4)\n\n# Bind this object to the mod_contrasts object\nmod_contrasts &lt;- mod_contrasts %&gt;%\n  bind_cols(pairwise_ds)\n\n\n\n\n\n\n\nWarning\n\n\n\nWhat are your options if the data do not meet the assumptions and it’s really not appropriate to continue with a regular one-way ANOVA? As always, there are multiple options and it is a judgement call.\n\nYou could run a non-parametric test, the Kruskal-Wallis for between-subject designs and the Friedman test for within-subject designs.\nIf normality is the problem, you could try transforming the data.\nYou could use bootstrapping, which is not something we will cover in this course at all."
  },
  {
    "objectID": "12-anova.html#anova-a10",
    "href": "12-anova.html#anova-a10",
    "title": "\n12  One-way ANOVA\n",
    "section": "\n12.3 Reporting the results of your ANOVA",
    "text": "12.3 Reporting the results of your ANOVA\nThe below code replicates the write-up in the paper, although has changed the Welch t-test to the pairwise comparisons from emmeans().\n\nSecond, and critically, for the 7-day diary postintervention, there was a significant difference between groups in overall intrusion frequency in daily life, F(`r mod_output$num.Df`, `r mod_output$den.Df`) = `r mod_output$statistic %&gt;% round(2)`, p = `r mod_output$p.value %&gt;% round(3)`, ηp2 = .`r mod_output$ges %&gt;% round(2)`. Planned comparisons demonstrated that relative to the no-task control group, only those in the reactivation-plus-Tetris group, t(`r mod_contrasts$df[1]`) = `r mod_contrasts$statistic[1] %&gt;% round(2)`, p = `r mod_contrasts$adj.p.value[1] %&gt;% round(2)`, d = `r mod_contrasts$Cohens_d[1] %&gt;% round(2)`, experienced significantly fewer intrusive memories; this finding replicated Experiment 1. The reactivation-plus-Tetris group had significantly fewer intrusive thoughts than the reactivation-only group, t(`r mod_contrasts$df[5]`) = `r mod_contrasts$statistic[5] %&gt;% round(2)`, p = `r mod_contrasts$adj.p.value[5] %&gt;% round(2)`, d = `r mod_contrasts$Cohens_d[5] %&gt;% round(2)`. Further, there were no significant differences between the reactivation-plus-Tetris group and the Tetris-only group, t(`r mod_contrasts$df[4]`) = `r mod_contrasts$statistic[4] %&gt;% round(2)`, p = `r mod_contrasts$adj.p.value[4] %&gt;% round(2)`, d = `r mod_contrasts$Cohens_d[4] %&gt;% round(2)`, the no-task control group and the reactivation-only group, t(`r mod_contrasts$df[3]`) = `r mod_contrasts$statistic[3] %&gt;% round(2)`, p = `r mod_contrasts$adj.p.value[3] %&gt;% round(2)`, or between the no-task control group and the Tetris-only group, t(`r mod_contrasts$df[2]`) = `r mod_contrasts$statistic[2] %&gt;% round(2)`, p = `r mod_contrasts$adj.p.value[2] %&gt;% round(2)`\n\nIf you add that code to your R Markdown document, knitting it should create the following:\n\nSecond, and critically, for the 7-day diary postintervention, there was a significant difference between groups in overall intrusion frequency in daily life, F(3, 68) = 3.79, p = 0.014, ηp2 = .0.14. Planned comparisons demonstrated that relative to the no-task control group, only those in the reactivation-plus-Tetris group, t(68) = 3.04, p = 0.02, d = 1, experienced significantly fewer intrusive memories; this finding replicated Experiment 1. Critically, as predicted by reconsolidation theory, the reactivation-plus-Tetris group had significantly fewer intrusive memories than the Tetris-only group, t(68) = -1.89, p = 0.38, d = -0.84, as well as the reactivation-only group, t(68) = -2.78, p = 0.04, d = -1.11. Further, there were no significant differences between the no-task control group and the reactivation-only group, t(68) = 0.26, p = 1, or between the no-task control group and the Tetris-only group, t(68) = 1.15, p = 1"
  },
  {
    "objectID": "12-anova.html#end-of-chapter",
    "href": "12-anova.html#end-of-chapter",
    "title": "\n12  One-way ANOVA\n",
    "section": "\n12.4 End of chapter",
    "text": "12.4 End of chapter\nWell done! You have now covered how to run a one-way ANOVA using the afex package. Linear regression models are great for their flexibility, but it is not always simple for expressing a design with several levels. Combining afex and emmeans is a powerful combination when you have categorical independent variables / predictors with several levels.\nIn the next chapter, we will extend this to when you have multiple independent variables and you want to investigate the interaction between them for how they affect your dependent variable / outcome.\n\n\n\n\nBlanca, M. J., Alarcón, R., Arnau, J., Bono, R., & Bendayan, R. (2018). Effect of variance ratio on ANOVA robustness: Might 1.5 be the limit? Behavior Research Methods, 50(3), 937–962. https://doi.org/10.3758/s13428-017-0918-2\n\n\nJames, E. L., Bonsall, M. B., Hoppitt, L., Tunbridge, E. M., Geddes, J. R., Milton, A. L., & Holmes, E. A. (2015). Computer Game Play Reduces Intrusive Memories of Experimental Trauma via Reconsolidation-Update Mechanisms: Psychological Science, 26(8), 1201–1215. https://doi.org/10.1177/0956797615583071\n\n\nKnief, U., & Forstmeier, W. (2021). Violating the normality assumption may be the lesser of two evils. Behavior Research Methods, 53(6), 2576–2590. https://doi.org/10.3758/s13428-021-01587-5"
  },
  {
    "objectID": "13-factorial-anova.html#chapter-preparation",
    "href": "13-factorial-anova.html#chapter-preparation",
    "title": "\n13  Factorial ANOVA\n",
    "section": "\n13.1 Chapter preparation",
    "text": "13.1 Chapter preparation\n\n13.1.1 Introduction to the data set\nFor this chapter, we are using open data from experiment 3 in Zhang et al. (2014) which you might remember from Chapter 7. Now you have developed your inferential skills, we can return to reproduce their analyses. The abstract of their article is:\n\nAlthough documenting everyday activities may seem trivial, four studies reveal that creating records of the present generates unexpected benefits by allowing future rediscoveries. In Study 1, we used a time-capsule paradigm to show that individuals underestimate the extent to which rediscovering experiences from the past will be curiosity provoking and interesting in the future. In Studies 2 and 3, we found that people are particularly likely to underestimate the pleasure of rediscovering ordinary, mundane experiences, as opposed to extraordinary experiences. Finally, Study 4 demonstrates that underestimating the pleasure of rediscovery leads to time-inconsistent choices: Individuals forgo opportunities to document the present but then prefer rediscovering those moments in the future to engaging in an alternative fun activity. Underestimating the value of rediscovery is linked to people’s erroneous faith in their memory of everyday events. By documenting the present, people provide themselves with the opportunity to rediscover mundane moments that may otherwise have been forgotten.\n\nIn summary, they were interested in whether people could predict how interested they would be in rediscovering past experiences. They call it a “time capsule” effect, where people store photos or messages to remind themselves of past events in the future. They predicted participants in the ordinary group would underestimate their future feelings (i.e., there would be a bigger difference between time 1 and time 2 measures) compared to participants in the extraordinary group.\nNow we are focusing on the analysis rather than just visualisation, we can describe the experiment as a 2 x 2 mixed design. The first IV is time (time1, time2) and is within-subjects. The second IV is type of event (ordinary vs. extraordinary) and is a between-subjects factor. We will then use interest as a DV for a composite measure which took the mean of items on interest, meaningfulness, and enjoyment\n\n13.1.2 Organising your files and project for the chapter\nBefore we can get started, you need to organise your files and project for the chapter, so your working directory is in order.\n\nIn your folder for research methods and the book ResearchMethods1_2/Quant_Fundamentals, create a new folder called Chapter_13_F_ANOVA. Within Chapter_13_F_ANOVA, create two new folders called data and figures.\nCreate an R Project for Chapter_13_F_ANOVA as an existing directory for your chapter folder. This should now be your working directory.\nCreate a new R Markdown document and give it a sensible title describing the chapter, such as 13 Factorial ANOVA. Delete everything below line 10 so you have a blank file to work with and save the file in your Chapter_13_F_ANOVA folder.\nIf you must download the data again, please save the following file: Zhang_2014.csv. Right click the link and select “save link as”, or clicking the link will save the files to your Downloads. Make sure that you save the file as “.csv”. Save or copy the file to your data/ folder within Chapter_13_F_ANOVA.\n\nYou are now ready to start working on the chapter!\n\n13.1.3 Activity 1 - Load the packages and read the data\nWe already worked on the data wrangling in Chapter 7, so please type or copy and paste the following code to prepare for the chapter.\n\n# Load the packages below\n#library(\"rcompanion\")\nlibrary(effectsize)\n#library(\"car\")\nlibrary(broom)\nlibrary(afex)\nlibrary(emmeans)\nlibrary(tidyverse)\nlibrary(performance)\n\n# Load the data file\n# This should be the Zhang_2014.csv file \nzhang_data &lt;- read_csv(\"data/Zhang_2014.csv\")\n\n# Wrangle the data for plotting. \n# select and rename key variables\n# mutate to add participant ID and recode\nzhang_wide &lt;- zhang_data %&gt;%\n  select(Gender, \n         Age, \n         Condition, \n         time1_interest = T1_Predicted_Interest_Composite, \n         time2_interest = T2_Actual_Interest_Composite) %&gt;%\n  mutate(participant_ID = row_number(),\n         Condition = case_match(Condition, \n                            1 ~ \"Ordinary\", \n                            2 ~ \"Extraordinary\"))\n\nzhang_long &lt;- zhang_wide %&gt;% \n  pivot_longer(cols = time1_interest:time2_interest,\n               names_to = \"Time\",\n               values_to = \"Interest\")\n\nFor different functions, we need the data in wide- or long-format, so we have two versions of the data prepared for the chapter. Pay careful attention to when you need one version or the other.\n\n13.1.4 Activity 2 - Calculate descriptive statistics\n\n\n\n\n\n\nTry this\n\n\n\nBefore we start on the inferential statistics, one key part of understanding your data and reporting for context in a report is calculating descriptive statistics like the mean and standard deviation.\nFor the combination of Condition and Time, calculate the mean and standard deviation of Interest. We will need this at the end of the chapter, so save your results to the object name zhang_descriptives.\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\nzhang_descriptives &lt;- zhang_long %&gt;%\n  group_by(Condition, Time) %&gt;%\n  summarise(mean = round(mean(Interest, na.rm = TRUE), 2),\n            sd = round(sd(Interest, na.rm = TRUE), 2))\n\n`summarise()` has grouped output by 'Condition'. You can override using the\n`.groups` argument.\n\nzhang_descriptives\n\n\n\n\nCondition\nTime\nmean\nsd\n\n\n\nExtraordinary\ntime1_interest\n4.36\n1.13\n\n\nExtraordinary\ntime2_interest\n4.65\n1.14\n\n\nOrdinary\ntime1_interest\n4.04\n1.09\n\n\nOrdinary\ntime2_interest\n4.73\n1.24\n\n\n\n\n\n\n\n\n\n\n13.1.5 Activity 3 - Create a violin-boxplot\nTo communicate your findings, it is also important to visualise your data. Initially, this might be a quick boxplot for exploratory data analysis, but something like a violin-boxplot would be great for communicating your findings in a report.\n\n\n\n\n\n\nTry this\n\n\n\nTry and recreate the following violin-boxplot that you learnt how to create in Chapter 7. The finer details like the colour scheme are not important, but see how many features you can recreate before checking the code.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# specify as an object, so we only change it in one place\ndodge_value &lt;- 0.9\n\nzhang_long %&gt;% \n  mutate(Time = case_match(Time,\n                           \"time1_interest\" ~ \"Time 1\",\n                           \"time2_interest\" ~ \"Time 2\")) %&gt;% \n  ggplot(aes(y = Interest, x = Condition, fill = Time)) +\n  geom_violin(alpha = 0.5) + \n  geom_boxplot(width = 0.2, \n               alpha = 0.7,\n               fatten = NULL,\n               position = position_dodge(dodge_value)) + \n  stat_summary(fun = \"mean\", \n               geom = \"point\",\n               position = position_dodge(dodge_value)) +\n  stat_summary(fun.data = \"mean_cl_boot\", \n               geom = \"errorbar\", \n               width = .1,\n               position = position_dodge(dodge_value)) +\n  scale_fill_viridis_d(option = \"E\") + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7)) + \n  theme_classic()"
  },
  {
    "objectID": "13-factorial-anova.html#factorial-a5",
    "href": "13-factorial-anova.html#factorial-a5",
    "title": "\n13  Factorial ANOVA\n",
    "section": "\n13.2 Factorial ANOVA",
    "text": "13.2 Factorial ANOVA\nTo run the factorial ANOVA, we will be using the afex package again. Remember that you must specify both IVs, one of which is between-subjects and the other is within-subjects. Look up the help documentation for aov_ez if you need further information.\n\n13.2.1 Activity 4 - Using the aov_ez() function.\nBefore we show you the code, try and complete the following skeleton version first. Think about what variable in the data corresponds to each argument.\nSave the ANOVA model to an object called mod_factorial to be consistent with explanations below. For making it easier to report the results later, pull out the mod_factorial$anova_table component and apply the tidy() function from broom as a second step.\n\nmod_factorial &lt;- aov_ez(id = \"NULL\",\n               data = NULL, \n               between = \"NULL\", \n               within = \"NULL\",\n               dv = \"NULL\", \n               type = 3,\n               es = \"NULL\") \n\nfactorial_output &lt;- NULL\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\nmod_factorial &lt;- aov_ez(id = \"participant_ID\",\n               data = zhang_long, \n               between = \"Condition\", \n               within = \"Time\",\n               dv = \"Interest\", \n               type = 3,\n               include_aov = TRUE,\n               es = \"pes\") \n\nfactorial_output &lt;- mod_factorial$anova_table %&gt;% \n  tidy()\n\nWe can look at the results of the factorial ANOVA by printing the object.\n\nmod_factorial\n\nAnova Table (Type 3 tests)\n\nResponse: Interest\n          Effect     df  MSE         F  ges p.value\n1      Condition 1, 128 2.05      0.46 .003    .498\n2           Time 1, 128 0.61 25.88 *** .044   &lt;.001\n3 Condition:Time 1, 128 0.61    4.44 * .008    .037\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n\n\n\n\n\nLook at the results. Remember the pre-class information about how to read p-values in scientific notation.\n\nIs the main effect of Condition significant? \nYes\nNo\nIs the main effect of Time significant? \nYes\nNo\nIs the two-way interaction significant? \nYes\nNo\n\n13.2.2 Activity 5 - Checking assumptions for factorial ANOVA\nThe assumptions for a factorial ANOVA are the same as the one-way ANOVA.\n\nThe DV is interval or ratio data.\nThe observations should be independent.\nThe residuals should be normally distributed.\nThere should be homogeneity of variance between the groups.\n\nAs before, we know assumption 2 is met from the design of the study. Assumption 1 throws up an interesting issue which is the problem of ordinal data. Ordinal data are the kind of data that come from Likert scales and are very common in psychology. The problem is that ordinal data are not interval or ratio data, there’s a fixed number of integer values they can take (the values of the Likert scale) and you cannot claim that the distance between the values is equal (is the difference between strongly agree and agree the same as the difference between agree and neutral?).\nTechnically, we should not use an ANOVA to analyse ordinal data - but almost everyone does. Many people argue that if you take the average of multiple Likert scale items, you can interpret the data as if they are interval and they can be normally distributed. Other people argue you should use non-parametric methods or more complex models such as ordinal regression for this type of data, but it is beyond the scope of what we cover in this course (if you are super interested, there is a PsyTeachR book for another course - Statistics and Research Design - which covers ordinal regression). Whichever route you choose, you should understand the data you have and you should be able to justify your decision.\nTo test assumption 3, you can run check_model() from performance on the model object (mod_factorial). Unless you add the argument re_formula = NA, you get a little warning saying the function does it anyway. The background of this argument is beyond the scope of this course, but expressed as a linear model, a mixed ANOVA looks like something called a mixed-effects model, so this argument is saying that there is not a formula for it, since we did not have one.\n\ncheck_model(mod_factorial, \n            re_formula = NA) # Specify or you get a warning \n\n\n\n\n\n\n\nDoes it look like we have any obvious problems with normality here? \nYes\nNo\nThe one annoying thing here is we do not get a diagnostic plot for checking homogeneity of variance / homoscedasticity. We can create our own using the lm component of the model object (mod_factorial$lm), but it takes a few steps. In the code below:\n\nWe first isolate the standardised residuals of the model object. We must convert it to a data frame and rename the two columns.\nWe combine the residuals with the wide version of the data.\nWe pivot the data longer so all the residuals are in one column and create a new variable to take the square root of the absolute residuals. This recreates how the diagnostic plots you saw in Chapters 8, 9, and 12 look.\nFinally, we plot the standardised residuals and add a line to join the means of each group. If the line is roughly flat, we support homoscedasticity. If the line angles up or down substantially, then this points to signs of heteroscedasticity.\n\n\n# Isolate standardised residuals as a data frame\nresiduals &lt;- as.data.frame(rstandard(mod_factorial$lm)) %&gt;% \n  select(residuals_time1 = time1_interest,\n         residuals_time2 = time2_interest)\n\n# add residuals to the wide version of the data, so we have the groups\nzhang_wide &lt;- zhang_wide %&gt;% \n  bind_cols(residuals)\n\n# Pivot longer and calculate the square root of absolute standardised residuals\nresiduals_long &lt;- zhang_wide %&gt;% \n  pivot_longer(cols = residuals_time1:residuals_time2, \n               names_to = \"Time\", \n               values_to = \"Residuals\") %&gt;% \n  mutate(std_residuals = sqrt(abs(Residuals)))\n\n# Plot the residuals\nresiduals_long %&gt;%\n  # we need groups as numbers for the line to plot \n  mutate(Condition = case_match(Condition,\n                                \"Ordinary\" ~ 1,\n                                \"Extraordinary\" ~ 2)) %&gt;% \n  ggplot(aes(x = Condition, y = std_residuals)) + \n  geom_point() + \n  # add line joining the mean of residuals per group\n  stat_summary(geom = \"line\", \n               fun = mean, \n               color = \"blue\", \n               linewidth = 1.5) + \n    labs(x = \"Condition\", y = \"Standardised Residuals\")\n\n\n\n\n\n\n\nDoes it look like we have any obvious problems with homoscedasticity here? \nYes\nNo\n\n13.2.3 Activity 6 - Post-hoc tests\nBecause the interaction is significant, we should follow this up with post-hoc tests using emmeans() to determine which comparisons are significant. If the overall interaction is not significant, you should not conduct additional tests.\nemmeans() requires you to specify the aov object, and then the factors you want to contrast. For an interaction, we use the notation pairwise ~ IV1 | IV2 and you specify which multiple comparison correction you want to apply.\nRun the below code and view the results.\n\n# run the tests\nposthoc_factorial &lt;- emmeans(mod_factorial, \n                             pairwise ~ Time | Condition, \n                             adjust = \"bonferroni\")\n\nposthoc_factorial\n\n$emmeans\nCondition = Extraordinary:\n Time           emmean    SE  df lower.CL upper.CL\n time1_interest   4.36 0.137 128     4.09     4.63\n time2_interest   4.65 0.147 128     4.36     4.94\n\nCondition = Ordinary:\n Time           emmean    SE  df lower.CL upper.CL\n time1_interest   4.04 0.139 128     3.76     4.31\n time2_interest   4.73 0.149 128     4.44     5.03\n\nConfidence level used: 0.95 \n\n$contrasts\nCondition = Extraordinary:\n contrast                        estimate    SE  df t.ratio p.value\n time1_interest - time2_interest   -0.288 0.136 128  -2.123  0.0357\n\nCondition = Ordinary:\n contrast                        estimate    SE  df t.ratio p.value\n time1_interest - time2_interest   -0.695 0.138 128  -5.049  &lt;.0001\n\n\nIn the output, we first get the estimated marginal means for the combination of IVs. We then get the contrasts we requested. This looks at the difference in levels of the first IV for each level of the second IV.\nYou can use tidy() to tidy up the output of the contrasts and save it into a tibble which makes it easier to use in inline code later.\n\n# tidy up the output of the tests\ncontrasts_factorial &lt;- posthoc_factorial$contrasts %&gt;%\n  tidy()\n\ncontrasts_factorial\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCondition\nterm\ncontrast\nnull.value\nestimate\nstd.error\ndf\nstatistic\np.value\n\n\n\nExtraordinary\nTime\ntime1_interest - time2_interest\n0\n-0.2878788\n0.1356011\n128\n-2.122983\n0.0356806\n\n\nOrdinary\nTime\ntime1_interest - time2_interest\n0\n-0.6953125\n0.1377035\n128\n-5.049343\n0.0000015\n\n\n\n\n\n\nNote that because there are two IVs/factors, we could also reverse the order. Above, we get the results contrasting time 1 and time 2 for each event condition. Instead, we could look at the difference between ordinary and extraordinary events at each time point.\nRun the code below and compare the output to contrast_factorial. Look at how the contrasts are expressed subtly different when you switch the order. Think carefully about your research question and hypotheses for which way around is the most informative.\n\nposthoc_factorial2 &lt;- emmeans(mod_factorial, \n                             pairwise ~ Condition | Time, \n                             adjust = \"bonferroni\") \n\nposthoc_factorial2\n\ncontrasts_factorial2 &lt;- posthoc_factorial2$contrasts %&gt;%\n  tidy()\n\ncontrasts_factorial2\n\n$emmeans\nTime = time1_interest:\n Condition     emmean    SE  df lower.CL upper.CL\n Extraordinary   4.36 0.137 128     4.09     4.63\n Ordinary        4.04 0.139 128     3.76     4.31\n\nTime = time2_interest:\n Condition     emmean    SE  df lower.CL upper.CL\n Extraordinary   4.65 0.147 128     4.36     4.94\n Ordinary        4.73 0.149 128     4.44     5.03\n\nConfidence level used: 0.95 \n\n$contrasts\nTime = time1_interest:\n contrast                 estimate    SE  df t.ratio p.value\n Extraordinary - Ordinary   0.3246 0.195 128   1.661  0.0992\n\nTime = time2_interest:\n contrast                 estimate    SE  df t.ratio p.value\n Extraordinary - Ordinary  -0.0829 0.209 128  -0.397  0.6923\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTime\nterm\ncontrast\nnull.value\nestimate\nstd.error\ndf\nstatistic\np.value\n\n\n\ntime1_interest\nCondition\nExtraordinary - Ordinary\n0\n0.3245739\n0.1954025\n128\n1.6610529\n0.0991504\n\n\ntime2_interest\nCondition\nExtraordinary - Ordinary\n0\n-0.0828598\n0.2088845\n128\n-0.3966778\n0.6922656\n\n\n\n\n\n\nBecause our main effects (condition and time) only have two levels, we do not need to do any post-hoc tests to determine which conditions differ from each other, however, if one of our factors had three levels then we could use emmeans() to calculate the contrast for the main effects, like we did for the one-way ANOVA.\nFinally, to calculate standardised effect sizes for the pairwise comparisons, we again need to do this individually using cohens_d() from effectsize.\nAs we have a mixed design, we must follow a slightly different process for each comparison. Cohen’s d has a different calculation for between-subjects and within-subjects contrasts, so we must express it differently. For the first comparison, we are interested in the difference between time 1 and time 2 for each group, so this represents a within-subjects comparison.\n\n# time 1 vs time 2 for Extraordinary group\nd_extraordinary &lt;- cohens_d(x = \"time1_interest\", \n                            y = \"time2_interest\", \n                            paired = TRUE,\n                            data = filter(zhang_wide, \n                                          Condition == \"Extraordinary\"))\n# time 1 vs time 2 for Ordinary group\nd_ordinary &lt;- cohens_d(x = \"time1_interest\", \n                       y = \"time2_interest\", \n                       paired = TRUE,\n                       data = filter(zhang_wide, \n                                     Condition == \"Ordinary\"))\n\n# bind together the two contrasts\nCondition_ds &lt;- bind_rows(d_extraordinary, \n                          d_ordinary)\n\n# add the contrasts to the emmeans tidy table\ncontrasts_factorial &lt;- contrasts_factorial %&gt;%\n  bind_cols(Condition_ds)\n\ncontrasts_factorial\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCondition\nterm\ncontrast\nnull.value\nestimate\nstd.error\ndf\nstatistic\np.value\nCohens_d\nCI\nCI_low\nCI_high\n\n\n\nExtraordinary\nTime\ntime1_interest - time2_interest\n0\n-0.2878788\n0.1356011\n128\n-2.122983\n0.0356806\n-0.3086922\n0.95\n-0.554559\n-0.0605597\n\n\nOrdinary\nTime\ntime1_interest - time2_interest\n0\n-0.6953125\n0.1377035\n128\n-5.049343\n0.0000015\n-0.5552045\n0.95\n-0.816696\n-0.2898832\n\n\n\n\n\n\nFor the second comparison, we are interested in the difference between ordinary and extraordinary at each time point, so this represents a between-subjects comparison.\n\n# Extraordinary vs ordinary at time 1\nd_time1 &lt;- cohens_d(time1_interest ~ Condition,\n                       data = zhang_wide)\n\n# Extraordinary vs ordinary at time 2\nd_time2 &lt;- cohens_d(time2_interest ~ Condition,\n                       data = zhang_wide)\n\n# bind the two contrasts together\nTime_ds &lt;- bind_rows(d_time1,\n                     d_time2)\n\n# add the contrasts to the emmeans tidy table\ncontrasts_factorial2 &lt;- contrasts_factorial2 %&gt;%\n  bind_cols(Time_ds)\n\ncontrasts_factorial2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTime\nterm\ncontrast\nnull.value\nestimate\nstd.error\ndf\nstatistic\np.value\nCohens_d\nCI\nCI_low\nCI_high\n\n\n\ntime1_interest\nCondition\nExtraordinary - Ordinary\n0\n0.3245739\n0.1954025\n128\n1.6610529\n0.0991504\n0.2914024\n0.95\n-0.0548458\n0.6365251\n\n\ntime2_interest\nCondition\nExtraordinary - Ordinary\n0\n-0.0828598\n0.2088845\n128\n-0.3966778\n0.6922656\n-0.0695901\n0.95\n-0.4134010\n0.2744922\n\n\n\n\n\n\n\n13.2.4 Activity 7 - Creating an interaction plot\nWhen you have a factorial design, one powerful way of visualising the data is through an interaction plot. This is essentially a line graph where the x-axis has one IV and separate lines for a second IV. However, once you have the factorial ANOVA model, you can add confidence intervals to the plot to visualise uncertainty. afex has it’s own function called afex_plot() which you can use with the model object you created.\nIn the code below, there are a few key argument to highlight:\n\nobject is the afex model you created.\nx is the variable you want on the x-axis.\ntrace is the variable you want to plot as separate lines.\nerror controls whether the error bars show confidence intervals for between-subjects or within-subjects. In a mixed design, these have different properties, so you must think about which you want to plot and highlight to the reader.\nfactor_levels lets you edit the levels of factors you plot, such as renaming or reordering them. You add each factor into a list but check the documentation and vignettes for other options.\n\n\nafex_plot(object = mod_factorial, \n          x = \"Condition\", \n          trace = \"Time\", \n          error = \"between\",\n          factor_levels = list(Time = c(\"Time 1\", \"Time 2\")))\n\n\n\n\n\n\n\nOne handy feature about this function is it uses ggplot2 in the background, so you can add layers to the initial function like other plots that you have created.\n\nafex_plot(mod_factorial, \n          x = \"Condition\", \n          trace = \"Time\", \n          error = \"between\",\n          factor_levels = list(Time = c(\"Time 1\", \"Time 2\"))) + \n  theme_classic() + \n  scale_y_continuous(breaks = 1:7)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nSince afex_plot() uses ggplot2, you can use ggsave() to save your plots and insert them into your work."
  },
  {
    "objectID": "13-factorial-anova.html#end-of-chapter",
    "href": "13-factorial-anova.html#end-of-chapter",
    "title": "\n13  Factorial ANOVA\n",
    "section": "\n13.4 End of Chapter",
    "text": "13.4 End of Chapter\nWell done, you have now covered the ANOVA section of the course to learn how to express experimental designs into statistical models. ANOVA and factorial ANOVA are incredibly flexible tools where you can start to combine multiple independent variables. You might have between-subject factors, within-subject factors, or a combination of the two in a mixed design. The most important thing to keep in mind is your research question, hypothesis, and design come first. Factorial ANOVA can get arbitrarily more complicated but try and avoid the temptation to create complex models just because you can. You do not get extra points for complication, it is better to think about which model will let you address your research question.\nIn the next chapter, we finish the core chapters on the final extension of the general linear model we cover in this course. In Research Methods 1, you learnt about simple linear regression when you only have one predictor. In multiple linear regression, you can add two or more predictors, and even the interaction between predictors.\n\n\n\n\nZhang, T., Kim, T., Brooks, A. W., Gino, F., & Norton, M. I. (2014). A “Present” for the Future: The Unexpected Value of Rediscovery. Psychological Science, 25(10), 1851–1860. https://doi.org/10.1177/0956797614542274"
  },
  {
    "objectID": "14-multiple-regression.html#chapter-preparation",
    "href": "14-multiple-regression.html#chapter-preparation",
    "title": "\n14  Multiple Regression\n",
    "section": "\n14.1 Chapter preparation",
    "text": "14.1 Chapter preparation\n\n14.1.1 Introduction to the data set\nFor this chapter, we are using open data from Przybylski & Weinstein (2017). The abstract of their article is:\n\nAlthough the time adolescents spend with digital technologies has sparked widespread concerns that their use might be negatively associated with mental well-being, these potential deleterious influences have not been rigorously studied. Using a preregistered plan for analyzing data collected from a representative sample of English adolescents (n = 120,115), we obtained evidence that the links between digital-screen time and mental well-being are described by quadratic functions. Further, our results showed that these links vary as a function of when digital technologies are used (i.e., weekday vs. weekend), suggesting that a full understanding of the impact of these recreational activities will require examining their functionality among other daily pursuits. Overall, the evidence indicated that moderate use of digital technology is not intrinsically harmful and may be advantageous in a connected world. The findings inform recommendations for limiting adolescents’ technology use and provide a template for conducting rigorous investigations into the relations between digital technology and children’s and adolescents’ health.\n\nIn summary, this was a large-scale study that found support for the “Goldilocks” hypothesis among adolescents: that there is a “just right” amount of screen time, such that any amount more or less than this amount is associated with lower well-being. This was a huge survey study: the data contain responses from over 120,000 participants! In this chapter, we will look at whether the relationship between screen time and well-being is moderated by participants’ (self-reported) gender.\nThe outcome/dependant variable used in the study was the Warwick-Edinburgh Mental Well-Being Scale (WEMWBS). This is a 14-item scale with 5 response categories, summed together to form a single score ranging from 14-70.\nPrzybylski & Weinstein (2017) looked at multiple measures of screen time, but we will be focusing on smartphone use. They found that decrements in well-being started to appear when respondents reported more than one hour of weekly smartphone use. Our research question is: Does the negative association between hours of use and well-being (beyond the one-hour point) differ for boys and girls?\n\n14.1.2 Organising your files and project for the chapter\nBefore we can get started, you need to organise your files and project for the chapter, so your working directory is in order.\n\nIn your folder for research methods and the book ResearchMethods1_2/Quant_Fundamentals, create a new folder called Chapter_14_multiple_regression. Within Chapter_14_multiple_regression, create two new folders called data and figures.\nCreate an R Project for Chapter_14_multiple_regression as an existing directory for your chapter folder. This should now be your working directory.\nCreate a new R Markdown document and give it a sensible title describing the chapter, such as 14 Multiple Regression. Delete everything below line 10 so you have a blank file to work with and save the file in your Chapter_14_multiple_regression folder.\n\nFor this chapter, there are three data files you need. Please save the following files:\n\nPrzybylski_2017_participants.csv.\nPrzybylski_2017_screentime.csv\nPrzybylski_2017_wellbeing.csv\n\n\n\nRight click the link and select “save link as”, or clicking the link will save the files to your Downloads. Make sure that you save the files as “.csv”. Save or copy the files to your data/ folder within Chapter_14_multiple_regression.\nYou are now ready to start working on the chapter!\n\n14.1.3 Activity 1 - Load the packages and read the data\nAs the first activity, try and test yourself by completing the following task list.\n\n\n\n\n\n\nTry this\n\n\n\nTo prepare for wrangling the data, complete the following tasks:\n\n\nLoad the following packages (one of these is new, so revisit Chapter 1 if you need a refresher of installing R packages, but remember not to install packages on the university computers / online server):\n\npwr\nsjPlot\nperformance\ntidyverse\n\n\nRead the three data files to the following object names to be consistent with the tasks below.\n\n\n# load packages here\n?\n\n# read the three data files \n# this should be Przybylski_2017_participants.csv\npinfo &lt;- ?\n\n# this should be Przybylski_2017_wellbeing.csv\nwellbeing &lt;- ?\n\n# this should be Przybylski_2017_screentime.csv\nscreen &lt;- ?\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# load packages here\nlibrary(pwr)\nlibrary(sjPlot)\nlibrary(performance)\nlibrary(tidyverse)\n\n# read the three data files \n# this should be Przybylski_2017_participants.csv\npinfo &lt;- read_csv(\"data/Przybylski_2017_participants.csv\")\n\n# this should be Przybylski_2017_wellbeing.csv\nwellbeing &lt;- read_csv(\"data/Przybylski_2017_wellbeing.csv\")\n\n# this should be Przybylski_2017_screentime.csv\nscreen &lt;- read_csv(\"data/Przybylski_2017_screentime.csv\")\n\n\n\n\n\n14.1.4 Activity 2 - Explore the data\nTake a look at the resulting tibbles pinfo, wellbeing, and screen. Use functions like glimpse() to look at what the data frames contain.\n\nThe pinfo data has information on the participant’s background.\nThe wellbeing data has information from the well-being questionnaire.\n\nThe screen data has information about screen time use on weekends (variables ending with we) and weekdays (variables ending with wk) for four types of activities:\n\nUsing a computer (variables starting with Comph; Q10 on the survey)\nPlaying video games (variables starting with Comp; Q9 on the survey)\nUsing a smartphone (variables starting with Smart; Q11 on the survey)\nWatching TV (variables starting with Watch; Q8 on the survey).\n\n\n\nIf you want more information about these variables, look at the items 8-11 on pages 4-5 of the the PDF version of the survey on the authors’ OSF project.\nOnce you have explored the objects, try and answer the following questions:\n\nThe variable corresponding to gender is located in the object named \npinfo\nwellbeing\nscreen and this variable is called .\nThe well-being data is in \nlong\nwide format and contains observations from  participants on  items.\nIndividual participants in this data set are identified by the variable called . This variable will allow us to link information across the three tables.\nIf you run the function summary() on the three data sets, are there any missing data points? \nYes\nNo\n\n14.1.5 Activity 3 - Compute the well-being score for each respondent\n\n\n\n\n\n\nTry this\n\n\n\nThe WEMWBS well-being score is simply the sum of all the items.\nWrangle the data to create a new table called wemwbs. The data should have two variables:\n\nSerial - the participant ID.\ntotal_wellbeing - the total WEMWBS score.\n\nThink about what wrangling steps you need to apply to achieve this.\n\n\n\n\n\n\n\n\nShow me some hints\n\n\n\n\n\n\nGather the data and pivot from wide to long.\nGroup the data by a variable.\nSummarise the data to calculate the sum score per participant.\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\nwemwbs &lt;- wellbeing %&gt;%\n  pivot_longer(cols = WBOptimf:WBCheer,\n               names_to = \"var\", \n               values_to = \"score\") %&gt;%\n  group_by(Serial) %&gt;%\n  summarise(total_wellbeing = sum(score))\n\n\n\n\nFor a sanity check, verify for yourself that the scores all fall in the 14-70 range. Przybylski & Weinstein (2017) reported a mean of 47.52 with a standard deviation of 9.55. Can you reproduce these values?\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\nwemwbs %&gt;% \n  summarise(mean = mean(total_wellbeing),\n            sd = sd(total_wellbeing),\n            min = min(total_wellbeing),\n            max = max(total_wellbeing))\n\n\n\n\nmean\nsd\nmin\nmax\n\n\n47.52189\n9.546374\n14\n70\n\n\n\n\n\n\n\n\nNow, visualise the distribution of tot_wellbeing in a histogram using ggplot2. The distribution of well-being scores is \nsymmetric\nnegatively skewed\npositively skewed.\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\nwemwbs %&gt;% \n  ggplot(aes(x = total_wellbeing)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\n\n14.1.6 Activity 4 - Wrangle and visualise the data\nBefore we move onto the final modelling stages, we can wrangle the data to plot the data like the original article. We can plot the relationship between well-being and hours of technology use, split into four categories of technology (video games, computers, smartphones, TV).\nFor this step, we are going to give you the code as there are a few new functions we have not taught you about. Make sure as you type the code to question what each line of the code is doing. The functions might be unfamiliar but you should be able to follow what it is doing. We are working with many rows here, so the code might take longer to run than you are used to.\n\n# Pivot the screen data longer\n# Separate the variable into the category and day of the week\n# Recode the new variables \nscreen_long &lt;- screen %&gt;%\n  pivot_longer(cols = Comph_we:Watch_wk,\n               names_to = \"var\", \n               values_to = \"hours\") %&gt;%\n  separate(col = var, # split variable name\n           into = c(\"variable\", \"day\"), # split into two components\n           sep = \"_\") %&gt;%  # split when it sees a _\n  mutate(variable = case_match(variable,\n                               \"Watch\" ~ \"Watching TV\",\n                               \"Comp\" ~ \"Playing Video Games\",\n                               \"Comph\" ~ \"Using Computers\",\n                               \"Smart\" ~ \"Using Smartphone\"),\n         day = case_match(day,\n                          \"wk\" ~ \"Weekday\",\n                          \"we\" ~ \"Weekend\"))\n\n# Join the two data sets together \n# group by three variables\n# calculate the mean well-being score\ndat_means &lt;- wemwbs %&gt;% \n  inner_join(screen_long, \n             by = \"Serial\") %&gt;%\n  group_by(variable, \n           day, \n           hours) %&gt;%\n  summarise(mean_wellbeing = mean(total_wellbeing))\n\nWe now have data at the group level rather than per participant. Each row of dat_means is a value for mean well-being split by each level of variable (technology type), day (weekday or weekend), and hours of technology use. If you run the following code, we get a line graph showing the relationship split between technology type and day.\n\ndat_means %&gt;% \n  ggplot(aes(x = hours, y = mean_wellbeing, linetype = day)) +\n  geom_line() +\n  geom_point() +\n  facet_wrap(~ variable, nrow = 2) + \n  theme_classic() + \n  labs(x = \"Hours of Technology Use\",\n       y = \"Mean Well-Being Score\")\n\n\n\n\n\n\n\nThe graph shows that smartphone use of more than 1 hour per day is associated with increasingly negative well-being. Note that we have combined the tables using an inner_join(), such that we only include data for which we have observations across the wemwbs and screen_long tables.\nIn the next step, we are going to focus on the smartphone/well-being relationship for our multiple linear regression demonstration."
  },
  {
    "objectID": "13-factorial-anova.html#factorial-a8",
    "href": "13-factorial-anova.html#factorial-a8",
    "title": "\n13  Factorial ANOVA\n",
    "section": "\n13.3 Reporting the results of your factorial ANOVA",
    "text": "13.3 Reporting the results of your factorial ANOVA\nNow you have all your values, we can work on the write-up of your results.\nIn the in-line code demonstration below, we manually entered p-values where they are &lt; .001. There is a way to get R to produce this formatting but it’s overly complicated for our purposes in this course. If you want to push yourself, look up the papaja package for creating reproducible manuscripts.\nThe values of partial eta-squared do not match between our analysis and those reported in the paper. We have not figured out why this is yet, so if you know, please get in touch!\nWe have also replaced the simple effects in the main paper with our pairwise comparisons.\nCopy and paste the text and inline code below into white-space in your R Markdown document. If you saved all the descriptives, model, and contrasts using the same object names as us, this should knit.\n\nWe conducted the same repeated measures ANOVA with interest as the dependent measure and again found a main effect of time, F(`r factorial_output$num.Df[2]`, `r factorial_output$den.Df[2]`) = `r factorial_output$statistic[2] %&gt;% round(2)`, p &lt; .001, ηp2 = `r factorial_output$ges[2] %&gt;% round(3)`; anticipated interest at Time 1 (M = `r zhang_descriptives$mean[1] %&gt;% round(2)`), SD = `r zhang_descriptives$sd[1]%&gt;% round(2)`)) was lower than actual interest at Time 2 (M = `r zhang_descriptives$mean[2]%&gt;% round(2)`, SD = `r zhang_descriptives$sd[2]%&gt;% round(2)`). We also observed an interaction between time and type of experience, F(`r factorial_output$num.Df[3]`, `r factorial_output$den.Df[3]`) = `r factorial_output$statistic[3] %&gt;% round(3)`, p = `r factorial_output$p.value[3] %&gt;% round(2)`, ηp2 = `r factorial_output$ges[3] %&gt;% round(3)`. Pairwise comparisons revealed that for ordinary events, predicted interest at Time 1 (M = `r zhang_descriptives$mean[3]%&gt;% round(2)`, SD = `r zhang_descriptives$sd[3]%&gt;% round(2)`) was lower than experienced interest at Time 2 (M = `r zhang_descriptives$mean[4]%&gt;% round(2)`, SD = `r zhang_descriptives$sd[4]%&gt;% round(2)`), t(`r contrasts_factorial$df[2]%&gt;% round(2)`) = `r contrasts_factorial$statistic[2]%&gt;% round(2)`, p &lt; .001, d = `r contrasts_factorial$Cohens_d[2]%&gt;% round(2)`. Although predicted interest for extraordinary events at Time 1 (M = `r zhang_descriptives$mean[1]%&gt;% round(2)`, SD = `r zhang_descriptives$sd[1]%&gt;% round(2)`) was lower than experienced interest at Time 2 (M = `r zhang_descriptives$mean[2]%&gt;% round(2)`, SD = `r zhang_descriptives$sd[2]%&gt;% round(2)`), t(`r contrasts_factorial$df[1]%&gt;% round(2)`) = `r contrasts_factorial$statistic[1]%&gt;% round(2)`, p &lt; .001, d = `r contrasts_factorial$Cohens_d[1]%&gt;% round(2)`, the magnitude of underestimation was smaller than for ordinary events.\n\n\nWe conducted the same repeated measures ANOVA with interest as the dependent measure and again found a main effect of time, F(1, 128) = 25.88, p &lt; .001, ηp2 = 0.044; anticipated interest at Time 1 (M = 4.36), SD = 1.13)) was lower than actual interest at Time 2 (M = 4.65, SD = 1.14). We also observed an interaction between time and type of experience, F(1, 128) = 4.445, p = 0.04, ηp2 = 0.008. Pairwise comparisons revealed that for ordinary events, predicted interest at Time 1 (M = 4.04, SD = 1.09) was lower than experienced interest at Time 2 (M = 4.73, SD = 1.24), t(128) = -5.05, p &lt; .001, d = -0.56. Although predicted interest for extraordinary events at Time 1 (M = 4.36, SD = 1.13) was lower than experienced interest at Time 2 (M = 4.65, SD = 1.14), t(128) = -2.12, p &lt; .001, d = -0.31, the magnitude of underestimation was smaller than for ordinary events."
  },
  {
    "objectID": "10-power.html",
    "href": "10-power.html",
    "title": "\n10  Statistical Power and Effect Sizes\n",
    "section": "",
    "text": "10.1 Chapter preparation",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Statistical Power and Effect Sizes</span>"
    ]
  },
  {
    "objectID": "10-power.html#chapter-preparation",
    "href": "10-power.html#chapter-preparation",
    "title": "\n10  Statistical Power and Effect Sizes\n",
    "section": "\n10.1 Chapter preparation",
    "text": "10.1 Chapter preparation\n\n10.1.1 Organising your files and project for the chapter\nIn contrast to previous chapters, there will be no data wrangling in this chapter, so we do not need to worry about downloading files. We will still be working around some key studies, but we will introduce them as needed. However, you will still be working in an R Markdown document, so you need to make sure your working directory is in order.\n\nIn your folder for research methods and the book ResearchMethods1_2/Quant_Fundamentals, create a new folder called Chapter_10_power.\nCreate an R Project for Chapter_10_power as an existing directory for your chapter folder. This should now be your working directory.\nCreate a new R Markdown document and give it a sensible title describing the chapter, such as 10 Statistical Power and Effect Sizes. Delete everything below line 10 so you have a blank file to work with and save the file in your Chapter_10_power folder.\nIn a code chunk, load the pwr and tidyverse packages. If you need to install any packages, revisit Chapter 1 if you need a refresher, but remember not to install packages on the university computers / online server.\n\nYou are now ready to start working on the chapter!"
  },
  {
    "objectID": "10-power.html#nhst-and-statistical-power-recap",
    "href": "10-power.html#nhst-and-statistical-power-recap",
    "title": "\n10  Statistical Power and Effect Sizes\n",
    "section": "\n10.2 NHST and statistical power recap",
    "text": "10.2 NHST and statistical power recap\nGiven there is no data wrangling for this chapter and the functions for power analysis are pretty straight forward, we have a little space to recap the key concepts behind power analysis. Almost all the work here comes into thinking and justifying your decisions, rather than spending lots of time on wrangling and analysis.\nThe branch of statistics we are using here is Null Hypothesis Significance Testing (NHST). There are two types of hypotheses and what you are trying to establish is the probability of rejecting the null hypothesis. Those two hypotheses are:\n\nThe null hypothesis which states that there is no difference (\\(H_0: \\mu_1 = \\mu_2\\)) or no relationship (\\(H_0: r = 0\\)).\nThe alternative hypothesis which states that there is a difference (\\(H_1: \\mu_1 \\ne \\mu_2\\)) or there is a relationship (\\(H_1: r \\ne 0\\)).\n\nNHST is designed to control error rates associated with two main decisions around these hypotheses:\n\nType I error - or false positive, is the probability of rejecting the null hypothesis when it should not be rejected (otherwise called alpha or \\(\\alpha\\)). In other words, you conclude that there is a real “effect” when in fact there is no effect. The field standard rate of acceptable false positives is \\(\\alpha = .05\\), meaning that we would accept 1 in 20 studies may be a false positive.\nType II error - or false negative, is the probability of retaining the null hypothesis when it should be rejected (otherwise called beta or \\(\\beta\\)). In other words, you conclude that there was no real “effect” when in fact there was one. There is less tradition around this, but the most common rule of thumb you will come across is \\(\\beta = .20\\), meaning that we would accept 1 in 5 studies may be a false negative.\n\nStatistical power is the opposite of beta and represents the long-run probability of correctly rejecting the null hypothesis when there is a real effect to detect. In other words, how likely are you to detect an effect that is really there? You calculate Power as \\(1-\\beta\\), meaning that if the field standard for beta is \\(\\beta = .20\\), then the field standard for power is \\(1 - .20 = .80\\) (80%).\nIn addition to alpha and beta/power, there are two other key concepts (there are more depending on the test, but we will add them in when we need them):\n\nEffect size - A number that expresses the magnitude of the phenomenon relevant to your research question. In Chapters 8 and 9, we introduced you to different standardised effect sizes such as Pearson’s r and Cohen’s d. \nSample size - The number of observations (usually participants, but it might be animals or stimuli depending on your topic) in your study.\n\nCritically, there is a relationship between these four concepts, where if you know three, you can calculate the fourth in a process called power analysis. The two most useful types of power analysis are:\n\nA priori power analysis: How many participants do I need, for a given alpha, beta/power, and smallest effect size of interest? This is most useful in the design stage to help you plan how many participants you need to design an informative study.\nSensitivity power analysis: What effect size can I detect, for a given alpha, beta/power, and sample size? This is most useful after you finish collecting data or when you are using secondary data as the sample size is not longer under your control and it helps put your findings in context.\n\nYou may now be thinking though, if there is a relationship between all four concepts, could we calculate power for a given alpha, sample size, and effect size? It is a tempting idea and you might see some articles report it, but unfortunately is is misleading and tells you nothing more than the p-value does. The short version is we are typically using a sample to learn something about a population, so there is uncertainty in the estimate. Using the observed effect size in your study assumes this is the true population effect, which is rarely a good assumption. If you are interested, Lakens (2022) is a great resource for sample size justification in general, but also explains why post-hoc power is not a good idea.\nAfter the brief recap, we will now focus on a priori and sensitivity power analyses applied to different statistical models."
  },
  {
    "objectID": "10-power.html#power-analysis-for-t-tests-categorical-predictors",
    "href": "10-power.html#power-analysis-for-t-tests-categorical-predictors",
    "title": "\n10  Statistical Power and Effect Sizes\n",
    "section": "\n10.3 Power analysis for t-tests / categorical predictors",
    "text": "10.3 Power analysis for t-tests / categorical predictors\n\n10.3.1 Introduction to the study\nIn this section, imagine we are designing a study to build on Irving et al. (2022) who tested an intervention to correct statistical misinformation. Participants read an article about a new fictional study where one passage falsely concludes watching TV causes cognitive decline. In the correction group, participants receive an extra passage where the fictional researcher explains they only reported a correlation, not a causal relationship. In the no-correction group, the extra passage just explains the fictional researcher was not available to comment. Irving et al. then tested participants’ comprehension of the story and coded their answers for mistaken causal inferences. They expected participants in the correction group to make fewer causal inferences than those in the no-correction group, and found evidence supporting this prediction with an effect size equivalent to Cohen’s d = 0.64, 95% CI = [0.28, 0.99]. Inspired by their study, we want to design an experiment to correct another type of misinformation in articles.\nIrving et al. (2022) themselves provide an excellent example of explaining and justifying the rationale behind their power analysis, so we will walk through the decision making process and how it changes the outputs. For our smallest effect size of interest, our starting point is the estimate of d = 0.64. However, it is worth consulting other sources to calibrate our understanding of effects in the area, such as Irving et al. citing a meta-analysis. For debunking, the average effect across 30 studies was d = 1.14, 95% CI = [0.68, 1.61], so we could use the lower bound of the confidence interval, but this may still represent an overestimate. Irving et al. used the smallest effect (d = 0.54) from the studies most similar to their design which was included in the meta-analysis. As a value slightly smaller than the other estimates, we will also use this as the smallest effect of interest for our study.\nNow we have settled on our smallest effect size of interest, we will use d = 0.54 in the following demonstrations. We start with a priori and sensitivity power analysis for two independent samples, exploring how the outputs change as we alter inputs like alpha, power, and the number of tails in the test.\n\n10.3.2 A priori power analysis\nFor an independent samples t-test (we will cover regression shortly), there is the function pwr.t.test(). We can enter the following arguments:\n\nn: The number of observations.\nd: The effect size as Cohen’s d. \nsig.level: The alpha level.\npower: The power value as 1-\\(\\beta\\).\ntype: Whether you want power for a one-, paired-, or independant-samples t-test.\nalternative: Whether you have a one- or two-sided hypothesis.\n\nRemember, power analysis works by leaving one argument blank, so for calculating the sample size, we leave n blank or enter NULL as the argument. As our starting point, we enter d = 0.54, sig.level = .05, power = .90, type = two.sample and alternative = two-sided.\n\npwr.t.test(n = NULL, \n           d = 0.54, \n           sig.level = .05, \n           power = .90, \n           type = \"two.sample\", \n           alternative = \"two.sided\")\n\n\n     Two-sample t test power calculation \n\n              n = 73.04123\n              d = 0.54\n      sig.level = 0.05\n          power = 0.9\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nAs the note warns us, for an independent-samples t-test, n represents the number of observations per group, so we need 74 per group (we round up as we cannot have .04 of a person) or N = 148.\nIf you wanted to use these values in inline code, you can save the power analysis object and pick out values to work with.\n\nirving_samplesize &lt;- pwr.t.test(n = NULL, \n                           d = 0.54, \n                           sig.level = .05, \n                           power = .90, \n                           type = \"two.sample\", \n                           alternative = \"two.sided\") %&gt;% \n  pluck(\"n\") %&gt;% \n  ceiling()\n\nIn this code, we save the power analysis function to an object, use the pluck() function to pick out a specific component (the argument name must be spelt exactly), and use the ceiling() function to round up. This helps to avoid manually calculating the values as you can use the object.\n\n# sample size per group\nirving_samplesize\n\n# total sample size\nirving_samplesize * 2\n\n[1] 74\n[1] 148\n\n\nThe power analysis function is pretty straight forward to work with, it is the thinking and decision making that goes into selecting the value for each argument that is the hardest part here. It is ultimately a subjective decision you must be able to justify in a report and there will always be compromises. You never have unlimited resources, so you are trying to balance designing the most informative study with maximizing the resources available to you.\n\n\n\n\n\n\nTry this\n\n\n\nWith decision making in mind, we can tweak the arguments to see how it affects the sample size we need. We will tweak one argument at a time, so your starting point will be the arguments we started with above.\n\nIf we used a one-tailed test predicting a positive effect (\"greater\"), we would need  participants per group (N = ).\nIf we wanted to make fewer type I errors and reduce alpha to .005, we would need  participants per group (N = ).\nIf we were happy with a larger beta and reduce power to .80 (80%), we would need  participants per group (N = ).\nIf we wanted to decrease our smallest effect size of interest and set d = .40, we would need  participants per group (N = ).\nIf we thought it was appropriate to change the design to within-subjects and use a paired-samples t-test instead (\"paired\"), we would need  participants.\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\n\nWe can calculate sample size for a one-tailed test by entering alternative = \"greater\" or alternative = \"less\". This must match the effect size direction or you will receive an error.\n\n\npwr.t.test(n = NULL, \n           d = 0.54, \n           sig.level = .05, \n           power = .90, \n           type = \"two.sample\", \n           alternative = \"greater\") %&gt;% \n  pluck(\"n\") %&gt;% \n  ceiling()\n\n[1] 60\n\n\n\nWe can decrease alpha by entering alpha = .005 to calculate the sample size for reducing the type I error rate.\n\n\npwr.t.test(n = NULL, \n           d = 0.54, \n           sig.level = .005, \n           power = .90, \n           type = \"two.sample\", \n           alternative = \"two.sided\") %&gt;% \n  pluck(\"n\") %&gt;% \n  ceiling()\n\n[1] 117\n\n\n\nWe can decrease power if we were happy with a larger beta / type II error rate by entering power = .80.\n\n\npwr.t.test(n = NULL, \n           d = 0.54, \n           sig.level = .05, \n           power = .80, \n           type = \"two.sample\", \n           alternative = \"two.sided\") %&gt;% \n  pluck(\"n\") %&gt;% \n  ceiling()\n\n[1] 55\n\n\n\nWe can decrease the smallest effect size of interest if we wanted the study to be more sensitive by entering d = .40.\n\n\npwr.t.test(n = NULL, \n           d = 0.40, \n           sig.level = .05, \n           power = .90, \n           type = \"two.sample\", \n           alternative = \"two.sided\") %&gt;% \n  pluck(\"n\") %&gt;% \n  ceiling()\n\n[1] 133\n\n\n\nIf we changed the design and test to within-subjects, we can enter type = \"paired\".\n\n\npwr.t.test(n = NULL, \n           d = 0.54, \n           sig.level = .05, \n           power = .90, \n           type = \"paired\", \n           alternative = \"two.sided\") %&gt;% \n  pluck(\"n\") %&gt;% \n  ceiling()\n\n[1] 39\n\n\n\n\n\nThese are important lessons to recognise which inputs increase and which decrease the sample size you need. For an a priori power analysis in the design phase, you can tweak the inputs depending on how sensitive you want your study given the resources available to you. Holding everything else constant, we can summarise the patterns as:\n\nUsing a one-tailed test \nincreases\ndecreases the sample size you need.\nReducing alpha \nincreases\ndecreases the sample size you need.\nReducing power / increasing beta \ndecreases\nincreases the sample size you need.\nReducing the smallest effect size of interest \nincreases\ndecreases the sample size you need.\nSwitching to a within-subjects design \nincreases\ndecreases the sample size you need.\n\n10.3.3 Sensitivity power analysis\nNow imagine you already knew the sample size or had access to a population of a known size. In this scenario, you would conduct a sensitivity power analysis. This would tell you what effect sizes your study would be powered to detect for a given alpha, power, and sample size. This is helpful for interpreting your results as you can outline what effect sizes your study was sensitive to and which effects would be too small for you to reliably detect.\nImagine we had finished collecting data and we knew we had 40 participants in each group but did not conduct an a priori power analysis when designing the study. Instead of leaving n blank, we can leave d blank.\n\npwr.t.test(n = 40, \n           d = NULL, \n           sig.level = .05, \n           power = .90, \n           type = \"two.sample\", \n           alternative = \"two.sided\")\n\n\n     Two-sample t test power calculation \n\n              n = 40\n              d = 0.7339255\n      sig.level = 0.05\n          power = 0.9\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nThe output tells us that the study is sensitive to detect effect sizes of d = 0.73 with 90% power. This helps us to interpret the results if we did not plan with power in mind. If the effect size we could detect with 90% power is larger than our smallest effect size of interest, our study was potentially underpowered. This might sound like post-hoc power we warned you about, but the key difference is you are comparing the effect size your study was sensitive to against your smallest effect size of interest, not your observed effect size.\nFor a sensitivity power analysis, you will often find yourself with unequal sample sizes. The previous function assumes equal sample sizes, but pwr.t2n.test() lets you set n1 and n2. For example, imagine we ended up with two groups of 39 and 43 participants.\n\npwr.t2n.test(n1 = 39, \n             n2 = 43,\n             d = NULL, \n             sig.level = .05, \n             power = .90, \n             alternative = \"two.sided\") %&gt;% \n  pluck(\"d\") %&gt;% \n  round(digits = 2)\n\n[1] 0.73\n\n\nOne other key point here is power exists along a curve, there is not just a single value for power once your sample size is fixed. We can visualise this through something called a power curve. Figure 10.1 shows statistical power against Cohen’s d as the effect size for a fixed sample of 40 participants per group. We would have 90% power to detect a Cohen’s d of 0.75 (the value is a little different here as we set the effect size, rather than calculate it as the output), shown where the two lines meet. You would have more and more power to detect effects larger than 0.75 (follow the curve to the right), but less power to detect effects smaller than 0.75 (follow the curve to the left). The grey shaded region highlights the effects your study would be less sensitive to than your desired value for power.\n\n\n\n\nFigure 10.1: Power curve for 40 participants per group and 90% power.\n\n\n\nOn the other hand, Figure 10.2 shows statistical power against Cohen’s d as the effect size for a fixed sample of 80 participants per group. This time, we would have 90% power to detect effects of d = 0.53 and there is a smaller grey region. We would have more power to detect effects larger than d = 0.53 but less power to detect effects smaller than 0.53.\n\n\n\n\nFigure 10.2: Power curve for 80 participants per group and 90% power.\n\n\n\nHopefully, these demonstrations reinforce the idea of sensitivity and how power exists along a curve once you have a fixed sample size.\n\n10.3.4 Power for regression with a categorical predictor\nIn Chapters 8 and 9, we recommended expressing your designs as linear regression models. They have many benefits, but one downside is the effect size and process we need for power analysis is not the most intuitive. Typically, people report effect sizes like Cohen’s d when comparing groups, but here we need Cohen’s \\(f^2\\). You can convert between effect sizes and we recommend the website psychometrica.de which has an online calculator for converting effect sizes in section 14. Alternatively, you can use the following code to save \\(f^2\\) as an object.\n\n# enter your Cohen's d value\nd &lt;- 0.54\n\n# This calculates f2 from d\nf2 &lt;- (d / 2)^2\n\nNow we have \\(f^2\\), we can use the function pwr.f2.test() which calculates power for regression models. For the equivalent of a t-test, we have the following new arguments:\n\nu: The numerator degrees of freedom, the number of predictors in your model.\nv: The denominator degrees of freedom, a little more awkward but the sample size minus u minus 1.\nf2: The effect size \\(f^2\\), which is a kind of transformed version of \\(R^2\\) for the amount of variance explained by the model.\n\nFor our power analysis, we will save the inputs as objects to make it easier to reuse them, and enter them in the following arguments:\n\n# number of predictors\nu &lt;- 1\n\n# alpha for type I error rate\nalpha &lt;- .05\n\n# power for 1-beta\npower &lt;-  .90\n\npwr.f2.test(u = u, \n            v = NULL, \n            sig.level = alpha, \n            power = power, \n            f2 = f2)\n\n\n     Multiple regression power calculation \n\n              u = 1\n              v = 144.0824\n             f2 = 0.0729\n      sig.level = 0.05\n          power = 0.9\n\n\nUsing the objects from the power analysis, we can calculate the sample size we need with a little reorganising.\n\nirving_v &lt;- pwr.f2.test(u = 1, \n                        v = NULL, \n                        sig.level = .05, \n                        power = .90, \n                        f2 = f2) %&gt;% \n  pluck(\"v\") \n\nceiling(irving_v + u + 1)\n\n[1] 147\n\n\nIn the t-test power analysis function, we needed 148 participants in total, so this is off by 1 participant. There are a few steps for rounding errors here, so this is close enough to show it is the equivalent but more awkward process.\nIf you wanted to use this function for a sensitivity power analysis, you can convert \\(f^2\\) back to Cohen’s d using psychometrica.de or use the following code:\n\n# f2 from the output\nf2 &lt;- .073\n\n# convert to d by square root of f2 times 2\nd &lt;- sqrt(f2) * 2"
  },
  {
    "objectID": "10-power.html#power-analysis-for-correlations-continuous-predictors",
    "href": "10-power.html#power-analysis-for-correlations-continuous-predictors",
    "title": "\n10  Statistical Power and Effect Sizes\n",
    "section": "\n10.4 Power analysis for correlations / continuous predictors",
    "text": "10.4 Power analysis for correlations / continuous predictors\n\n10.4.1 Introduction to the study\nFor this section, we need a new study to work with for a correlation / continuous predictor. Wingen et al. (2020) were interested in the relationship between the replication rate in psychology studies and the public trust in psychology research. The replication crisis has led to a lot of introspection in the field to consider how we conduct robust research. However, being honest about the state of the field might be good for science, but perhaps it is related to lower public trust in science. We will focus on study 1 which asked the question: does trust in psychology correlate with expected replicability?\nWingen et al. (2020) reported a power analysis and they aimed for 95% power, 5% alpha, and their smallest effect size of interest was r = .20. Like Irving et al. (2022), they chose this value based on a meta-analysis which summarised hundreds of studies across social psychology. We will use these values as a starting point and adapt them to see it’s impact on the sample size we need.\n\n10.4.2 A priori power analysis\nFor Pearson’s r correlation, there is the function pwr.r.test(). All the arguments are the same as for the t-test, apart from we specify r as an effect size instead of Cohen’s d and we do not need to specify the type of test.\n\npwr.r.test(n = NULL, \n           r = .20, \n           sig.level = .05, \n           power = .95, \n           alternative = \"two.sided\")\n\n\n     approximate correlation power calculation (arctangh transformation) \n\n              n = 318.2637\n              r = 0.2\n      sig.level = 0.05\n          power = 0.95\n    alternative = two.sided\n\n\nAs before, we can isolate the sample size we would need for a study sensitive to these inputs.\n\npwr.r.test(n = NULL, \n           r = .20, \n           sig.level = .05, \n           power = .95, \n           alternative = \"two.sided\") %&gt;% \n  pluck(\"n\") %&gt;% \n  ceiling()\n\n[1] 319\n\n\nOur starting point is 319 participants to detect our smallest effect size of interest r = .20 with 95% power and 5% alpha.\n\n\n\n\n\n\nTry this\n\n\n\nWith decision making in mind, we can tweak the arguments to see how it affects the sample size we need. We will tweak one argument at a time, so your starting point will be the arguments we started with above.\n\nIf we used a one-tailed test predicting a positive relationship, we would need  participants. This reproduces the power analysis from Wingen et al., as they used a one-tailed test.\nIf we wanted to make fewer type I errors and reduce alpha to .005, we would need  participants.\nIf we were happy with a larger beta and reduce power to .80 (80%), we would need  participants.\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\n\nWe can calculate sample size for a one-tailed test by entering alternative = \"greater\" or alternative = \"less\". This must match the effect size direction or you will receive an error.\n\n\npwr.r.test(n = NULL, \n           r = .20, \n           sig.level = .05, \n           power = .95, \n           alternative = \"greater\") %&gt;% \n  pluck(\"n\") %&gt;% \n  ceiling()\n\n[1] 266\n\n\n\nWe can decrease alpha by entering alpha = .005 to calculate the sample size for reducing the type I error rate.\n\n\npwr.r.test(n = NULL, \n           r = .20, \n           sig.level = .005, \n           power = .95, \n           alternative = \"two.sided\") %&gt;% \n  pluck(\"n\") %&gt;% \n  ceiling()\n\n[1] 485\n\n\n\nWe can decrease power if we were happy with a larger beta / type II error rate by entering power = .80.\n\n\npwr.r.test(n = NULL, \n           r = .20, \n           sig.level = .05, \n           power = .80, \n           alternative = \"two.sided\") %&gt;% \n  pluck(\"n\") %&gt;% \n  ceiling()\n\n[1] 194\n\n\n\n\n\nLike for the independent samples t-test, the design phase allows you to carefully consider the inputs you choose and tweak them depending on how sensitive you want your study given the resources available to you. Holding everything else constant, we can summarise the patterns here as:\n\nUsing a one-tailed test \nincreases\ndecreases the sample size you need.\nReducing alpha \nincreases\ndecreases the sample size you need.\nReducing power / increasing beta \ndecreases\nincreases the sample size you need.\n\n10.4.3 Sensitivity power analysis\nWingen et al. (2020) is a great example of a sensitivity power analysis in the wild as they are relatively rare to see in published research. They explain they recruited participants online, so they ended up with more participants than they aimed for.\n\n\n\n\n\n\nTry this\n\n\n\nTheir final sample size was 271, so try and adapt the function to calculate the effect size r they were sensitive to. Both of these answers assume 5% alpha and a one-sided test.\nTo 2 decimal places, they could detect an effect of r =  with 80% power and r =  with 95% power.\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have had this in a code chunk for 80% power:\n\npwr.r.test(n = 271, \n           r = NULL, \n           sig.level = .05, \n           power = .80, \n           alternative = \"greater\") %&gt;% \n  pluck(\"r\") %&gt;% \n  round(digits = 2)\n\n[1] 0.15\n\n\nAnd this in a code chunk for 95% power:\n\npwr.r.test(n = 271, \n           r = NULL, \n           sig.level = .05, \n           power = .95, \n           alternative = \"greater\") %&gt;% \n  pluck(\"r\") %&gt;% \n  round(digits = 2)\n\n[1] 0.2\n\n\n\n\n\n\n10.4.4 Power for regression with a continuous predictor\nLike the categorical predictor, we have a mismatch between the effect size you typically see reported (Pearson’s r) and the effect size we need for a regression power analysis (\\(f^2\\)). The website psychometrica.de still works for converting effect sizes in section 14. Alternatively, you can use the following code to save \\(f^2\\) as an object.\n\n# effect size as Pearson's r\nr &lt;- .20\n\n# convert to f2 by squaring r values\nf2 &lt;- r^2 / (1 - r^2)\n\nNow we have \\(f^2\\), we can use the function pwr.f2.test() which calculates power for regression models.\n\n# number of predictors\nu &lt;- 1\n\n# alpha for type I error rate\nalpha &lt;- .05\n\n# power for 1-beta\npower &lt;-  .95\n\npwr.f2.test(u = u, \n            v = NULL, \n            sig.level = alpha, \n            power = power, \n            f2 = f2)\n\n\n     Multiple regression power calculation \n\n              u = 1\n              v = 311.807\n             f2 = 0.04166667\n      sig.level = 0.05\n          power = 0.95\n\n\nUsing the objects from the power analysis, we can calculate the sample size we need with a little reorganising.\n\nwingen_v &lt;- pwr.f2.test(u = 1, \n                        v = NULL, \n                        sig.level = .05, \n                        power = .95, \n                        f2 = f2) %&gt;% \n  pluck(\"v\") \n\nceiling(wingen_v + u + 1)\n\n[1] 314\n\n\nIn the Pearson’s r power analysis function, we needed 319 participants in total, so the estimate is off by 5 participants this time. We still have a few steps for rounding error, so this is close enough to show it is the equivalent but more awkward process.\nIf you wanted to use this function for a sensitivity power analysis, you can convert \\(f^2\\) back to Pearson’s \\(r\\) using psychometrica.de or use the following code:\n\n# f2 from the output\nf2 &lt;- .042\n\n# convert to r from the square root of f2 / f2 + 1\nr &lt;- sqrt(f2 / (f2 + 1))"
  },
  {
    "objectID": "10-power.html#end-of-chapter",
    "href": "10-power.html#end-of-chapter",
    "title": "\n10  Statistical Power and Effect Sizes\n",
    "section": "\n10.8 End of Chapter",
    "text": "10.8 End of Chapter\nGreat work, being able to conduct a power analysis is a great skill to have for designing an informative study. Although things have improved over the years, it is still relatively rare to see a study in the wild report a power analysis to justify their sample size. Keep in mind they involve a lot of subjective decision making as the values you choose for alpha, power, and your smallest effect size have flexibility. A larger sample - and hence more powerful study - would always be useful, but you are never working with unlimited resources. You must make compromises and think about whether you can conduct an informative study with the resources available to you. This means the hard work comes into making decisions about the values you enter, rather than the data skills for power analysis being difficult.\nIn the next - and final for the Research Methods 1 component - chapter, we cover screening data and decision making in data analysis. In Chapters 8 and 9, we covered topics like diagnostic checks for statistical models. Some of them looked fine, whereas some looked potentially problematic. In the next chapter, we work through the decisions you must make when analysing data like checking for missing data, outliers, and issues with diagnostic checks. Importantly, we outline the kind of solutions you can consider for those problems which we omitted in previous chapters.\n\n\n\n\nBakker, M., Veldkamp, C. L. S., Akker, O. R. van den, Assen, M. A. L. M. van, Crompvoets, E., Ong, H. H., & Wicherts, J. M. (2020). Recommendations in pre-registrations and internal review board proposals promote formal power analyses but do not increase sample size. PLoS ONE, 15(7), e0236079. https://doi.org/10.1371/journal.pone.0236079\n\n\nBartlett, J., & Charles, S. (2022). Power to the People: A Beginner’s Tutorial to Power Analysis using jamovi. Meta-Psychology, 6. https://doi.org/10.15626/MP.2021.3078\n\n\nChampely, S. (2020). Pwr: Basic functions for power analysis. https://CRAN.R-project.org/package=pwr\n\n\nIrving, D., Clark, R. W. A., Lewandowsky, S., & Allen, P. J. (2022). Correcting statistical misinformation about scientific findings in the media: Causation versus correlation. Journal of Experimental Psychology. Applied. https://doi.org/10.1037/xap0000408\n\n\nLakens, D. (2022). Sample Size Justification. Collabra: Psychology, 8(1), 33267. https://doi.org/10.1525/collabra.33267\n\n\nR Core Team. (2024). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nWingen, T., Berkessel, J. B., & Englich, B. (2020). No Replication, No Trust? How Low Replicability Influences Trust in Psychology. Social Psychological and Personality Science, 11(4), 454–463. https://doi.org/10.1177/1948550619877412"
  },
  {
    "objectID": "10-power.html#reporting-a-power-analysis",
    "href": "10-power.html#reporting-a-power-analysis",
    "title": "\n10  Statistical Power and Effect Sizes\n",
    "section": "\n10.5 Reporting a power analysis",
    "text": "10.5 Reporting a power analysis\nBakker et al. (2020) warned that only 20% of power analyses contained enough information to be fully reproducible. To report your power analysis, the reader needs the following four key pieces of information:\n\nThe type of test you based the power analysis on (e.g., t-test, correlation, regression),\nThe software used to calculate power (i.e., cite the pwr package, see How to cite R),\nThe inputs that you used (alpha, power, effect size, sample size, tails), and\nWhy you chose those inputs.\n\nIn this chapter, we will only cover the first three. The justification for your inputs comes under evaluation skills, so we will work on that in the course materials. Please note there is no single ‘correct’ way to report a power analysis, we just provide examples. Just be sure that you have the four key pieces of information.\n\n10.5.1 Reporting a t-test power analysis\nFor a t-test, the key distinctive input is Cohen’s d as the effect size.\n\n“To detect an effect size of Cohen’s d = 0.54 with 90% power (alpha = .05, two-tailed), the pwr package (Champely, 2020) in R (R Core Team, 2024) suggests we would need 74 participants per group (N = 148) for an independent samples t-test.”\n\nAlternatively, if you reported a sensitivity power analysis, the emphasis goes to the effect size your study would be sensitive to.\n\n“With our final sample size of 40 participants per group, a sensitivity power analysis for an independent samples t-test using the pwr package (Champely, 2020; R Core Team, 2024) showed we could detect an effect size of d = 0.73 with 90% power (5% alpha, two-sided).”\n\n\n10.5.2 Reporting a correlation power analysis\nFor a correlation, the key distinctive input is Pearson’s r as the effect size.\n\n“To detect an effect size of r = .20 with 95% power (alpha = .05, one-tailed), the pwr package (Champely, 2020) in R (R Core Team, 2024) suggests we would need 266 participants for a Pearson’s r correlation.”\n\nAnd for a sensitivity power analysis.\n\n“With our final sample size of 271 participants, a sensitivity power analysis for a Pearson’s r correlation using the pwr package (Champely, 2020; R Core Team, 2024) showed we could detect an effect size of r = .20 with 95% power (5% alpha, one-sided).”\n\n\n10.5.3 Reporting a regression power analysis\nFor regression, the key distinctive inputs are \\(f^2\\) as the effect size, including any details of converting effect sizes, plus the number of predictors.\n\n“To detect an effect size of Cohen’s \\(f^2\\) = .073, we first converted the effect size from d = 0.54. For 90% power (alpha = .05, two-tailed), the pwr package (Champely, 2020) in R (R Core Team, 2024) suggests we would need 147 participants split into two groups for a regression model with one categorical predictor.”\n\nFor a sensitivity power analysis, remember to include a note of any effect size conversions.\n\n“We used the pwr package (Champely, 2020; R Core Team, 2024) to conduct a sensitivity power analysis for linear regression with one predictor. With a final sample size of 319, we would be able to detect an effect size of Cohen’s \\(f^2\\) = .041 (95% power, 5% alpha). Converted to Pearson’s r, this would be an effect size of r = .20.”"
  },
  {
    "objectID": "11-screening-data.html#chapter-preparation",
    "href": "11-screening-data.html#chapter-preparation",
    "title": "\n11  Missing data, outliers, and checking assumptions\n",
    "section": "\n11.1 Chapter preparation",
    "text": "11.1 Chapter preparation\n\n11.1.1 Organising your files and project for the chapter\nFor this chapter, we are going to revisit the data sets you worked with in Chapters 8 (Dawtry et al., 2015) and 9 (Lopez et al., 2023). They each presented some useful examples for checking statistical assumptions and the decisions that go into data analysis. We might not use both data sets for each topic we cover, but they will be useful to demonstrate some of the problems and decisions we highlighted in previous chapters, but did not explore solutions.\nBefore we can get started, you need to organise your files and project for the chapter, so your working directory is in order.\n\nIn your folder for research methods and the book ResearchMethods1_2/Quant_Fundamentals, create a new folder called Chapter_11_screening_data. Within CChapter_11_screening_data, create two new folders called data and figures.\nCreate an R Project for Chapter_11_screening_data as an existing directory for your chapter folder. This should now be your working directory.\nCreate a new R Markdown document and give it a sensible title describing the chapter, such as 11 Missing Data, Outliers, and Assumptions. Delete everything below line 10 so you have a blank file to work with and save the file in your Chapter_11_screening_data folder.\nThe Dawtry et al. (2015) data wrangling steps were quite long, so please save this clean version of the data to focus on screening data in this chapter: Dawtry_2015_clean.csv. You will also need to save the data from Lopez et al. (2023) if you have not downloaded it yet: Lopez_2023.csv. Right click the link and select “save link as”, or clicking the link will save the files to your Downloads. Make sure that you save the files as “.csv”. Save or copy the files to your data/ folder within Chapter_11_screening_data.\n\nYou are now ready to start working on the chapter!\n\n11.1.2 Activity 1 - Read and wrangle the data\nAs the first activity, try and test yourself by completing the following task list to read and wrangle the two data files. There is nothing extra to do with this version of the Dawtry data and one small step for the Lopez data.\n\n\n\n\n\n\nTry this\n\n\n\nTo read and wrangle the data, complete the following tasks:\n\n\nLoad the following packages:\n\nperformance\ntidyverse\n\n\nRead the data file data/Dawtry_2015_clean.csv to the object name dawtry_clean.\nRead the data file data/Lopez_2023.csv to the object name lopez_data.\n\nCreate a new object called lopez_clean based on lopez_data:\n\nCreate a new variable called Condition_label by recoding Condition. “0” is the “Control” group and “1” is the “Experimental” group.\n\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# load the relevant packages\nlibrary(performance)\nlibrary(tidyverse)\n\n# Read the Dawtry_2015_clean.csv file \ndawtry_clean &lt;- read_csv(\"data/Dawtry_2015_clean.csv\")\n\n# Read the Lopez_2023.csv file \nlopez_data &lt;- read_csv(\"data/Lopez_2023.csv\")\n\n# recode condition\nlopez_clean &lt;- lopez_data %&gt;% \n  mutate(Condition_label = case_match(Condition,\n                                      0 ~ \"Control\",\n                                      1 ~ \"Experimental\"))"
  },
  {
    "objectID": "11-screening-data.html#outliers",
    "href": "11-screening-data.html#outliers",
    "title": "\n11  Missing data, outliers, and checking assumptions\n",
    "section": "\n11.3 Outliers",
    "text": "11.3 Outliers\nThe next data screening concept revolves around identifying potential outliers. Like missing data, the difficulty here comes in first deciding what an outlier is and then deciding on what to do with it. Leys et al. (2019) mention one study found 14 definitions and 39 unique ways of identifying outliers, so this is our second key area of decision making. Leys et al. categorise outliers into three types:\n\nError outliers - a mistake or impossible value.\nInteresting outliers - values that looks extreme until you take a moderator into account.\nRandom outliers - values that are extreme compared to the majority of data points. Even simpler, we can consider values as legitimate or not legitimate. Error outliers would be not legitimate as they represent a mistake or error, so they would potentially provide misleading results. These are values you can justify removing or correcting as they should not be there in the first place.\n\nInteresting and random outliers would be legitimate as they are not clear mistakes or errors; they are just different to the majority of values in the data. In most cases, it is not a good idea to remove these kind of values as they potentially tell you something interesting, but you might need to approach the data analysis in a different way to ensure the results are robust to extreme values.\n\n11.3.1 Identifying error outliers\nUnless you can specifically identify values or participants you know contain errors, the main way to check is by ensuring the values are within known limits.\nWe can look at dawtry_clean and the key variables we explored in Chapter 8. Fairness and satisfaction was on a 1-9 scale, so we can check the minimum and maximum values numerically and via a plot. For example, we can isolate the variable and apply the summary() function.\n\ndawtry_clean %&gt;% \n  select(fairness_satisfaction) %&gt;% \n  summary()\n\n fairness_satisfaction\n Min.   :1.000        \n 1st Qu.:2.000        \n Median :3.000        \n Mean   :3.539        \n 3rd Qu.:5.000        \n Max.   :9.000        \n\n\nThe minimum and maximum values are nice and consistent with what we expect.\nFor a visual check, we can also plot the minimum and maximum possible values on a boxplot. This is just a check for you, so you do not need to worry so much about the presentation.\n\ndawtry_clean %&gt;% \n  ggplot(aes(y = fairness_satisfaction, x = \"\")) + # make x blank \n  geom_boxplot() + \n  scale_y_continuous(limits = c(1, 9), \n                     breaks = seq(1, 9, 1)) + \n  geom_hline(yintercept = c(1, 9), # min and max values\n             linetype = 2) # create dashed line\n\n\n\n\n\n\n\n\n\n\n\n\n\nTry this\n\n\n\nIf you explore redistribution from dawtry_clean, the minimum and maximum values are 1-6. Does it look like there are any problematic looking values? \nYes\nNo.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNo, it looks like all values are within the expected 1-6 range.\n\ndawtry_clean %&gt;% \n  select(redistribution) %&gt;% \n  summary()\n\n redistribution\n Min.   :1.00  \n 1st Qu.:3.25  \n Median :4.00  \n Mean   :3.91  \n 3rd Qu.:4.75  \n Max.   :6.00  \n\n\nWe can also confirm this with a visual check.\n\ndawtry_clean %&gt;% \n  ggplot(aes(y = redistribution, x = \"\")) + # make x blank \n  geom_boxplot() + \n  scale_y_continuous(limits = c(1, 6), \n                     breaks = seq(1, 6, 1)) + \n  geom_hline(yintercept = c(1, 6), # min and max values\n             linetype = 2) # create dashed line\n\n\n\n\n\n\n\n\n\n\nIf you did identify error outliers to remove, then you could use filter() (Chapter 5) to directly remove values outside your known range, or you could first use case_when() to code observations as outliers or not (Chapter 4), before deciding to filter them out.\n\n11.3.2 Identifying interesting or random outliers\nIdentifying error outliers relies on manually setting known minimum and maximum values, whereas identifying interesting or random outliers relies on data driven boundaries. For this example, we focus on univariate outliers, where we focus on one variable at a time. When we return to checking assumptions of regression models, you can identify interesting or random outliers through observations with large leverage / Cook’s distance values. In general, we recommend not removing outliers providing you are confident they are not errors. It is better to focus on modelling your outcome in a more robust way. However, it is also important you know how to identify errors for strategies you will come across in published research.\nWe focus here on setting boundaries using the median absolute deviation as recommended by Leys et al. (2019). You will see other approaches in the literature, but this method is useful as it’s influenced less by the very outliers it is trying to identify. We will use lopez_clean from Lopez et al. (2023) for this section.\nThere are two main steps to this process because we have two groups and each group will have different boundaries. If you only have individual variables, then you could just mutate() your data, without the initial group_by() and summarise() step.\nFirst, we group by the condition to get one value per group. We then calculate a few values for the median ounces of soup, 3 times the MAD in line with Leys et al., then calculating the upper and lower bound using these objects.\n\n# create a new object with values per group\nmad_bounds &lt;- lopez_clean %&gt;% \n  group_by(Condition_label) %&gt;% \n  summarise(oz_median = median(M_postsoup), # median of soup in oz\n            oz_MAD = 3 * mad(M_postsoup), # 3 times the MAD\n            lower = oz_median - oz_MAD, # lower bound \n            upper = oz_median + oz_MAD) # upper bound\n\nmad_bounds\n\n\n\n\nCondition_label\noz_median\noz_MAD\nlower\nupper\n\n\n\nControl\n7.8\n14.67774\n-6.87774\n22.47774\n\n\nExperimental\n10.6\n17.56881\n-6.96881\n28.16881\n\n\n\n\n\n\nIn this example, the lower bound is lower than 0 as the smallest possible value. The upper bounds are then between 22 and 28 depending on the group.\nSecond, we must add these values to the other information we have available. We join the data sets using Condition_label. This adds the relevant values to each group. We then use mutate() and case_when() to label values as outliers or not. If they are smaller or larger than the lower and upper bounds, they are labelled as “outliers”. If they are larger or smaller than the lower and upper bounds, they are labelled as “no outliers”.\n\nlopez_mad &lt;- lopez_clean %&gt;% \n  inner_join(mad_bounds, by = \"Condition_label\") %&gt;% \n  mutate(oz_outlier = case_when(M_postsoup &lt; lower | M_postsoup &gt; upper ~ \"Outlier\",\n                                M_postsoup &gt;= lower | M_postsoup &lt;= upper ~ \"No Outlier\"))\n\nWe can use these in one of two ways. First, we can visualise the presence of outliers by adding coloured points.\n\nlopez_mad %&gt;% \n  ggplot(aes(x = Condition_label, y = M_postsoup)) + \n  geom_boxplot() + \n  geom_point(aes(colour = oz_outlier)) # needs to be within aes to set dynamic values\n\n\n\n\n\n\n\nWe can see a few values per group flagged as outliers using this criterion. If you did decide to remove outliers, then you could use filter to remove them.\n\nlopez_remove &lt;- lopez_mad %&gt;% \n  filter(oz_outlier == \"No Outlier\")\n\n\n\n\n\n\n\nTry this\n\n\n\nIf you switch to dawtry_clean from Dawtry et al. (2015), apply the MAD procedure to the variable fairness_satisfaction. Does it look like there are any outliers using this criterion? \nYes\nNo.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNo, none of the values are outside the MAD thresholds. The thresholds are well beyond the minimum and maximum possible values of 1-9 for this variable.\n\ndawtry_mad &lt;- dawtry_clean %&gt;% \n  mutate(fs_median = median(fairness_satisfaction), # median of fairness/satisfaction\n         fs_MAD = 3 * mad(fairness_satisfaction), # 3 times the MAD\n         lower = fs_median - fs_MAD, # lower bound \n         upper = fs_median + fs_MAD,  # upper bound\n         fs_outlier = case_when(fairness_satisfaction &lt; lower | fairness_satisfaction &gt; upper ~ \"Outlier\",\n                                fairness_satisfaction &gt;= lower | fairness_satisfaction &lt;= upper ~ \"No Outlier\"))\n\nFor this variable and it’s bounded scale, no value is above or below the thresholds. You can see this in the data, or add horizontal lines in a plot since we are only plotting one variable. The dashed lines are the MAD thresholds and the solid lines are the minimum and maximum possible values.\n\ndawtry_mad %&gt;% \n  ggplot(aes(y = fairness_satisfaction, x = \"\")) + \n  geom_boxplot() + \n  geom_hline(aes(yintercept = lower), \n             linetype = 2) + # dashed line\n  geom_hline(yintercept = c(1, 9)) + \n  geom_hline(aes(yintercept = upper), \n             linetype = 2) + \n  scale_y_continuous(limits = c(-4, 10), \n                     breaks = seq(-4, 10, 2))\n\n\n\n\n\n\n\n\n\n\nRemember identifying outliers is a crucial researcher degree of freedom, so pre-register your choice of outlier detection wherever possible, and document how many outliers you removed. We still recommend favouring a more robust model, but you can make an informed decision."
  },
  {
    "objectID": "11-screening-data.html#checking-assumptions",
    "href": "11-screening-data.html#checking-assumptions",
    "title": "\n11  Missing data, outliers, and checking assumptions\n",
    "section": "\n11.4 Checking assumptions",
    "text": "11.4 Checking assumptions"
  },
  {
    "objectID": "11-screening-data.html#test-yourself",
    "href": "11-screening-data.html#test-yourself",
    "title": "\n11  Missing data, outliers, and checking assumptions\n",
    "section": "\n11.5 Test yourself",
    "text": "11.5 Test yourself\nTo end the chapter, we have some knowledge check questions to test your understanding of the concepts we covered in the chapter. We then have some error mode tasks to see if you can find the solution to some common errors in the concepts we covered in this chapter.\n\n11.5.1 Knowledge check\nQuestion 1.\n\n11.5.2 Error mode\nThe following questions are designed to introduce you to making and fixing errors. For this topic, we focus on the new types of data visualisation. Remember to keep a note of what kind of error messages you receive and how you fixed them, so you have a bank of solutions when you tackle errors independently.\nCreate and save a new R Markdown file for these activities. Delete the example code, so your file is blank from line 10.\n…"
  },
  {
    "objectID": "11-screening-data.html#end-of-chapter",
    "href": "11-screening-data.html#end-of-chapter",
    "title": "\n11  Missing data, outliers, and checking assumptions\n",
    "section": "\n11.7 End of Chapter",
    "text": "11.7 End of Chapter\nThat is the final chapter you will complete for Research Methods 1.\n\n\n\n\nDawtry, R. J., Sutton, R. M., & Sibley, C. G. (2015). Why Wealthier People Think People Are Wealthier, and Why It Matters: From Social Sampling to Attitudes to Redistribution. Psychological Science, 26(9), 1389–1400. https://doi.org/10.1177/0956797615586560\n\n\nJakobsen, J. C., Gluud, C., Wetterslev, J., & Winkel, P. (2017). When and how should multiple imputation be used for handling missing data in randomised clinical trials – a practical guide with flowcharts. BMC Medical Research Methodology, 17(1), 162. https://doi.org/10.1186/s12874-017-0442-1\n\n\nLeys, C., Delacre, M., Mora, Y. L., Lakens, D., & Ley, C. (2019). How to Classify, Detect, and Manage Univariate and Multivariate Outliers, With Emphasis on Pre-Registration. International Review of Social Psychology, 32(1), 5. https://doi.org/10.5334/irsp.289\n\n\nLopez, A., Choi, A. K., Dellawar, N. C., Cullen, B. C., Avila Contreras, S., Rosenfeld, D. L., & Tomiyama, A. J. (2023). Visual cues and food intake: A preregistered replication of Wansink et al (2005). Journal of Experimental Psychology: General. https://doi.org/10.1037/xge0001503.supp"
  }
]