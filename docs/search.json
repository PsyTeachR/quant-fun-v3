[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fundamentals of Quantitative Analysis",
    "section": "",
    "text": "Overview\nBook Name: Fundamentals of Quantitative Analysis.\nSummary: Materials for the MSc Conversion Research Methods 1 and 2 courses at the University of Glasgow School of Psychology & Neuroscience.\nAuthors: James Bartlett and Wil Toivo. This version of the book was adapted from a previous version written by Emily Nordmann and Phil McAleer.\nAim: This course covers data skills such as creating reproducible documents with R Markdown, data wrangling, and data visualisation with the tidyverse family of packages. It also introduces statistical concepts such as Null Hypothesis Significance Testing (NHST), as well as demonstrating how to perform numerous analyses based around the general linear model including regression and ANOVA.\nContact: This book is a living document and will be regularly checked and updated for improvements. Should you have any issues using the book or have any queries, please contact James Bartlett and Wil Toivo.\nR Version: This book has been written with R version 4.4.1 (2024-06-14)."
  },
  {
    "objectID": "00-foreword.html#welcome-to-the-fundamentals-of-quantitative-analysis",
    "href": "00-foreword.html#welcome-to-the-fundamentals-of-quantitative-analysis",
    "title": "How to use this book",
    "section": "Welcome to the Fundamentals of Quantitative Analysis",
    "text": "Welcome to the Fundamentals of Quantitative Analysis\nWe wrote and designed this book to support RM1 and RM2 on the MSc Psychology Conversion programme, where you will learn core quantitative data skills using R and R Studio. In addition to this book, the course team will support you with demonstration videos and we encourage you to use Teams or office hours to ask any questions.\nThe ability to work with quantitative data is a key skill for psychologists and by using R and R Studio as our tool, we can also promote reproducible research practices. Although at first it may seem like writing a programming script is more time-consuming than other point-and-click approaches, you speed up with practice. Once you have written a script that does what you need it to do, you can easily re-run your analysis without having to go through each step again manually which is easier and less likely to result in errors if you do something slightly different or forget one of the steps.\nCrucially, with an analysis script, you can demonstrate to other researchers how you got from the raw data to the statistics you report in your final paper. Sharing analysis scripts alongside published articles on sites such as the Open Science Framework is now an important open science practice. Even if you do not continue with quantitative research yourself, the skills you develop throughout these courses will allow you to evaluate quantitative research and to understand what goes on behind the scenes to produce their numbers and conclusions, allowing you to become a much more confident and competent consumer and user of research."
  },
  {
    "objectID": "00-foreword.html#how-to-use-this-book",
    "href": "00-foreword.html#how-to-use-this-book",
    "title": "How to use this book",
    "section": "How to use this book",
    "text": "How to use this book\nWe follow a scaffolding approach in this book to build your skills from following along to independently being able to apply these skills to new scenarios.\nIn each chapter, we first guide you through a set of demonstrations focused on different data skills, highlighting key parts of the output and what it means (just keep in mind we focus on the practical side of doing and interpreting in this book, the course lectures cover the conceptual background). We strongly encourage you to type out the code yourself, as this is good practice for learning to code, but remember you can copy and paste from the book if you need to. Typing the code will seem much slower at first and you will make lots errors, but you will learn much more quickly this way.\nAs you work through the book, you will see technical terms highlighted like console which link to a glossary we have developed as a team. If you hover the cursor over the highlighted word, it will show you a little definition, and you will be able to see a full list of words we highlighted at the bottom of each chapter. There are also different colour-coded boxes to emphasise different content. These provide information, warn you about something, highlight if something is dangerous and you should really pay attention, and try it yourself boxes when we have activities for you to complete.\n\n\n\n\n\n\nNote\n\n\n\nThese boxes have little interesting - but not critical - bits of information.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThese boxes warn you about something important in R / R Studio, so you pay attention when you use it.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThese boxes highlight where you need to be cautious when using or interpreting something, as it might be easy to make an error.\n\n\n\n\n\n\n\n\nTry this\n\n\n\nThese boxes will invite you to try something yourself, like complete independent activities or answer questions.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThese boxes will include small hints or solutions to check your understanding. Here we show the explanations by default, but normally they will be collapsed.\n\n\n\nAfter these demonstrations, we give you little activities and independent tasks using a new data set to test your understanding using interactive questions. This gives you instant feedback on whether you could apply the skills or if there is something you need to check again.\nSome of these activities are what we call “error mode”. You never stop making errors when coding - we still make them all the time - but you get faster at recognising and fixing common sources of error. Hoffman & Elmi (2021) demonstrated incorporating errors in learning materials can be useful to students, so we will give you a few segments of code containing errors that you need to fix. Seeing errors can be one of the most intimidating parts of learning to code, so this activity will normalise making errors and develop your problem solving skills.\nFinally, there are four data analysis journeys we will direct you to at key points throughout the book. We will tell you the end product you are aiming for from a new raw data set we provide, and your job is to break that end product down and identify a list of tasks to get there. Completing an independent data analysis task is the skill set you will need once it comes to assessments and your dissertation, as this is the point where you are the one making decisions.\nIn contrast to assignments, for all of these activities and data analysis journeys we provide solutions at the end of each chapter. No one is going to check whether you tried to figure out an activity yourself, rather than going straight to the solution, but if you copy and paste without thinking, you will learn nothing. Developing data skills and the knowledge that underpins those skills is like learning a language: the more you practice and the more you use it, the better you become."
  },
  {
    "objectID": "00-foreword.html#accompanying-videos",
    "href": "00-foreword.html#accompanying-videos",
    "title": "How to use this book",
    "section": "Accompanying videos",
    "text": "Accompanying videos\nMost of the chapters of this book have an associated video that you can access via Moodle. These videos are there to support you as you get comfortable in your data skills as you can see how someone else interacts with R / R Studio. However, it is important that you use them wisely. You should always try to work through each chapter of the book on your own first, and only then watch the video if you get stuck, or for extra information.\nFinally, this book is a living document. That means occasionally we will make updates to the book such as fixing typos and including additional detail or activities. When we make substantial changes, we will create new support materials such as the videos. However, it would be impossible to record a new video every time we make a minor change to an activity, so you may notice slight differences between the videos and the content of this book. Where there are differences between the book and the video, the book should always be considered the definitive version."
  },
  {
    "objectID": "00-foreword.html#data-set-acknowledgements",
    "href": "00-foreword.html#data-set-acknowledgements",
    "title": "How to use this book",
    "section": "Data set acknowledgements",
    "text": "Data set acknowledgements\nAlmost all the demonstrations and activities in this book use real data from published research to reinforce how these skills are the same ones researchers use behind the scenes of their articles. We use a range of data from our own research, open data that researchers share with their papers, and some we adapted from the Open Stats Lab who created activities using open data."
  },
  {
    "objectID": "00-foreword.html#intended-learning-outcomes-ilos",
    "href": "00-foreword.html#intended-learning-outcomes-ilos",
    "title": "How to use this book",
    "section": "Intended learning outcomes (ILOs)",
    "text": "Intended learning outcomes (ILOs)\nBy the end of the courses associated with this book, you will be able to:\n\nWrite reproducible reports using R Markdown.\nClean and wrangle data into appropriate forms for analysis.\nVisualise data using a range of plots.\nConduct and interpret a core set of statistical tests from the general linear model (regression, ANOVA)."
  },
  {
    "objectID": "00-foreword.html#acknowledgements",
    "href": "00-foreword.html#acknowledgements",
    "title": "How to use this book",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nWe put a lot of effort into creating the resources in this book, but occasionally typos or broken links will slip through. When a student helps us and highlights an error or makes a suggestion, we like to acknowledge it. We would like to thank the following students for helping us:\nRia Manwar.\n\n\n\n\nHoffman, H. J., & Elmi, A. F. (2021). Do Students Learn More from Erroneous Code? Exploring Student Performance and Satisfaction in an Error-Free Versus an Error-full SAS® Programming Environment. Journal of Statistics and Data Science Education, 0(0), 1–13. https://doi.org/10.1080/26939169.2021.1967229"
  },
  {
    "objectID": "01-programming-basics.html#r-and-rstudio",
    "href": "01-programming-basics.html#r-and-rstudio",
    "title": "1  Introduction to programming with R/R Studio",
    "section": "\n1.1 R and RStudio",
    "text": "1.1 R and RStudio\nR is a programming language that you will write code in and RStudio is an Integrated Development Environment (IDE) which makes working with R easier. Think of it as knowing English and using a plain text editor like NotePad to write a book versus using a word processor like Microsoft Word. You could do it, but it would not look as good and it would be much harder without things like spell-checking and formatting.\nIn a similar way, you can use R without RStudio but we wouldn not recommend it. The key thing to remember is that although you will do all of your work using RStudio for this course, you are actually using two pieces of software. This means that you will need both, you need to keep both up-to-date, and you should cite both in any work you do (see the Appendix on citing R and RStudio when needed).\nBut first we need to look at starting up R and RStudio. There are two ways you can use R for Psychology as a student here at the University of Glasgow. First, you can use a online version of R and R through your web browser and we will refer to this as the R server. Second, you can download and install R and RStudio for free on your laptop or desktop computer.\n\n1.1.1 Installing R and RStudio on your computer\nWe recommend wherever possible installing R and RStudio on your own computer. This is known as a local installation as you do not need to be connected to the internet to use it. We find it is easier to save and manage your files, and you can take your computer wherever you go.\nHowever, we appreciate not everyone has a computer that will support R and RStudio. All of our computer lab and library spaces have R and RStudio installed, so you will always be able to access those for working through the materials and your assignments. If you cannot install R and RStudio on your computer and there are accessibility issues preventing you from using the university computers, please come and speak with your course leads who will advise alternative options.\nTo install R and RStudio on your computer, please see the Installing R/RStudio guide which we use across all of our books. The guide covers installing R/RStudio on a Windows computer, Mac, and accessing the software on one of the university computers. Please install R and RStudio before continuing with the chapter."
  },
  {
    "objectID": "01-programming-basics.html#getting-to-know-r-studio",
    "href": "01-programming-basics.html#getting-to-know-r-studio",
    "title": "1  Introduction to programming with R/R Studio",
    "section": "\n1.2 Getting to know R Studio",
    "text": "1.2 Getting to know R Studio\nBy default, RStudio has four windows:\n\nThe console, where you can type R code in the bottom left (as shown in Figure Figure 1.1).\nEventually, there will be a script editor in the top left, but you will not see this when you open RStudio for the first time.\nThe environment window in top right, where you will see things like data, functions, and objects that you create.\nFinally, the bottom right window shows files, plots, packages, and help documentation.\n\n\n\n\n\nFigure 1.1: RStudio interface\n\n\n\nYou will learn more about how to use the features included in RStudio throughout this course, but we recommend watching the RStudio Essentials 1 series of videos from the Posit team (the company who maintain RStudio). The video we link here lasts around 30 minutes and gives a tour of the main parts of RStudio.\n\n1.2.1 Console vs. scripts\nWhen you first open up RStudio, you will not see an R script like above, there will just be the console window taking up the whole left half. You can write code in the console to test it out, but you cannot save that code anywhere, and you would lose all your code if you closed down RStudio.\nFor this chapter only, we will use the console window to show you some simple R code, but from Chapter 2 - Creating reproducible documents - we will teach you to work in a type of R script called an R Markdown document which ends with the file name .Rmd.\nYou can open a new file in a number of ways, but the simplest is in the top menu of RStudio, selecting File &gt;&gt; New File &gt;&gt; R Markdown and clicking OK. You will then be able to see the extra pane in the top left like Figure Figure 1.1."
  },
  {
    "objectID": "01-programming-basics.html#writing-code-with-functions-and-arguments",
    "href": "01-programming-basics.html#writing-code-with-functions-and-arguments",
    "title": "1  Introduction to programming with R/R Studio",
    "section": "\n1.3 Writing code with functions and arguments",
    "text": "1.3 Writing code with functions and arguments\nR code is made up of functions and arguments that go into the functions to create outputs. Functions in R execute specific tasks and normally take one or more arguments. You can think of these concepts like a spoken language as verbs (function) that require a subject and an object (arguments). You could also think of them as a kind of recipe. Some recipes (function) are quite simple and have one or two ingredients (arguments), while other recipes are more complicated with many ingredients (arguments).\nYou can spot functions as they end in round brackets (known as parentheses, ()), and the arguments go within the round brackets. They tend to look a bit like this:\n\nfunction_name(argument1 = value, argument2 = value)\n\nThat would be the layout of a function with two arguments and each argument takes a value. Bare with us as these concepts might feel super abstract until you start using them.\nYou will learn to use many functions throughout this book and you can look up all the arguments that a function takes in the help documentation by using the format ?function. You will see some arguments are required while others are optional. Optional arguments will often use what is known as a default setting, value, or option (normally specified in the help documentation) if you do not enter any value.\nAs an example, let us look at the help documentation for the function rnorm() - a function which randomly generates a set of numbers from what is known as the Normal Distribution.\n\n1.3.1 Activity 1 - Finding help documentation for functions\nOpen up RStudio and in the console window (bottom left), type the following code:\n\n?rnorm\n\nThe help documentation for rnorm() should appear in the bottom right help panel. In the Usage section of the help, we see that rnorm() takes the following form:\n\nrnorm(n, mean = 0, sd = 1)\n\nIn the Arguments section of the help, there are explanations for each of the arguments:\n\nn is the number of observations/numbers/data points we want to create,\nmean is the mean of the observations/numbers/data points we will create.\nand sd is the standard deviation of the observations/numbers/data points we will create.\n\nIn the Details section of the help, it notes that if no values are entered for mean and sd it will use a default of 0 for the mean and 1 for the standard deviation. So, these are the values the function will use for its arguments of mean and sd if you do not state any. However, because there is no default value for n, this means that you must state a value for the arguments n, otherwise the code will not run.\nThis is all still a little abstract, so let us try an example. Still using rnorm() let us set the required argument n to ask R to produce 5 random numbers.\n\n1.3.2 Activity 2 - Running your first function\nType the following two lines of code into your console window. Press enter/return on your keyboard at the end of each line to “run” that line. So, type set.seed(10072024) and press enter/return and then type rnorm(n = 5) and press enter/return. You will now see these numbers in your console window:\n\n\n[1] -0.6773381  2.9686894 -1.0461339 -1.4800300  0.4313315\n\n\nThese numbers have a mean close to 0 (M = 0.039) and a standard deviation (SD) close to 1 (SD = 1.784) - they are not exact because you only sampled a very small set and that sampling is random.\n\n\n\n\n\n\nWhat does set.seed() do?\n\n\n\n\n\nYou can get R to generate seemingly random numbers, but they are not totally random. Computers generate random numbers through a predictable process, but they pick a starting point based on something like the clock time. If you run rnorm(n = 5) several times in the console, you will see the five numbers are different each time. However, when you run set.seed(10072024) first, you will get the same five numbers every time, which is useful when you want a random but reproducible set of numbers.\n\n\n\nNow, we can play with the function and change the additional arguments to produce a different set of numbers. This time we will say we want 5 numbers again (n = 5) but we want our mean closer to 10 (mean = 10) and our standard deviation closer to 2 (sd = 2). We would do that as follows and you should see the output numbers below.\n\nset.seed(10072024)\n\nrnorm(n = 5, mean = 10, sd = 2)\n\n[1]  8.645324 15.937379  7.907732  7.039940 10.862663\n\n\nThis time, we created 5 random numbers again, but this set has a mean close to 10 (M = 10.079) and a SD close to 2 (SD = 3.569). Hopefully, you are starting to get a sense of arguments within functions, how you can change them, and how you can always remember to use the help documentation to understand what arguments a function requires.\nOver time, you start to remember which arguments you need within functions you commonly use, but even experienced R users have to regularly check the documentation. Coding is not a memory test, so do not worry if you find yourself needing to constantly look up the name of arguments.\n\n\n\n\n\n\nError mode\n\n\n\nOne thing that can be intimidating at first is making **&lt;a href=‘https://psyteachr.github.io/glossary/e#error’ target=’_blank’ class=‘glossary’ title=‘The statistical error in a linear model is how much an observation’s value differs from the (typically unobserved) true value of a population parameter.’&gt;errors**. They have little red marks and produce sometimes vague messages to try and explain what went wrong. You will make many errors as you learn and over time, you do not stop making errors, but you get faster at working out what went wrong and how you can fix it. So, we will introduce you to common errors as we work through the book to help with problem solving.\nTry and run the following code in the console:\n\nrnorm(mean = 10, sd = 2)\n\nYou should get an error saying something like Error in rnorm(mean = 10, sd = 2): argument \"n\" is missing, with no default. This error message is useful as it is telling us we forget to state the n argument which has no default value, so the function has no idea how many observations to give you. You would fix this error by adding a value for n within the function.\n\n\n\n1.3.3 Stating argument names\nIn the examples above, we have written out the argument names in our code (for example, we wrote n = 5, mean = 10, sd = 2), however, this is not strictly necessary. The following two lines of code would produce very similar outputs with the same number of values and similar means and standard deviations. Remember though: each time you run rnorm(), it will produce a slightly different set of numbers unless you set a seed.\n\nrnorm(n = 6, mean = 3, sd = 1)\nrnorm(6, 3, 1)\n\nThe main thing is that both lines of code would still work - the code knows what to do with the numbers. Both options work as the code is following a set order of arguments: n then mean then sd. If you do not write out the argument names, the code will use the default order of arguments, which for rnorm will assume that the first number you enter is n, the second number is mean, and the third number is sd.\nSo, you can write the argument names or not, but it is important to know the default order if you choose not to write the argument names. Alternatively, if you write out the argument names, then you can write the arguments in whatever order you like. The code below will still work and produce six numbers with a mean close to 3 and a standard deviation close to 1.\n\nrnorm(sd = 1, \n      n = 6, \n      mean = 3)\n\nWhen you are first learning R, we recommend writing out the argument names every time as it can help you remember and understand what each part of the function is doing. However, as your skills progress you may find it quicker to omit the argument names and you will also see examples of code online that do not use argument names. In this course, we will always write out the argument names the first time we use each function, but afterwards, we may omit them.\n\n\n\n\n\n\nWarning\n\n\n\nIf you do omit argument names, it is important to check the values you use for arguments are the ones you intended to you. The sneakiest errors are the ones that “work” in that they do not produce an error, but they are doing something different to what you expect. For example, if you wanted five numbers with a mean of 1 and SD of 2, rnorm(5, 2, 1) would work, but we accidentally entered the mean and SD the wrong way around.\n\n\n\n1.3.4 Tab auto-complete\nOne very useful feature of RStudio is the tab auto-complete for functions (see Figure Figure 1.2). If you write the name of the function and then press the tab key on your keyboard, RStudio will show you the arguments that function takes along with a brief description. If you press enter on the argument name, it will fill in the name for you, just like auto-complete on your phone.\nYou can also use the tab button when writing a function name to auto-complete that function name or to find functions that start with certain letters. This feature can be really helpful if you cannot quite remember the name of a function or argument.\n\n\n\n\nFigure 1.2: Tab auto-complete"
  },
  {
    "objectID": "01-programming-basics.html#packages",
    "href": "01-programming-basics.html#packages",
    "title": "1  Introduction to programming with R/R Studio",
    "section": "\n1.4 Base R and packages",
    "text": "1.4 Base R and packages\nWhen you install R, you will have access to a range of functions including options for data wrangling and statistical analysis. The functions that are included in the default installation of R are typically referred to as Base R and there is a useful cheat sheet that shows many Base R functions about halfway down this page under Contributed Cheatsheets here, along with a host of other cheatsheets you might find useful.\nHowever, the power of R is that it is extendable and open source. If a function does not exist or does not work very well, anyone can create a new package that contains data and/or code to allow you to perform new tasks. You can think of Base R as the default apps that come on your phone and other packages as additional apps; the ones that you really want to use to make the phone your own, but you need to download them separately.\n\n1.4.1 Activity 3 - Install the tidyverse to your own computer\nTo use a package, you must first install it. The following code installs the package tidyverse, a package we will use extensively throughout this course and introduce in the next chapter.\n\n\n\n\n\n\nWarning\n\n\n\nPlease do not complete this activity if you are working on the online R server or if you are using the computers in a University lab or Boyd Orr Building. You should only complete this activity on your own device. The university computers and server already have a version of all the packages we introduce you to, and installing a new version can cause problems by having a conflict between one version on your user profile and another version on the system profile.\n\n\nIf you are working on your own computer, use the code below to install the tidyverse and typing it into the console and pressing enter/return. Remember: if you are using the online R server or using a university computer, then skip this activity.\n\ninstall.packages(\"tidyverse\")\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you have a Windows computer and get an error message that says something like “WARNING: Rtools is required to build R packages” you may need to download and install an extra bit of software called Rtools. This was part of the R/RStudio installation instructions, so please see Installing R for more detailed instructions.\n\n\nYou only need to install a package once, but each time you start R / RStudio, you must load the packages you want to use. This is like how you need to install an app on your phone once, but you need to open it every time you want to use it.\nTo load packages, we use the function library() which loads packages into your working library. Typically, you would start any analysis script by loading all of the packages you need, but we will come back to that in the next chapter.\n\n1.4.2 Activity 4 - Load the tidyverse\nRun the code below to load the tidyverse into your working library. You must complete this activity regardless of whether you are using your own computer or the university computers / online server.\n\nlibrary(tidyverse)\n\nOften when you load packages you get information in your console window. Some packages will provide little messages to tell you what it has done or warn you about something. Sometimes these messages can look like errors and make you panic, but try and read over what it is saying first. For example, you should have something that looks like Figure Figure 1.3 when you load tidyverse. You might think you have done something wrong as it has little red crosses, but it is just telling you that it has loaded a set of packages and there are some conflicts.\n\n\n\n\nFigure 1.3: Example loading message from tidyverse.\n\n\n\nNow that we have loaded the tidyverse package, we can use any of the functions it contains but remember, you must run the library() function every time you start R.\n\n1.4.3 Package updates\nIn addition to updates to R and R Studio, the creators of packages also update their code. This can be to add additional functions to a package, or it can be to fix errors.\nOne thing to avoid is unintentionally updating an installed package. When you run install.packages(), it will always install the latest version of the package and it will overwrite any older versions you may have installed. Often this is not a problem, but sometimes you will find that the update means your code no longer works as the package has changed substantially. It is possible to revert back to an older version of a package but try to avoid updating a package unintentionally.\n\n\n\n\n\n\nWarning\n\n\n\nTo avoid accidentally overwriting a package with a later version, you should never include install.packages() in your analysis scripts in case you, or someone else runs the code by mistake. Remember, the online server and university computers will already have all of the packages you need for this course, so you only need to install packages if you are using your own computer.\n\n\n\n1.4.4 Package conflicts\nThere are thousands of different R packages and each package has many functions. Unfortunately, different people develop different packages and sometimes they use the same name for different functions. For example, the packages dplyr and MASS both have a function called select(). Do not run the below code, but if you did you would see a warning telling you that there is a conflict.\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(MASS)\n\n\nAttaching package: 'MASS'\n\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\n\nYou would see a warning that The following object is masked from 'package:dplyr': select.\nIn this case, R is telling you that the function select() in the dplyr package is being hidden (or ‘masked’) by another function with the same name from the MASS package. If you were to try and use select(), R would use the function from the package that was loaded most recently - in this case it would use the function from MASS. This can be an issue because you think you are using one function but really you are using another. They often work differently and you get odd issues in your code that you do not expect.\nThere are various solutions but one simple one - if you already know of the clash - is to specify which package you want to use for a particular function by writing the code in the format package::function, meaning “use the function from the package”, for example:\n\ndplyr::select()\nMASS::select()\n\nClashes are inevitable in your learning and when you see one, you will probably not spot it at first but you will learn to resolve them quickly."
  },
  {
    "objectID": "01-programming-basics.html#objects",
    "href": "01-programming-basics.html#objects",
    "title": "1  Introduction to programming with R/R Studio",
    "section": "\n1.5 Objects",
    "text": "1.5 Objects\nSo far, you have learnt about packages, and functions and arguments. Earlier we said functions give us outputs and another name for outputs - or at least specific types of outputs - are objects.\nObjects are the output of functions but you can also create objects without functions. Most of your coding will involve creating and manipulating objects. Objects contain stuff, which could be numbers, words, or the result of functions, operations, and analyses.\nThe first key thing to know about objects is how to create them and to give them content. You assign content to an object using &lt;- - often called the “left arrow” or the assignment operator which you can read as “assigned to”. Note that we do not use the = symbol as an assignment operator. There is a large discussion on why objects are assigned content and not equal to content but that is for another time. For now, just remember that we assign (&lt;-) content, be it words, numbers, or function output, to objects.\n\n1.5.1 Activity 5 - Create some objects\nType the following code into the console window and run each line. You should see that name, age, today, new_year, and data appear in the environment pane like Figure Figure 1.4.\n\nname &lt;- \"James\"\nage &lt;- 16 + 14 \ntoday &lt;- Sys.Date()\nnew_year &lt;- as.Date(\"2025-01-01\")\ndata &lt;- rnorm(n = 10, mean = 15, sd = 3)\n\n\n\n\n\nFigure 1.4: Objects in the environment. Feel free to change your numbers and check that they match the environment!\n\n\n\nNote that in these examples, name,age, and new_year would always contain the values James, 30, and the date of New Year’s Day 2025, but today will draw the date from the operating system on the day you are using the computer, and data will be a randomly generated set of data - as we saw earlier - so the values of these objects will not be static.\n\n\n\n\n\n\nTry this\n\n\n\nTry changing the name to your name and the age to your age, and seeing if they update in the environment window.\n\n\nImportantly, for what we will learn in future chapters, you can use different objects in calculations and interact with each other. For example:\n\nage + 10\n\n[1] 40\n\n\n\nnew_year - today\n\nTime difference of 110 days\n\n\n\nmean(data)\n\n[1] 15.02667\n\n\nFinally, you can store the result of these operations on objects in a new object as below:\n\ndecade &lt;- age + 10\n\nRemember that you may find it helpful to read &lt;- as contains or assigned to, e.g., name contains the text James or James is assigned to the object name.\nYou will constantly be creating objects throughout this course and you will learn more about them and how they behave as we go along. For now, it is enough to understand that they are a way of saving values, that these values can be numbers, text, or the result of operations, and that you can use objects in further operations to create new objects.\n\n\n\n\n\n\nWhat should I call objects?\n\n\n\nIn coding, we are trying to balance keeping objects names as short as possible to be easy to type repeatedly, while being informative enough that you know what they represent days, weeks, or months later when they are not fresh in your memory.\nFor example, dob might save time now, but birth_date will be easier to understand in future.\n\n\n\n1.5.2 Looking after the environment\nNow that you are starting to learn about the other windows in RStudio like the environment window, if you have been writing a lot of code, you may find that the environment window (or workspace) becomes cluttered with many objects. This can make it difficult to figure out which object you need and you run the risk of using the wrong value or data frame. If you are working on a new dataset, or if you have tried lots of different code before getting the final version, it is good practice to remember to clear the environment to avoid using the wrong object. You can do this in several ways.\n\nTo remove individual objects, you can type rm(object_name) in the console. Try this now to remove one of the objects you created in the previous section. For example, you would remove the object age by writing rm(age).\nTo clear all objects from the environment, run rm(list = ls()) in the console.\nTo clear all objects from the environment, you can also click the broom icon in the environment pane like Figure Figure 1.5.\n\n\n\n\n\nFigure 1.5: Clearing the workspace."
  },
  {
    "objectID": "01-programming-basics.html#global-options",
    "href": "01-programming-basics.html#global-options",
    "title": "1  Introduction to programming with R/R Studio",
    "section": "\n1.6 Global options",
    "text": "1.6 Global options\nWhen you open RStudio, it will show you what you were last working on, including your code and any objects you have created, assuming this is not the first time you have used RStudio. This might sound helpful, but it can cause more problems than it is worth because it means that you risk accidentally using an old version of an object.\nFor example, you might have Date in the environment from the last time you did some work and you start working on the wrong Date without realising. In reality, we recommend changing the settings so that each time you start RStudio, it opens a fresh new environment.\nYou can do this by clicking on the top menu Tools &gt;&gt; Global Options... and then deselecting boxes so that your General box looks like Figure Figure 1.6 and applying the changes to save your selections.\n\n\n\n\nFigure 1.6: Global options - you want to make your global options look similar, in terms of what is ticked, to the above. The main thing is to make sure that you untick Restore RData into workspace at startup, and set Save workspace to .RData on exit to Never. Unticking the History options are optional but can help. The update option is really just in case you want to.\n\n\n\nThat should save a lot of hassle going forward. You will still encounter issues of course, so we are going to end this chapter by outlining where you can get help."
  },
  {
    "objectID": "01-programming-basics.html#getting-help",
    "href": "01-programming-basics.html#getting-help",
    "title": "1  Introduction to programming with R/R Studio",
    "section": "\n1.7 Getting Help",
    "text": "1.7 Getting Help\n\n1.7.1 Help and additional resources\nLearning to code really means trying stuff out, searching for help online when it does not work, and finding examples of code to adapt to your own needs.\nIf you are having difficulty with any of the content in this book, then you can of course ask for help from the course team but learning to problem solve effectively is a key skill that you will develop throughout this course and beyond.\nThere are a wealth of additional resources in the Appendix of this book, so it might be worth checking them out, but here are four approaches we take to resolving an issue when we hit a problem.\n\nUse the help documentation. If you are struggling to understand how a function works or what the arguments are, remember the ?function command.\nThink about when you last had to use this function or code successfully. Look back on what you did then and see what is the difference.\nIf you get an error message, copy and paste it into Google. It is very likely someone else has had the same problem.\nTrying Googling your question in the style of the package name or function name and what you want to do. For example, arrange data tidyverse or maybe sort data in R.\n\nIf those approaches do not work, in addition to these course materials and the other PsyTeachR books from other courses we run, there are many excellent online resources for learning data skills that can serve as quick guides:\n\nIndividual package cheat sheets which you can find via the top menu: Help &gt;&gt; Cheat Sheets.\nR Cookbook.\nStackOverflow.\nR for Data Science.\n\n1.7.2 Debugging tips\nAnother top skill for resolving issues is what is known as debugging - fixing your coding mistakes. A large part of coding is trying to figure why your code does not work and this is true whether you are a novice or an expert. As you progress through this course, try and keep a record of mistakes you make and how you fixed them. We will highlight common mistakes to look out for throughout the book but you will undoubtedly make (and fix) new mistakes yourself.\nYou never stop making mistakes, you just get better at problem solving and having a list of strategies that worked in the past. That is why we include error mode as a set of activities to develop your problem solving skills and normalise making errors.\nAs a short list of suggestions when you come across an error, keep in mind:\n\nHave you loaded the correct packages for the functions you are trying to use? One common mistake is to write the code to load the package, e.g., library(tidyverse) but then forget to press enter/return to run it.\nHave you made a typo? Coding has to be specific on spelling and data is not the same as DATA, and t.test is not the same as t_test.\nIs there a package conflict? Have you tried specifying the package and function with package::function?\nIs it definitely an error? Not all red text in R / RStudio means an error. Sometimes it is just giving you a message with information.\n\n1.7.3 Activity 6 - Reset your R session\nFinally, if you find that your code is not working and you cannot figure out why, it might be worth starting a new session. This will clear the environment and detach all loaded packages. Think of it like restarting your phone.\nWhen you open up R and start writing code, loading packages, and creating objects, you are typically doing so in a new session. In addition to clearing your environment workspace, it can sometimes be useful to start a new session. This will happen automatically each time you start RStudio on your computer, although sessions can persist if you use the online server.\nThis last activity shows a quick way to restart R from inside RStudio. On the Top Menu, click Session &gt;&gt; Restart R like Figure Figure 1.7.\n\n\n\n\nFigure 1.7: Restarting your R session from within RStudio.\n\n\n\nTry not to worry about making mistakes. Accept that you will make them and learn from them. We are always here to help if you are struggling, so reach out to the course team, post on Teams, or attend a graduate teaching assistant (GTA) session."
  },
  {
    "objectID": "01-programming-basics.html#test-yourself",
    "href": "01-programming-basics.html#test-yourself",
    "title": "1  Introduction to programming with R/R Studio",
    "section": "\n1.8 Test yourself",
    "text": "1.8 Test yourself\nThroughout the book, you will find additional questions and activities like these to help you check your understanding. Some will have blanks to fill in, some will be multiple choice, but the chapters include the answers and explanations to check your understanding against. You are always welcome to ask further questions to the course team though.\n\n1.8.1 Knowledge check\nQuestion 1. Why should you never include the code install.packages() in your analysis scripts?\n\nYou should use library() insteadPackages are already part of Base RYou (or someone else) may accidentally install a package update that stops your code workingYou already have the latest version of the package\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nRemember, when you run install.packages() it will always install the latest version of the package and it will overwrite any older versions of the package you may have installed.\n\n\n\nQuestion 2. What will the following code produce?\n\nrnorm(6, 50, 10)\n\n\nA dataset with 10 numbers that has a mean of 6 and an SD of 50A dataset with 6 numbers that has a mean of 50 and an SD of 10A dataset with 50 numbers that has a mean of 10 and an SD of 6A dataset with 50 numbers that has a mean of 10 and an SD of 6\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nThe default form for rnorm() is rnorm(n, mean, sd). If you need help remembering what each argument of a function does, look up the help documentation by running ?rnorm.\n\n\n\nQuestion 3. If you have two packages that have functions with the same name and you want to specify exactly which package to use, what code would you use?\n\npackage::functionfunction::packagelibrary(package)install.packages(package)\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nYou should use the form package::function, for example dplyr::select. Remember that when you first load your packages R will warn you if any functions have the same name - remember to look out for this!\n\n\n\nQuestion 4. Which of the following is most likely to be the input to an argument?\n\n35&lt;-read_csv()\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nread_csv() looks like a function as it has the round brackets at the end and the &lt;- is the assignment symbol, so it is most likely that 35 might be the input to an argument as it is just a value.\n\n\n\nQuestion 5. An easy way to spot functions is to look for\n\ncomputersnumbersround brackets\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nRemember that functions tend to have round brackets or parentheses at the end of their name and the arguments and values go inside the parentheses.\n\n\n\nQuestion 6. The job of &lt;- is to send the output from the function to a/an\n\nargumentobjectassignment\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nThis is the assignment operator (&lt;-) and we use it to assign content such as the output of functions to an object.\n\n\n\n\n1.8.2 Error mode\nThe following questions are designed to introduce you to making and fixing errors. Try and run the code, look at the error message, and see if you can fix it before checking the answer. Consider keeping a note of what kind of error messages you receive and how you fixed them, so you have a bank of solutions when you tackle errors independently.\nQuestion 7. Type the following code into the console and press enter/return: rnorm(n = 10, meen = 5, sd = 1). You should get an error saying something like Error in rnorm(n = 10, meen = 5, sd = 1) : unused argument (meen = 5). How can you fix it?\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nWe accidentally spelt one of the arguments incorrectly. If you look closely, you will see that we typed meen spelt with two es instead of one e when we should have typed mean.\n\n\n\nQuestion 8. To end on a sneaky one that we have not covered in this chapter, type the following code into the console and press enter/return: rnorm(n = 10, mean = 5, sd = 1. What happened and how can you fix it? Before checking the explain this answer box below, maybe try and Google what happens to see if you can describe it and find a solution.\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nWe missed the final bracket, so we start the function name rnorm(, enter our arguments, but there is no closing bracket. You will see in the console like Figure Figure 1.8, there is a little + symbol and you can enter new code, but there is no output.\n\n\n\n\nFigure 1.8: An R function without a closing bracket in the console.\n\n\n\nThis can be really frustrating as it looks like nothing is happening, but when you did not add a closing bracket, R is just sitting there waiting for you to add something else. To fix it, you can either type ) and press enter/return to finish the function and it should work, or you can press the escape (esc) key to cancel the code and start again."
  },
  {
    "objectID": "01-programming-basics.html#words-from-this-chapter",
    "href": "01-programming-basics.html#words-from-this-chapter",
    "title": "1  Introduction to programming with R/R Studio",
    "section": "\n1.9 Words from this Chapter",
    "text": "1.9 Words from this Chapter\nBelow, you will find a list of words that we used in this chapter that might be new to you in case you need to refer back to what they mean. The links in this table take you to the entry for the words in the PsyTeachR Glossary. Note that numerous members of the team wrote entries in the Glossary and as such the entries may use slightly different terminology from what we used in the chapter.\n\n\n\n\nterm\ndefinition\n\n\n\nargument\nA variable that provides input to a function.\n\n\nassignment-operator\nThe symbol &lt;-, which functions like = and assigns the value on the right to the object on the left\n\n\nbase-r\nThe set of R functions that come with a basic installation of R, before you add external packages.\n\n\nconflict\nHaving two packages loaded that have a function with the same name.\n\n\nconsole\nThe pane in RStudio where you can type in commands and view output messages.\n\n\ndefault-value\nA value that a function uses for an argument if it is skipped.\n\n\nenvironment\nA data structure that contains R objects such as variables and functions\n\n\nerror\nThe statistical error in a linear model is how much an observation's value differs from the (typically unobserved) true value of a population parameter.\n\n\nfunction\nA named section of code that can be reused.\n\n\nmean\nA descriptive statistic that measures the average value of a set of numbers.\n\n\nnormal-distribution\nA symmetric distribution of data where values near the centre are most probable.\n\n\nobject\nA word that identifies and stores the value of some data for later use.\n\n\npackage\nA group of R functions.\n\n\nr-markdown\nThe R-specific version of markdown: a way to specify formatting, such as headers, paragraphs, lists, bolding, and links, as well as code blocks and inline code.\n\n\nrstudio\nAn integrated development environment (IDE) that helps you process R code.\n\n\nscript\nA plain-text file that contains commands in a coding language, such as R.\n\n\nsession\nWhen you start R/RStudio and executive code to fill the workspace until you close R/RStudio\n\n\nstandard-deviation\nA descriptive statistic that measures how spread out data are relative to the mean.\n\n\ntidyverse\nA set of R packages that help you create and work with tidy data"
  },
  {
    "objectID": "01-programming-basics.html#end-of-chapter",
    "href": "01-programming-basics.html#end-of-chapter",
    "title": "1  Introduction to programming with R/R Studio",
    "section": "\n1.10 End of chapter",
    "text": "1.10 End of chapter\nWell done on reaching the end of the first chapter! This was one of the longest chapters in the book to introduce you to several foundational concepts of coding in R and RStudio. The next chapter builds on these skills to produce something a little more concrete by showing you how to create reproducible documents."
  },
  {
    "objectID": "02-starting-with-data.html#02-projects",
    "href": "02-starting-with-data.html#02-projects",
    "title": "2  Creating Reproducible Documents",
    "section": "\n2.1 File structure, working directories, and R Projects",
    "text": "2.1 File structure, working directories, and R Projects\nIn chapter 1, we never worked with files, so you did not have to worry about where you put things on your computer. Before we can start working with R Markdown files, we must explain what a working directory is and how your computer knows where to find things.\nYour working directory is the folder where your computer starts to look for files. It would be able to access files from within that folder and within sub-folders in your working directory, but it would not be able to access folders outside your working directory.\nIn this course, we are going to prescribe a way of working to support an organised file system, helping you to know where everything is and where R will try to save things on your computer and where it will try to save and load things. Once you become more comfortable working with files, you can work in a different way that makes sense to you, but we recommend following our instructions for at least RM1 as the first course.\n\n2.1.1 Activity 1: Create a folder for all your work\nIn your documents or OneDrive, create a new folder called ResearchMethods1_2. This will be your highest level folder where you will save everything for Research Methods 1 and 2.\n\n\n\n\n\n\nTop tip\n\n\n\nWhen you are a student at the University of Glasgow, you have access to the full Microsoft suite of software. One of those is the cloud storage system OneDrive. We heavily recommend using this to save all your work in as it backs up your work online and you can access it from multiple devices.\n\n\nWithin that folder, create two new folders called Assessments and Quant_Fundamentals. In Assessments, you can save all your assessments for RM1 and RM2 as you come to them. In Quant_Fundamentals, that is where you will save all your work as you progress through this book.\nWithin Quant_Fundamentals, create a new folder called Chapter_02_reproducible_docs. As you work through the book, you will create a new chapter folder each time you start a new chapter and the sub-folders will always be the same. Within Chapter_02_reproducible_docs, create two new folders called data and figures. As a diagram, it should look like Figure 2.1.\n\n\n\n\nFigure 2.1: Prescribed file structure for RM 1 and RM 2.\n\n\n\n\n\n\n\n\n\nHow to name files and folders\n\n\n\nYou might notice in the folder names we avoided using spaces by adding things like underscores _ or capitalising different words. Historically, spaces in folder/file names could cause problems for code, but now it’s just slightly easier when file names and folder names do not have spaces in them.\nFor naming files and folders, try and choose something sensible so you know what it refers to. You are trying to balance being as short as possible, while still being immediately identifiable. For example, instead of fundamentals of quantitative analysis, we called it Quant_Fundamentals.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nWhen you create and name folders to use with R / RStudio, whatever you do, do not call the folder “R”. If you do this, sometimes R has an identity crisis and will not save or load your files properly. It can also really damage your setup and require you to reinstall everything as R tends to save all the packages in a folder called R. If there is another folder called R, then it gets confused and stops working properly.\n\n\n\n\n\n\n\n\nFile management when using the online server\n\n\n\n\n\nIf we support you to use the online University of Glasgow R Server, working with files is a little different. If you downloaded R / RStudio to your own computer or you are using one of the library/lab computers, please ignore this section.\nThe main disadvantage to using the R server is that you will need create folders on the server and then upload and download any files you are working on to and from the server. Please be aware that there is no link between your computer and the R server. If you change files on the server, they will not appear on your computer until you download them from the server, and you need to be very careful when you submit your assessment files that you are submitting the right file. This is the main reason we recommend installing R / RStudio on your computer wherever possible.\nGoing forward throughout this book, if you are using the server, you will need to follow an extra step where you also upload them to the sever. As an example:\n\nLog on to the R server using the link we provided to you.\nIn the file pane, click New folder and create the same structure we demonstrated above.\nDownload ahi-cesd.csv and participant-info.csv into the data folder you created for chapter 2. To download a file from this book, right click the link and select “save link as”. Make sure that both files are saved as “.csv”. Do not open them on your machine as often other software like Excel can change setting and ruin the files.\nNow that the files are stored on your computer, go to RStudio on the server and click Upload then Browse and choose the folder for the chapter you are working on.\nClick Choose file and go and find the data you want to upload.\n\n\n\n\n\n2.1.2 Manually setting the working directory\nNow that you have a folder structure that will keep everything nice and organised, we will demonstrate how you can manually set the working directory. If you open RStudio, you can check where the current working directory is by typing the function getwd() into the console and pressing enter/return. That will show you the current file path R is using to navigate files. If you look at the Files window in the bottom right, this will also show you the files and folders available from your working directory.\nIf you click on the top menu Session &gt;&gt; Set Working Directory &gt;&gt; Choose Directory..., (Figure 2.2) you can navigate through your documents or OneDrive until you can select Chapter_02_reproducible_docs. Click open and that will set the folder as your working directory. You can double check this worked by running getwd() again in the console.\n\n\n\n\nFigure 2.2: Manually setting the working directory.\n\n\n\n\n2.1.3 Activity 2 - Creating an R Project\nKnowing how to check and manually set your working directory is useful, but there is a more efficient way of setting your working directory alongside organised file management. You are going to create something called an R Project.\nTo create a new project for the work you will do in this chapter (Figure 2.3):\n\nClick on the top menu and navigate to File &gt;&gt; New Project....\nYou have the option to select from New Directory, Existing Directory, or Version Control. You already created a folder for Chapter_02_reproducible_docs, so select Existing Directory.\nClick Browse… next to Project working directory to select the folder you want to create the project in.\nWhen you have navigated to Chapter_02_reproducible_docs for this chapter, click Open and then Create Project.\n\n\n\n\n\n\n\n\n\n\nFigure 2.3: Starting a new project.\n\n\nRStudio will restart itself and open with this new project directory as the working directory. You should see something like Figure 2.4.\n\n\n\n\nFigure 2.4: RStudio screen in a new project in your chapter 2 folder.\n\n\n\nIn the files tab in the bottom right window, you will see all the contents in your project directory. You can see your two sub-folders for data and figures and a file called Chapter_02_reproducible_docs.Rproj. This is a file that contains all of the project information. When you come back to this project after closing down RStudio, if you double click on the .Rproj file, it will open up your project and have your working directory all set up and ready to go.\n\n\n\n\n\n\nWarning\n\n\n\nIn each chapter, we will repeat these instructions at the start to prescribe this file structure, but when you create your own folders and projects, do not ever save a new project inside another project. This can cause some hard to resolve problems. For example, it would be fine to create a new project within the Quant_Fundamentals folder as we will do for each new chapter, but should never create a new project within the Chapter_02_reproducible_docs folder."
  },
  {
    "objectID": "02-starting-with-data.html#creating-and-navigating-r-markdown-documents",
    "href": "02-starting-with-data.html#creating-and-navigating-r-markdown-documents",
    "title": "2  Creating Reproducible Documents",
    "section": "\n2.2 Creating and navigating R Markdown documents",
    "text": "2.2 Creating and navigating R Markdown documents\nNow you know how to navigate files and folders on your computer, we can start working with R Markdown files.\nThroughout this data skills book and related assignments, you will use a file format called R Markdown (abbreviated as .Rmd) which is a great way to create dynamic documents combining regular text and embedded code chunks.\nR Markdown documents are self-contained and fully reproducible, meaning if you have the necessary data, you should be able to run someone else’s analyses. This is an important part of your open science training as one of the reasons we teach data skills this way is that it enables us to share open and reproducible information.\nUsing these worksheets enables you to keep a record of all the code you write as you progress through this book (as well as any notes to help yourself), for data skills assessments we can give you a task to add required code, and in your research reports you can independently process, visualise, and analyse your data all from one file.\nFor more information about R Markdown, feel free to have a look at their main webpage http://rmarkdown.rstudio.com, but for now the key advantage to know about is that it allows you to write code into a document, along with regular text, and then knit it to create your document as either a webpage (html), a PDF, or Word document (.docx).\n\n2.2.1 Activity 3: Open, save, and knit a new R Markdown document\nOpen a new R Markdown document by clicking the ‘new item’ icon and then click ‘R Markdown’ like Figure 2.5.\n\n\n\n\n\n\n\n\n\nFigure 2.5: Creating a new R Markdown document from the menu (left) and setting title, author, date, and output (right).\n\n\nAfter selecting R Markdown, there are different format options you can explore in time, but Select Document and there are four boxes to complete:\n\nTitle: This is the title for the document which will appear at the top of the page. For this chapter, enter 02 Creating Reproducible Documents.\nAuthor: This is where you can add your name or names for multiple people. For this chapter, enter your GUID as this will be good practice for the data skills assignments.\nDate: By default, it adds today’s date, so it will update every time you knit the document. Leave the default so you know when you completed the chapter, but if you untick, you can manually enter a static date.\nDefault Output Format: You have the option to select from html, PDF, and Word. We will demonstrate how to change output format in a later chapter, so keep html for now as it’s the most flexible format.\n\nOnce you click OK, this will open a new R Markdown document.\nSave this R Markdown document by clicking File &gt;&gt; Save as from the top menu, and name this file “02_reproducible_docs”. Note the document title and file name are separate, so you still have to name the file when you save it.\nIf you have set the working directory correctly, you should now see this file appear in your Files window in the bottom right hand corner like Figure 2.6, alongside your .Rproj file and two folders.\n\n\n\n\nFigure 2.6: New .Rmd file in your working directory.\n\n\n\nNow you have the default version of the R Markdown file, you have a bunch of text and code to show its capabilities (Figure 2.7).\n\n\n\n\nFigure 2.7: Default text and code in a new R Markdown document.\n\n\n\nWe will now demonstrate what it looks like to knit a document. This means that we are going to compile (i.e., turn) our code into a document that is more presentable. This way, you can check it knits and there are no errors. So, as we add changes in the following activities, you can identify if and when any errors appear and fix them quicker.\nAt the top of your R Markdown window, you should see a Knit button next to a little ball of yarn (Figure 2.8). If you click that, the document will knit and produce a html file.\n\n\n\n\nFigure 2.8: Clicking the knit button on a .Rmd document.\n\n\n\nYou will see a small version of the knitted document appear in the Viewer tab in the bottom right of your screen. You will also see it has created a new file in your working directory. It will have the same name as your R Markdown file, but with .html as the file ending. You can view the knitted document by clicking the “Show in new window” button or opening the file from your folder (Figure 2.9). This should open the document in your default internet browser as websites are created in html.\n\n\n\n\n\n\n\n\n\nFigure 2.9: On the left, you can see a small version of the knitted document in the Viewer tab. On the right, you can see the full version open in your internet browser.\n\n\nNow everything is working and knitting, we can start editing the R Markdown file to add new content.\n\n2.2.2 Activity 4: Create a new code chunk\nLet’s start using your new R Markdown document to combine code and text. Follow these steps:\n\nDelete everything below line 10.\n\n\n\n\n\n\n\nWhat does the {r setup} chunk do?\n\n\n\n\n\nAt the moment, you do not need to worry about the code chunk between lines 8 and 10. We are slowly introducing you to different features in R Markdown as it’s easier to understand by doing, rather than giving you a list of explanations.\nIf you are really curious though, this setting forces R Markdown to show both the code and output for all code chunks. When we add code shortly, if you change it to echo = FALSE, it will only show the output and not the code.\n\n\n\n\nOn line 12, type “## About me”.\nWith your cursor on line 14, insert a blank code chunk by clicking on the top menu Code &gt;&gt; Insert Chunk or using the shortcut at the top of the R Markdown window that looks like a small green c and select R.\n\nYour document should now look something like Figure 2.10.\n\n\n\n\nFigure 2.10: Creating a new R chunk in your blank R Markdown document\n\n\n\nWhat you have created is called a code chunk. R Markdown assumes anything written outside of a code chunk is just normal text, just like you would have in a text editor like Word. It assumes anything written inside the code chunk is R code. This makes it easy to combine both text and code in one document.\n\n\n\n\n\n\nError mode\n\n\n\nWhen you create a new code chunk, you should notice that the grey box starts and ends with three back ticks (```), followed by the {r}, and then it ends with three back ticks again. This is the structure that creates a code chunk. You could actually just type this structure instead of using the Insert approach but we are introducing you to some shortcuts\nOne common mistake is to accidentally delete one or more of these back ticks. A useful thing to notice is that code chunks tend to have a different color background - in the default appearance of RStudio a code chunk is grey and the normal text is white. You can use this to look for mistakes. If the colour of certain parts of your Markdown does not look right, check that you have not deleted the backticks.\nRemember it is backticks (i.e. this `) and not single quotes (i.e. not this ’).\n\n\n\n\n\n\n\n\nMarkdown language\n\n\n\nWhen you typed “## About me”, you might notice the two hashes. You will see the effect of this shortly, but this is using Markdown language to add document formatting. Markdown is a type of formatting language, so instead of using buttons to add features like you would in Word, you add symbols which will produce different features when you knit the document.\nThe hashes create headers. One (#) creates a first level header (larger text), two (##) creates a second level header, and so on. Make sure there is a space between the text and hash or it will not knit properly.\nAs we progress through the book, we will slowly introduce you to different Markdown features, but you can see the RStudio Markdown Basics page if you are interested.\n\n\n\n2.2.3 Activity 5: Write some code\nNow we are going to use the code examples you read about in Chapter 1 - Introduction to programming with R/R Studio - to add some code to our R Markdown document.\nIn your code chunk, write the code below but replace the values of name/age/birthday with your own details). Remember that the four lines of code should all be inside the code chunk.\nNote: Text and dates need to be contained in quotation marks, e.g., “my name”. Numerical values are written without quotation marks, e.g., 45.\n\nname &lt;- \"James\" \nage &lt;- 30\ntoday &lt;- Sys.Date()\nnext_birthday &lt;- as.Date(\"2025-02-18\") # Year, month, day format\n\n\n\n\n\n\n\nError mode\n\n\n\nMissing and/or unnecessary quotation marks are a common cause of code not working. For example, if you try and type name &lt;- James, R will try and look for an object called James and throw an error since there is not an object called that. When you add quotation marks, R recognises you are storing a character.\n\n\n\n2.2.4 Activity 6: Run your code\nWe now have code in our code chunk and now we are going to run the code. Running the code just means making it do what you told it, such as creating objects or using functions. Remember you need to write the code first, then tell RStudio to run the code.\nWhen you are working in an R Markdown document, there are several ways to run your lines of code.\n\nOne option is you can highlight the code you want to run and then click Run &gt;&gt; Run Selected Line(s) (Figure 2.11).\n\n\n\n\n\nFigure 2.11: Slower method of running code by highlighting and clicking Run Selected Line(s).\n\n\n\n\nYou can press the green “play” button at the top-right of the code chunk and this will run all lines of code in that chunk (Figure 2.12).\n\n\n\n\n\nFigure 2.12: Slightly faster method of running all code in a chunk by clicking the green “play” button.\n\n\n\n\nThere are keyboard shortcuts to run code which will be the fastest as you learn and use RStudio more frequently. For example, to run a single line of code, make sure that the cursor is in the line of code (it can be anywhere on the line) you want to run and press ctrl + enter (command + return on a Mac).\n\n\n\n\n\n\n\nKeyboard shortcuts\n\n\n\nThere are loads of keyboard shortcuts, but you might only use a handful to speed up your day-to-day tasks. For a full list, look in the top menu Help &gt;&gt; Keyboard shortcuts help.\n\n\nNow run your code using one of the methods above. You should see the variables name, age, today, and next_birthday appear in the environment pane in the top right corner.\n\n\n\n\n\n\nTry this\n\n\n\nClear out the environment using the broom handle approach we saw in Chapter 1 and try a different method to see which works best for you.\n\n\n\n2.2.5 Activity 7: Inline code\nYour code works and you now know how to run it, but one of the incredible benefits we said about R Markdown is that you can mix text and code. Even better is the ability to combine code with text to put specific outputs of your code, like a value, using inline code.\nThink about a time you have had to copy and paste a value or text from one file into another and you will know how easy it can be to make mistakes or find the origin of your mistake. Inline code avoids this. It is easier to show you what inline code does rather than to explain it so let us have a go.\nFirst, copy and paste this text exactly (do not change anything) to underneath and outside your code chunk:\n\nMy name is `r name` and I am `r age` years old. \n\nIt is `r next_birthday - today` days until my birthday.\n\nYour .Rmd should look like Figure 2.13 but nothing will happen yet. Unlike code chunks, you cannot run inline code. You need to knit your document for it to do it’s magic.\n\n\n\n\nFigure 2.13: Complete .Rmd file with your about me section and inline code.\n\n\n\n\n\n\n\n\n\nHow does inline code work?\n\n\n\n\n\nInline code has the following form:\n\n`r object`\n\nor\n\n`r function(...)`\n\nHere, we are using the first version where we are referencing an object we already created. This is normally a good idea if you have a long function to run as it’s easier to spot mistakes in a code chunk than inline code.\nYou will see it has the form of a backtick (`), r and a space, the object/function you want to reference, and a final backtick. When the R Markdown file knits, it sees the r and recognises it as inline code and uses the object or function.\nIf you just write the two backticks without the r, it will just add code formatting and not produce inline code.\n\n\n\n\n2.2.6 Activity 8: Knitting your file\nAs our final step in this part, we are going to knit our file again to see how it looks now. So, click the Knit button to regenerate your knitted .html version.\nIf you look at the knitted .html document in the Viewer tab or in your browser, you should see the sentence we copied in from Activity 7. As if by magic, that slightly odd bit of text you copied and pasted now appears as a normal sentence with the values pulled in from the objects you created:\nMy name is James and I am 30 years old. It is 145 days until my birthday.\nR Markdown is an incredibly powerful and flexible format, we wrote this whole book using it! There are a few final things to note about knitting that will be useful going forward for your data skills learning and assessments:\n\nR Markdown will only knit if your code works. If you have an error, it will stop and tell you to fix the error before you can click knit and try again. This is a good way of checking whether you have written functioning code in your assessments.\nWhen you knit an R Markdown document, it runs the code from the start of the document to the end in order, and in a fresh session. This means it cannot access your environment, just the objects you create within that R Markdown. One common error can be writing and running code as you work on the document, but the code chunks are in the wrong order, or you created an object in the console but not in the code chunks. This means R Markdown would not know the object exists yet, or it does not have access to it at all.\nYou can choose to knit to a Word document rather than HTML. This can be useful for sharing with others or adding further edits, but you might lose some functionality. By default, html looks good and is accessible, so that will be our default throughout this book, but look out for our instructions on what output format we want your assessments in.\nYou can choose to knit to PDF, however, unless you are using the server this requires a LaTeX installation and can be quite complicated. If you do not already know what LaTeX is and how to use it, we do not recommend trying to knit to PDF just yet. If you do know how to use LaTeX, you probably do not need us to give you instructions!\n\nWe will test some of these warnings in error mode in the test yourself section, but we have one final demonstration for how R Markdown files support reproducibility."
  },
  {
    "objectID": "02-starting-with-data.html#demonstrating-reproducibility",
    "href": "02-starting-with-data.html#demonstrating-reproducibility",
    "title": "2  Creating Reproducible Documents",
    "section": "\n2.3 Demonstrating reproducibility",
    "text": "2.3 Demonstrating reproducibility\nAt the start of this chapter, we plugged the benefits of reproducible research as the ability to produce the same result for different people using the same software on different computers. We are going to end the chapter on a demonstration of this by giving you an R Markdown document and data. You should be able to click knit and see the results without editing anything. We do not expect you to understand the code included in it, we are previewing the skills you will develop over the next four chapters on visualisation and data wrangling.\n\n2.3.1 Activity 9 - Knit the reproducibility demonstration document\nPlease follow these steps and you should be able to knit the document without editing anything. Make sure you are still in your Chapter_02_reproducible_docs folder. If you are coming back to this activity, remember to set your working directory by opening the .Rproj file.\n\nIf you are working on your own computer, make sure you installed the tidyverse package. Please refer to Chapter 1 - Activity 3 if you have not completed this step yet. If you are working on a university computer or the online server, you do not need to complete this step as tidyverse will already be installed.\nDownload the R Markdown document through the following link: 02_reproducibility_demo.Rmd. To download a file from this book, right click the link and select “save link as”, or just clicking the link will save the file to your Downloads. Save or copy the file to your Chapter_02_reproducible_docs folder.\nDownload these two data files. Data file one: ahi-cesd.csv. Data file two: participant-info.csv. Right click the links and select “save link as”, or clicking the links will save the files to your Downloads. Make sure that both files are saved as “.csv”. Do not open them on your machine as often other software like Excel can change setting and ruin the files. Save or copy the file to your data/ folder within Chapter_02_reproducible_docs.\n\nAt this point, you should have “02_reproducibility_demo.Rmd” within your Chapter_02_reproducible_docs folder. You should have “ahi-cesd.csv” and “participant_info.csv” in the data/ folder within Chapter_02_reproducible_docs.\nIf you open “02_reproducibility_demo.Rmd” and followed all the steps above, you should be able to click knit. This will turn the R Markdown file into a knitted html file, showing some data wrangling, summary statistics, and two graphs (Figure 2.14). In the next chapter, you will learn how to write this code yourself, starting with creating graphs.\n\n\n\n\n\n\n\n\n\nFigure 2.14: You should see the reproducibility demonstration as the .Rmd (left) and be able to knit it into a html file (right).\n\n\nIf you have any questions or problems about anything contained in this chapter, please remember you are always welcome to post on the course Teams channel, attend a GTA support session, or attend the office hours of one of the team."
  },
  {
    "objectID": "02-starting-with-data.html#test-yourself",
    "href": "02-starting-with-data.html#test-yourself",
    "title": "2  Creating Reproducible Documents",
    "section": "\n2.4 Test yourself",
    "text": "2.4 Test yourself\nTo end the chapter, we have some knowledge check questions to test your understanding of the concepts we covered in the chapter. We then have some error mode tasks to see if you can find the solution to some common errors in the concepts we covered in this chapter.\n\n2.4.1 Knowledge check\nQuestion 1. One of the key first steps when we open RStudio is to:\n\nset your working directory/open a projectput on some music as we will be here a whilecheck out the newsmake a coffee\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nOne of the most common issues we see where code does not work the first time is because people have forgotten to set the working directory. The working directory is the starting folder on your computer where you want to save any files, any output, or contains your data. R/RStudio needs to know where you want it to look, so you must either manually set your working directory, or open a .Rproj file.\n\n\n\nQuestion 2. When using the default environment color settings for RStudio, what color would the background of a code chunk be in R Markdown? \nwhite\nred\ngreen\ngrey\nQuestion 3. When using the default environment color settings for RStudio, what color would the background of normal text be in R Markdown? \nwhite\nred\ngreen\ngrey\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nAssuming you have not changed any of the settings in RStudio, code chunks will tend to have a grey background and normal text will tend to have a white background. This is a good way to check that you have closed and opened code chunks correctly.\n\n\n\nQuestion 4. Code chunks start and end with:\n\nthree single quotesthree backticksthree double quotesthree single clefs\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nCode chunks always take the same general format of three backticks followed by curly parentheses and a lower case r inside the parentheses ({r}). People often mistake these backticks for single quotes but that will not work. If you have set your code chunk correctly using backticks, the background color should change to grey from white\n\n\n\nQuestion 5. Inline code is:\n\nwhere you nicely organise your code in a line.where you make sure all the code is nicely indented from the side.a fancy way of saying you have written good code.an approach of integrating code and text in a sentence outside of a code chunk.\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nInline coding is an incredibly useful approach for merging text and code in a sentence outside of a code chunk. It can be really useful for when you want to add values from your code directly into your text. If you copy and paste values, you can easily create errors, so it’s useful to add inline code where possible.\n\n\n\n\n2.4.2 Error mode\nThe following questions are designed to introduce you to making and fixing errors. For this topic, we focus on R Markdown and potential errors in using code blocks and inline code. Remember to keep a note of what kind of error messages you receive and how you fixed them, so you have a bank of solutions when you tackle errors independently.\nCreate and save a new R Markdown file by following the instructions in activity 3 and activity 4. You should have a blank R Markdown file below line 10. Below, we have several variations of a code chunk and inline code errors. Copy and paste them into your R Markdown file, click knit, and look at the error message you receive. See if you can fix the error and get it working before checking the answer.\nQuestion 5. Copy the following text/code/code chunk into your R Markdown file and press knit. You should receive an error like Error while opening file. No such file or directory.\ncity &lt;- \"Glasgow\"\n\n```{r}\n\n```\n\n`r city` is a city in Scotland. \n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nHere, we wrote city &lt;- \"Glasgow\" outside the code chunk. So, when we try and knit, it is not evaluated as code, and city does not exist as an object to be referenced in inline code. If you copy city &lt;- \"Glasgow\" into the code chunk and press knit, it should work.\n\n\n\nQuestion 6. Copy the following text/code/code chunk into your R Markdown file and press knit. You should receive an error like Error in parse(): ! attempt to use zero-length variable name which is not very helpful for diagnosing the problem.\n\n```{r}\ncity &lt;- \"Glasgow\"\n``\n\n`r city` is a city in Scotland. \n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nHere, we missed a final backtick in the code chunk. You might have noticed all the text had a grey background, so R Markdown thought everything was code. So, when it reached the inline code and text, it tried interpreting it as code and caused the error. If you add the final backtick to the code chunk, you should be able to click knit successfully.\n\n\n\nQuestion 7. Copy the following text/code/code chunk into your R Markdown file and press knit. You should receive an error like Error while opening file. No such file or directory.\n\n`r city` is a city in Scotland. \n\n```{r}\ncity &lt;- \"Glasgow\"\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nHere, we tried using inline code before the code chunk. R Markdown runs the code from start to finish in a fresh environment. We tried referencing city in inline code, but R Markdown did not know it existed yet. To fix it, you need to move the inline code below the code chunk, so you create city before referencing it in inline code.\n\n\n\nQuestion 8. Copy the following text/code/code chunk into your R Markdown file and press knit. This…works?\n\n```{r}\ncity &lt;- \"Glasgow\"\n```\n\n`city` is a city in Scotland. \n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nHere, we have a sneaky kind of “error” where it knits, but it is not doing what we wanted it to do. In the inline code part, we only added code formatting city, we did not add the r to get R Markdown to interpret it as R code:\n\n`r city`\n\nIf you add the r after the first backtick, it should knit and add the city object in."
  },
  {
    "objectID": "02-starting-with-data.html#words-from-this-chapter",
    "href": "02-starting-with-data.html#words-from-this-chapter",
    "title": "2  Creating Reproducible Documents",
    "section": "\n2.5 Words from this Chapter",
    "text": "2.5 Words from this Chapter\nBelow, you will find a list of words that we used in this chapter that might be new to you in case you need to refer back to what they mean. The links in this table take you to the entry for the words in the PsyTeachR Glossary. Note that numerous members of the team wrote entries in the Glossary and as such the entries may use slightly different terminology from what we used in the chapter.\n\n\n\n\nterm\ndefinition\n\n\n\nchunk\nA section of code in an R Markdown file\n\n\nhtml\nHyper-Text Markup Language: A system for semantically tagging structure and information on web pages.\n\n\ninline-code\nDirectly inserting the result of code into the text of a .Rmd file.\n\n\nknit\nTo create an HTML, PDF, or Word document from an R Markdown (Rmd) document\n\n\nlatex\nA typesetting program needed to create PDF files from R Markdown documents.\n\n\nmarkdown\nA way to specify formatting, such as headers, paragraphs, lists, bolding, and links.\n\n\nr-markdown\nThe R-specific version of markdown: a way to specify formatting, such as headers, paragraphs, lists, bolding, and links, as well as code blocks and inline code.\n\n\nr-project\nA project is simply a working directory designated with a .RProj file. When you open an R project, it automatically sets the working directory to the folder the project is located in.\n\n\nreproducible-research\nResearch that documents all of the steps between raw data and results in a way that can be verified.\n\n\nworking-directory\nThe filepath where R is currently loading files from and saving files to."
  },
  {
    "objectID": "02-starting-with-data.html#end-of-chapter",
    "href": "02-starting-with-data.html#end-of-chapter",
    "title": "2  Creating Reproducible Documents",
    "section": "\n2.6 End of chapter",
    "text": "2.6 End of chapter\nWell done on reaching the end of the second chapter! This was another long chapter as we had to cover a range of foundational skills to prepare you for learning more of the coding element in future chapters.\nThe next chapter builds on all the skills you have developed so far in R programming and creating reproducible documents to focus on something more tangible: data visualisation in R to create plots of your data."
  },
  {
    "objectID": "03-intro-data-viz.html#chapter-preparation",
    "href": "03-intro-data-viz.html#chapter-preparation",
    "title": "3  Introduction to Data Visualisation",
    "section": "\n3.1 Chapter preparation",
    "text": "3.1 Chapter preparation\n\n3.1.1 Introduction to the data set\nFrom now on, we are going to use different data sets from psychology to develop and practice your data skills. This will prepare you for working with different kinds of psychology data and introduce you to different kinds of research questions they might ask. For this chapter, we are using open data from Woodworth et al. (2018). The abstract of their article is:\n\nWe present two datasets. The first dataset comprises 992 point-in-time records of self-reported happiness and depression in 295 participants, each assigned to one of four intervention groups, in a study of the effect of web-based positive-psychology interventions. Each point-in-time measurement consists of a participant’s responses to the 24 items of the Authentic Happiness Inventory and to the 20 items of the Center for Epidemiological Studies Depression (CES-D) scale. Measurements were sought at the time of each participant’s enrolment in the study and on five subsequent occasions, the last being approximately 189 days after enrolment. The second dataset contains basic demographic information about each participant.\n\nIn summary, we have two files containing demographic information about participants and measurements of two scales on happiness and depression:\n\nThe Authentic Happiness Inventory (AHI),\nThe Center for Epidemiological Studies Depression (CES-D) scale.\n\n3.1.2 Organising your files and project for the chapter\nBefore we can get started, you need to organise your files and project for the chapter, so your working directory is in order. If you need a refresher of this process, you can look back over Chapter 2 - File structure, working directories, and R Projects.\n\nIn your folder for research methods and the book ResearchMethods1_2/Quant_Fundamentals, create a new folder called Chapter_03_intro_data_viz. Within Chapter_03_intro_data_viz, create two new folders called data and figures.\nCreate an R Project for Chapter_03_intro_data_viz as an existing directory for your chapter folder. This should now be your working directory.\nCreate a new R Markdown document and give it a sensible title describing the chapter, such as 03 Introduction to Data Visualisation. Delete everything below line 10 so you have a blank file to work with and save the file in your Chapter_03_intro_data_viz folder.\nDownload these two data files which we used at the end of Chapter 2. Data file one: ahi-cesd.csv. Data file two: participant-info.csv. Right click the links and select “save link as”, or clicking the links will save the files to your Downloads. Make sure that both files are saved as “.csv”. Do not open them on your machine as often other software like Excel can change setting and ruin the files. Save or copy the file to your data/ folder within Chapter_03_intro_data_viz.\n\nYou are now ready to start working on the chapter!\n\n\n\n\n\n\nReminder of file management if you use the online server\n\n\n\n\n\nIf we support you to use the online University of Glasgow R Server, working with files is a little different. If you downloaded R / RStudio to your own computer or you are using one of the library/lab computers, please ignore this section.\nThe main disadvantage to using the R server is that you will need create folders on the server and then upload and download any files you are working on to and from the server. Please be aware that there is no link between your computer and the R server. If you change files on the server, they will not appear on your computer until you download them from the server, and you need to be very careful when you submit your assessment files that you are submitting the right file. This is the main reason we recommend installing R / RStudio on your computer wherever possible.\nGoing forward throughout this book, if you are using the server, you will need to follow an extra step where you also upload them to the sever. As an example:\n\nLog on to the R server using the link we provided to you.\nIn the file pane, click New folder and create the same structure we demonstrated above.\nDownload these two data files which we used at the end of Chapter 2. Data file one: ahi-cesd.csv. Data file two: participant-info.csv. Save the two files into the data folder you created for chapter 3. To download a file from this book, right click the link and select “save link as”. Make sure that both files are saved as “.csv”. Do not open them on your machine as often other software like Excel can change setting and ruin the files.\nNow that the files are stored on your computer, go to RStudio on the server and click Upload then Browse and choose the folder for the chapter you are working on.\nClick Choose file and go and find the data you want to upload."
  },
  {
    "objectID": "03-intro-data-viz.html#loading-the-tidyverse-and-reading-data-files",
    "href": "03-intro-data-viz.html#loading-the-tidyverse-and-reading-data-files",
    "title": "3  Introduction to Data Visualisation",
    "section": "\n3.2 Loading the tidyverse and reading data files",
    "text": "3.2 Loading the tidyverse and reading data files\n\n3.2.1 Activity 1 - Loading the tidyverse package\nFor everything we do in this chapter and almost every chapter from now, we need to use the tidyverse package. The tidyverse is a package of packages, containing a kind of ecosystem of functions that work together for data wrangling, descriptive statistics, and visualisation. So let’s load that package into our library using the library() function.\nTo load the tidyverse, below line 10 of your RMarkdown document, create a code chunk, type the following code into your code chunk, and run the code:\n\nlibrary(tidyverse)\n\nRemember that sometimes in the console or below your code chunk, you will see information about the package you have loaded. If you see an error message, be sure to read it and try to identify what the problem is. For example, if you are working on your own computer, have you installed tidyverse so R/RStudio can access it? Are there any spelling mistakes in the function or package?\nRemember though, not all messages are errors, tidyverse explains what packages it loaded and highlights function name clashes. See activity 3 and 4 from Chapter 1 if you need a refresher.\n\n3.2.2 Activity 2 - Reading data files using read_csv()\n\nNow we have loaded tidyverse, we can read in the data we need for the remaining activities. “Read” in this sense just means to bring the data into RStudio and store it in an object, so we can work with it.\nWe will use the function read_csv() that allows us to read in .csv files. There are also functions that allow you to read in Excel files (e.g. .xlsx) and other formats, but in this course we will only use .csv files as they are not software specific, meaning they are more accessible to share, promoting our open science principles.\n\n\n\n\n\n\nWhere does read_csv() come from?\n\n\n\n\n\nWhen we describe tidyverse as a package of packages, the read_csv() function comes from a package called readr. This is one of the packages that tidyverse loads and contains several functions for reading different kinds of data.\n\n\n\nCreate a new code chunk below where you loaded tidyverse, type the following code, and run the code chunk:\n\ndat &lt;- read_csv(\"data/ahi-cesd.csv\")\n\npinfo &lt;- read_csv(\"data/participant-info.csv\")\n\nTo break down the code:\n\nFirst, we create an object called dat that contains the data in the ahi-cesd.csv file within data/.\nNext, we create an object called pinfo that contains the data in the participant-info.csv file within data/.\nBoth lines have the same format of object &lt;- function(\"folder/datafile_name.csv\")\nRemember that &lt;- is called the assignment operator but we can read it as “assigned to”. For example, the first line can be read as the data in data/ahi-cesd.csv is assigned to the object called dat.\n\n\n\n\n\n\n\nError mode\n\n\n\nThere are several common mistakes that can happen here, so be careful how you are typing the code to read in the data.\n\nYou need the double quotation marks around the data file name, so R recognises you are giving it a file path.\nComputers are literal, so you must spell the data file name correctly. For example, R would not know what data/participant-inf.csv is. This is where pressing the tab key on your keyboard can be super helpful, as you can search and auto-complete your files and avoid spelling mistakes.\nFor the same reason as spelling mistakes, you must add the .csv part on the end to tell R the specific file you want.\nYou must point R to the right folder relative to your working directory. If you typed ahi-cesd.csv, you would receive an error as R would look in your chapter folder where ahi-cesd.csv does not exist, rather than within the data/ folder you stored it in.\n\n\n\nIf you have done this activity correctly, you should now see the objects dat and pinfo in the environment window in the top right of RStudio. If they are not there, check there are no error messages, check the spelling of the code and file names, and check your working directory is Chapter_03_intro_data_viz.\n\n\n\n\n\n\nBe careful to use the right read_csv() function\n\n\n\nThere is also a function called read.csv(). Be very careful not to use this function instead of read_csv() as they have different ways of naming columns. For the activities and the assignments in RM1 and RM2, we will always ask and expect you to use read_csv(). This is really a reminder to watch spelling on functions and to be careful to use the right functions, especially when the names are so close.\n\n\n\n3.2.3 Activity 3 - Wrangling the two data sets\nFor this final preparation step, we would like you to add the following code. We are not tackling data wrangling until the next chapter, so we are not going to fully explain the code just yet. Copy the code (if you hover over the code, there is a copy to clipboard icon in the top right) and paste it into a code chunk below where you read the two data files, then run the code again.\n\nall_dat &lt;- inner_join(dat, \n                      pinfo, \n                      by= c(\"id\", \"intervention\"))\n\nsummarydata &lt;- select(.data = all_dat, \n                      id,\n                      occasion, \n                      elapsed.days,\n                      intervention,\n                      ahiTotal, \n                      cesdTotal, \n                      sex, \n                      age, \n                      educ, \n                      income)\n\nFor a brief overview, we are joining the two data files by common columns (“id” and “intervention”) to create the object all_dat. We are then selecting 10 columns from the original 54 to make the data easier to work with in summarydata.\nThis final object summarydata is the source of the data we will be working with for the rest of this chapter.\n\n3.2.4 Activity 4 - Exploring the data set\nBefore we start plotting, it is a good idea to explore the data set you are working with. There is a handy function called glimpse() which provides an overview of the columns and responses in your data set.\nCreate a new code chunk below where you read and wrangled the data, and type and run the following code:\n\nglimpse(summarydata)\n\nRows: 992\nColumns: 8\n$ ahiTotal     &lt;dbl&gt; 32, 34, 34, 35, 36, 37, 38, 38, 38, 38, 39, 40, 41, 41, 4…\n$ cesdTotal    &lt;dbl&gt; 50, 49, 47, 41, 36, 35, 50, 55, 47, 39, 45, 47, 33, 27, 3…\n$ sex          &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, …\n$ age          &lt;dbl&gt; 46, 37, 37, 19, 40, 49, 42, 57, 41, 41, 52, 41, 52, 58, 5…\n$ educ         &lt;dbl&gt; 4, 3, 3, 2, 5, 4, 4, 4, 4, 4, 5, 4, 5, 5, 5, 4, 3, 4, 3, …\n$ income       &lt;dbl&gt; 3, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 3, 2, 2, 3, 2, 2, 2, …\n$ occasion     &lt;dbl&gt; 5, 2, 3, 0, 5, 0, 2, 2, 2, 4, 4, 0, 4, 0, 1, 4, 0, 5, 4, …\n$ elapsed.days &lt;dbl&gt; 182.025139, 14.191806, 33.033831, 0.000000, 202.096887, 0…\n\n\n\n\n\n\n\n\nWhere does glimpse() come from?\n\n\n\n\n\nThe glimpse() function comes from a package called dplyr, which is part of the tidyverse. This package contains many functions for wrangling data like joining data sets and selecting columns. We will explore loads of functions within dplyr in the next few chapters on data wrangling.\n\n\n\nThis function provides a condensed summary of your data. You can see there are 992 rows and 10 columns. You see all the column names for each variable in the data set. You can also see that all the variables are automatically considered as numeric (in this case double represented by &lt;dbl&gt;). Treating categorical variables like “sex” and “income” as numbers will cause us problems later, but it is fine for the variables we will be working on now."
  },
  {
    "objectID": "03-intro-data-viz.html#ggplot2-and-the-layer-system",
    "href": "03-intro-data-viz.html#ggplot2-and-the-layer-system",
    "title": "3  Introduction to Data Visualisation",
    "section": "\n3.3 ggplot2 and the layer system",
    "text": "3.3 ggplot2 and the layer system\nThere are multiple approaches to data visualisation in R but we will use ggplot2 which uses a layered grammar of graphics where you build up plots in a series of layers. You can think of it as building a picture with multiple elements that sit over each other.\nFigure 3.2 from Nordmann et al. (2022) demonstrates the idea of building up a plot by adding layers. One function creates the first layer, the basic plot area, and you add functions and arguments to add additional layers such as the data, the labels, the colors etc. If you are used to making plots in other software, this might seem a bit odd at first, but it means that you can customise each layer separately to make complex and beautiful figures with relative ease.\nYou can get a sense of what plots are possible from the website data-to-viz, but we will build up your data visualisation skills over the RM1 and RM2 courses.\n\n\n\n\nFigure 3.2: Building a figure using the ggplot2 layering system from Nordmann et al. (2022)."
  },
  {
    "objectID": "03-intro-data-viz.html#histograms-and-density-plots",
    "href": "03-intro-data-viz.html#histograms-and-density-plots",
    "title": "3  Introduction to Data Visualisation",
    "section": "\n3.4 Histograms and density plots",
    "text": "3.4 Histograms and density plots\nWe are going to start by plotting the distribution of participant age in a histogram, and add layers to demonstrate how we build the plot step-by-step.\n\n3.4.1 Step 1: Start with the ggplot function\nThis first layer tells R to access the ggplot function.\nThe first argument tells R to plot the summarydata dataframe. In the aes function, you specify the aesthetics of the plot, such as the axes and colours. What you need to specify depends on the plot you want to make (you will learn more about this later).\nFor a basic histogram, you only need to specify the x-axis (the y-axis will automatically be counts).\nFor each step, type the code in a new code chunk and run it after we add each layer to see it’s effect.\n\n# Plot the variable age from summarydata\nggplot(summarydata, aes(x = age)) # Plot age on the x axis\n\n\n\n\n\n\n\n\n\n\n\n\n\nR Markdown tip of the chapter: Add code comments\n\n\n\nAfter we introduced you to R Markdown to create reproducible documents in Chapter 2, we are going to add a tip in every chapter to demonstrate extra functionality.\nIn the code chunk above, we added a code comment by adding a hash (#). In code chunks and scripts, you can add a comment which R will ignore, so you can explain to yourself what the code is doing. In R Markdown, you can combine adding notes to yourself outside and inside the code chunks.\nCode comments help explain what the code is doing and why you added certain values. It might seem redundant for simple functions, but as your code becomes more complex, you will forget what it is doing when you return to it after days, months, or years. Future you will thank past you.\n\n\n\n3.4.2 Step 2: Add the geom_histogram layer\nYou can see that the code above produces an empty plot, because we have not specified which type of plot we want to make.\nWe will do this by adding another layer: geom_histogram(). A geom is an expression of the type of plot you want to create. For this variable, we want to create a histogram which is a type of plot showing the frequency of each observation.\nYou will see that you add the layers by adding a + at the end of each layer. As you read new code, try and read it line by line to walk through what it is doing. You can interpret + as “and then”. So, you could describe the plot as currently saying “plot the age variable from summary data, and then add a histogram”.\n\n# Plot the variable age from summarydata\nggplot(summarydata, aes(x = age)) +  # Plot age on the x axis\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n3.4.3 Step 3: Edit the histogram bins\nIn just two lines of code, we have a histogram! For exploratory data analysis, this is how ggplot2 is such a flexible and quick tool to get a visual overview of your data.\nAfter running the last code chunk, you might have noticed a message warning you about the bin width: stat_bin() using bins = 30. A histogram describes the frequency of values within your variable. To do so, it must collect the values into “bins”. By default - the warning ggplot2 gives you - it uses 30 bins, meaning it tries to plot 30 bars. Depending on the granularity of your data, you might want more or fewer bins.\nYou can control this using one of two arguments. First, you can add an argument called binwidth which sets the bins by how wide you want the bars on your x-axis scale. For example, we can plot the data for every 5 years:\n\n# Plot the variable age from summarydata\nggplot(summarydata, aes(x = age)) +  # Plot age on the x axis\n  geom_histogram(binwidth = 5) # collate bins into a 5-year span\n\n\n\n\n\n\n\nAlternatively, you can control precisely how many bars the histograms uses through the bins argument. For example, we can plot age by collecting the observations into 10 bars:\n\n# Plot the variable age from summarydata\nggplot(summarydata, aes(x = age)) +  # Plot age on the x axis\n  geom_histogram(bins = 10) # Plot age using 10 bars\n\n\n\n\n\n\n\n\n\n\n\n\n\nTry this\n\n\n\nPlay around with the bin and binwidth arguments to see what effect it has on the plot. One of the best ways of learning is through trial and error to see what effect your changes have on the result.\n\n\n\n3.4.4 Step 4: Edit the axis names\nBy default, the axis names come from the variable names in your data. When you are making quick plots for yourself, you rarely need to worry about this. However, as you edit your plot for a report to show other people, it is normally a good idea to edit the names so they clearly communicate what they represent.\nThere are different layers to control the axes depending on the type of variable you use. Both the x- and y-axis here are continuous numbers, so we can use the scale_x_continuous and scale_y_continuous layers to control them.\nThere are many options available in ggplot2 for controlling the axes, but you will learn through experience and searching what you need in different scenarios.\n\n# Plot the variable age from summarydata\nggplot(summarydata, aes(x = age)) +  # Plot age on the x axis\n  geom_histogram(binwidth = 5) + # collate bins into a 5-year span\n  scale_x_continuous(name = \"Age\") +\n  scale_y_continuous(name = \"Frequency\")\n\n\n\n\n\n\n\n\n3.4.5 Step 5: Change the plot theme\nSo far, we used the default plot theme which has the grey gridlines as a background. This looks pretty ugly, so we can edit the plot them by adding a theme_ layer. For example, we can add a black-and-white theme:\n\n# Plot the variable age from summarydata\nggplot(summarydata, aes(x = age)) +  # Plot age on the x axis\n  geom_histogram(binwidth = 5) + # collate bins into a 5-year span\n  scale_x_continuous(name = \"Age\") +\n  scale_y_continuous(name = \"Frequency\") + \n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\n\n\nTry this\n\n\n\nThere are loads of themes available. As you start typing theme_, you should see the full range appear as a drop-down to autocomplete. Try one or two alternatives such as theme_classic() or theme_minimal() to see how they look.\n\n\n\n3.4.6 Switch the geom layer\nThe layer system makes it easy to create new types of plots by adapting existing recipes. For example, rather than creating a histogram, we can create a smoothed density plot by calling geom_density() rather than geom_histogram(). Apart from the name of the y-axis, the rest of the code remains identical to demonstrate how easy it is to customise your ggplot2 layers.\n\n# Plot the variable age from summarydata\nggplot(summarydata, aes(x = age)) +  # Plot age on the x axis\n  geom_density() + # summarise age as a smoothed density plot\n  scale_x_continuous(name = \"Age\") +\n  scale_y_continuous(name = \"Density\") + \n  theme_bw()\n\n\n\n\n\n\n\n\n3.4.7 Activity 5 - Apply your plotting skills to a new variable\nBefore we move on to barplots, an important learning step is being able to apply or transfer what you learnt in one scenario to something new.\nIn the data set, there is a variable for The Authentic Happiness Inventory (AHI): ahiTotal. Plot the new variable and try to recreate the customisation layers before checking the solution below. It might take some trial-and-error to get some features right, so do not worry if it does not immediately look the same.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow me the solution code\n\n\n\n\n\nTo recreate the plot, this is the code:\n\n# Plot the variable ahi total from summarydata\nggplot(summarydata, aes(x = ahiTotal)) +  # Plot ahi total on the x axis\n  geom_histogram(bins = 10) + \n  scale_x_continuous(name = \"Authentic Happiness Inventory (AHI)\") +\n  scale_y_continuous(name = \"Frequency\") + \n  theme_classic()\n\nWe were a little sneaky with using the classic theme to get you exploring."
  },
  {
    "objectID": "03-intro-data-viz.html#barplots",
    "href": "03-intro-data-viz.html#barplots",
    "title": "3  Introduction to Data Visualisation",
    "section": "\n3.5 Barplots",
    "text": "3.5 Barplots\nIn the next section, we are going to cover making barplots - potentially the most common type of visualisation you will see in published research. A barplot shows counts of categorical data, or factors, where the height of each bar represents the count of that particular variable.\nYou will see people use them to represent continuous outcomes, such as showing the mean on the y-axis, but there is good reason to never use bar plots to communicate continuous data we will cover in the course materials (see Weissgerber et al., 2019 if you are interested). We will cover more advanced plots for continuous data in Chapter 7 - Building your data visualisation skills.\n\n3.5.1 Activity 6 - Covert to factors\nEarlier, we highlighted that all the variables were processed as numbers. This was fine for most of the variables, but sex, educ, and income should be categories or what we call factors.\nTo get around this, we need to convert these variables into factors. This is relates to data wrangling, so this is one final time we would like you to copy and run code, before we fully explain how to write this kind of code independently in the next chapter.\nCopy and run the following code in your R Markdown document, at least below where you read and wrangled the data:\n\n# Overwrite summary data \nsummarydata &lt;- mutate(summarydata, # mutate to change columns \n         sex = as.factor(sex), # save sex as a factor\n         educ = as.factor(educ),\n         income = as.factor(income))\n\nYou can interpret this code as “overwrite summarydata and transform three columns (sex, educ, and income) into the same values but now considered factors and not doubles”.\n\n\n\n\n\n\nError mode\n\n\n\nIf you do not do convert numbers to factors when they should represent distinct categories, you can get some weird looking figures. Instead of treating the numbers as categories, it will try and plot the full range of numerical values. If you notice this, just go back and convert your variables to factors (which we will break down in the next chapter).\n\n\n\n3.5.2 Activity 7 - Create a bar plot\nNow you are familiar with the layering system, we will jump straight into creating the barplot. As before, type and run the code in each step, making notes to yourself either in the R Markdown document outside the code chunks, or using code comments.\n\n# Plot the variable sex from summarydata\nggplot(summarydata, aes(x = sex)) + \n  geom_bar()\n\n\n\n\n\n\n\nCompared to the histogram plot, the only difference here is using the geom_bar() as the layer instead. Rather than plot the frequency of your variable in bins, we plot the frequency of each unique category.\nWe can see 1s are way more frequent than 2s, but for this to make sense to you and your reader, we need to edit the axis labels.\n\n3.5.3 Activity 8 - Edit the axis labels\nIn the histogram section, we demonstrated how to edit the axis labels. We used scale_y_continuous and scale_x_continuous as we had two continuous variables for the x-axis range and the y-axis frequency. This time, we need a slightly different layer since the x-axis now represents distinct groups: scale_x_discrete.\nType and run the following code:\n\n# Plot the variable sex from summarydata\nggplot(summarydata, aes(x = sex)) + \n  geom_bar() + \n  scale_x_discrete(name = \"Participant Sex\", \n                   labels = c(\"Female\", # 1 = Female\n                              \"Male\")) + # 2 = Male\n  scale_y_continuous(name = \"Number of Participants\")\n\n\n\n\n\n\n\nWithin scale_x_discrete, we have a new argument called “labels”. This is where we can edit the labels for each category. Instead of 1 and 2, we labelled the x-axis clearer as “Female” and “Male”, making it easier to understand there are way more female participants compared to male.\n\n\n\n\n\n\nWhat does c() mean in labels?\n\n\n\n\n\nWhen we specified the labels, you might have noticed the c(\"Female\", \"Male\") format. c() stands for concatenate and you will see it a lot in R. When we give a value to a function argument, we must provide one “value”. However, in scenarios like this, we want to apply multiple values since we have several categories.\nWe can do this by adding all of our categories within c(), separated by a comma between each category.\n\n\n\n\n\n\n\n\n\nError mode\n\n\n\nWhen you edit “labels”, it is crucial the values you give it are in the right order. There would be nothing stopping us from writing c(\"Male\", \"Female\") and R will gladly listen to you and add those labels. However, that would be inaccurate as 1s mean Female and 2s mean Male. We are only editing the labels and not the underlying values in the data.\nThese errors are the most sneaky as it will not cause an error to fix, but they are still incorrect.\n\n\n\n3.5.4 Activity 9 - Apply your plotting skills to a new variable\nAn important learning step is being able to apply or transfer what you learnt in one scenario to something new.\nIn the data set, there is a variable for the level of education: educ. Plot the new variable and try to recreate the customisation layers before checking the solution below.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow me the solution code\n\n\n\n\n\nTo recreate the plot, this is the code:\n\n# Plot the variable educ from summarydata\nggplot(summarydata, aes(x = educ)) + \n  geom_bar() + \n  theme_classic() + \n  scale_x_discrete(name = \"Level of Education\", \n                   labels = c(\"Less than year 12\", # 1\n                              \"Year 12\", # 2 \n                              \"Vocational training\", # 3\n                              \"Bachelor's degree\", # 4\n                              \"Postgraduate degree\")) + # 5 \n  scale_y_continuous(name = \"Number of Participants\")"
  },
  {
    "objectID": "03-intro-data-viz.html#saving-your-figures",
    "href": "03-intro-data-viz.html#saving-your-figures",
    "title": "3  Introduction to Data Visualisation",
    "section": "\n3.6 Saving your Figures",
    "text": "3.6 Saving your Figures\nThe final step today will be to demonstrate how to save plots you create in ggplot2. It is so useful to be able to save a copy of your plots as an image file so that you can use them in a presentation or report. One approach we can use is the function ggsave().\n\n3.6.1 Activity 10 - Saving your last plot\nThere are two ways you can use ggsave(). If you do not tell ggsave() which plot you want to save, by default it will save the last plot you created.\nTo demonstrate this, let us run the code again from Activity 8 to produce the final version of our barplot. You do not need to write the code again if you already have it available in a code chunk, but make sure you run the code:\n\n# Plot the variable sex from summarydata\nggplot(summarydata, aes(x = sex)) + \n  geom_bar() + \n  scale_x_discrete(name = \"Participant Sex\", \n                   labels = c(\"Female\", # 1 = Female\n                              \"Male\")) + # 2 = Male\n  scale_y_continuous(name = \"Number of Participants\")\n\nNow that we have the plot we want to save as our last produced plot, all that ggsave() requires is for you to tell it the file path / name that it should save the plot to and the type of image file you want to create. The example below uses .png but you could also use .jpeg or another image type.\nType and run the following code into a new code chunk and then check your figures folder. If you have performed this correctly, then you should see the saved image. This is why we include a figures folder as part of the chapter structure, so you know exactly where your figures will be if you want to find them again.\n\nggsave(\"figures/participant_sex_barplot.png\")\n\nThe image tends to save at a default size, or the size that the image is displayed in your viewer, but you can change this manually if you think that the dimensions of the plot are not correct or if you need a particular size or file type. Sometimes the dimensions look a little off when you save them, so you might need to play around with the size.\nType and run the following code to overwrite the image file with new dimensions. Try different dimensions and units to see the difference. You might want to create participant_sex_barplot-v1.png, participant_sex_barplot-v2.png etc. and compare them.\nOne final tip, by default, the plot has a transparent background which you do not notice on a white document, but looks odd on anything else. So, you can set a specific background colour through the argument bg.\n\n ggsave(\"figures/participant_sex_barplot\", \n        width = 10, # 10 inches wide\n        height = 8, # 8 inches high\n        units = \"in\", \n        bg = \"white\") # Make sure the background is white\n\nRemember, you can use ?ggsave() in the console window to bring up the help file for this function if you want to look at what other arguments are available.\n\n3.6.2 Saving a specific plot\nAlternatively, the second way of using ggsave() is to save your plot as an object, and then tell it which object you want to save.\nType and run the code below and then check your folder for the image file. Resize the plot if you think it needs it.\n\n\n\n\n\n\nWarning\n\n\n\nWe do not add on ggsave() as a plot layer. Instead it is a separate line of code and we tell it which object to save. So, do not add + ggsave() as a layer to your plot.\n\n\n\nsex_barplot &lt;- ggplot(summarydata, aes(x = sex)) +\n  geom_bar() +\n  scale_x_discrete(name = \"Participant Sex\",\n                   labels = c(\"Female\", # 1 = Female\n                              \"Male\")) + # 2 = Male\n  scale_y_continuous(name = \"Number of Participants\")\n\n\nggsave(\"figures/participant-sex-barplot.png\", \n       plot = sex_barplot)\n\nNote that when you save a plot to an object, you will not see the plot displayed anywhere. To get the figure to display, you need to type the object name in the console (i.e., sex_barplot). The benefit of saving figures this way is that if you are making several plots, you cannot accidentally save the wrong one because you are explicitly specifying which plot to save rather than just saving the last one."
  },
  {
    "objectID": "03-intro-data-viz.html#test-yourself",
    "href": "03-intro-data-viz.html#test-yourself",
    "title": "3  Introduction to Data Visualisation",
    "section": "\n3.7 Test Yourself",
    "text": "3.7 Test Yourself\nTo end the chapter, we have some knowledge check questions to test your understanding of the concepts we covered in the chapter. We then have some error mode tasks to see if you can find the solution to some common errors in the concepts we covered in this chapter.\n\n3.7.1 Knowledge check\n\nWhich of these is the appropriate order of functions to create a barplot?\n\n\nggplot() %&gt;% geom_bar()geom_plot() + geom_boxplot()ggplot() + geom_bar()geom_bar() + ggplot()\n\n\nWhy would this line of code not create a barplot, assuming you already loaded all data and libraries and you spelt the data and column names correctly?\n\n\nggplot(summarydata, aes(x = sex)) +\n  geom_barplot()\n\n\nbecause there is no geom_barplot() and it should be geom_bar()because this would create a histogrambecause you have not included a y axisbecause you have piped the barplot and not added it\n\n\nIf I wanted precisely 5 bars in my histogram, what argument would I use?\n\n\nggplot() + geom_histogram(binwidth = 5)ggplot() + geom_histogram(bars = 5)ggplot() + geom_histogram(bins = 5)ggplot() + geom_histogram()\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\n\nggplot() + geom_histogram(bins = 5). This is the correct answer as you are asking ggplot2 to give you the plot organised into 5 bins.\nggplot() + geom_histogram(bars = 5). This is incorrect as you bars is not the right argument name. You want 5 bars, but the argument is bins.\nggplot() + geom_histogram(binwidth = 5). This is incorrect as binwidth controls the x-axis range to include per bar, rather than the number of bars.\nggplot() + geom_histogram(). This is incorrect as you did not control the number of bins, so it will default to 30.\n\n\n\n\n\n3.7.2 Error mode\nThe following questions are designed to introduce you to making and fixing errors. For this topic, we focus on reading data and using ggplot2. Remember to keep a note of what kind of error messages you receive and how you fixed them, so you have a bank of solutions when you tackle errors independently.\nCreate and save a new R Markdown file for these activities by following the instructions in Chapter 2. You should have a blank R Markdown file below line 10. Below, we have several variations of a code chunk and inline code errors. Copy and paste them into your R Markdown file, click knit, and look at the error message you receive. See if you can fix the error and get it working before checking the answer.\nQuestion 4. Copy the following code chunk into your R Markdown file and press knit. You should receive an error like Error in read_csv(): ! could not find function \"read_csv\".\n```{r}\npinfo &lt;- read_csv(\"data/participant-info.csv\")\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nIf you only added this code chunk in, you have not loaded tidyverse yet. Remember R Markdown knits from start to finish in a fresh session, so it will not work even if you have loaded already tidyverse outside the R Markdown document. So, you would need to add library(tidyverse) first.\n\n\n\nQuestion 5. Copy the following code chunk into your R Markdown file and press knit. You should receive an error like ! participant-info.csv does not exist in current working directory.\n```{r}\nlibrary(tidyverse)\n\npinfo &lt;- read_csv(\"participant-info.csv\")\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nYou had tidyverse loaded this time, but it is not pointing to the right folder. Your working directory should be the main chapter folder, where participant-info.csv does not exist. You will need to edit it to data/participant-info.csv to work.\n\n\n\nQuestion 7. Copy the following code chunk into your R Markdown file and press knit. You should receive a long error where the problem is buried in the first five lines:\n\nError in geom_histogram()\n\n\n! Problem while computing stat.\n\n\ni Error occurred in the 1st layer.\n\n\nCaused by error in setup_params():\n\n\n! stat_bin() requires an x or y aesthetic.\n\n```{r}\nlibrary(tidyverse)\n\npinfo &lt;- read_csv(\"data/participant-info.csv\")\n\n# Plot the variable age from pinfo\nggplot(pinfo, x = age) +   # Plot age on the x axis\n  geom_histogram()\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nThis is potentially a sneaky one where we missed the aes() argument and it is only line 5 of the error which gives it away: ! stat_bin() requires an x or y aesthetic. The first ggplot2 layer has two key components: the data object you want to use, and the aesthetics to set. You need to add “aes()” around where you specify the x-axis: ggplot(pinfo, aes(x = age)).\n\n\n\nQuestion 7. Copy the following code chunk into your R Markdown file and press knit. This…works, but does not look quite right?\n```{r}\nlibrary(tidyverse)\n\npinfo &lt;- read_csv(\"data/participant-info.csv\")\n\n# Plot the variable age from pinfo\nggplot(pinfo, aes(x = age)) # Plot age on the x axis\n  geom_histogram()\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nThere is a missing + between the two ggplot2 layers. The code should be:\n\n# Plot the variable age from pinfo\nggplot(pinfo, aes(x = age)) +  # Plot age on the x axis\n  geom_histogram()\n\nAt the moment, it runs the first layer to create an empty plot, then prints the information contained within geom_histogram.\n\n\n\nQuestion 8. Copy the following code chunk into your R Markdown file and press knit. You should receive a long error again with lines 5-7 key:\n\n! stat_bin() requires a continuous x aesthetic.\n\n\nx the x aesthetic is discrete.\n\n\ni Perhaps you want stat=\"count\"?\n\n```{r}\nlibrary(tidyverse)\n\npinfo &lt;- read_csv(\"data/participant-info.csv\")\n\n# Plot the variable age from pinfo\nggplot(pinfo, aes(x = age)) +   # Plot age on the x axis\n  geom_histogram() + \n  scale_x_discrete(name = \"Participant Age\")\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nThe error message here is a little more useful and points to how we tried to edit the x-axis name. In a histogram, the x-axis is continuous for the range of a numeric variable. We tried using the discrete version of the layer to control the axis (scale_x_discrete(name = \"Participant Age\")) which we had to use for the bar plot. To fix the error, you would need to correct the layer to scale_x_continuous(name = \"Participant Age\")."
  },
  {
    "objectID": "03-intro-data-viz.html#words-from-this-chapter",
    "href": "03-intro-data-viz.html#words-from-this-chapter",
    "title": "3  Introduction to Data Visualisation",
    "section": "\n3.8 Words from this Chapter",
    "text": "3.8 Words from this Chapter\nBelow you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the PsyTeachR Glossary. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter.\n\n\n\nterm\ndefinition\n\n\n\nassignment-operator\nThe symbol &lt;-, which functions like = and assigns the value on the right to the object on the left\n\n\nbarplot\nalso known as a bar chart, barplots represent the frequency or count of a variable through the height of one or more bars.\n\n\ncomment\nComments are text that R will not run as code. You can annotate .R files or chunks in R Markdown files with comments by prefacing each line of the comment with one or more hash symbols (#).\n\n\nconsole\nThe pane in RStudio where you can type in commands and view output messages.\n\n\ncsv\nComma-separated variable: a file type for representing data where each variable is separated from the next by a comma.\n\n\ndata-visualisation\nA graphical representation of your data set.\n\n\ndata-wrangling\nThe process of preparing data for visualisation and statistical analysis.\n\n\ndescriptive\nStatistics that describe an aspect of data (e.g., mean, median, mode, variance, range)\n\n\ndouble\nA data type representing a real decimal number\n\n\nenvironment\nA data structure that contains R objects such as variables and functions\n\n\nfactor-data-type\nA data type where a specific set of values are stored with labels\n\n\ngeom\nThe geometric style in which data are displayed, such as boxplot, density, or histogram.\n\n\nhistogram\nA type of plot showing the frequency of each observation organised into bins. Bins control the width of each bar and how many observations it represents.\n\n\nnumeric\nA data type representing a real decimal number or integer.\n\n\nobject\nA word that identifies and stores the value of some data for later use.\n\n\ntidyverse\nA set of R packages that help you create and work with tidy data"
  },
  {
    "objectID": "03-intro-data-viz.html#end-of-chapter",
    "href": "03-intro-data-viz.html#end-of-chapter",
    "title": "3  Introduction to Data Visualisation",
    "section": "\n3.9 End of chapter",
    "text": "3.9 End of chapter\nWell done! It takes a while to get used to the layering system in ggplot2, particularly if you are used to making graphs a different way. But once it clicks, you will be able to make informative and professional visualisations with ease. Remember, data visualisation is useful for yourself to quickly plot your data, and it’s useful for your reader in communicating your key findings.\n\n\n\n\nNordmann, E., McAleer, P., Toivo, W., Paterson, H., & DeBruine, L. M. (2022). Data Visualization Using R for Researchers Who Do Not Use R. Advances in Methods and Practices in Psychological Science, 5(2), 25152459221074654. https://doi.org/10.1177/25152459221074654\n\n\nWeissgerber, T. L., Winham, S. J., Heinzen, E. P., Milin-Lazovic, J. S., Garcia-Valencia, O., Bukumiric, Z., Savic, M. D., Garovic, V. D., & Milic, N. M. (2019). Reveal, Don’t Conceal. Circulation, 140(18), 1506–1518. https://doi.org/10.1161/CIRCULATIONAHA.118.037777\n\n\nWoodworth, R. J., O’Brien-Malone, A., Diamond, M. R., & Schüz, B. (2018). Data from, “Web-based Positive Psychology Interventions: A Reexamination of Effectiveness.” Journal of Open Psychology Data, 6(1), 1. https://doi.org/10.5334/jopd.35"
  },
  {
    "objectID": "04-wrangling-1.html#chapter-preparation",
    "href": "04-wrangling-1.html#chapter-preparation",
    "title": "4  Data wrangling 1: Join, select, and mutate",
    "section": "\n4.1 Chapter preparation",
    "text": "4.1 Chapter preparation\n\n4.1.1 Introduction to the data set\nFor this chapter, we are using open data from Woodworth et al. (2018) one more time. In the last two chapters, we asked you to trust us and copy some code until we reached data wrangling, and now is the time to fill in those gaps. If you need a reminder, the abstract of their article is:\n\nWe present two datasets. The first dataset comprises 992 point-in-time records of self-reported happiness and depression in 295 participants, each assigned to one of four intervention groups, in a study of the effect of web-based positive-psychology interventions. Each point-in-time measurement consists of a participant’s responses to the 24 items of the Authentic Happiness Inventory and to the 20 items of the Center for Epidemiological Studies Depression (CES-D) scale. Measurements were sought at the time of each participant’s enrolment in the study and on five subsequent occasions, the last being approximately 189 days after enrolment. The second dataset contains basic demographic information about each participant.\n\nIn summary, we have one data set containing demographic information about participants and a second data set containing measurements of two scales on happiness and depression.\n\n4.1.2 Organising your files and project for the chapter\nBefore we can get started, you need to organise your files and project for the chapter, so your working directory is in order.\n\nIn your folder for research methods and the book ResearchMethods1_2/Quant_Fundamentals, create a new folder called Chapter_04_06_datawrangling. As we are spending three chapters on data wrangling, we will work within one folder. Within Chapter_04_06_datawrangling, create two new folders called data and figures.\nCreate an R Project for Chapter_04_06_datawrangling as an existing directory for your chapter folder. This should now be your working directory.\nWe will work within one folder, but create a new R Markdown for each chapter. Create a new R Markdown document and give it a sensible title describing the chapter, such as 04 Data Wrangling 1. Delete everything below line 10 so you have a blank file to work with and save the file in your Chapter_04_06_datawrangling folder.\nIf you already have the two files from chapter 3, copy and paste them into the data/ folder. If you need to download them again, the links are data file one (ahi-cesd.csv) and data file two (participant-info.csv). Right click the links and select “save link as”, or clicking the links will save the files to your Downloads. Make sure that both files are saved as “.csv”. Save or copy the file to your data/ folder within Chapter_04_06_datawrangling.\n\nYou are now ready to start working on the chapter!\n\n\n\n\n\n\nReminder of file management if you use the online server\n\n\n\n\n\nIf we support you to use the online University of Glasgow R Server, working with files is a little different. If you downloaded R / RStudio to your own computer or you are using one of the library/lab computers, please ignore this section.\n\nLog on to the R server using the link we provided to you.\nIn the file pane, click New folder and create the same structure we demonstrated above.\nDownload these two data files which we used in Chapter 3. Data file one: ahi-cesd.csv. Data file two: participant-info.csv. Save the two files into the data folder you created for chapter 3. To download a file from this book, right click the link and select “save link as”. Make sure that both files are saved as “.csv”. Do not open them on your machine as often other software like Excel can change setting and ruin the files.\nNow that the files are stored on your computer, go to RStudio on the server and click Upload then Browse and choose the folder for the chapter you are working on.\nClick Choose file and go and find the data you want to upload.\n\n\n\n\n\n4.1.3 Activity 1 - Load tidyverse and read the data files\nAs the first activity, try and test yourself by loading tidyverse and reading the two data files. As a prompt, save the data files to these two object names to be consistent with the activities below, but you can check your answer below if you are stuck.\n\n# Load the tidyverse package below\n?\n  \n# Load the two data files\n# This should be the ahi-cesd.csv file \ndat &lt;- ?\n\n# This should be the participant-info.csv file\npinfo &lt;- ?\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# Load the tidyverse package below\nlibrary(tidyverse)\n\n# Load the two data files\n# This should be the ahi-cesd.csv file \ndat &lt;- read_csv(\"data/ahi-cesd.csv\")\n\n# This should be the participant-info.csv file\npinfo &lt;- read_csv(\"data/participant-info.csv\")"
  },
  {
    "objectID": "04-wrangling-1.html#tidyverse-and-the-dplyr-package",
    "href": "04-wrangling-1.html#tidyverse-and-the-dplyr-package",
    "title": "4  Data wrangling 1: Join, select, and mutate",
    "section": "\n4.2 Tidyverse and the dplyr package",
    "text": "4.2 Tidyverse and the dplyr package\nSo far, we have loaded a package called tidyverse in every chapter and it is going to be at the core of all the data skills you develop. The tidyverse (https://www.tidyverse.org/, Wickham (2017) is an ecosystem containing six core packages: dplyr, tidyr, readr, purrr, ggplot2, and tibble. Within these six core packages, you have access to functions that will pretty much cover everything you need to wrangle and visualise your data.\nIn chapter 3, we introduced you to the package ggplot2 for data visualisation. In this chapter, we focus on functions from the dplyr package, which the authors describe as a grammar of data manipulation (in the wrangling sense, not deviously making up data).\nThe dplyr package contains several key functions based on common English verbs to help you understand what the code is doing. For an overview, we will introduce you to the following functions:\n\n\nFunction\nDescription\n\n\n\n*_join()\nAdd columns from two data sets by matching observations\n\n\nselect()\nInclude or exclude certain variables (columns)\n\n\nmutate()\nCreate new variables (columns)\n\n\narrange()\nChange the order of observations (rows)\n\n\nfilter()\nInclude or exclude certain observations (rows)\n\n\ngroup_by()\nOrganize the observations (rows) into groups\n\n\nsummarise()\nCreate summary variables for groups of observations\n\n\n\nJust looking at the names gives you some idea of what the functions do. For example, select() selects columns and arrange() orders observations. You will be surprised by how far you can get with data wrangling using just these functions. There will always be unique problems to solve, but these functions cover the most common that apply to almost every data set.\nIn this chapter, we focus on the *_join() series of functions, select(), arrange(), and mutate()."
  },
  {
    "objectID": "04-wrangling-1.html#04-joins",
    "href": "04-wrangling-1.html#04-joins",
    "title": "4  Data wrangling 1: Join, select, and mutate",
    "section": "\n4.3 Joining two data frames with *_join() functions",
    "text": "4.3 Joining two data frames with *_join() functions\nThe first thing we will do is combine data files. We have two files, dat and pinfo, but what we really want is a single file that has both the happiness and depression scores and the demographic information about the participants as it makes it easier to work with the combined data.\nTo do this, we are going to use the function inner_join(). So far, we have described these types of functions as *_join(). This is because there are a series of functions that join two data sets in slightly different ways. You do not need to memorise these, but it might be useful to refer back to later.\n\n\n\n\n\n\nJoin function\nDescription\n\n\n\ninner_join()\nKeep observations in data set x that has a matching key in data set y\n\n\nleft_join()\nKeep all observations in data set x\n\n\nright_join()\nKeep all observations in data set y\n\n\nfull_join()\nKeep all observations in both data set x and y\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nAs these functions join data sets in different ways, they will produce different sample sizes depending on the presence of missing data in one or both data sets. For example, inner_join() will be the strictest as you must have matching observations in each data set. On the other hand, full_join() will be the least strict, as you retain observations that may not exist in one data set or the other.\n\n\n\n4.3.1 Activity 2 - Join the files together\nWe are going to join dat and pinfo by common identifiers. When we use inner_join(), this means we want to keep all the observations in dat that also has a corresponding identifier in pinfo. This is known as an inner-join, where you would exclude participants if they did not have a matching observation in one of the data sets.\nThe code below will create a new object, called all_dat, that combines the data from both dat and pinfo using the columns id and intervention to match the participants’ data across the two sets of data. id is a code or number for each unique participant and will be the most common approach you see for creating an identifier. intervention is the group the participant was placed in for the study by Woodworth et al. (2018).\nType and run the code in a new code chunk to inner join the two sets of data.\n\nall_dat &lt;- inner_join(x = dat, \n                      y = pinfo, \n                      by = c(\"id\", \"intervention\"))\n\nTo break down what this code is doing:\n\nall_dat is the new object you created with the joined data.\nx is the first argument and it should be the first data set / object you want to combine.\ny is the second argument and it should be the second data set / object you want to combine.\nby is the third argument and it lists the identifier as the name(s) of the column(s) you want to combine the data by in quote marks. In this scenario, there are two identifiers common to each data set. They both contain columns called “id” and “intervention”. We have to wrap them in c() to say that there is more than one column to combine by. If there was only one common identifier, you would write by = \"id\".\n\n\n\n\n\n\n\nWhy does my data include .x and .y columns?\n\n\n\nIf your data sets have more than one common column, you must enter them all in the by argument. This tells R there are matching columns and values across the data sets. If you do not enter all the common columns, then R will add on a .x and .y when it adds them together, to label which come from each data set.\nFor example, try and run this code and look at the columns in all_dat2. You will see it has an extra column compared to all_dat as there is both “intervention.x” and “intervention.y”.\n\nall_dat2 &lt;- inner_join(x = dat, \n                      y = pinfo, \n                      by = \"id\")\n\n\n\n\n4.3.2 Activity 3 - Explore your data objects\nOnce you have run this code, you should now see the new all_dat object in the environment pane. Remember to get into the habit of exploring your data and objects as you make changes, to check your wrangling is working as intended.\nThere are two main ways you can do this:\n\nClick on the data object in the Environment pane. This will open it up as a tab in RStudio, and you will be able to scroll through the rows and columns (Figure 4.1).\n\n\n\n\n\n\n\nWhy do I not see all my columns?\n\n\n\nOne common source of confusion is not seeing all your columns when you open up a data object as a tab. This is because RStudio shows you a maximum of 50 columns at a time. If you have more than 50 columns, to see more, you must use the arrows at the top of the tab where it says “Cols:”. For example in all_dat, it will say 1-50, if you click the right arrow, it will then say 5-54 so you can see the final 4 columns.\n\n\n\n\n\n\nFigure 4.1: Exploring a data object in RStudio by opening it as a tab. You can navigate around the columns and rows without opening it up in something like Excel. If there are more than 50 columns, you can click the arrows next to Cols.\n\n\n\n\nUse the glimpse() function to see an overview of the data objects.\n\nWe explored this in chapter 3, but glimpse() tells you how many rows and columns your data have, plus an overview of responses per column. Note: you will see a preview of all 54 columns, but we have shortened the preview to 10 columns to take up less space in the book.\n\nglimpse(all_dat)\n\n\n\nRows: 992\nColumns: 10\n$ id           &lt;dbl&gt; 12, 162, 162, 267, 126, 289, 113, 8, 185, 185, 246, 185, …\n$ occasion     &lt;dbl&gt; 5, 2, 3, 0, 5, 0, 2, 2, 2, 4, 4, 0, 4, 0, 1, 4, 0, 5, 4, …\n$ elapsed.days &lt;dbl&gt; 182.025139, 14.191806, 33.033831, 0.000000, 202.096887, 0…\n$ intervention &lt;dbl&gt; 2, 3, 3, 4, 2, 1, 1, 2, 3, 3, 3, 3, 1, 2, 2, 2, 3, 2, 2, …\n$ ahi01        &lt;dbl&gt; 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, …\n$ ahi02        &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, …\n$ ahi03        &lt;dbl&gt; 2, 1, 1, 2, 2, 4, 1, 1, 4, 4, 4, 4, 3, 3, 3, 2, 2, 2, 3, …\n$ ahi04        &lt;dbl&gt; 1, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, …\n$ ahi05        &lt;dbl&gt; 1, 2, 2, 2, 2, 1, 1, 1, 3, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ ahi06        &lt;dbl&gt; 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, …\n\n\n\n\n\n\n\n\nTry this\n\n\n\nNow you have explored all_dat, try and use one or both of these methods to explore the original dat and pinfo objects to see how they changed. Notice how the number of rows/observations and columns change from the original objects to when you join them."
  },
  {
    "objectID": "04-wrangling-1.html#selecting-variables-of-interest-with-select",
    "href": "04-wrangling-1.html#selecting-variables-of-interest-with-select",
    "title": "4  Data wrangling 1: Join, select, and mutate",
    "section": "\n4.4 Selecting variables of interest with select()\n",
    "text": "4.4 Selecting variables of interest with select()\n\nData sets often have a lot of variables we do not need and it can be easier to focus on just the columns we do need. In all_dat, we have 54 variables which takes ages to scroll through and it can be harder to find what you are looking for.\nFor the two scales on happiness and depression, we have all their items, as well as their total scores. We can create a data set that only includes the key variables and ignores all the individual items using the select() function. There are two ways you can use select: by selecting the variables you want to include, or by selecting the variables you want to ignore.\n\n4.4.1 Activity 4 - Selecting variables you want to include\nIf there are a smaller number of variables you want to include, then it will be more efficient to specify which variables you want to include. Returning to the data wrangling from chapter 3, we can select the columns from all_dat that we want to keep.\n\nsummarydata &lt;- select(.data = all_dat, # First argument as the data object\n                      id, # Stating variables we want to include\n                      occasion, \n                      elapsed.days,\n                      intervention,\n                      ahiTotal, \n                      cesdTotal, \n                      sex, \n                      age, \n                      educ, \n                      income)\n\nTo break down this code:\n\nWe are creating a new object called summarydata.\nFrom all_dat, we are selecting 10 columns we want to keep, which we list one by one.\n\n\n\n\n\n\n\nNote\n\n\n\nIn this example, the variables are in the same order as they were all_dat, but they do not need to be. You can use select() to create a new variable order if that helps you see all the important variables first. You can also rename variables as you select or reorder them, using the form new_name = old_name.\n\n\nKeep in mind it is important you select variables and assign them to a new object, or overwrite the old object. Both work, but think about if you need the original object later in your analysis and you do not want to go back and rerun code to recreate it. If you just use the select function on it’s own, it does not do anything to the object, R just shows you the variables you selected:\n\nselect(.data = all_dat, # First argument as the data object\n       id, # Stating variables we want to include\n       occasion, \n       elapsed.days,\n       intervention,\n       ahiTotal, \n       cesdTotal, \n       sex, \n       age, \n       educ, \n       income)\n\nIf you have several variables in order that you want to select, you can use a shortcut to avoid typing out every single name. When you select variables, you can use the format firstcolumn:lastcolumn to select all the variables from the first column you specify until the last column.\nFor example, if we wanted to isolate the individual items, we could use the following code:\n\nscaleitems &lt;- select(all_dat, # First argument as the data object\n                     ahi01:cesd20) # Range of variables to select\n\nYou can also pair this with individual variable selection:\n\nscaleitems &lt;- select(all_dat, # First argument as the data object\n                     id, # Individual variable to include\n                     ahi01:cesd20) # Range of variables to select\n\n\n\n\n\n\n\nTry this\n\n\n\nIf you wanted to select all the variables from id to intervention, plus all the variables from ahiTotal to income, how could you use this shortcut format? Try and complete the following code to recreate summarydata. Check your answer below when you have tried on your own.\n\nsummarydata2 &lt;- ?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nInstead of typing all 10 variables, you can select them using two ranges to ignore the scale items in the middle:\n\nsummarydata2 &lt;- select(all_dat, # First argument as the data object\n                      id:intervention, # variable range 1\n                      ahiTotal:income) # variable range 2\n\n\n\n\n\n4.4.2 Activity 5 - Selecting variables you want to ignore\nAlternatively, you can also state which variables you do not want to keep. This is really handy if you want to keep many columns and only remove one or two.\nFor example, if we wanted to remove two variables, you add a dash (-) before the variable name:\n\nall_dat_reduced2 &lt;- select(all_dat, \n                           -occasion, # Remove occasion\n                           -elapsed.days) # Remove elapsed.days\n\nThis also works using the range method, but you must add the dash before the first and last column in the range you want to remove. For example, we can recreate summarydata one more time by removing the scale items in the middle:\n\nsummarydata3 &lt;- select(all_dat, # \n                       -ahi01:-cesd20) # Remove range of variables\n\n\n\n\n\n\n\nTip\n\n\n\nYou can see there were at least three different ways of creating summarydata to keep the 10 variables we want to focus on. This is an important lesson as there is often not just one unique way of completing a task in R.\nWhen you first start coding, you might begin with the long way that makes sense to you. As you practice more, you recognise ways to simplify your code."
  },
  {
    "objectID": "04-wrangling-1.html#arranging-variables-of-interest-with-arrange",
    "href": "04-wrangling-1.html#arranging-variables-of-interest-with-arrange",
    "title": "4  Data wrangling 1: Join, select, and mutate",
    "section": "\n4.5 Arranging variables of interest with arrange()\n",
    "text": "4.5 Arranging variables of interest with arrange()\n\nAnother handy skill is being able to change the order of observations within columns in your data set. The function arrange() will sort the rows/observations by one or more columns. This can be useful for exploring your data set and answering basic questions, such as: who was the youngest or oldest participant?\n\n4.5.1 Activity 6 - Arranging in ascending order\nUsing summarydata, we can order the participants’ ages in ascending order:\n\nage_ascend &lt;- arrange(summarydata,\n                    age)\n\nTo break down the code,\n\nWe create a new object called age_ascend.\nWe apply the function arrange() to the summarydata object.\nWe order the observations by age, which is by default in ascending order from smallest to largest.\n\nIf you look in age_ascend, we organised the data in ascending order based on age and can see the youngest participant was 18 years old.\n\n4.5.2 Activity 7 - Arranging in descending order\nBy default, arrange() sorts observations in ascending order from the smallest to largest value, or alphabetical order from A to Z. If you want to arrange observations in descending order, you can wrap the name of the variable in the desc() function.\nFor example, we can order participants from oldest to youngest:\n\nage_descend &lt;- arrange(summarydata, \n                     desc(age)) # descending order of age\n\nThis time, we can see the oldest participant was 83 years old.\n\n4.5.3 Activity 8 - Sorting by multiple columns\nFinally, you can also sort by more than one column and a combination of ascending and descending columns. Unlike select(), you might not need to save your sorted observations as a new object, you could use arrange() more as a tool to explore your data.\nFor example, we could look for the oldest female participant. Note: your code will show all 992 observations you could scroll through, but we show the first 10 to save space.\n\narrange(summarydata, \n        sex, # order by sex first\n        desc(age)) # then descending age\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\noccasion\nelapsed.days\nintervention\nahiTotal\ncesdTotal\nsex\nage\neduc\nincome\n\n\n\n51\n4\n94.905451\n2\n86\n15\n1\n83\n2\n2\n\n\n51\n3\n32.644595\n2\n87\n7\n1\n83\n2\n2\n\n\n51\n0\n0.000000\n2\n90\n5\n1\n83\n2\n2\n\n\n51\n2\n15.764178\n2\n90\n4\n1\n83\n2\n2\n\n\n51\n5\n185.852778\n2\n91\n10\n1\n83\n2\n2\n\n\n244\n0\n0.000000\n2\n64\n33\n1\n77\n3\n2\n\n\n244\n1\n7.238877\n2\n70\n37\n1\n77\n3\n2\n\n\n244\n2\n16.900289\n2\n71\n16\n1\n77\n3\n2\n\n\n244\n3\n31.251377\n2\n75\n22\n1\n77\n3\n2\n\n\n215\n0\n0.000000\n4\n76\n1\n1\n75\n3\n2\n\n\n\n\n\n\n\n\n\n\n\n\nTry this\n\n\n\nUsing summarydata and arrange(), sort the data to answer the following questions:\n\nHow old is the participant with the highest total happiness score (ahiTotal)? \nWhat is the highest total depression score (cesdTotal) in a female participant (remember 1 = female, 2 = male)? \n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nWe only need to arrange by ahiTotal in descending order to find the highest value, then look at the age column.\n\n\narrange(summarydata, \n        desc(ahiTotal)) # descending ahiTotal\n\n\nWe first order by sex in ascending order so 1s are first, then descending order of cesdTotal for the highest value.\n\n\narrange(summarydata, \n        sex, # order by sex first\n        desc(cesdTotal)) # Descending depression total"
  },
  {
    "objectID": "04-wrangling-1.html#modifying-or-creating-variables-with-mutate",
    "href": "04-wrangling-1.html#modifying-or-creating-variables-with-mutate",
    "title": "4  Data wrangling 1: Join, select, and mutate",
    "section": "\n4.6 Modifying or creating variables with mutate()\n",
    "text": "4.6 Modifying or creating variables with mutate()\n\nIn the final data wrangling function for this chapter, we can use the function mutate() to modify existing variables or create new variables. This is an extremely powerful and flexible function. We will not be able to cover everything you can do with it in this chapter but we will introduce you to some common tasks you might want to apply.\n\n4.6.1 Activity 9 - Modifying existing variables\nIf you remember back to chapter 3, we had a problem where R interpreted variables like sex, educ, and income as numeric, but ideally we wanted to treat them as distinct categories or factors. We used mutate() to convert the three columns to factors:\n\n# Overwrite summary data \nsummarydata &lt;- mutate(summarydata, # mutate to change columns \n         sex = as.factor(sex), # save sex as a factor\n         educ = as.factor(educ),\n         income = as.factor(income))\n\nTo break down the code:\n\nWe overwrite summarydata by assigning the function to an existing object name.\nWe use the mutate() function on the old summarydata data by using it as the first argument.\nWe can add one or more arguments to modify or create variables. Here, we modify an existing variable sex, use an equals sign (=), then how we want to modify the variable. In this example, we convert sex to a factor by using the function as.factor(sex).\n\nYou might not just want to turn a variable into a factor, you might want to completely recode what it’s values represent. For this, there is a function called case_match() which you can use within mutate(). For example, if we wanted to make sex easier to interpret, we could overwrite it’s values from 1 and 2:\n\nsex_recode &lt;- mutate(summarydata,\n                     sex = case_match(sex, # overwrite existing\n                                      \"1\" ~ \"Female\", # old to new\n                                      \"2\" ~ \"Male\")) # old to new\n\nTo break down this code,\n\nWe create a new object sex_recode by mutating the summarydata object.\nWe modify an existing variable sex by applying case_match() to sex.\nWithin case_match(), the value on the left is the existing value in the data you want to recode. The value on the right is the new value you want to overwrite it to. So, we want to change all the 1s in the data to Female. We then add a new line for every old value we want to change.\n\n\n\n\n\n\n\nError mode\n\n\n\nIn the previous exercise, we already converted sex to a factor. So, we had to add quote marks around the old values (\"1\") as they are no longer considered numeric. If you do not add the quote marks, you will get an error like Can't convert \"..1 (left)\" &lt;double&gt; to &lt;factor&gt;.\nIf you applied this step before converting sex to a factor, then 1 ~ \"Female\" would work. This shows why it is important to keep data types in mind as R might not know what you mean if you state one data type when it is expecting another.\n\n\n\n\n\n\n\n\nTry this\n\n\n\nUsing what you just learnt about using mutate and case_match(), recode the variable income and complete the code below. These are what the numeric values mean as labels:\n1 = Below average\n2 = Average\n3 = Above average\n\nincome_recode &lt;- mutate(summarydata,\n                     income = ?\n                       )\n\nCheck your code against the solution when you have attempted yourself first.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nFollowing the same format as sex, we add a new label for each of the three levels of income.\n\nincome_recode &lt;- mutate(summarydata,\n                     income = case_match(income, # overwrite existing\n                                      \"1\" ~ \"Below average\", # old to new\n                                      \"2\" ~ \"Average\", # old to new\n                                      \"3\" ~ \"Above average\")) # old to new\n\n\n\n\n\n4.6.2 Activity 10 - Creating new variables\nYou can also create new variables using mutate(). There are many possibilities here, so we will demonstrate a few key principles for inspiration and you will learn how to tackle unique problems as you come to them.\nIn it’s simplest application, you can use mutate() to add a single value to all rows. For example, you might want to label a data set before joining with another data set so you can identify their origin. Instead of overwriting an existing variable, we specify a new variable name and the value we want to assign:\n\nsummarydata &lt;- mutate(summarydata,\n                      study = \"Woodworth et al. (2018)\")\n\nUsing a similar kind of logic to case_match() we introduced you to earlier, there is an extremely flexible function called case_when() to help create new variables. Before we explain how it works, we will jump straight into an example to give you something concrete to work with.\nWoodworth et al. (2018) includes scores from the Center for Epidemiological Studies Depression (CES-D) scale. Scores range from 0 to 60, with scores of 16 or more considered a cut-off for being at risk of clinical depression. We have the scores, so we can use case_when() to label whether participants are at risk or not.\n\nsummarydata &lt;- mutate(summarydata,\n                      depression_risk = case_when(\n                        cesdTotal &lt; 16 ~ \"Not at risk\",\n                        cesdTotal &gt; 15 ~ \"At risk\"))\n\nTo break down the code:\n\nWe overwrite summarydata by mutating the existing summarydata object.\nWe create a new variable called depression_risk by applying the case_when() function to the variable cesdTotal.\nWe apply two comparisons to label responses as either “Not at risk” or “At risk”. If cesdTotal is less than 16 (i.e., 15 or smaller), then it receives the value “Not at risk”. If cesdTotal is more than 15 (i.e., 16 or higher), then it receives the value “At risk”.\n\nThe function case_when() applies these criteria line by line as it works through your rows. Depending on which criteria your observation meet, it receives the label “Not at risk” or “At risk”. You can also set the argument .default to assign one value for anything that does not pass any criteria you give it.\nThe comparisons use something called a Boolean expression. These are logical expressions which can return the values of TRUE or FALSE. To demonstrate the idea, imagine we were applying the logic manually to scores in the data. The first value is 50, so we could apply our criteria to see which one it meets:\n\n50 &lt; 16\n50 &gt; 15\n\n[1] FALSE\n[1] TRUE\n\n\nR evaluates the first comparison as FALSE as 50 is not smaller than 16, but it evaluates the second comparison as TRUE as 50 is larger than 15. So, case_when() would apply the label “At risk” as the second statement evaluates to TRUE.\n\n\n\n\n\n\nTry this\n\n\n\nTry and pick a few more cesdTotal scores from the data and apply the criteria to see if they are evaluated as TRUE OR FALSE. It can be tricky moving from imagining what you want to do to being able to express it in code, so the more practice the better.\n\n\nWe have only used less than or greater than, but there are several options for expressing Boolean logic, the most common of which are:\n\n\nOperator\nName\nis TRUE if and only if\n\n\n\nA &lt; B\nless than\nA is less than B\n\n\nA &lt;= B\nless than or equal\nA is less than or equal to B\n\n\nA &gt; B\ngreater than\nA is greater than B\n\n\nA &gt;= B\ngreater than or equal\nA is greater than or equal to B\n\n\nA == B\nequivalence\nA exactly equals B\n\n\nA != B\nnot equal\nA does not exactly equal B\n\n\nA %in% B\nin\nA is an element of vector B\n\n\n\nBoolean expressions will come up again in chapter 5 when it comes to filter(), so there will be plenty more practice as you apply your understanding to different data sets and use cases.\n\n\n\n\n\n\nTry this\n\n\n\nUsing what you just learnt about using mutate and case_when(), create a new variable called happy using the ahiTotal variable and complete the code below.\nThe Authentic Happiness Inventory (AHI) does not have official cutoffs, but let us pretend scores of 65 or more are “happy” and scores of less than 65 are “unhappy”.\n\nsummarydata &lt;- mutate(summarydata,\n                     happy = ?\n                       )\n\nCheck your code against the solution when you have attempted it yourself first.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nFollowing the same format as depression_risk and cesdTotal, we add a new comparison for each criterion we want to use as a Boolean expression:\n\nsummarydata &lt;- mutate(summarydata,\n                      happy = case_when(\n                        ahiTotal &lt; 65 ~ \"Unhappy\",\n                        ahiTotal &gt; 64 ~ \"Happy\"))\n\nIf you looked at the table of Boolean operators, you could also express 65 or more as:\n\nsummarydata &lt;- mutate(summarydata,\n                      happy = case_when(\n                        ahiTotal &lt; 65 ~ \"Unhappy\",\n                        ahiTotal &gt;= 65 ~ \"Happy\"))"
  },
  {
    "objectID": "04-wrangling-1.html#ld-test",
    "href": "04-wrangling-1.html#ld-test",
    "title": "4  Data wrangling 1: Join, select, and mutate",
    "section": "\n4.7 Test yourself",
    "text": "4.7 Test yourself\nTo end the chapter, we have some knowledge check questions to test your understanding of the concepts we covered in the chapter. We then have some error mode tasks to see if you can find the solution to some common errors in the concepts we covered in this chapter.\n\n4.7.1 Knowledge check\nQuestion 1. Which of the following functions would you use if you wanted to keep only certain columns?\n\nselect()arrange()mutate()inner_join()\n\nQuestion 2. Which of the following functions would you use if you wanted to join two data sets by their shared identifier?\n\nselect()arrange()mutate()inner_join()\n\nQuestion 3. Which of the following functions would you use if you wanted to add or modify a column?\n\nselect()arrange()mutate()inner_join()\n\nQuestion 4. When you use mutate(), which additional function could you use to recode an existing variable?\n\narrange()case_when()case_match()filter()\n\nQuestion 5. When you use mutate(), which additional function could you use to create a new variable depending on specific criteria you set?\n\narrange()case_when()case_match()filter()\n\n\n4.7.2 Error mode\nThe following questions are designed to introduce you to making and fixing errors. For this topic, we focus on data wrangling using the functions inner_join(), select(), and mutate(). Remember to keep a note of what kind of error messages you receive and how you fixed them, so you have a bank of solutions when you tackle errors independently.\nCreate and save a new R Markdown file for these activities. Delete the example code, so your file is blank from line 10. Create a new code chunk to load tidyverse and the two data files:\n\n# Load the tidyverse package\nlibrary(tidyverse)\n\n# Load the two data files\ndat &lt;- read_csv(\"data/ahi-cesd.csv\")\npinfo &lt;- read_csv(\"data/participant-info.csv\")\n\nBelow, we have several variations of a code chunk error or misspecification. Copy and paste them into your R Markdown file below the code chunk to load tidyverse and the data. Once you have copied the activities, click knit and look at the error message you receive. See if you can fix the error and get it working before checking the answer.\nQuestion 6. Copy the following code chunk into your R Markdown file and press knit. This…works, but we want 54 columns rather than 55 columns. Some of the columns do not look quite right?\n```{r}\nall_dat &lt;- inner_join(x = dat, \n                      y = pinfo, \n                      by = c(\"id\"))\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nThis was a prompt to look out for duplicate columns when we do not specify all the common columns between the data sets you want to join. You join by “id” which works, but because you did not also add “intervention”, you get .x and .y appended to two “intervention” columns.\n\nall_dat &lt;- inner_join(x = dat, \n                      y = pinfo, \n                      by = c(\"id\", \"intervention\"))\n\n\n\n\nQuestion 7. Copy the following code chunk into your R Markdown file and press knit. You should receive an error like ! Can't subset columns that don't exist. x Column \"interventnion\" doesnt exist.\n```{r}\nselect_data &lt;- select(.data = pinfo,\n                      id,\n                      intervetnion,\n                      sex, \n                      age, \n                      educ, \n                      income)\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nThis is an example of a sneaky typo causing an error. R is case and spelling sensitive, so it does not know what you mean when you asked it to select the column “intervetnion” rather than “intervention”. To fix the error, you just need to fix the typo:\n\nselect_data &lt;- select(.data = pinfo,\n                      id,\n                      intervention,\n                      sex, \n                      age, \n                      educ, \n                      income)\n\n\n\n\nQuestion 8. Copy the following code chunk into your R Markdown file and press knit. You should receive an error like ! Cant convert \"..1 (left)\" &lt;character&gt; to &lt;double&gt;.\n```{r}\nrecode_variable &lt;- mutate(pinfo,\n                          sex = case_match(sex,\n                                           \"1\" ~ \"Female\",\n                                           \"2\" ~ \"Male\"))\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nThis is the opposite problem to what we warned about in the case_match section. You need to honour data types and we have not converted sex to a factor or character in this example. So, R does not know how to match the character “1” against the number/double 1 in the data. To fix the error, you need to remove the double quotes to give R a number/double like it can see in the data:\n\nrecode_variable &lt;- mutate(pinfo,\n                          sex = case_match(sex,\n                                           1 ~ \"Female\",\n                                           2 ~ \"Male\"))\n\n\n\n\nQuestion 9. Copy the following code chunk into your R Markdown file and press knit. We want to create two groups depending on if we consider a participant a teenager if they are younger than 20, or not a teenger if they are 20 years or older. The code below…works? This is a sneaky one, so think about the criteria we want vs the criteria we set.\n```{r}\nage_groups &lt;- mutate(pinfo,\n                      age_groups = case_when(\n                        age &lt; 20 ~ \"Teenager\",\n                        age &gt; 20 ~ \"Not a teenager\"))\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nThis is a really sneaky one as it does not actually affect a participant in the data, but there is a small mismatch between the criteria we want and the criteria we set.\nIn our “teenager” group, this is accurate as we want to classify them if they are younger than 20. However, in the “not a teenager” group we currently set the criterion if they are older than 20, i.e., 21 or older. This would mean 20 year old participants are stuck in the middle with no group.\nWe see this kind of mistake a lot, so think carefully about your Boolean expression and check examples in the console if you are unsure. To fix, you could use:\n\nage_groups &lt;- mutate(pinfo,\n                      age_groups = case_when(\n                        age &lt; 20 ~ \"Teenager\",\n                        age &gt; 19 ~ \"Not a teenager\"))\n\nor\n\nage_groups &lt;- mutate(pinfo,\n                      age_groups = case_when(\n                        age &lt; 20 ~ \"Teenager\",\n                        age &gt;= 20 ~ \"Not a teenager\"))"
  },
  {
    "objectID": "04-wrangling-1.html#words-from-this-chapter",
    "href": "04-wrangling-1.html#words-from-this-chapter",
    "title": "4  Data wrangling 1: Join, select, and mutate",
    "section": "\n4.8 Words from this Chapter",
    "text": "4.8 Words from this Chapter\nBelow you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the PsyTeachR Glossary. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter.\n\n\n\nterm\ndefinition\n\n\n\narrange()\nOrder the rows of a data set by the values of one or more columns.\n\n\nboolean-expression\nA logical statement in programming to evaluate a condition and return a Boolean value, which can be TRUE or FALSE.\n\n\ncase_match()\nYou can switch values from old to new. Statements are evaluated sequentially, meaning the old value is replaced with the first new value it matches.\n\n\ncase_when()\nAn if else statement to check old values against a set of criteria. Statements are evaluated sequentially, meaning each observation is checked against the criteria, and it receives the first match it passes.\n\n\ndata-wrangling\nThe process of preparing data for visualisation and statistical analysis.\n\n\nfunction\nA named section of code that can be reused.\n\n\ninner-join\nA mutating join that returns all the rows that have a match in the other table.\n\n\nmutate()\nYou can create new columns that are functions of existing variables. You can also modify variables if the name is the same as an existing column.\n\n\npackage\nA group of R functions.\n\n\nselect()\nSelect, reorder, or rename variables in your data set."
  },
  {
    "objectID": "04-wrangling-1.html#end-of-chapter",
    "href": "04-wrangling-1.html#end-of-chapter",
    "title": "4  Data wrangling 1: Join, select, and mutate",
    "section": "\n4.9 End of Chapter",
    "text": "4.9 End of Chapter\nExcellent work so far! Data wrangling is a critical skill and being able to clean and prepare your data using code will save you time in the long run. Manually tidying data might seem quicker now when you are unfamilar with these functions, but it is open to errors which may not have a paper trail as you edit files. By reproducibly wrangling your data, you can still make mistakes, but they are reproducible mistakes you can fix.\nIn the next chapter, we start by recapping the key functions from this chapter on a new data set, then introduce you to more data wrangling functions from dplyr to expand your toolkit.\n\n\n\n\nDasu, T., & Johnson, T. (2003). Exploratory data mining and data cleaning. Wiley-Interscience.\n\n\nWickham, H. (2017). Tidyverse: Easily install and load the ’tidyverse’. https://CRAN.R-project.org/package=tidyverse\n\n\nWoodworth, R. J., O’Brien-Malone, A., Diamond, M. R., & Schüz, B. (2018). Data from, “Web-based Positive Psychology Interventions: A Reexamination of Effectiveness.” Journal of Open Psychology Data, 6(1), 1. https://doi.org/10.5334/jopd.35"
  },
  {
    "objectID": "05-wrangling-2.html#chapter-preparation",
    "href": "05-wrangling-2.html#chapter-preparation",
    "title": "5  Data wrangling 2: Filter and summarise",
    "section": "\n5.1 Chapter preparation",
    "text": "5.1 Chapter preparation\n\n5.1.1 Introduction to the data set\nFor this chapter, we are using open data from Witt et al. (2018). The abstract of their article is:\n\nCan one’s ability to perform an action, such as hitting a softball, influence one’s perception? According to the action-specific account, perception of spatial layout is influenced by the perceiver’s abilities to perform an intended action. Alternative accounts posit that purported effects are instead due to nonperceptual processes, such as response bias. Despite much confirmatory research on both sides of the debate, researchers who promote a response-bias account have never used the Pong task, which has yielded one of the most robust action-specific effects. Conversely, researchers who promote a perceptual account have rarely used the opposition’s preferred test for response bias, namely, the postexperiment survey. The current experiments rectified this. We found that even for people naive to the experiment’s hypothesis, the ability to block a moving ball affected the ball’s perceived speed. Moreover, when participants were explicitly told the hypothesis and instructed to resist the influence of their ability to block the ball, their ability still affected their perception of the ball’s speed.\n\nTo summarise, their research question was: does your ability to perform an action influence your perception? For instance, does your ability to hit a tennis ball influence how fast you perceive the ball to be moving? Or to phrase another way, do expert tennis players perceive the ball moving slower than novice tennis players?\nThis experiment does not use tennis players, instead they used the Pong task like the classic retro arcade game. Participants aimed to block moving balls with various sizes of paddles. Participants tend to estimate the balls as moving faster when they have to block it with a smaller paddle as opposed to when they have a bigger paddle. In this chapter, we will wrangle their data to reinforce skills from Chapter 4, and add more dplyr functions to your toolkit.\n\n5.1.2 Organising your files and project for the chapter\nBefore we can get started, you need to organise your files and project for the chapter, so your working directory is in order.\n\nIn your folder for research methods and the book ResearchMethods1_2/Quant_Fundamentals, you should have a folder from chapter 4 called Chapter_04_06_datawrangling where you created an R Project.\nCreate a new R Markdown document and give it a sensible title describing the chapter, such as 05 Data Wrangling 2. Delete everything below line 10 so you have a blank file to work with and save the file in your Chapter_04_06_datawrangling folder.\nWe are working with a new data set, so please save the following data file: witt_2018.csv. Right click the link and select “save link as”, or clicking the link will save the files to your Downloads. Make sure that you save the file as “.csv”. Save or copy the file to your data/ folder within Chapter_04_06_datawrangling.\n\nYou are now ready to start working on the chapter!"
  },
  {
    "objectID": "05-wrangling-2.html#select-arrange-and-mutate-recap",
    "href": "05-wrangling-2.html#select-arrange-and-mutate-recap",
    "title": "5  Data wrangling 2: Filter and summarise",
    "section": "\n5.2 Select, arrange, and mutate recap",
    "text": "5.2 Select, arrange, and mutate recap\nBefore we introduce you to new functions, we will recap data wrangling functions from Chapter 4 to select, arrange, and mutate. Following along is one thing but being able to transfer your understanding to a new data set is a key sign of your skill development. Feel free to use Chapter 4 to help you, but try and complete the recap activities independently before checking the solutions. This will help prepare you as we move from the chapters, to the data analysis journeys, to the assessments, and to your future career.\n\n5.2.1 Activity 1 - Load tidyverse and read the data file\nAs the first activity, try and test yourself by loading tidyverse and reading the data file. As a prompt, save the data file to this object name to be consistent with the activities below, but you can check your answer below if you are stuck.\n\n# Load the tidyverse package below\n?\n  \n# Load the data file\n# This should be the witt_2018.csv file \npong_data &lt;- ?\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# Load the tidyverse package below\nlibrary(tidyverse)\n\n# Load the data file\n# This should be the witt_2018.csv file \npong_data &lt;- read_csv(\"data/witt_2018.csv\")\n\n\n\n\n\n5.2.2 Activity 2 - Explore pong_data\n\nRemember the first critical step when you come across any new data is exploring to see how many columns you are working with, how many rows/observations there are, and what the values look like. For example, you can click on pong_data in the environment and scroll around it as a tab. You can also get a preview of your data by using the glimpse() function.\n\nglimpse(pong_data)\n\nRows: 4,608\nColumns: 8\n$ Participant     &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ JudgedSpeed     &lt;dbl&gt; 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, …\n$ PaddleLength    &lt;dbl&gt; 50, 250, 50, 250, 250, 50, 250, 50, 250, 50, 50, 250, …\n$ BallSpeed       &lt;dbl&gt; 5, 3, 4, 3, 7, 5, 6, 2, 4, 4, 7, 7, 3, 6, 5, 7, 2, 5, …\n$ TrialNumber     &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,…\n$ BackgroundColor &lt;chr&gt; \"red\", \"blue\", \"red\", \"red\", \"blue\", \"blue\", \"red\", \"r…\n$ HitOrMiss       &lt;dbl&gt; 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, …\n$ BlockNumber     &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n\n\nIf you look at that table, you can see there are 8 columns and 4608 rows. Seven of the column names are &lt;dbl&gt;, short for double, and one is &lt;chr&gt;, short for character. We will need to keep the data types in mind as we wrangle the data.\n\n5.2.3 Data types in R\nWe try and balance developing your data skills in a practical way while slowly introducing some of the underlying technical points. In the last chapter, we warned about honoring data types so R knew how to handle numbers/doubles vs factors. Now we have explored a few data sets, it is time to clarify some key differences between data types in R.\nWe often store data in two-dimensional tables, either called data frames, tables, or tibbles. There are other ways of storing data that you will discover in time but in this book, we will be using data frame or tibbles (a special type of data frame in the tidyverse). A data frame is really just a table of data with columns and rows of information. Within the cells of the data frame - a cell being where a row and a column meet - you get different types of data, including double, integer, character and factor. To summarise:\n\n\n\n\n\n\nType of Data\nDescription\n\n\n\nDouble\nNumbers that can take decimals\n\n\nInteger\nNumbers that cannot take decimals\n\n\nCharacter\nTends to contain letters or be words\n\n\nFactor\nNominal (categorical). Can be words or numbers (e.g., animal or human, 1 or 2)\n\n\n\nDouble and integer can both be referred to as numeric data, and you will see this word from time to time. For clarity, we will use double as a term for any number that can take a decimal (e.g. 3.14) and integer as a term for any whole number (no decimal, e.g. 3).\nSomewhat confusingly, double data might not have decimal places in it. For instance, the value of 1 could be double as well as integer. However, the value of 1.1 could only be double and never integer. Integers cannot have decimal places. The more you work with data the more this will make sense, but it highlights the importance of looking at your data and checking what type it is as the type determines what you can do with the data.\nIn pong_data, each row (observation) represents one trial per participant and there are 288 trials for each of the 16 participants. Most of the data is a double (i.e., numbers) and one column is a character (i.e., text). The columns (variables) we have in the data set are:\n\n\n\n\n\n\n\nVariable\nType\nDescription\n\n\n\nParticipant\ndouble\nparticipant number\n\n\nJudgedSpeed\ndouble\nspeed judgement (1 = fast, 0 = slow)\n\n\nPaddleLength\ndouble\npaddle length (pixels)\n\n\nBallSpeed\ndouble\nball speed (2 pixels/4ms)\n\n\nTrialNumber\ndouble\ntrial number\n\n\nBackgroundColor\ncharacter\nbackground display colour\n\n\nHitOrMiss\ndouble\nhit ball = 1, missed ball = 0\n\n\nBlockNumber\ndouble\nblock number (out of 12 blocks)\n\n\n\n5.2.4 Activity 3 - select() a range of columns\nEither by inclusion (stating all the variables you want to keep) or exclusion (stating all the variables you want to drop), create a new object named select_dat and select the following columns from pong_data:\n\nParticipant\nPaddleLength\nTrialNumber\nBackgroundColor\nHitOrMiss\n\n\n# select 5 variables from pong_data\nselect_dat &lt;- ?\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# select 5 variables from pong_data\nselect_dat &lt;- select(pong_data,\n                     Participant,\n                     PaddleLength,\n                     TrialNumber,\n                     BackgroundColor,\n                     HitOrMiss)\n\nor\n\n# remove 3 variables from pong_data\nselect_dat &lt;- select(pong_data,\n                     -JudgedSpeed,\n                     -BallSpeed,\n                     -BlockNumber)\n\n\n\n\n\n5.2.5 Activity 4 - Reorder the variables using select()\n\nWe can also use select() to reorder your columns, as the new data object will display the variables in the order that you entered them.\nUse select() to keep only the columns Participant, JudgedSpeed, BallSpeed, TrialNumber, and HitOrMiss from pong_data but this time, display them in ascending alphabetical order. Save this tibble in a new object named reorder_dat.\n\n# reorder the 5 variables from pong_data\nreorder_dat &lt;- ?\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# reorder the 5 variables from pong_data\nreorder_dat &lt;- select(pong_data, # original data\n                     BallSpeed,\n                     HitOrMiss,\n                     JudgedSpeed,\n                     Participant,\n                     TrialNumber)\n\n\n\n\n\n5.2.6 Activity 5 - Reorder observations using arrange()\n\nReorder observations in the data using the following two variables: HitOrMiss (putting hits (1) first) and JudgedSpeed (putting fast judgement (1) first). Store this in an object named arrange_dat.\n\n# arrange pong_data by HitOrMiss and JudgedSpeed\narrange_dat &lt;- ?\n\nNow try and answer the following questions about the data.\n\nWhat is the trial number (TrialNumber) in the 1st row? \nWhat is the background colour (BackgroundColor) in the 10th row? \n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou needed to include desc() to change it from running smallest-to-largest to largest-to-smallest as the values are 0 and 1. You should have the following in a code chunk:\n\n# arrange pong_data by HitOrMiss and JudgedSpeed\narrange_dat &lt;- arrange(pong_data, # original data\n                     desc(HitOrMiss),\n                     desc(JudgedSpeed))\n\n\n\n\n\n5.2.7 Activity 6 - Modifying or creating variables using mutate()\n\nSome of these values could be a little easier to understand. They are represented in the data by 0s and 1s, but it might not be immediately obvious what they mean.\nCreate a new variable called JudgedSpeedLabel by mutating the original pong_data object. Change the values in JudgedSpeed using the following labels:\n0 = Slow\n1 = Fast\n\n# mutate pong_data and recode values into a new variable\npong_data &lt;- ?\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# mutate pong_data and recode values into a new variable\npong_data &lt;- mutate(pong_data, \n                    JudgedSpeedLabel = case_match(JudgedSpeed, \n                                                  0 ~ \"Slow\",\n                                                  1 ~ \"Fast\"))"
  },
  {
    "objectID": "05-wrangling-2.html#removing-or-retaining-observations-using-filter",
    "href": "05-wrangling-2.html#removing-or-retaining-observations-using-filter",
    "title": "5  Data wrangling 2: Filter and summarise",
    "section": "\n5.3 Removing or retaining observations using filter()\n",
    "text": "5.3 Removing or retaining observations using filter()\n\nNow we have revisited key data wrangling functions from Chapter 4 to select, arrange, and mutate, it is time to add some new functions from dplyr to your toolkit.\nUsing select, we could remove columns, but there are many situations where you want to include or exclude certain observations/rows. The function filter() will possibly be one of your most used for data wrangling. For example, imagine you want to only analyse participants who provided informed consent and exclude participants who did not. Similarly, you might want to focus your analyses only on participants who are under the age of 21.\n\n5.3.1 Activity 7 - Filter using one criterion\nWe will jump straight into an example. Imagine that you realised you made a mistake creating your experiment and all your trial numbers are wrong. The first trial (trial number 1) was a practice, so you should exclude it and your experiment actually started on trial 2.\n\npong_data_filter &lt;- filter(pong_data,\n                           TrialNumber &gt; 1)\n\nTo break down the code:\n\nWe create a new object called pong_data_filter by applying the filter function to pong_data.\nWe add the Boolean expression TrialNumber &gt; 1 to keep all responses higher than 1 (i.e., 2 or higher).\n\nThe filter() function uses our old friends the Boolean expressions we introduced you to in Chapter 4. You can add one or more logical expressions to filter observations. The function retains observations when they are evaluated to TRUE and ignores observations when they are evaluated to FALSE. Remember, when you are working out how to express your ideas in code, test them out. For example, we can see what the expression would do to different trial numbers:\n\n1 &gt; 1\n2 &gt; 1\n\n[1] FALSE\n[1] TRUE\n\n\n1 is not larger than 1, so it’s evaluated to FALSE and would be ignored. 2 is larger than 2, so it’s evaluated to TRUE and would be retained. Explore the two data sets pong_data and pong_data_filter and the number of rows they have to see the effects of applying the function.\nAs a reminder from Chapter 4, the most common Boolean expressions are:\n\n\nOperator\nName\nis TRUE if and only if\n\n\n\nA &lt; B\nless than\nA is less than B\n\n\nA &lt;= B\nless than or equal\nA is less than or equal to B\n\n\nA &gt; B\ngreater than\nA is greater than B\n\n\nA &gt;= B\ngreater than or equal\nA is greater than or equal to B\n\n\nA == B\nequivalence\nA exactly equals B\n\n\nA != B\nnot equal\nA does not exactly equal B\n\n\nA %in% B\nin\nA is an element of vector B\n\n\n\n\n\n\n\n\n\nTry this\n\n\n\nUsing the filter() example and the table above, imagine we wanted to only keep trials where participants judged the speed to be “Fast”. Use the pong_data_filter after removing trial number 1 and assign it to a new object pong_data_fast. You could use the JudgedSpeed or JudgedSpeedLabel variable to do this.\nFor a hint, you want to keep responses when they are equivalent to “Fast” or 1 depending on the variable you use.\n\n# Retain fast judged speed trials\npong_data_fast &lt;- filter(pong_data_filter,\n                         ?)\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nYou were looking for the equivalence Boolean operator (==) to retain responses which were equal to “Fast” or 1. If you used JudgedSpeedLabel, you should have:\n\n# Retain fast judged speed trials\npong_data_fast &lt;- filter(pong_data_filter,\n                         JudgedSpeedLabel == \"Fast\")\n\nIf you used JudgedSpeed, you should have:\n\n# Retain fast judged speed trials\npong_data_fast &lt;- filter(pong_data_filter,\n                         JudgedSpeedLabel == 1)\n\nNote we use a double equals == and not a single equals = for the Boolean operator. We also must honour the data type for the expression we set.\n\n\n\n\n5.3.2 Activity 8 - Filter using two or more criteria\nYou explored using one criterion to filter out or retain observations/rows, but you can make the expressions arbitrarily more complicated by adding two or more criteria to evaluate against. Just note the more criteria you add, the more selective you are being. You are probably going to be excluding more and more observations, so think about what you want to achieve.\nFocusing on one variable, you can specify multiple values to compare against. For example, you might want to only keep responses which had a ball speed of 2 or 4:\n\npong_data_BallSpeed &lt;- filter(pong_data_filter,\n                              BallSpeed == 2 | BallSpeed == 4)\n\nTo break down the code:\n\nWe create a new object called pong_data_BallSpeed by applying the filter function to pong_data_filter.\nWe add the Boolean expression BallSpeed == 2, the vertical line symbol (|), then a second expression BallSpeed == 4. The vertical line symbol (|) means “or”, so our expression is retain BallSpeed responses which equal 2 OR 4, and ignore all the others.\n\nFor two values, this is pretty straightforward, but it could get out of hand when you have four or five values to evaluate against. There is a super handy shortcut from the Boolean expressions table for “in” which we can apply if we wanted to keep ball speeds of 2, 4, 5, and 7:\n\npong_data_BallSpeed &lt;- filter(pong_data_filter,\n                              BallSpeed %in% c(2, 4, 5, 7))\n\nYou can read the expression here as: for each observation/row, check whether the value of BallSpeed is in the vector of numbers 2, 4, 5, 7. Remember filter() works by whether the expression is evaluted to TRUE or FALSE, so you can see how it works by testing some numbers:\n\n1 %in% c(2, 4, 5, 7)\n2 %in% c(2, 4, 5, 7)\n\n[1] FALSE\n[1] TRUE\n\n\n1 is not present in c(2, 4, 5, 7), so it is evaluated to FALSE and would be ignored. 2 is presented in c(2, 4, 5, 7), so it is evaluated to TRUE and would be retained.\nYou can also add two or more expressions including multiple variables by adding them to the function separated by commas. For example, imagine we wanted to retain observations/rows which had a “Fast” speed judgement with ball speeds of 2, 4, 5, and 7:\n\npong_fast_BallSpeed &lt;- filter(pong_data_filter, \n                         JudgedSpeedLabel == \"Fast\", \n                         BallSpeed %in% c(\"2\", \"4\", \"5\", \"7\"))\n\nIn the first expression, we only want to keep observations/rows which have a JudgedSpeedLabel of “Fast”. In the second expression, we only want to keep observations/rows which have a BallSpeed of 2, 4, 5, or 7. In other words, retain “Fast” observations AND those with a ball speed of 2, 4, 5, or 7. Adding more expressions makes your criteria more selective as rows must pass both conditions to be retained in the data.\n\n\n\n\n\n\nTry this\n\n\n\nUsing the examples above, imagine we wanted to only keep trials where:\n\nThe PaddleLength is 50.\nThe BackgroundColor is red.\nThe HitOrMiss is 1.\n\nUse the pong_data_filter object and assign it to a new object pong_data_three_criteria.\n\n# apply three criteria to filter pong_data_filter\npong_data_three_criteria &lt;- filter(pong_data_filter,\n                                   ?)\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# apply three criteria to filter pong_data_filter\npong_data_three_criteria &lt;- filter(pong_data_filter,\n                                   PaddleLength == 50,\n                                   BackgroundColor == \"red\",\n                                   HitOrMiss == 1)"
  },
  {
    "objectID": "05-wrangling-2.html#counting-observations-using-count",
    "href": "05-wrangling-2.html#counting-observations-using-count",
    "title": "5  Data wrangling 2: Filter and summarise",
    "section": "\n5.4 Counting observations using count()\n",
    "text": "5.4 Counting observations using count()\n\nAs we work from wrangling data towards analysing your data to produce numerical summaries, we can start introducing different ways of summarising your data set.\nIn it’s simplest sense, we can look at different ways of counting your observations. Often, it is helpful to know how many observations you have, either in total, or broken down by groups. This can help you spot if something has gone wrong in a calculation, e.g., if you have done something with the code and your mean or median is only being calculated using a subset of the values you intended. Alternatively, it can be useful for reporting descriptive statistics, such as how many participants were in your study or how many people were in each group.\n\n5.4.1 Activity 9 - Counting observations\nTo count observations, you have the function count(). Without any additional arguments, you can use the function to report how many observations are in your data set:\n\ncount(pong_data_filter)\n\n\n\n\nn\n\n\n4592\n\n\n\n\n\nThis corresponds nicely with the number of observations you can see in the data environment window and from when we have used glimpse() for a summary of the object.\nYou can then add one or more variables to the function to count the number of observations within each variable and across the combination of variables when you supply two or more. For example, we could count the number of observations within BackgroundColor:\n\ncount(pong_data_filter,\n      BackgroundColor) # count observations within variable 1\n\nAnd it would give the answer of:\n\n\n\n\n\nBackgroundColor\nn\n\n\n\nblue\n2304\n\n\nred\n2304\n\n\n\n\n\n\nWe can see there are an equal number of blue and red backgrounds across all the observations.\n\n\n\n\n\n\nTry this\n\n\n\nOne way of sense checking your data and making sure there is not a sneaky error is checking how many observations there are per unique participant and ensuring that matches up with what you understand about the study.\nUse the count() function on the pong_data_filter object to answer the following questions about the data:\n\nHow many observations do we have for each unique Participant in the data? \nHitOrMiss codes for whether the Participant hit or missed the ball in the trial. If you count the number of HitOrMiss per Participant, participant number 3 made  hits and  misses.\n\n\n# count observations per Participant\ncount(pong_data_filter,\n      ?)\n\n# count observations of HitOrMiss per Participant\n# Hint: you can add multiple variables with a comma. \ncount(pong_data_filter,\n      ?)\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nTo answer question 1, we only need to add Participant as an argument after the data pong_data_filter.\n\n# count observations per Participant\ncount(pong_data_filter,\n      Participant)\n\nTo answer question 2, we need both Participant and HitOrMiss as arguments after the data pong_data_filter, as we want the number of hits and misses per participant.\n\n# count observations of HitOrMiss per Participant\ncount(pong_data_filter,\n      Participant,\n      HitOrMiss)"
  },
  {
    "objectID": "05-wrangling-2.html#summarising-data-using-summarise-and-group_by",
    "href": "05-wrangling-2.html#summarising-data-using-summarise-and-group_by",
    "title": "5  Data wrangling 2: Filter and summarise",
    "section": "\n5.5 Summarising data using summarise() and group_by()\n",
    "text": "5.5 Summarising data using summarise() and group_by()\n\nCounting data is useful, but it might not be the only way of summarising data that you want. A more flexible function is summarise() which you can use to calculate summary statistics across your whole data frame, or grouped by additional variables.\n\n5.5.1 Activity 10 - Summarising all the observations\nTo start with something familiar, we can use summarise() to count observations. The function works in a similar format to mutate() where you enter a variable name and tell R what function you want applying to the data frame or variable. For example, we can use the n() function to calculate the number of observations in pong_data_filter:\n\nN_observations &lt;- summarise(pong_data_filter,\n                            N_observations = n())\n\nTo break down the code:\n\nWe create a new object N_observations by applying the summarise() function to pong_data_filter.\nWe create a new variable name called N_observations, add an equals for what that new variable represents, and add our desired function n(). You do not need to add any further arguments, it calculates the number of observations in the object you give it.\n\nThis creates a new object as a data frame with 1 observation and 1 column to produce a single number:\n\n\n\n\n\nN_observations\n\n\n4592\n\n\n\n\n\nReassuringly, this is exactly the same as we received for count(). If you only want the number of observations, then count() will be more efficient. However, if you want to produce the number of observations in addition to other summary statistics, then summarise() is going to be more useful.\nTo demonstrate the flexibility of summarise(), we can add another summary statistic for the mean hit rate. When binary outcomes like a hit or a miss are coded as 0 and 1, taking the mean provides the proportion of hits (or whatever is coded as 1).\n\nsummarise(pong_data_filter,\n          N_observations = n(),\n          hit_proportion = mean(HitOrMiss, \n                                na.rm = TRUE))\n\n\n\n\nN_observations\nhit_proportion\n\n\n4592\n0.6879355\n\n\n\n\n\nIn this example, we have not saved the summarise() output to a new object, just printed it’s result. We can see we get the number of observations as before, but we also get the mean value for the hit rate. The proportion of hits across all observations was 0.688 or 68.8%.\n\n\n\n\n\n\nWhy is my mean NA?\n\n\n\nWhen you use the mean() function, you might find the result is NA. This is likely due to the presence of an NA or missing value in your variable. NAs are contagious as if you try and calculate the mean of a set of numbers containing one or more NA values, the overall mean will also be an NA.\nSo, the mean() function has an additional argument na.rm = TRUE which tells R what to do if there are missing values. The job of na.rm is to say whether to remove (rm) the NAs (na.rm = TRUE) or not (na.rm = FALSE).\nThis data set has no missing values but we showed you how to use it here so you can try to remember it exists in future. You do not need to use it all the time and you should think carefully about whether you should ignore NAs, but the option is there if you need it.\n\n\n\n\n\n\n\n\nTry this\n\n\n\nUsing what you learnt above, apply the summarise() function to calculate the mean value of JudgedSpeed using the pong_data_filter object and fill in the blanks below. Remember, calculating the mean of a binary outcome of 0s and 1s tells you the proportion, so the mean here would be the proportion of responses judged to be fast.\nRounded to 3 decimal places, the mean proportion of fast responses is  or rounded to 1 decimal place %.\n\n# mean value of JudgedSpeed for the proportion\nsummarise(pong_data_filter,\n          ?)\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nYou only needed to add one argument to calculate the mean of the JudgedSpeed variable. We called the new variable fast_proportion, but this was not important for the answer. Just make sure you call your variables something sensible, so you could understand what it means later.\n\n# mean value of JudgedSpeed for the proportion\nsummarise(pong_data_filter,\n          fast_proportion = mean(JudgedSpeed))\n\n\n\n\n\n5.5.2 Activity 11 - Grouping your summary statistics\nSummarising your whole data set is great, but there will often be times you want separate summary statistics for different groups in your data. The group_by() function takes an existing data frame or tibble and creates a grouped data frame. As a data frame, this does not look much different, but it adds a kind of hidden property which functions like summarise() detects and uses.\nAs an example, let us see how the summary statistics compare between each level of judged speed. For the initial step, we need to apply the group_by() function:\n\n# Group pong_data_filter by JudgedSpeedLabel\npong_data_grouped &lt;- group_by(pong_data_filter,\n                              JudgedSpeedLabel)\n\nTo break down the code:\n\nWe create a new object pong_data_grouped by applying the group_by() function to pong_data_filter.\nWe add one or more variables we want to group any summary statistics by. In this case, we group by JudgedSpeedLabel so we will get separate values for fast and slow.\n\nIf you open pong_data_grouped as a tab, it does not look any different. Remember, group_by() adds a kind of hidden property. To check this, we can run the str() function on the data object which will show us the structure of an object:\n\n# Show the structure of the data object pong_data_grouped\nstr(pong_data_grouped)\n\ngropd_df [4,592 × 9] (S3: grouped_df/tbl_df/tbl/data.frame)\n $ Participant     : num [1:4592] 1 1 1 1 1 1 1 1 1 1 ...\n $ JudgedSpeed     : num [1:4592] 0 1 0 1 0 1 0 0 0 1 ...\n $ PaddleLength    : num [1:4592] 250 50 250 250 50 250 50 250 50 50 ...\n $ BallSpeed       : num [1:4592] 3 4 3 7 5 6 2 4 4 7 ...\n $ TrialNumber     : num [1:4592] 2 3 4 5 6 7 8 9 10 11 ...\n $ BackgroundColor : chr [1:4592] \"blue\" \"red\" \"red\" \"blue\" ...\n $ HitOrMiss       : num [1:4592] 1 0 1 1 1 1 1 1 1 0 ...\n $ BlockNumber     : num [1:4592] 1 1 1 1 1 1 1 1 1 1 ...\n $ JudgedSpeedLabel: chr [1:4592] \"Slow\" \"Fast\" \"Slow\" \"Fast\" ...\n - attr(*, \"groups\")= tibble [2 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ JudgedSpeedLabel: chr [1:2] \"Fast\" \"Slow\"\n  ..$ .rows           : list&lt;int&gt; [1:2] \n  .. ..$ : int [1:2512] 2 4 6 10 11 13 15 17 19 22 ...\n  .. ..$ : int [1:2080] 1 3 5 7 8 9 12 14 16 18 ...\n  .. ..@ ptype: int(0) \n  ..- attr(*, \".drop\")= logi TRUE\n\n\nThe two key elements here are in the first line (gropd_df [4,592 × 9] (S3: grouped_df/tbl_df/tbl/data.frame)) and below the variables (- attr(*, \"groups\")... ..$ JudgedSpeedLabel: chr [1:2] \"Fast\" \"Slow\"). The first line confirms we now have a grouped data frame and the two lines below the variables show the values we group by.\nThe next step is applying the summarise() function as before. Here, we will calculate the total and mean number of hits by whether the participants judged the speed to be fast or slow:\n\n# Sum hits for the number of hits \n# Mean hits for the proportion of hits\nhits_by_judgedspeed &lt;- summarise(pong_data_grouped,\n                                 sum_hits = sum(HitOrMiss),\n                                 prop_hits = mean(HitOrMiss))\n\nCalling the object shows we now get two rows per summary statistic:\n\nhits_by_judgedspeed\n\n\n\n\nJudgedSpeedLabel\nsum_hits\nprop_hits\n\n\n\nFast\n1651\n0.6572452\n\n\nSlow\n1508\n0.7250000\n\n\n\n\n\n\nAlthough there were more hits in the fast judged speed, the proportion of hits to misses was lower. Participants hit .657 (65.7%) of trials they judged to be fast but .725 (72.5%) of trials they judged to be slow.\n\n\n\n\n\n\nTry this\n\n\n\nUsing what you learnt above, apply the group_by() and summarise() functions to calculate the sum and mean value of HitOrMiss depending on whether BackgroundColor was blue or red. In your group_by() object, make sure you use the pong_data_filter object. After writing the code and checking the new object, answer the following questions:\n\nRounded to 2 decimal places, the mean proportion of hits to the blue background was  or rounded to 0 decimal places %.\nRounded to 3 decimal places, the mean proportion of hits to the red background was  or rounded to 1 decimal place %.\n\n\n# Group pong_data_filter by BackgroundColor\npong_data_background &lt;- ?\n\n# Sum hits for the number of hits \n# Mean hits for the proportion of hits\nhits_by_background &lt;- ?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThere are two steps here to follow the previous example. The main difference is using BackgroundColor in group_by(), and then the summarise() element is largely the same.\n\n# Group pong_data_filter by BackgroundColor\npong_data_background &lt;- group_by(pong_data_filter,\n                                 BackgroundColor)\n\n# Sum hits for the number of hits \n# Mean hits for the proportion of hits\nhits_by_background &lt;- summarise(pong_data_background,\n                                 sum_hits = sum(HitOrMiss),\n                                 prop_hits = mean(HitOrMiss))\n\n\n\n\n\n\n\n\n\n\nR Markdown tip of the chapter: Create pretty tables\n\n\n\nAfter we introduced you to R Markdown to create reproducible documents in Chapter 2, we are going to add a tip in every chapter to demonstrate extra functionality.\nR Markdown is great for embedding plots and statistics in reproducible documents, but tables can be a little tricky. If you only call objects like hits_by_background, the output does not look super professional and it is not consistent with APA formatting guidelines.\nThere are a few options available to you. One of the packages that helps create R Markdown - knitr - can create tables from objects you create. There is a function called kable() which can create tables with no further arguments, but you will need to edit the object to make sure it has headers and labels consistent with APA. The following code creates a simple table if you have knitr installed:\n\nknitr::kable(hits_by_judgedspeed)\n\nYou will need to knit your document to see what it looks like, but it should look similar to Figure 5.1. The row labels are fine, but you would need to tidy up the headers and round prop_hits to three decimals (see the function round()).\n\n\n\n\nFigure 5.1: Example of using kable() to create tables in R Markdown.\n\n\n\nSee The R Markdown Cookbook for a guide on creating tables using kable().\nAlternatively, there is a package called gt which can also create tables with plenty of formatting options. See their documentation https://gt.rstudio.com/ online for further information.\n\n\n\n5.5.3 Ungrouping data\nFor a final word of warning, there is an additional function which removes a group from a data frame. For example, if you wanted to use objects like pong_data_grouped for additional wrangling, visualisation, or analysis, it can create problems if you leave the group property. If you only use these objects to create summary tables like hits_by_judgedspeed, then there is no issue.\nIt is good practice to ungroup the data before performing another function using the ungroup() function:\n\npong_data_grouped &lt;- ungroup(pong_data_grouped)\n\nIf you run str(pong_data_grouped) again, you will see we removed the grouping property. Remember, you only need to apply this if you are using the object in further steps. We will demonstrate in the next chapter how you can add this in a more streamlined way."
  },
  {
    "objectID": "05-wrangling-2.html#test-yourself",
    "href": "05-wrangling-2.html#test-yourself",
    "title": "5  Data wrangling 2: Filter and summarise",
    "section": "\n5.6 Test yourself",
    "text": "5.6 Test yourself\nTo end the chapter, we have some knowledge check questions to test your understanding of the concepts we covered in the chapter. We then have some error mode tasks to see if you can find the solution to some common errors in the concepts we covered in this chapter.\n\n5.6.1 Knowledge check\nQuestion 1. What type of data would these most likely be:\n\nMale = \nInteger\nDouble\nCharacter\n7.15 = \nDouble\nCharacter\nInteger\n137 = \nDouble\nInteger\nCharacter\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nThere are several different types of data as well as different levels of measurement and it takes a while to recognise the nuanced differences. It is important to try to remember which is which because you can only do certain types of analyses on certain types of data and certain types of measurements. For instance, you cannot take the average of characters or categorical data. Likewise, you can do any maths on double data, just like you can on interval and ratio data. Integer data is funny in that sometimes it is ordinal and sometimes it is interval, sometimes you should take the median, sometimes you should take the mean. The main point is to always know what type of data you are using and to think about what you can and cannot do with them.\nNote: in the last answer, 137 could also be double as it is not clear if it could take a decimal or not.\n\n\n\nQuestion 2. Which of the dplyr functions would you use to count the number of observations in your data set or variables?\n\nselectfiltercountmutategroup_by\n\nQuestion 3. Which of the dplyr functions would you use to calculate the mean of a column?\n\nfiltergroup_bymutatesummariseselect\n\nQuestion 4. Which of the dplyr functions would you use to remove certain observations (e.g., remove all males)?\n\nselectcountsummarisemutatefiltergroup_by\n\nQuestion 5. Which of the dplyr functions would you use to subset summary statistics by?\n\nfiltercountmutatesummarisegroup_byselect\n\n\n5.6.2 Error mode\nThe following questions are designed to introduce you to making and fixing errors. For this topic, we focus on data wrangling using the functions filter(), count(), and group_by() and summarise(). Remember to keep a note of what kind of error messages you receive and how you fixed them, so you have a bank of solutions when you tackle errors independently.\nCreate and save a new R Markdown file for these activities. Delete the example code, so your file is blank from line 10. Create a new code chunk to load tidyverse and the data file:\n\n# Load the tidyverse package below\nlibrary(tidyverse)\n\n# Load the data file\npong_data &lt;- read_csv(\"data/witt_2018.csv\")\n\nBelow, we have several variations of a code chunk error or misspecification. Copy and paste them into your R Markdown file below the code chunk to load tidyverse and the data. Once you have copied the activities, click knit and look at the error message you receive. See if you can fix the error and get it working before checking the answer.\nQuestion 6. Copy the following code chunk into your R Markdown file and press knit. We want to filter data to only include a paddle length of 50. You should receive the error starting with Error in \"filter()\" ! We detected a named input.\n\n```{r}\n# filter pong_data to retain PaddleLength of 50\npong_data_filter &lt;- filter(pong_data,\n                           PaddleLength = 50)\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nIn the code, we use a single equals sign (=) rather than the Boolean operator a double equals sign (==). With a single equals, R is interpreting this as “PaddleLength is equal to 50” like you were saving an object or setting an argument. The error message below line two tries to help and suggests you might need to include == instead.\n\n# filter pong_data to retain PaddleLength of 50\npong_data_filter &lt;- filter(pong_data,\n                           PaddleLength == 50)\n\n\n\n\nQuestion 7. Copy the following code chunk into your R Markdown file and press knit. We want to count the number of trials per block (BlockNumber). This…works, but if you look at the output, have we counted the number of trials?\n```{r}\n# Count block numbers from pong_data\ncount_blocknumbers &lt;- summarise(pong_data,\n                                N_blocks = sum(BlockNumber))\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nThe mistake is using sum() to count the number of trials per block. sum() would only work when you have 0s and 1s. Here, it just adds up all the numbers, totalling 29952. There are two options here. In every other scenario, you need to either count():\n\n# Count block numbers from pong_data\ncount_blocknumbers &lt;- count(pong_data,\n                            BlockNumber)\n\nor group_by() and `n():\n\n# Group by block number\ngroup_blocks &lt;- group_by(pong_data,\n                         BlockNumber)\n# Then calculate the number of trials per block\ncount_blocknumbers &lt;- summarise(group_blocks,\n                                N_blocks = n())\n\n\n\n\nQuestion 8. Copy the following code chunk into your R Markdown file and press knit. Here, we want the proportion of fast judgements per paddle length by taking the mean of JudgedSpeed. This code… works, but do we have a proportion of fast judgements per paddle length?\n```{r}\n# Mean judged speed for the proportion of fast judgements\nhits_by_background &lt;- summarise(pong_data,\n                                prop_fast = mean(JudgedSpeed))\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nWe wanted the mean proportion of fast judgements, but we forgot to add a group by! We only got one value, so we need to add an initial step to group the responses by PaddleLength first, before we then calculate the mean proportion.\n\n# Group pong_data by paddle length\npong_data_paddle &lt;- group_by(pong_data,\n                                 PaddleLength)\n\n# Mean judged speed for the proportion of fast judgements\nhits_by_background &lt;- summarise(pong_data_paddle,\n                                 prop_fast = mean(JudgedSpeed))"
  },
  {
    "objectID": "05-wrangling-2.html#words-from-this-chapter",
    "href": "05-wrangling-2.html#words-from-this-chapter",
    "title": "5  Data wrangling 2: Filter and summarise",
    "section": "\n5.7 Words from this Chapter",
    "text": "5.7 Words from this Chapter\nBelow you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the PsyTeachR Glossary. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter.\n\n\n\n\nterm\ndefinition\n\n\n\ncharacter\nA data type representing strings of text.\n\n\ncount()\nCount the observations in your data set, or the number of observations in one or more variables.\n\n\ndata-frame\nA container data type for storing tabular data.\n\n\ndouble\nA data type representing a real decimal number\n\n\nfactor\nA data type where a specific set of values are stored with labels; An explanatory variable manipulated by the experimenter\n\n\nfilter()\nThe ability to subset a data frame to keep all observations/rows that satisfy one or more conditions.\n\n\nfunction\nA named section of code that can be reused.\n\n\ngroup_by()\nTake an existing data frame or tibble and convert it to a grouped data frame.\n\n\ninteger\nA data type representing whole numbers.\n\n\nnumeric\nA data type representing a real decimal number or integer.\n\n\nsummarise()\nCreates a new data frame to summarise all the observations you provide. You can also group by an additional variable to create separate summary statistics.\n\n\ntibble\nA container for tabular data with some different properties to a data frame\n\n\nungroup()\nRemove a grouping property from a grouped data frame or tibble."
  },
  {
    "objectID": "05-wrangling-2.html#end-of-chapter",
    "href": "05-wrangling-2.html#end-of-chapter",
    "title": "5  Data wrangling 2: Filter and summarise",
    "section": "\n5.8 End of chapter",
    "text": "5.8 End of chapter\nBrilliant work again! You have another handful of functions added to your data wrangling toolkit and we are almost ready to tackle more advanced plotting techniques and inferential statistics.\nIn the next chapter, we finish the key data wrangling functions. For example, showing you how you can pipe together multiple functions to streamline your code. We will also demonstrate how to pivot your data wider from long form where there are multiple observations per participant to wide form where there is one row per participant, and vice versa.\n\n\n\n\nWitt, J. K., Tenhundfeld, N. L., & Tymoski, M. J. (2018). Is there a chastity belt on perception? Psychological Science, 29(1), 139–146."
  },
  {
    "objectID": "06-wrangling-3.html#chapter-preparation",
    "href": "06-wrangling-3.html#chapter-preparation",
    "title": "6  Data Wrangling 3: Pivots and Pipes",
    "section": "\n6.1 Chapter preparation",
    "text": "6.1 Chapter preparation\n\n6.1.1 Introduction to the data set\nFor this chapter, we are using open data from Alter et al. (2024). The abstract of their article is:\n\nThe biggest difference in statistical training from previous decades is the increased use of software. However, little research examines how software impacts learning statistics. Assessing the value of software to statistical learning demands appropriate, valid, and reliable measures. The present study expands the arsenal of tools by reporting on the psychometric properties of the Value of Software to Statistical Learning (VSSL) scale in an undergraduate student sample. We propose a brief measure with strong psychometric support to assess students’ perceived value of software in an educational setting. We provide data from a course using SPSS, given its wide use and popularity in the social sciences. However, the VSSL is adaptable to any statistical software, and we provide instructions for customizing it to suit alternative packages. Recommendations for administering, scoring, and interpreting the VSSL are provided to aid statistics instructors and education researchers understand how software influences students’ statistical learning.\n\nTo summarise, they developed a new scale to measure students’ perceived value of software to learning statistics - Value of Software to Statistical Learning (VSSL). The authors wanted to develop this scale in a way that could be adapted to different software, from SPSS in their article (which some of you may have used in the past), to perhaps R in future. Alongside data from their new scale, they collected data from other scales measuring a similar kind of construct (e.g., Students’ Attitudes toward Statistics and Technology) and related constructs (e.g., Quantitative Attitudes).\nIn this chapter, we will wrangle their data to reinforce skills from Chapter 4 and 5. Scale data is extremely common to work with in psychology and there is a high likelihood you will use one or more in your dissertation or future careers. After recapping skills from the past two chapters on this new data set, we will add more data wrangling functions to your toolkit.\n\n6.1.2 Organising your files and project for the chapter\nBefore we can get started, you need to organise your files and project for the chapter, so your working directory is in order.\n\nIn your folder for research methods and the book ResearchMethods1_2/Quant_Fundamentals, you should have a folder from chapter 4 called Chapter_04_06_datawrangling where you created an R Project.\nCreate a new R Markdown document and give it a sensible title describing the chapter, such as 06 Data Wrangling 3. Delete everything below line 10 so you have a blank file to work with and save the file in your Chapter_04_06_datawrangling folder.\nWe are working with a new data set separated into two files. The links are data file one (Alter_2024_demographics.csv) and data file two (Alter_2024_scales.csv). Right click the links and select “save link as”, or clicking the links will save the files to your Downloads. Make sure that both files are saved as “.csv”. Save or copy the file to your data/ folder within Chapter_04_06_datawrangling.\n\nYou are now ready to start working on the chapter!"
  },
  {
    "objectID": "06-wrangling-3.html#recapping-all-the-previous-dplyr-functions",
    "href": "06-wrangling-3.html#recapping-all-the-previous-dplyr-functions",
    "title": "6  Data Wrangling 3: Pivots and Pipes",
    "section": "\n6.2 Recapping all the previous dplyr functions",
    "text": "6.2 Recapping all the previous dplyr functions\nIn this first section, we will prepare the data for some analysis later by practicing the data wrangling skills you learnt in Chapters 4 and 5 on this new data set.\n\n6.2.1 Activity 1 - Load tidyverse and read the data files\nAs the first activity, load tidyverse and read the two data files. As a prompt, save the data files to these object names to be consistent with the activities below, but you can check your answer below if you are stuck.\n\n# Load the tidyverse package below\n?\n\n# Load the data files\n# This should be the Alter_2024_demographics.csv file \ndemog &lt;- ?\n\n# This should be the Alter_2024_scales.csv file \nscales &lt;- ?\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# Load the tidyverse package below\nlibrary(tidyverse)\n\n# Load the data files\n# This should be the Alter_2024_demographics.csv file \ndemog &lt;- read_csv(\"data/Alter_2024_demographics.csv\")\n\n# This should be the Alter_2024_scales.csv file \nscales &lt;- read_csv(\"data/Alter_2024_scales.csv\")\n\n\n\n\n\n6.2.2 Activity 2 - Explore demog and scales\n\nThe data from Alter et al. (2024) is split into two data files. In demog, we have the participant ID (StudentIDE) and several demographic variables. The columns (variables) we have in the data set are:\n\n\n\n\n\n\n\nVariable\nType\nDescription\n\n\n\nStudentIDE\ndouble\nParticipant number\n\n\nGenderE\ndouble\nGender: 1 = Female, 2 = Male, 3 = Non-Binary\n\n\nRaceEthE\ndouble\nRace: 1 = Black/African American, 2 = Hispanic/Other Latinx, 3 = White, 4 = Multiracial, 5 = Asian/Pacific Islander, 6 = Native American/Alaska Native, 7 = South/Central American\n\n\nGradeE\ncharacter\nExpected grade: 1 = A, 2 = B, 3 = C, 4 = D, 5 = F\n\n\nStuStaE\ncharacter\nStudent status: 1 = Freshman, 2 = Sophomore, 3 = Junior, 4 = Senior or Higher\n\n\nGPAE\ncharacter\nExpected Grade Point Average (GPA)\n\n\nMajorE\ncharacter\nDegree major\n\n\nAgeE\ndouble\nAge in years\n\n\n\nIn scales, we then have the participant ID (StudentIDE) and all the individual scale items. The columns (variables) we have in the data set are:\n\n\n\n\n\n\n\nVariable\nType\nDescription\n\n\n\nStudentIDE\ndouble\nParticipant number\n\n\nMA1E to MA8E\ndouble\n\nEnjoyment of Mathematics and statistics, not analysed in this study.\n\n\nQANX1E to QANX4E\ndouble\n\nQuantitative anxiety: four items scored on a 5-point Likert scale ranging from 1 (Not at all Anxious) to 5 (Extremely Anxious)\n\n\nQINFL1E to QINFL7E\ndouble\n\nQuantitative attitudes: seven items scored on a 5-point Likert scale ranging from 1 (Strongly Disagree) to 5 (Strongly Agree)\n\n\nQSF1E to QSF4E\ndouble\n\nStudy motivation, not analysed in this study.\n\n\nQHIND1E to QHIND5E\ndouble\n\nQuantitative hindrances: five items scored on a 5-point Likert scale ranging from 1 (Strongly Disagree) to 5 (Strongly Agree)\n\n\nQSC1E to QSC4E\ndouble\n\nMathematical self-efficacy, not analysed in this study.\n\n\nQSE1E to QSE6E\ndouble\n\nMathematical ability, not analysed in this study.\n\n\nSPSS1E to SPSS10E\ndouble\n\nVSSL scale on SPSS: 10 items scored on a 5-point Likert scale ranging from 1 (Never True) to 5 (Always True)\n\n\n\n\n\n\n\n\n\nTry this\n\n\n\nNow we have introduced the two data sets, explore them using different methods we introduced. For example, opening the data objects as a tab to scroll around, explore with glimpse(), or even try plotting some of the variables to see what they look like using visualisation skills from Chapter 3.\n\n\n\n6.2.3 Activity 3 - Joining the two data sets using inner_join()\n\nAt the moment, we have two separate data sets, but it will make things easier to join them together so we have both demographic information and the participants’ responses to the scales.\nWe did not recap joining data sets in the last chapter, so you might need to revisit Chapter 4 - Joining two data frames - for a recap.\nCreate a new data object called full_data and see if you can spot a common variable between both data sets that you can use an identifier.\n\n# join demog and scales by a common identifier \nfull_data &lt;- ?\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# join demog and scales by a common identifier \nfull_data &lt;- inner_join(x = demog,\n                        y = scales,\n                        by = \"StudentIDE\")\n\n\n\n\n\n6.2.4 Activity 4 - Selecting a range of columns using select()\n\nThere are some scales in the data that Alter et al. (2024) did not analyse, so we can get rid of them to declutter. Furthermore, the purpose of their study was to validate the new VSSL scale and they found some items did not make the cut. Create a new object called full_data_select and retain the following variables from your new full_data object:\n\nStudentIDE\nGenderE\nRaceEthE\nAgeE\nQANX1E to QINFL7E\nQHIND1E to QHIND5E\nSPSS1E, SPSS4E, SPSS5E, SPSS6E, SPSS7E, SPSS8E, SPSS9E.\n\nRemember: you can select variables either by retaining the variables you want to keep, or removing the variables you want to remove. You should have 27 columns remaining.\n\n# select the key variables listed above\nfull_data_select &lt;- ?\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk if you chose to retain:\n\n# select the key variables listed above\nfull_data_select &lt;- select(full_data,\n                           StudentIDE, \n                           GenderE,\n                           RaceEthE, \n                           AgeE, \n                           QANX1E:QINFL7E, \n                           QHIND1E:QHIND5E, \n                           SPSS1E, SPSS4E, SPSS5E, SPSS6E, SPSS7E, SPSS8E, SPSS9E)\n\nor the following if you chose to remove:\n\n# select the key variables listed above\nfull_data_select &lt;- select(full_data,\n                           -GradeE, \n                           -StuStaE, \n                           -GPAE, \n                           -MajorE, \n                           -MA1E:-MA8E,\n                           -QSF1E:-QSF4E,\n                           -QSC1E:-QSE6E,\n                           -SPSS2E, -SPSS3E, -SPSS10E)\n\nThere are a similar number to retain or remove, so there is no real time saving one way or the other.\n\n\n\n\n6.2.5 Activity 5 - Reorder observations using arrange()\n\nFor a quick check of the data, order the values of AgeE using the object full_data_select and answer the following questions:\n\nThe youngest participant is  years old.\nThe old participant is  years old.\n\n\n# youngest participants\n?\n\n# oldest participants\n?\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# youngest participants\narrange(full_data_select, \n        AgeE)\n\n# oldest participants\narrange(full_data_select, \n        desc(AgeE))\n\n\n\n\n\n6.2.6 Activity 6 - Modifying or creating variables using mutate()\n\nAt the moment, we have categorical variables such gender (GenderE) and race (RaceEthE) which have numerical codes. When it comes to summarising or plotting later, this would not be the easiest to understand.\nUsing the full_data_select object, use mutate() to recode these two existing variables and replace the numbers with labels and create a new object full_data_mutate. As a reminder of what each number refers to:\nGenderE\n\n1 = Female\n2 = Male\n3 = Non-binary\n\nRaceEthE\n\n1 = Black/African American\n2 = Hispanic/Other Latinx\n3 = White\n4 = Multiracial\n5 = Asian/Pacific Islander\n6 = Native American/Alaska Native\n7 = South/Central American\n\n\n# recode gender and race to labels\nfull_data_mutate &lt;- ?\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk (some lines wrap due to being quite long, but it will look right if you copy and paste it to your RStudio):\n\n# recode gender and race to labels\nfull_data_mutate &lt;- mutate(full_data_select,\n                           GenderE = case_match(GenderE,\n                                                1 ~ \"Female\",\n                                                2 ~ \"Male\",\n                                                3 ~ \"Non-binary\"),\n                           RaceEthE = case_match(RaceEthE,\n                                                 1 ~ \"Black/African American\",\n                                                 2 ~ \"Hispanic/Other Latinx\",\n                                                 3 ~ \"White\",\n                                                 4 ~ \"Multiracial\",\n                                                 5 ~ \"Asian/Pacific Islander\",\n                                                 6 ~ \"Native American/Alaska Native\",\n                                                 7 ~ \"South/Central American\"))\n\n\n\n\n\n6.2.6.1 Bonus activity - reverse coding scales\nFor a bonus activity, we want to demonstrate a super common task when working with scale data. Often, scales will reverse code some items to express the same idea in opposite ways: one positive and one negative. If the scale is measuring a consistent construct, the responses should be more positive in one and more negative in the other. If you analysed this immediately, you would get two opposing answers, so a key data wrangling step is reverse coding some items so all the numbers mean a similar thing.\nIn Alter et al. (2024), the three VSSL items we removed were the ones which needed to be reverse coded, but it is a good excuse to practice. Using the scales object, what function could you use to recode existing responses? Hint: we want to recode 1 to 5, 2 to 4, etc.\n\n# recode items 2, 3, and 10\nscales_reverse &lt;- mutate(scales,\n                         SPSS2_R = ?,\n                         SPSS3_R = ?,\n                         SPSS10_R = ?)\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nBased on what we covered before, we expect you will have completed a perfectly accurate but long process of recoding each item one by one:\n\n# recode items 2, 3, and 10\nscales_reverse &lt;- mutate(scales,\n                         SPSS2_R = case_match(SPSS2E,\n                                              1 ~ 5,\n                                              2 ~ 4,\n                                              3 ~ 3,\n                                              4 ~ 2,\n                                              5 ~ 1),\n                         SPSS3_R = case_match(SPSS3E,\n                                              1 ~ 5,\n                                              2 ~ 4,\n                                              3 ~ 3,\n                                              4 ~ 2,\n                                              5 ~ 1),\n                         SPSS10_R = case_match(SPSS10E,\n                                              1 ~ 5,\n                                              2 ~ 4,\n                                              3 ~ 3,\n                                              4 ~ 2,\n                                              5 ~ 1))\n\nHowever, there is a neat shortcut where you can subtract the response from the biggest scale unit plus 1. For example, if you have a 5-point scale, you would subtract the response from 6, if you have a 7-point scale, from 8 etc.\n\n# Reverse code by subtracting responses from 6\nscales_reverse &lt;- mutate(scales,\n                         SPSS2_R = 6 - SPSS2E,\n                         SPSS3_R = 6 - SPSS3E,\n                         SPSS10_R = 6 - SPSS10E)\n\nExplore your new data object to see what the new reverse coded variables look like.\n\n\n\n\n6.2.7 Activity 7 - Removing or retaining observations using filter()\n\nTo practice filtering data to retain specific participants, imagine we wanted to focus on two specific groups of people.\nFirst, we just want to explore the data of “Non-binary” participants. Second, we want to explore the data of “Female”, “Asian/Pacific Islander” participants. Use filter() on the full_data_mutate object to create two objects: NB_participants and F_asian_participants.\n\n# non-binary participants\nNB_participants &lt;- ?\n\n# female, Asian/Pacific Islander participants\nF_asian_participants &lt;- ?\n\nAfter creating the objects, answer the following questions:\n\nWe have  non-binary participant(s) in the data set.\nWe have  female, Asian/Pacific Islander participant(s) in the data set.\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# non-binary participants\nNB_participants &lt;- filter(full_data_mutate,\n                          GenderE == \"Non-binary\")\n\n# female, Asian/Pacific Islander participants\nF_asian_participants &lt;- filter(full_data_mutate,\n                          GenderE == \"Female\",\n                          RaceEthE == \"Asian/Pacific Islander\")\n\n\n\n\n\n6.2.7.1 Bonus activity - Removing NAs with drop_na()\n\nOne concept we will spend more time on in Chapter 11 - Screening Data - is removing participants who do not provide an answer. We delve more into the decision making in the course materials, but there is a handy function in tidyr called drop_na(). You could do this using filter, but the standalone function streamlines things. If you run the function on your whole data set, it will remove observations with one or more NAs in all their variables:\n\n# remove observations with any NAs\nno_NAs &lt;- drop_na(full_data_mutate)\n\nHowever, often you do not want to remove all variables with an NA as there might be valuable information elsewhere. You can add one or more variables to ask drop_na() to only remove NAs present in those specific variables:\n\n# remove observations with any NAs\nage_NAs &lt;- drop_na(full_data_mutate,\n                   AgeE)\n\nThis impacts the number of participants we remove as we had 171 when we removed all NAs, but 179 when we only removed NAs in age.\n\n6.2.8 Activity 8 - Summarising data using count() and summarise()\n\n\n6.2.8.1 Counting observations\nAs the final recap activity, it is time to calculate some summary statistics to understand our data set. First, use count() on the full_data_mutate object to answer the following questions:\n\nHow many observations do we have of each gender?  males,  females, and  non-binary.\nHow many observations do we have of each race?  white,  Black/African American, and  NA with missing data.\n\n\n# count each group in GenderE\n?\n\n# count each group in RaceE\n?\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# count each group in GenderE\ncount(full_data_mutate,\n      GenderE)\n\n# count each group in RaceE\ncount(full_data_mutate,\n      RaceEthE)\n\n\n\n\n\n6.2.8.2 Summarising observations\nOne useful demographic summary is the mean and standard deviation (SD) of participant ages. We have covered the function for the mean (mean()) several times, but a key part of coding is knowing what you want, but not the function to do it. So, in the process of the next answer, try and find the function for the standard deviation on your own. If you are really stuck though, you can see the hint below.\n\n\n\n\n\n\nGive me a hint for the SD function\n\n\n\n\n\n\n# Function for the standard deviation\nsd()\n\n\n\n\n\n# Mean and SD age\nmean_age &lt;- summarise(full_data_mutate,\n                      mean_age = ?,\n                      SD_age = ?)\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# Mean and SD age\nmean_age &lt;- summarise(full_data_mutate,\n                      mean_age = mean(AgeE, na.rm = TRUE),\n                      SD_age = sd(AgeE, na.rm = TRUE))\n\nRemember, if there are NAs present in the data like this, you need to add na.rm = TRUE or handle NAs prior to applying the function.\n\n\n\n\n\n\n\n\n\nError mode\n\n\n\nAs a transition point to restructuring data, imagine we wanted to calculate the sum score of the items to calculate a number for the whole scale per participant. Based on how we have used mutate() or summarise() before, you might try:\n\nsum_VSSL &lt;- mutate(full_data_mutate,\n                      VSSL = sum(c(SPSS1E, SPSS4E, SPSS5E, SPSS6E, SPSS7E, SPSS8E, SPSS9E), na.rm = TRUE))\n\nHowever, if you look at the object, the VSSL column is the same for every participant (4413) which does not look right? This is due to how functions work within mutate(). It is essentially applying the sum() function to all the columns first and adding them together, rather than summing the values of each column within each participant.\nWe can fix this problem by restructuring the data."
  },
  {
    "objectID": "06-wrangling-3.html#restructuring-data-using-pivot_longer-and-pivot_wider",
    "href": "06-wrangling-3.html#restructuring-data-using-pivot_longer-and-pivot_wider",
    "title": "6  Data Wrangling 3: Pivots and Pipes",
    "section": "\n6.3 Restructuring data using pivot_longer() and pivot_wider()\n",
    "text": "6.3 Restructuring data using pivot_longer() and pivot_wider()\n\nApart from joining two data sets, we have pretty much just worked with the data files as they come to us where each row represents one observation/participant and each column represents one variable. That is great but there are scenarios where you get data sets in messier formats that do not follow this pattern. Furthermore, you might need to restructure your data to perform certain functions, like taking the mean/sum of many columns per participant or visualising multiple elements. Before we work on the data wrangling side, we need a brief explanation of data formats.\n\n6.3.1 Tidy data\nFor most of this book, we use a type of data organisation known as tidy data. Any data in this format is easily processed through the tidyverse family of packages. However, the data you work with will not always be formatted in the most efficient way possible. If that happens, then our first step is to put it into a tidy data format. There are two fundamental principles defining tidy data:\n\nEach variable must have its own column.\nEach observation must have its own row.\n\nWickham (2014) adds the following principle:\n\nEach type of observation unit forms a table.\n\nGrolemund and Wickham (2023) restate this third principle as: “Each value must have its own cell (i.e. no grouping two variables together, e.g. time/date in one cell)” where a cell is where any specific row and column meet. A single data point in a data frame / tibble is a cell for example. The Grolemund and Wickham (2023) book is a very useful source for further reading and it is free, but browsing the chapter on tidy data will help you visualise how you want to arrange data.\n\n\n\n\n\n\nNote\n\n\n\nIf you have worked with any kind of data before, particularly if you have used Excel, it is likely that you will have used wide format or long format data. In wide format, each participant’s data is all in one row with multiple columns for different data points. This means that the data set tends to be very wide and you will have as many rows as you have participants.\nLong format is where each row is a single observation, typically a single trial in an experiment or a response to a single item on a questionnaire. When you have multiple trials per participant, you will have multiple rows for the same participant. To identify participants, you would need a variable with some kind of participant id, which can be as simple as a distinct integer value for each participant. In addition to the participant identifier, you would have any measurements taken during each observation (e.g., response time) and what experimental condition the observation was taken under.\nIn wide format data, each row corresponds to a single participant, with multiple observations for that participant spread across columns. So for instance, with survey data, you would have a separate column for each survey question.\nTidy data is a mix of both of these approaches and most functions in the tidyverse assume the tidy format, so typically the first thing you need to do when you get data is think about what format you need your data to perform the functions and analyses you want. For some functions, you need your data in wide format, and in others you need your data in long format. This means being able to quickly restructure your data is a key skill.\n\n\n\n6.3.2 Activity 9: Gathering with pivot_longer()\n\nIn it’s current format, we have wide data where each row is a separate participant and each column is a separate variable. We can use the function pivot_longer() from the tidyr package within tidyverse.\nThe pivot functions can be easier to show than explain first, so type and run the following code using the full_data_mutate object:\n\nfull_data_long &lt;- pivot_longer(data = full_data_mutate,\n                      cols = SPSS1E:SPSS9E,\n                      names_to = \"Question\", \n                      values_to = \"Response\")\n\nTo break down the code:\n\nWe create a new data object called full_data_long by applying the pivot_longer() function to full_data_mutate.\nIn the cols argument, we specify the columns we want to gather. We use the colon method here like select() to choose the 7 columns for the VSSL items. If the columns are not in order, you could use the c() method instead (e.g., cols = c(SPSS1E, SPSS9E)).\nThe names_to argument is what your first new column will be called. All the column names you selected in cols will be pivoted into this new column, so call it something sensible you will remember later. Here, we call the new column “Question”.\nThe values_to argument is what your second new column will be called. For all the columns you gather, the response of each participant will be in one column stacked on top of each other next to its label in “Question”. You also need to call this something memorable, like “Response” here.\n\nNow, explore the new full_data_long object you just created and compare it to full_data_mutate. Instead of 181 rows, we now have 1267 rows. Instead of 27 variables, we now have 22 variables. We have 181 participants who responded to 7 VSSL items, so we pivot the data into long format to get 181 * 7 = 1267 rows.\nVisually, you can see the difference with a preview of just the participant ID and VSSL items here:\n\n\nOriginal wide format\nNew long format\n\n\n\n\n\n\n\n\nStudentIDE\nSPSS1E\nSPSS4E\nSPSS5E\nSPSS6E\nSPSS7E\nSPSS8E\nSPSS9E\n\n\n\n1\n4\n3\n3\n3\n4\n4\n4\n\n\n2\n4\n4\n4\n4\n4\n4\n4\n\n\n3\n3\n2\n3\n2\n2\n3\n3\n\n\n4\n2\n2\n2\n2\n2\n2\n2\n\n\n5\n4\n3\n4\n4\n3\n4\n3\n\n\n6\n2\n3\n2\n1\n3\n3\n3\n\n\n7\n4\n2\n4\n4\n2\n3\n2\n\n\n8\n2\n3\n3\n3\n3\n3\n2\n\n\n9\n3\n3\n3\n1\n4\n3\n2\n\n\n10\n4\n4\n3\n5\n4\n2\n4\n\n\n\n\n\n\n\n\n\n\n\n\n\nStudentIDE\nQuestion\nResponse\n\n\n\n1\nSPSS1E\n4\n\n\n1\nSPSS4E\n3\n\n\n1\nSPSS5E\n3\n\n\n1\nSPSS6E\n3\n\n\n1\nSPSS7E\n4\n\n\n1\nSPSS8E\n4\n\n\n1\nSPSS9E\n4\n\n\n2\nSPSS1E\n4\n\n\n2\nSPSS4E\n4\n\n\n2\nSPSS5E\n4\n\n\n\n\n\n\n\n\n\nNow we have our data in long form, we can calculate summary statistics for participants using group_by() and summarise(). First, we group the data by the participant ID, as we want one value per participant:\n\n# group full_data_long by StudentIDE\nlongdata_grouped &lt;- group_by(full_data_long, \n                             StudentIDE)\n\nSecond, we create a new variable using summarise() to take the sum of all the items. This will create the VSSL scale score consistent with Alter et al. (2024):\n\n# Calculate the sum of VSSL items by taking the sum of Response\nVSSL_sum &lt;- summarise(longdata_grouped,\n                      VSSL_sum = sum(Response))\n\nOur new object goes from 1267 rows back to 181 as we grouped by the participant ID and took the sum of Response. This means we apply the function we provide summarise() to all the rows we want to group by, in this case across all 7 VSSL items. Your new object has just two columns: StudentIDE and VSSL_sum and should look like the following extract:\n\n\n\n\n\nStudentIDE\nVSSL_sum\n\n\n\n1\n25\n\n\n2\n28\n\n\n3\n18\n\n\n4\n14\n\n\n5\n25\n\n\n6\n17\n\n\n\n\n\n\nAt this point, you could join the object to full_data_mutate to add the scale score to all the other variables.\n\n\n\n\n\n\nTry this\n\n\n\nWe calculated the VSSL scale score by pivoting longer, grouping the data, and taking the sum of the 7 items. To test your understanding, complete the same steps to calculate the scale score of Quantitative anxiety using the four columns QANX1E to QANX4E. The scale score here also involves taking the sum of the columns. Use the full_data_mutate object as your starting point for the data.\nCheck your attempt with the solution below when you have tried on your own.\n\n# gather the four quant anxiety items to long form\nquant_anxiety_long &lt;- ?\n\n# group the long data by participant ID\nquant_anxiety_group &lt;- ?\n\n# calculate the sum quant anxiety per participant\nsum_quant_anxiety &lt;- ?\n\nTo check your answers:\n\nParticipant 1 has a sum quantitative anxiety score of \nParticipant 5 has a sum quantitative anxiety score of \n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe complete the task in three steps. First, we pivot longer using the four columns QANX1E to QANX4E to create the new quant_anxiety_long object. Second, we group that new long data object by the participant ID. Third, we calculate the sum quantitative anxiety score by taking the sum of the responses per participant ID.\n\n# gather the four quant anxiety items to long form\nquant_anxiety_long &lt;- pivot_longer(data = full_data_mutate,\n                                   cols = QANX1E:QANX4E,\n                                   names_to = \"Question\",\n                                   values_to = \"Response\")\n\n# group the long data by participant ID\nquant_anxiety_group &lt;- group_by(quant_anxiety_long, \n                                StudentIDE)\n\n# calculate the sum quant anxiety per participant\nsum_quant_anxiety &lt;- summarise(quant_anxiety_group,\n                               sum_quant_anxiety = sum(Response))\n\n\n\n\n\n6.3.3 Spreading with pivot_wider()\n\nYou might also find yourself in situations where you must restructure data in the opposite direction: from long to wide. There is a complementary function called pivot_wider() where you can spread values from one column to multiple columns. You need two columns in your long form data set, one for the variable names which will be your new column names, then one for the responses which will be the values in each cell.\nTo demonstrate this function, we will transform full_data_long back to wide format so we have 7 columns of VSSL items:\n\nfull_data_wide &lt;- pivot_wider(data = full_data_long,\n                              names_from = \"Question\",\n                              values_from = \"Response\")\n\nTo break down the code:\n\nWe create a new object full_data_wide by applying the function pivot_wider() to full_data_long.\nIn the names_from argument, we add the column name “Question” which contains the names of the variables you want as your new column names.\nIn the values_from argument, we add the column name “Response” which contains the values of the variables which will be the cells of your data frame.\n\nThe new object full_data_wide should now look exactly the same as the full_data_mutate object we started with.\n\n\n\n\n\n\nDo I need to add quotes to the column names?\n\n\n\nYou might have noticed we added quotes around the column names to specify the names_from and values_from arguments. When we specify columns in tidyverse functions, we do not need to add the quotes, we can just type the name and it will work (names_from = \"Question\" and names_from = Question would both work here). However, in other functions outside the tidyverse, you normally need to add the quotes around column names. When to add quotes or not can take a while to get used to, so this is just a note to highlight you might try one method and it does not work, but you can try the other method if you get an error.\n\n\n\n\n\n\n\n\nTry this\n\n\n\nIn the pivot_longer() section, you should have created a new object quant_anxiety_long if you completed the “Try this” activity. To test your understanding of pivot_wider(), spread the four items and responses of Quantitative anxiety back to wide format. Use the quant_anxiety_long object as your starting point and create a new object called quant_anxiety_wide.\nCheck your attempt with the solution below when you have tried on your own.\n\n# spread the quant anxiety items back to wide form\nquant_anxiety_wide &lt;- ?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThis task follows the exact format as full_data_wide if you named your variables the same as ours. It is just important the names_from and values_from columns are the same as those you used in quant_anxiety_long.\n\n# spread the quant anxiety items back to wide form\nquant_anxiety_wide &lt;- pivot_wider(quant_anxiety_long, \n                                  names_from = \"Question\",\n                                  values_from = \"Response\")"
  },
  {
    "objectID": "06-wrangling-3.html#combining-several-functions-with-pipes",
    "href": "06-wrangling-3.html#combining-several-functions-with-pipes",
    "title": "6  Data Wrangling 3: Pivots and Pipes",
    "section": "\n6.4 Combining several functions with pipes",
    "text": "6.4 Combining several functions with pipes\nIn this final section on data wrangling, we are not covering new functions, but a new way of working. So far, we have created lots of new objects by applying individual tidyverse functions, but there is a way to string together several functions and streamline your code. We wanted to introduce you to the individual functions first to develop your fundamentals skills and understanding of what the functions do, but now we can be a little more efficient.\nInstead of creating several objects, you can use pipes. We write pipes as %&gt;% and you can read them as “and then”. Pipes allow you to string together ‘sentences’ of code into ‘paragraphs’ so that you do not need to create intermediary objects.\nThis is another one of those concepts that is initially easier to show than tell:\n\n# Create an object starting with demog \nfull_data_pipe &lt;-  demog %&gt;%\n  # Join with scales\n  inner_join(y = scales,\n             by = \"StudentIDE\") %&gt;%\n  # Select key columns\n  select(StudentIDE, \n         GenderE,\n         RaceEthE, \n         AgeE, \n         QANX1E:QINFL7E, \n         QHIND1E:QHIND5E, \n         SPSS1E, SPSS4E, SPSS5E, SPSS6E, SPSS7E, SPSS8E, SPSS9E) %&gt;% \n  # Recode variables with labels\n  mutate(GenderE = case_match(GenderE,\n                              1 ~ \"Female\",\n                              2 ~ \"Male\",\n                              3 ~ \"Non-binary\"),\n         RaceEthE = case_match(RaceEthE,\n                               1 ~ \"Black/African American\",\n                               2 ~ \"Hispanic/Other Latinx\",\n                               3 ~ \"White\",\n                               4 ~ \"Multiracial\",\n                               5 ~ \"Asian/Pacific Islander\",\n                               6 ~ \"Native American/Alaska Native\",\n                               7 ~ \"South/Central American\"))\n\nInstead of creating all the intermediary objects, we go straight from joining the two data sets to recoding the variables in mutate, all in one object. Side by side, you can see the difference in the process we had to go through:\n\n\nCreating separate objects\nCombining functions using pipes\n\n\n\n\n# join demog and scales by a common identifier \nfull_data &lt;- inner_join(x = demog,\n                        y = scales,\n                        by = \"StudentIDE\")\n\n# select the key variables listed above\nfull_data_select &lt;- select(full_data,\n                           StudentIDE, \n                           GenderE,\n                           RaceEthE, \n                           AgeE, \n                           QANX1E:QINFL7E, \n                           QHIND1E:QHIND5E, \n                           SPSS1E, SPSS4E:SPSS9E)\n\n# recode gender and race to labels\nfull_data_mutate &lt;- mutate(full_data_select,\n                           GenderE = case_match(GenderE,\n                                                1 ~ \"Female\",\n                                                2 ~ \"Male\",\n                                                3 ~ \"Non-binary\"),\n                           RaceEthE = case_match(RaceEthE,\n                                                 1 ~ \"Black...\",\n                                                 2 ~ \"Hispanic...\",\n                                                 3 ~ \"White\",\n                                                 4 ~ \"Multiracial\",\n                                                 5 ~ \"Asian...\",\n                                                 6 ~ \"Native American...\",\n                                                 7 ~ \"South...\"))\n\n\n\n\n# Create an object starting with demog \nfull_data_pipe &lt;-  demog %&gt;%\n  # Join with scales\n  inner_join(y = scales,\n             by = \"StudentIDE\") %&gt;%\n  # Select key columns\n  select(StudentIDE, \n         GenderE,\n         RaceEthE, \n         AgeE, \n         QANX1E:QINFL7E, \n         QHIND1E:QHIND5E, \n         SPSS1E, SPSS4E:SPSS9E) %&gt;% \n  # Recode variables with labels\n  mutate(GenderE = case_match(GenderE,\n                              1 ~ \"Female\",\n                              2 ~ \"Male\",\n                              3 ~ \"Non-binary\"),\n         RaceEthE = case_match(RaceEthE,\n                               1 ~ \"Black...\",\n                               2 ~ \"Hispanic...\",\n                               3 ~ \"White\",\n                               4 ~ \"Multiracial\",\n                               5 ~ \"Asian...\",\n                               6 ~ \"Native American...\",\n                               7 ~ \"South...\"))\n\n\n\n\nAs you get used to using pipes, remember you can interpret them as “and then”. So, we could explain the function of the code to ourselves as:\n\nCreate full_data_pipe by starting with demog data, and then\nJoin with the scales data using StudentIDE as an identifier, and then,\nSelect our key columns, and then\nMutate to recode gender and race.\n\nIt can be tricky at first to understand what pipes are doing from a conceptual point of view, but it is well worth learning to use them. When your code starts getting longer, they are much more efficient and you write less code which is always a good thing to debug and find errors. You also have fewer objects in your environment as we created one object instead of three, tidying your workspace.\n\n\n\n\n\n\nError mode\n\n\n\nOne key difference that can trip people up is we no longer specify the data object as the first argument in each function. The reason that this function - the %&gt;% - is called a pipe is because it ‘pipes’ the data through to the next function. When you wrote the code previously, the first argument of each function was the dataset you wanted to work on. When you use pipes, it will automatically take the data from the previous line of code so you do not need to specify it again.\nFor example, if we tried to specify demog again in select(), we would just receive an error.\n\n# Create an object starting with demog \nfull_data_pipe &lt;-  demog %&gt;%\n  # Join with scales\n  inner_join(y = scales,\n             by = \"StudentIDE\") %&gt;%\n  # Select key columns\n  select(.data = demog,\n         StudentIDE, \n         GenderE,\n         RaceEthE, \n         AgeE, \n         QANX1E:QINFL7E, \n         QHIND1E:QHIND5E, \n         SPSS1E, SPSS4E:SPSS9E)\n\n\n\n\n\n\n\n\n\nTry this\n\n\n\nPipes also work with other functions like filter(), group_by() and summarise(). If you start with the object full_data_mutate, try and express the following instructions in code:\n\nCreate a new object age_groups using full_data_mutate as your starting point, and then\nFilter to only include “White” and “Black/African American” participants using RaceEthE, and then,\nGroup the observations by RaceEthE, and then,\nSummarise the data to calculate the mean and standard deviation AgeE.\n\nCheck your attempt with the solution below when you have tried on your own.\n\n# create age_groups by filtering, grouping, and summarising\nage_groups &lt;- full_data_mutate %&gt;% \n  ?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe complete this task in three steps. First, we filter full_data_mutate to just focus on White and Black/African American participants. Second, we group the data by RaceEthE so our summary statistics are split into two groups. Third, we calculate the mean and SD age.\n\n# create age_groups by filtering, grouping, and summarising\nage_groups &lt;- full_data_mutate %&gt;% \n  filter(RaceEthE %in% c(\"White\", \"Black/African American\")) %&gt;% \n  group_by(RaceEthE) %&gt;% \n  summarise(mean_age = mean(AgeE, na.rm = TRUE),\n            SD_age = sd(AgeE, na.rm = TRUE))"
  },
  {
    "objectID": "06-wrangling-3.html#test-yourself",
    "href": "06-wrangling-3.html#test-yourself",
    "title": "6  Data Wrangling 3: Pivots and Pipes",
    "section": "\n6.5 Test yourself",
    "text": "6.5 Test yourself\nTo end the chapter, we have some knowledge check questions to test your understanding of the concepts we covered in the chapter. We then have some error mode tasks to see if you can find the solution to some common errors in the concepts we covered in this chapter.\n\n6.5.1 Knowledge check\nWhich function(s) would you use to approach each of the following problems?\nQuestion 1. We have a data set of 400 adults but we want to remove anyone with an age of 50 years or more. To do this, we could use:\n\nsummarise()filter()select()mutate()group_by()arrange()\n\nQuestion 2. We are interested in overall summary statistics for our data, such as the mean and total number of observations for a variable. To do this, we could use:\n\narrange()select()filter()summarise()group_by()mutate()\n\nQuestion 3. Our data set has a column with the number of cats a person has and a column with the number of dogs. We want to calculate a new column which contains the total number of pets each participant has. To do this, we could use:\n\nselect()group_by()filter()mutate()summarise()arrange()\n\nQuestion 4. We want to calculate the mean value of a column for several groups in our data set. To do this, we could use:\n\nfilter() and select()group_by() and summarise()group_by() and arrange()arrange() and mutate()\n\nQuestion 5. If we wanted to apply the following wrangling steps with pipes, which series of functions would work? With the object wide_data, select several columns and then, pivot three columns longer and then, group by a participant ID and then, calculate the sum of responses.\n\nselect() %&gt;% pivot_longer() %&gt;% group_by() %&gt;% summarise() %&gt;% wide_datawide_data %&gt;% pivot_longer() %&gt;% select() %&gt;% summarise() %&gt;% group_by()long_data %&gt;% select() %&gt;% pivot__longer_wider() %&gt;% group_by() %&gt;% summarise()wide_data %&gt;% select() %&gt;% pivot_longer() %&gt;% group_by() %&gt;% summarise()\n\n\n6.5.2 Error mode\nThe following questions are designed to introduce you to making and fixing errors. For this topic, we focus on data wrangling using past functions, pivot_longer(), and pipes (%&gt;%). Remember to keep a note of what kind of error messages you receive and how you fixed them, so you have a bank of solutions when you tackle errors independently.\nCreate and save a new R Markdown file for these activities. Delete the example code, so your file is blank from line 10. Create a new code chunk to load tidyverse and the data files:\n\n# Load the tidyverse package below\nlibrary(tidyverse)\n\n# Load the data files\n# This should be the Alter_2024_demographics.csv file \ndemog &lt;- read_csv(\"data/Alter_2024_demographics.csv\")\n\n# This should be the Alter_2024_scales.csv file \nscales &lt;- read_csv(\"data/Alter_2024_scales.csv\")\n\nBelow, we have several variations of a code chunk error or misspecification. Copy and paste them into your R Markdown file below the code chunk to load tidyverse and the data files. Once you have copied the activities, click knit and look at the error message you receive. See if you can fix the error and get it working before checking the answer.\nQuestion 6. Copy the following code chunk into your R Markdown file and press knit. In this code chunk, we want to calculate the mean and SD age of all participants using demog. There are two errors/omissions here to try and fix:\n\nOne causes the document not to knit. You should receive an error like Caused by error in \"SD()\": ! could not find function \"SD\".\nThe other looks like we just get NA values?\n\n```{r}\n# calculate the mean and SD age\ndemog %&gt;% \n  summarise(mean_age = mean(AgeE),\n            SD_age = SD(AgeE))\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nThe first error is using the wrong function name for SD. Because we always abbreviate standard deviation to SD, it is tempting to try and use that as the function name. However, the function is lowercase: sd().\nThe second error is not including the na.rm = TRUE argument. There are NAs in the data, so you either need to address them before running the function, or ignoring the NAs with na.rm = TRUE.\n\n# calculate the mean and SD age\ndemog %&gt;% \n  summarise(mean_age = mean(AgeE, na.rm = TRUE),\n            SD_age = sd(AgeE, na.rm = TRUE))\n\n\n\n\nQuestion 7. Copy the following code chunk into your R Markdown file and press knit. We want to calculate the sum of the five quantitative hindrances items per participant. This code… works, but does it look like it fits in the possible 5-25 range?\n```{r}\n# sum quant hindrances items per participant\nsum_quant_hindrance &lt;- scales %&gt;% \n  mutate(sum_quant_hindrance = sum(c(QHIND1E, QHIND2E, QHIND3E, QHIND4E, QHIND5E), na.rm = TRUE))\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nThis is the main of warning we flagged in the opening section to pivot_longer(). Intuitively, it is the right idea to try and calculate the sum in a new column. However, in mutate(), it sums all the columns, not the observations for each participant.\nInstead, we can pivot longer focusing on the quantitative hindrance items, group by participant ID, and summarise.\n\n# sum quant hindrances items per participant\nsum_quant_hindrance &lt;- scales %&gt;% \n  # pivot longer on 5 quant hindrances items\n  pivot_longer(cols = QHIND1E:QHIND5E,\n               names_to = \"Question\",\n               values_to = \"Response\") %&gt;% \n  # group by student ID\n  group_by(StudentIDE) %&gt;% \n  # summarise for sum of new long column \n  summarise(sum_quant_hindrance = sum(Response, na.rm = TRUE))\n\n\n\n\nQuestion 8. Copy the following code chunk into your R Markdown file and press knit. We want to filter demog to focus on female participant and calculate the mean age of the female participants. You should receive an error containing Caused by error:! \"..1$StudentIDE\" must be a logical vector, not a double vector which is not the most helpful error for diagnosing the problem.\n```{r}\n# filter for females then calculate mean age\ndemog %&gt;% \n  filter(.data = demog, \n         GenderE == 2) %&gt;% \n  summarise(.data = demog,\n            mean_age = mean(AgeE, na.rm = TRUE))\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nWe are using pipes but we tried adding in the .data argument in each line. Remember %&gt;% “pipes” the previous line into the next line, so you do not need to specify an object for it to work with. If you try and specify the .data argument with pipes, it thinks you are trying to set the next argument in the list.\n\n# filter for females then calculate mean age\ndemog %&gt;% \n  filter(GenderE == 2) %&gt;% \n  summarise(mean_age = mean(AgeE, na.rm = TRUE))"
  },
  {
    "objectID": "06-wrangling-3.html#words-from-this-chapter",
    "href": "06-wrangling-3.html#words-from-this-chapter",
    "title": "6  Data Wrangling 3: Pivots and Pipes",
    "section": "\n6.6 Words from this Chapter",
    "text": "6.6 Words from this Chapter\nBelow you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the PsyTeachR Glossary. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter.\n\n\n\n\nterm\ndefinition\n\n\n\npipe\nA way to order your code in a more readable format using the symbol %&gt;%\n\n\npivot_longer()\nGather data by increasing the number of rows and decreasing the number of columns.\n\n\npivot_wider()\nSpread data by decreasing the number of rows and increasing the number of columns.\n\n\nreverse-code\nHaving two similar questions, one expressed in a positive way, and another expressed in a negative way.\n\n\ntidy-data\nA format for data that maps the meaning onto the structure."
  },
  {
    "objectID": "06-wrangling-3.html#end-of-chapter",
    "href": "06-wrangling-3.html#end-of-chapter",
    "title": "6  Data Wrangling 3: Pivots and Pipes",
    "section": "\n6.7 End of chapter",
    "text": "6.7 End of chapter\nBrilliant work again! You recapped data wrangling functions from the past two chapters to a new data set, and added two more concepts to your arsenal: pivots and pipes. There really is no substitute for practicing on new data to transfer your knowledge and understanding. As you work with more and more data, you will see how far these data wrangling functions take you. They will your foundational skills for any new data set and give you the confidence to search for new functions when there is a new problem to solve.\nThis is a key milestone, so remember to go over anything you are unsure of. If you have any questions about data wrangling, please post them on Teams, visit the GTA support sessions, or pop into office hours.\nAt this point, we direct you to the first data analysis journey chapter: Analysis Journey 1: Data Wrangling. This is a bridge between the structured learning in these chapters and your assessments. We present you with a new data set, show you what the end product should look like, and see if you can apply your data wrangling skills to get there. If you get stuck, we have a range of hints and steps you can unhide, then the solution to check your attempts against.\nIn the next core chapter though, we turn to more advanced data visualisation to demonstrate how to create scatterplots, boxplots, and violin-boxplots.\n\n\n\n\nAlter, U., Dang, C., Kunicki, Z. J., & Counsell, A. (2024). The VSSL scale: A brief instructor tool for assessing students’ perceived value of software to learning statistics. Teaching Statistics, 46(3). https://doi.org/10.1111/test.12374\n\n\nWickham, H. (2014). Tidy Data. Journal of Statistical Software, 59, 1–23. https://doi.org/10.18637/jss.v059.i10"
  },
  {
    "objectID": "07-more-visualisation.html#chapter-preparation",
    "href": "07-more-visualisation.html#chapter-preparation",
    "title": "7  Scatterplots, boxplots, and violin-boxplots",
    "section": "\n7.1 Chapter preparation",
    "text": "7.1 Chapter preparation\n\n7.1.1 Introduction to the data set\nFor this chapter, we are using open data from Zhang et al. (2014). The abstract of their article is:\n\nAlthough documenting everyday activities may seem trivial, four studies reveal that creating records of the present generates unexpected benefits by allowing future rediscoveries. In Study 1, we used a time-capsule paradigm to show that individuals underestimate the extent to which rediscovering experiences from the past will be curiosity provoking and interesting in the future. In Studies 2 and 3, we found that people are particularly likely to underestimate the pleasure of rediscovering ordinary, mundane experiences, as opposed to extraordinary experiences. Finally, Study 4 demonstrates that underestimating the pleasure of rediscovery leads to time-inconsistent choices: Individuals forgo opportunities to document the present but then prefer rediscovering those moments in the future to engaging in an alternative fun activity. Underestimating the value of rediscovery is linked to people’s erroneous faith in their memory of everyday events. By documenting the present, people provide themselves with the opportunity to rediscover mundane moments that may otherwise have been forgotten.\n\nIn summary, they were interested in whether people could predict how interested they would be in rediscovering past experiences. They call it a “time capsule” effect, where people store photos or messages to remind themselves of past events in the future.\nAt the start of the study (time 1), participants in a romantic relationship wrote about two kinds of experiences. An “extraordinary” experience with their partner on Valentine’s day and an “ordinary” experience one week before. They were then asked how enjoyable, interesting, and meaningful they predict they will find these recollections in three months time (time 2). Three months later, Zhang et al. randomised participants into one of two groups. In the “extraordinary” group, they reread the extraordinary recollection. In the “ordinary” group, they reread the ordinary recollection. All the participants completed measures on how enjoyable, interesting, and meaningful they found the experience, but this time what they actually felt, rather than what they predict they will feel.\nThey predicted participants in the ordinary group would underestimate their future feelings (i.e., there would be a bigger difference between time 1 and time 2 measures) compared to participants in the extraordinary group. In this chapter, we focus on a composite measure which took the mean of items on interest, meaningfulness, and enjoyment.\n\n7.1.2 Organising your files and project for the chapter\nBefore we can get started, you need to organise your files and project for the chapter, so your working directory is in order.\n\nIn your folder for research methods and the book ResearchMethods1_2/Quant_Fundamentals, create a new folder called Chapter_07_dataviz. Within Chapter_07_dataviz, create two new folders called data and figures.\nCreate an R Project for Chapter_07_dataviz as an existing directory for your chapter folder. This should now be your working directory.\nCreate a new R Markdown document and give it a sensible title describing the chapter, such as 07 Scatterplots Boxplots Violins. Delete everything below line 10 so you have a blank file to work with and save the file in your Chapter_07_dataviz folder.\nWe are working with a new data set, so please save the following data file: Zhang_2014.csv. Right click the link and select “save link as”, or clicking the link will save the files to your Downloads. Make sure that you save the file as “.csv”. Save or copy the file to your data/ folder within Chapter_07_dataviz.\n\nYou are now ready to start working on the chapter!\n\n7.1.3 Activity 1 - Read and wrangle the data\nAs the first activity, try and test yourself by completing the following task list to practice your data wrangling skills. Create an object called zhang_data to be consistent with the tasks below. If you want to focus on data visualisation, then you can just type the code in the solution.\n\n\n\n\n\n\nTry this\n\n\n\nTo wrangle the data, complete the following tasks:\n\nLoad the tidyverse package.\nRead the data file data/Zhang_2014.csv.\n\nSelect the following columns:\n\nGender\nAge\nCondition\nT1_Predicted_Interest_Composite renamed to time1_interest\nT2_Actual_Interest_Composite renamed to time2_interest.\n\n\nThere is currently no identifier, so create a new variable called participant_ID. Hint: try participant_ID = row_number().\n\nRecode two variables to be easier to understand and visualise:\n\nGender: 1 = “Male”, 2 = “Female”.\nCondition: 1 = “Ordinary”, 2 = “Extraordinary”.\n\n\n\nYour data should now be in wide format and ready to create a scatterplot.\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# Load the tidyverse package below\nlibrary(tidyverse)\n\n# Load the data file\n# This should be the Zhang_2014.csv file \nzhang_data &lt;- read_csv(\"data/Zhang_2014.csv\")\n\n# Wrangle the data for plotting. \n# select and rename key variables\n# mutate to add participant ID and recode\nzhang_data &lt;- zhang_data %&gt;%\n  select(Gender, \n         Age, \n         Condition, \n         time1_interest = T1_Predicted_Interest_Composite, \n         time2_interest = T2_Actual_Interest_Composite) %&gt;%\n  mutate(participant_ID = row_number(),\n         Condition = case_match(Condition, \n                            1 ~ \"Ordinary\", \n                            2 ~ \"Extraordinary\"),\n         Gender = case_match(Gender,\n                             1 ~ \"Male\",\n                             2 ~ \"Female\")) \n\n\n\n\n\n7.1.4 Activity 2 - Explore the data\n\n\n\n\n\n\nTry this\n\n\n\nAfter the wrangling steps, try and explore zhang_data to see what variables you are working with. For example, opening the data object as a tab to scroll around, explore with glimpse(), or try plotting some of the individual variables to see what they look like using visualisation skills from Chapter 3.\n\n\nIn zhang_data, we have the following variables:\n\n\n\n\n\n\n\nVariable\nType\nDescription\n\n\n\nGender\ncharacter\nParticipant gender: Male (1) or Female (2)\n\n\nAge\ndouble\nParticipant age in years.\n\n\nCondition\ncharacter\nCondition participant was randomly allocated into: Ordinary (1) or Extraordinary (2).\n\n\ntime1_interest\ndouble\nHow interested they predict they will find the recollection on a 1 (not at all) to 7 (extremely) scale. This measure is the mean of enjoyment, interest, and meaningfulness.\n\n\ntime2_interest\ndouble\nHow interested they actually found the recollection on a 1 (not at all) to 7 (extremely) scale. This measure is the mean of enjoyment, interest, and meaningfulness.\n\n\nparticipant_ID\ninteger\nOur new participant ID as an integer from 1 to 130.\n\n\n\nWe will use this data set to demonstrate different ways of visualising continuous variables, either combining multiple continuous variables in a scatterplot or splitting continuous variables into categories in a boxplot or violin-boxplot."
  },
  {
    "objectID": "07-more-visualisation.html#viz-a3",
    "href": "07-more-visualisation.html#viz-a3",
    "title": "7  Scatterplots, boxplots, and violin-boxplots",
    "section": "\n7.2 Scatterplots",
    "text": "7.2 Scatterplots\nThe first visualisation is a scatterplot to show the relationship between two continuous variables. One variable goes on the x-axis and the other variables goes on the y-axis. Each dot then represents the intersection of those two variables per observation/participant. You will use these plots often when reporting a correlation or regression.\n\n7.2.1 Activity 3 - Creating a basic scatterplot\nLet us start by making a scatterplot of Age and time1_interest to see if there is any relationship between the two. We need to specify both the x- and y-axis variables, but the only difference to what we created in Chapter 3 is using a new layer geom_point.\n\nzhang_data %&gt;% \n  ggplot(aes(x = time1_interest, y = Age)) +\n       geom_point()\n\n\n\n\n\n\n\n\n7.2.2 Activity 4 - Editing axis labels\nThis plot is great for some exploratory data analysis, but it looks a little untidy to put into a report. We can use the scale_x_continuous and scale_y_continuous layers to control the tick marks, as well as the axis name.\n\nzhang_data %&gt;%  \n  ggplot(aes(x = time1_interest,y = Age)) +\n  geom_point() +\n  scale_x_continuous(name = \"Time 1 interest score (1-7)\", \n                     breaks = c(1:7)) + # tick marks from 1 to 7\n  scale_y_continuous(name = \"Age\",\n                     limits = c(15, 45), # change limits to 15 to 45\n                     breaks = seq(from = 15, # sequence from 15\n                                  to = 45, # to 45 \n                                  by = 5)) # in steps of 5\n\n\n\n\n\n\n\nTo break down these new arguments/functions in the layers:\n\nbreaks set the tick marks on the plot. We demonstrate two ways of setting this. On the x-axis, we just manually set values for 1 to 7. On the y-axis, we use a second function to set the breaks.\nseq() creates a sequence of numbers and can save a lot of time when you need to add lots of values. We set three arguments, from for the starting point, to for the end point, and by for the steps the sequence goes up in.\nlimits controls the start and end point of the graph scale. In the original graph, we can see there are points below 20 and above 40, so we might want to increase the limits of the graph to include a wider range.\n\n\n\n\n\n\n\nError mode\n\n\n\nWhen controlling the limits of the graph, sometimes you want to decrease the limits range to zoom in on an element of the data. If you decrease the range which cuts off some data points, you must be very careful as it actually cuts off data which you would receive a warning about:\n\nzhang_data %&gt;%  \n  ggplot(aes(x = time1_interest,y = Age)) +\n  geom_point() +\n  scale_y_continuous(name = \"Age\",\n                     limits = c(30, 40)) # in steps of 5\n\nWarning: Removed 124 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\nYou must be very careful when truncating axes, but if you do need to do it, there is a different function layer to use:\n\nzhang_data %&gt;%  \n  ggplot(aes(x = time1_interest,y = Age)) +\n  geom_point() +\n  coord_cartesian(ylim = c(30, 40))\n\n\n\n\n\n\n\n\n\n\n7.2.3 Activity 5 - Adding a regression line\nIt is often useful to add a regression line or line of best fit to a scatterplot. You can add a regression line with the geom_smooth() layer and by default will also provide a 95% confidence interval ribbon. You can specify what type of line you want to draw, most often you will need method = \"lm\" for a linear model or a straight line.\n\nzhang_data %&gt;%  \n  ggplot(aes(x = time1_interest,y = Age)) +\n  geom_point() +\n  scale_x_continuous(name = \"Time 1 interest score (1-7)\", \n                     breaks = c(1:7)) + # tick marks from 1 to 7\n  scale_y_continuous(name = \"Age\",\n                     limits = c(15, 45), # change limits to 15 to 45\n                     breaks = seq(from = 15, # sequence from 15\n                                  to = 45, # to 45 \n                                  by = 5)) +  # in steps of 5\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\nWith the regression line, we can see there is very little relationship between age and interest score at time 1.\n\n\n\n\n\n\nImportant\n\n\n\nRemember, you can save your plots using the function ggsave(). You can use the function after creating the last plot, or saving your plot as an object and using the plot argument. You have a Figures/ directory for the chapter, so try and save the plots you make to remind yourself later.\n\n\n\n\n\n\n\n\nTry this\n\n\n\nSo far, we made a scatterplot of age against interest at time 1. Now, create a scatterplot on your own using the two interest rating variables: time1_interest and time2_interest.\nAfter you made the scatterplot, it looks like there is a \npositive\nnegative relationship between interest ratings at time 1 and time 2.\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\nzhang_data %&gt;%  \n  ggplot(aes(x = time1_interest, y = time2_interest)) +\n  geom_point() +\n  scale_x_continuous(name = \"Time 1 interest score (1-7)\", \n                     breaks = c(1:7)) + # tick marks from 1 to 7\n  scale_y_continuous(name = \"Time 2 interest score (1-7)\", \n                     breaks = c(1:7)) + # tick marks from 1 to 7\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\n\n\n\n7.2.4 Activity 6 - Creating a grouped scatterplot\nBefore we move on, we can add a third variable to show how the relationship might differ for different groups within our data. We can do this by adding the colour argument to aes() and setting it as whatever variable we would like to distinguish between. In this case, we will see how the relationship between age and interest at time 1 differs for the male and female participants. There are a few participants with missing gender, so we will first filter them out.\n\nzhang_data %&gt;%\n  drop_na(Gender) %&gt;% \n  ggplot(aes(x = time1_interest, y = Age, colour = Gender)) +\n  geom_point() +\n  scale_x_continuous(name = \"Mean interest score (1-7)\",\n                     breaks = c(1:7)) + \n  scale_y_continuous(name = \"Age\") +\n  geom_smooth(method = \"lm\")\n\n\n\nGrouped scatterplot\n\n\n\n\n\n\n\n\n\nTry this\n\n\n\nFor your independent scatterplot of the two interest rating variables: time1_interest and time2_interest, add a colour argument using the Condition variable. This will show the relationship between time 1 and time 2 interest separately for participants in the ordinary and extraordinary groups.\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\nzhang_data %&gt;%  \n  ggplot(aes(x = time1_interest, y = time2_interest, colour = Condition)) +\n  geom_point() +\n  scale_x_continuous(name = \"Time 1 interest score (1-7)\", \n                     breaks = c(1:7)) + # tick marks from 1 to 7\n  scale_y_continuous(name = \"Time 2 interest score (1-7)\", \n                     breaks = c(1:7)) + # tick marks from 1 to 7\n  geom_smooth(method = \"lm\")"
  },
  {
    "objectID": "07-more-visualisation.html#viz-a4",
    "href": "07-more-visualisation.html#viz-a4",
    "title": "7  Scatterplots, boxplots, and violin-boxplots",
    "section": "\n7.3 Boxplots",
    "text": "7.3 Boxplots\nThe next visualisation is the boxplot which presents a range of summary statistics for your outcome, which you can split between different groups on the x-axis, or add further variables to divide by. For the boxplot element, you get five summary statistics: the median centre line, the first and third quartile as the box (essentially, the interquartile range), and 1.5 times the first and third quartiles as the whiskers extending from the box. If there are any values beyond the whiskers, you see the individual data points and this is one definition of an outlier (more on that in Chapter 11)\n\n7.3.1 Activity 7 - Creating a basic boxplot\nBefore we create the boxplot, we need a final data wrangling step. At the moment, we have time1_interest and time2_interest in wide format, but to plot together, we need to express it as a single variable. For that, we must restructure the data. This is why we spent so much time on data wrangling, as you might need to quickly restructure your data to plot certain elements.\n\n\n\n\n\n\nTry this\n\n\n\nTo wrangle the data, gather the variables time1_interest and time2_interest. Create a new object called zhang_data_long and use the names Time and Interest for your column names to be consistent with the demonstrations below.\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# gather the data to convert to long format\nzhang_data_long &lt;- zhang_data %&gt;% \n  pivot_longer(cols = time1_interest:time2_interest,\n               names_to = \"Time\",\n               values_to = \"Interest\")\n\n\n\n\nIf you only want to visualise one continuous variable, we need one variable on the y-axis and a new function layer geom_boxplot().\n\nzhang_data_long %&gt;% \n  ggplot(aes(y = Interest)) +\n  geom_boxplot() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7))\n\n\n\n\n\n\n\nTypically, you want to compare the outcome between one or more categories, so we can add a categorical variable like gender to the x-axis, removing the missing values first.\n\nzhang_data_long %&gt;% \n  drop_na(Gender) %&gt;% \n  ggplot(aes(y = Interest, x = Gender)) +\n  geom_boxplot() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7))\n\n\n\n\n\n\n\n\n7.3.2 Activity 8 - Adding colour to variables\nIt is not as important when you only have one variable on the x-axis, but one useful feature is adding colour to distinguish between categories. You can control this by adding a variable to the fill argument within aes().\nBy default, we get a legend which is redundant when we only have different colours on the x-axis, so we can turn it off by adding guides(fill = FALSE) as a layer.\n\nzhang_data_long %&gt;% \n  drop_na(Gender) %&gt;% \n  ggplot(aes(y = Interest, x = Gender, fill = Gender)) +\n  geom_boxplot() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7)) + \n  guides(fill = FALSE) # remove the legend\n\n\n\n\n\n\n\n\n\n\n\n\n\nError mode\n\n\n\nYou might have noticed we have now used two different arguments to control the colour. In scatterplots, we used colour. In boxplots, we used fill. It is one of those concepts that takes time to recognise which you need, depending on the type of geom you are using. Roughly, colour is when you want to control the outline or symbol, like the points. Whereas fill is when you want the inside of a geom coloured. You can see the difference here by controlling fill first:\n\nzhang_data_long %&gt;% \n  drop_na(Gender) %&gt;% \n  ggplot(aes(y = Interest, x = Gender, fill = Gender)) +\n  geom_boxplot() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7))\n\n\n\n\n\n\n\nThen colour:\n\nzhang_data_long %&gt;% \n  drop_na(Gender) %&gt;% \n  ggplot(aes(y = Interest, x = Gender, colour = Gender)) +\n  geom_boxplot() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7))\n\n\n\n\n\n\n\n\n\n\n7.3.3 Activity 9 - Controlling colours\nggplot2 has a default colour scheme which is fine for quick plots, but it is useful to control the colour scheme. You can do this manually by editing scale_fill_discrete() and choosing colours through the type argument (you can do this through character names or choosing a HEX code: https://r-charts.com/colors/).\n\nzhang_data_long %&gt;% \n  drop_na(Gender) %&gt;% \n  ggplot(aes(y = Interest, x = Gender, fill = Gender)) +\n  geom_boxplot() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7)) + \n  scale_fill_discrete(type = c(\"blue\", \"pink\"))\n\n\n\n\n\n\n\nAlternatively (and what we recommend), you can use scale_fill_viridis_d(). This function does exactly the same thing but it uses a colour-blind friendly palette (which also prints in black and white). There are 5 different options for colours and you can see them by changing option to A, B, C, D or E. We like option E with alpha = 0.6 (to control transparency and soften the tone) but play around with the options to see what you prefer.\n\nzhang_data_long %&gt;% \n  drop_na(Gender) %&gt;% \n  ggplot(aes(y = Interest, x = Gender, fill = Gender)) +\n  geom_boxplot() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7)) + \n  scale_fill_viridis_d(option = \"E\", \n                       alpha = 0.6) + \n  guides(fill = FALSE)\n\n\n\nBoxplots with friendly colours\n\n\n\n\n\n\n\n\n\nTry this\n\n\n\nFor your independent boxplot, use zhang_data_long to visualise Interest as your continuous variable and Condition for different categories. This will show the difference in interest rating between those in the ordinary and extraordinary groups.\nComparing the ordinary and extraordinary groups, it looks like \nordinary score higher on average\nvery little difference on average\nextraordinary score higher on average.\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\nzhang_data_long %&gt;% \n  ggplot(aes(y = Interest, x = Condition, fill = Condition)) +\n  geom_boxplot() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7)) + \n  scale_fill_viridis_d(option = \"E\", \n                       alpha = 0.6) + \n  guides(fill = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n7.3.4 Activity 10 - Ordering categories\nWhen we plot variables like Gender on the x-axis, R has an internal order it sets unless you create a factor. The default is alphabetical or numerical. In previous plots, it displayed Female then Male, as F comes before M.\nControlling the order of categories is an important design choice to communicate your message, and the most direct way is controlling the factor order before plotting. Here, we add mutate() in a pipe and manually set the factor levels, just be careful as it is case sensitive to the values in your data.\n\nzhang_data_long %&gt;% \n  drop_na(Gender) %&gt;% \n  mutate(Gender = factor(Gender, \n                         levels = c(\"Male\", \"Female\"))) %&gt;% \n  ggplot(aes(y = Interest, x = Gender, fill = Gender)) +\n  geom_boxplot() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7)) + \n  scale_fill_viridis_d(option = \"E\", \n                       alpha = 0.6) + \n  guides(fill = FALSE)\n\n\n\n\n\n\n\n\n7.3.5 Activity 11- Boxplots for multiple factors\nWhen you only have one independent variable, using the fill argument to change the colour can be a little redundant as the colours do not add any additional information. It makes more sense to use colour to represent a second variable.\nFor this example, we will use Condition and Time as variables. fill() now specifies a second independent variable, rather than repeating the variable on the x-axis as in the previous plot, so we do not want to deactivate the legend.\n\nzhang_data_long %&gt;% \n  ggplot(aes(y = Interest, x = Condition, fill = Time)) +\n  geom_boxplot() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7)) + \n  scale_fill_viridis_d(option = \"E\", \n                       alpha = 0.6)\n\n\n\n\n\n\n\nAs a final point here, the fill values on the legend are not the most professional looking. Like reordering factors, the easiest way of addressing this is editing the underlying data before piping to ggplot2.\n\nzhang_data_long %&gt;% \n  mutate(Time = case_match(Time,\n                           \"time1_interest\" ~ \"Time 1\",\n                           \"time2_interest\" ~ \"Time 2\")) %&gt;% \n  ggplot(aes(y = Interest, x = Condition, fill = Time)) +\n  geom_boxplot() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7)) + \n  scale_fill_viridis_d(option = \"E\", \n                       alpha = 0.6)"
  },
  {
    "objectID": "07-more-visualisation.html#viz-a7",
    "href": "07-more-visualisation.html#viz-a7",
    "title": "7  Scatterplots, boxplots, and violin-boxplots",
    "section": "\n7.4 Violin-boxplots",
    "text": "7.4 Violin-boxplots\nBoxplots are great for your own exploratory data analysis but you do not often see them reported in isolation. They visualise summary statistics, but you do not get much sense of the underlying distribution of values. When you want to communicate continuous outcomes, researchers in psychology are using violin-boxplots more often. This combines both elements: a violin plot to show the distribution of the data, and a boxplot to add summary statistics. This is where ggplot2 comes into it’s own as we can add and customise several layers.\n\n7.4.1 Activity 12 - Creating a basic violin plot\nViolin plots get their name as they look something like a violin when the data are roughly normally distributed. They show density, so the fatter the violin element, the more data points there are for that value. Compared to the boxplot, the only difference is changing the layer to geom_violin().\n\nzhang_data_long %&gt;% \n  drop_na(Gender) %&gt;% \n  ggplot(aes(y = Interest, x = Gender)) +\n  geom_violin() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7))\n\n\n\n\n\n\n\nThe distribution of values is great, but sometimes it might be useful to also add the underlying data points. These are all important design choices as it can be useful when you have smaller amounts of data, but overwhelming when you have thousands of data points. So, keep in mind what you want to communicate. Here, we use the layer geom_jitter() to jitter the points slightly, so they are not all in a vertical line and we get a better sense of the density.\n\nzhang_data_long %&gt;% \n  drop_na(Gender) %&gt;% \n  ggplot(aes(y = Interest, x = Gender)) +\n  geom_violin() + \n  geom_jitter(height = 0, # do not jitter height\n              width = .1) + # jitter width of points\n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7))\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIt is important to remember that R is very literal. ggplot2 works on a system of layers. It will add new geoms on top of existing ones and it will not stop to think whether this is a good idea. Try running the code above but put geom_jitter() first and then add geom_violin(). The order of your layers matters.\n\n\n\n7.4.2 Activity 13 - Creating a violin-boxplot\nInstead of adding the data points in a layer, we can add a boxplot to create the violin-boxplot. This way, we get distribution information from the violin layer and summary statistics from the boxplot layer.\n\nzhang_data_long %&gt;% \n  drop_na(Gender) %&gt;% \n  ggplot(aes(y = Interest, x = Gender)) +\n  geom_violin() + \n  geom_boxplot() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7))\n\n\n\n\n\n\n\nOn it’s own, this does not look great. We can edit the settings to reduce the width of the boxplots, add a colour scheme, and add transparency to the violin layer to make it easier to see the boxplot.\n\nzhang_data_long %&gt;% \n  drop_na(Gender) %&gt;% \n  ggplot(aes(y = Interest, x = Gender, fill = Gender)) +\n  geom_violin(alpha = 0.5) + \n  geom_boxplot(width = 0.2) + \n  scale_fill_viridis_d(option = \"E\") + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7)) + \n  guides(fill = FALSE)\n\n\n\n\n\n\n\nThe boxplot uses the median for the centre line, but in your report you might be presenting means per category which will be slightly different. One further variation is removing the centre median line, and replacing it with the mean and 95% confidence interval (more on that in the lectures and Chapter 8). This way, you get three layers: the violin plot for the density, the boxplot for distribution summary statistics, and the mean and 95% confidence interval.\nThis code uses two calls to stat_summary() which is a layer to add summary statistics. The first layer draws a point to represent the mean, and the second draws an errorbar that represents the 95% confidence interval around the mean.\n\nzhang_data_long %&gt;% \n  drop_na(Gender) %&gt;% \n  ggplot(aes(y = Interest, x = Gender, fill = Gender)) +\n  geom_violin(alpha = 0.5) + \n  geom_boxplot(width = 0.2, \n               fatten = NULL) + \n  stat_summary(fun = \"mean\", \n               geom = \"point\") +\n  stat_summary(fun.data = \"mean_cl_boot\", # confidence interval\n               geom = \"errorbar\", \n               width = 0.1) +\n  scale_fill_viridis_d(option = \"E\") + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7)) + \n  guides(fill = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nWhen you run the line stat_summary(fun.data = \"mean_cl_boot\", geom = \"errorbar\", width = .1) for the first time, you might be prompted to install the R package Hmisc. If you are on your own computer, follow the instructions in the Console to install the package. If you are on a university computer, this should already be installed.\n\n\n\n\n\n\n\n\nTry this\n\n\n\nFor your independent violin-boxplot, use zhang_data_long to visualise Interest as your continuous variable and Condition for different categories on the x-axis. Try and create the plot to look like this, so you might need to play around with different themes:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\nzhang_data_long %&gt;% \n  ggplot(aes(y = Interest, x = Condition, fill = Condition)) +\n  geom_violin(alpha = 0.5) + \n  geom_boxplot(width = 0.2, \n               fatten = NULL) + \n  stat_summary(fun = \"mean\", \n               geom = \"point\") +\n  stat_summary(fun.data = \"mean_cl_boot\", \n               geom = \"errorbar\", \n               width = .1) +\n  scale_fill_viridis_d(option = \"E\") + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7)) + \n  theme_minimal() + \n  guides(fill = FALSE)\n\n\n\n\n\n7.4.3 Activity 14 - Adding additional variables\nLike boxplots, we can add a second grouping variable to fill instead of just using it for colour.\n\nzhang_data_long %&gt;% \n  ggplot(aes(y = Interest, x = Condition, fill = Time)) +\n  geom_violin(alpha = 0.5) + \n  geom_boxplot(width = 0.2, \n               fatten = NULL) + \n  stat_summary(fun = \"mean\", \n               geom = \"point\") +\n  stat_summary(fun.data = \"mean_cl_boot\", \n               geom = \"errorbar\", \n               width = .1) +\n  scale_fill_viridis_d(option = \"E\") + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7)) + \n  theme_minimal()\n\n\n\n\n\n\n\nHowever, unless you are trying to recreate a Kandinsky painting in ggplot2, that does not look quite right. This is because we have multiple layers that each plot separate groups in different ways. To make it all fall into line, we need to add a constant value to offset the elements. We start off by defining a position dodge value as an object. This way, we can use the object name later, and we only need to edit it in one place if we wanted to change the value.\n\n# specify as an object, so we only change it in one place\ndodge_value &lt;- 0.9\n\nzhang_data_long %&gt;% \n  ggplot(aes(y = Interest, x = Condition, fill = Time)) +\n  geom_violin(alpha = 0.5) + \n  geom_boxplot(width = 0.2, \n               fatten = NULL,\n               position = position_dodge(dodge_value)) + \n  stat_summary(fun = \"mean\", \n               geom = \"point\",\n               position = position_dodge(dodge_value)) +\n  stat_summary(fun.data = \"mean_cl_boot\", \n               geom = \"errorbar\", \n               width = .1,\n               position = position_dodge(dodge_value)) +\n  scale_fill_viridis_d(option = \"E\") + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7))\n\n\n\n\n\n\n\nThis looks much better! Remember, if you want to change the legend labels, the easiest way is recoding the data before piping to ggplot2.\nFinally, we might want to add a third variable to group the data by. There is a facet function that produces different plots for each level of a grouping variable which can be very useful when you have more than two factors. The following code shows interest ratings for all three variables we have worked with: Condition, Time, and Gender.\n\n# specify as an object, so we only change it in one place\ndodge_value &lt;- 0.9\n\nzhang_data_long %&gt;% \n  drop_na(Gender) %&gt;% \n  ggplot(aes(y = Interest, x = Condition, fill = Time)) +\n  geom_violin(alpha = 0.5) + \n  geom_boxplot(width = 0.2, \n               fatten = NULL,\n               position = position_dodge(dodge_value)) + \n  stat_summary(fun = \"mean\", \n               geom = \"point\",\n               position = position_dodge(dodge_value)) +\n  stat_summary(fun.data = \"mean_cl_boot\", \n               geom = \"errorbar\", \n               width = .1,\n               position = position_dodge(dodge_value)) +\n  facet_wrap(~ Gender) + # facet by Gender\n  scale_fill_viridis_d(option = \"E\") + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7))\n\n\n\n\n\n\n\nFacets work in the same way as adding a variable to fill. It is not easy to change the labels within ggplot2, you are better off editing the values in your data first."
  },
  {
    "objectID": "07-more-visualisation.html#test-yourself",
    "href": "07-more-visualisation.html#test-yourself",
    "title": "7  Scatterplots, boxplots, and violin-boxplots",
    "section": "\n7.5 Test yourself",
    "text": "7.5 Test yourself\nTo end the chapter, we have some knowledge check questions to test your understanding of the concepts we covered in the chapter. We then have some error mode tasks to see if you can find the solution to some common errors in the concepts we covered in this chapter.\n\n7.5.1 Knowledge check\nQuestion 1. You want to plot several summary statistics including the median for your outcome, which ggplot2 layer could you use?\n\ngeom_boxplot()geom_point()geom_violin()\n\nQuestion 2. You want to create a scatterplot to show the correlation between two continuous variables, which ggplot2 layer could you use?\n\ngeom_point()geom_boxplot()geom_violin()\n\nQuestion 3. You want to show the density of values in your outcome, which ggplot2 layer could you use?\n\ngeom_boxplot()geom_point()geom_violin()\n\nQuestion 4. To separate a scatterplot into different groups, you could specify a grouping variable using the fill argument to change the colour of the points? \nTRUE\nFALSE\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nThis was a sneaky one, but relates to the error mode warning within the chapter. There are two ways to add a grouping variable for separate colours: colour and fill. In this scenario, colour would change the colour of the points, whereas fill would only change the colour of the regression line and its 95% confidence interval ribbon. Sometimes you need to play around with the settings to produce the effects you want.\n\n\n\nQuestion 5. The order of layers is important in ggplot2. Which order of layers would show individual data points on top of a boxplot?\n\ndata + ggplot() + geom_boxplot() + geom_jitter()data %&gt;% ggplot() + geom_jitter() + geom_boxplot()data + ggplot() + geom_jitter() + geom_boxplot()data %&gt;% ggplot() + geom_boxplot() + geom_jitter()\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nIn addition to the layer order, we also added an error mode feature to recognise when you need to use the pipe %&gt;% vs the +.\n\ndata %&gt;% ggplot() + geom_boxplot() + geom_jitter() was the correct answer as we add data point after the boxplot.\ndata + ggplot() + geom_boxplot() + geom_jitter() had the right order, but we used + instead of the pipe between the data and the initial ggplot() function.\ndata + ggplot() + geom_jitter() + geom_boxplot() and data %&gt;% ggplot() + geom_jitter() + geom_boxplot() both had the wrong layer order as the boxplot would overlay the points.\n\n\n\n\n\n7.5.2 Error mode\nThe following questions are designed to introduce you to making and fixing errors. For this topic, we focus on the new types of data visualisation. Remember to keep a note of what kind of error messages you receive and how you fixed them, so you have a bank of solutions when you tackle errors independently.\nCreate and save a new R Markdown file for these activities. Delete the example code, so your file is blank from line 10. Create a new code chunk to load tidyverse and wrangle the data files:\n\n# Load the tidyverse package below\nlibrary(tidyverse)\n\n# Load the data file\n# This should be the Zhang_2014.csv file \nzhang_data &lt;- read_csv(\"data/Zhang_2014.csv\")\n\n# Wrangle the data for plotting. \n# select and rename key variables\n# mutate to add participant ID and recode\nzhang_data &lt;- zhang_data %&gt;%\n  select(Gender, \n         Age, \n         Condition, \n         time1_interest = T1_Predicted_Interest_Composite, \n         time2_interest = T2_Actual_Interest_Composite) %&gt;%\n  mutate(participant_ID = row_number(),\n         Condition = case_match(Condition, \n                            1 ~ \"Ordinary\", \n                            2 ~ \"Extraordinary\"),\n         Gender = case_match(Gender,\n                             1 ~ \"Male\",\n                             2 ~ \"Female\")) \n\n# gather the data to convert to long format\nzhang_data_long &lt;- zhang_data %&gt;% \n  pivot_longer(cols = time1_interest:time2_interest,\n               names_to = \"Time\",\n               values_to = \"Interest\")\n\nBelow, we have several variations of a code chunk error or misspecification. Copy and paste them into your R Markdown file below the code chunk to load tidyverse and the data files. Once you have copied the activities, click knit and look at the error message you receive. See if you can fix the error and get it working before checking the answer.\nQuestion 6. Copy the following code chunk into your R Markdown file and press knit. This code… works, but it does not look quite right? Why are the tick marks not displaying properly?\n```{r}\nzhang_data %&gt;%  \n  ggplot(aes(x = time1_interest, y = time2_interest)) +\n  geom_point() +\n  theme_classic() + \n  scale_x_discrete(name = \"Time 1 interest score (1-7)\", \n                     breaks = c(1:7)) + # tick marks from 1 to 7\n  scale_y_discrete(name = \"Time 2 interest score (1-7)\", \n                     breaks = c(1:7)) + # tick marks from 1 to 7\n  geom_smooth(method = \"lm\")\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nIn this example, we used the wrong function for continuous variables. We used scale_x_discrete and scale_y_discrete, instead of scale_x_continuous and scale_y_continuous. We must honour the variable type when we customise the plot, so think about what type of variable is on each axis and which function lets you edit it.\n\nzhang_data %&gt;%  \n  ggplot(aes(x = time1_interest, y = time2_interest)) +\n  geom_point() +\n  theme_classic() + \n  scale_x_continuous(name = \"Time 1 interest score (1-7)\", \n                     breaks = c(1:7)) + # tick marks from 1 to 7\n  scale_y_continuous(name = \"Time 2 interest score (1-7)\", \n                     breaks = c(1:7)) + # tick marks from 1 to 7\n  geom_smooth(method = \"lm\")\n\n\n\n\nQuestion 7. Copy the following code chunk into your R Markdown file and press knit. You should receive an error like Error in \"fortify()\":! \"data\" must be a &lt;data.frame&gt;, or an object coercible by \"fortify()\" which is a little cryptic.\n```{r}\nzhang_data_long + \n  ggplot(aes(y = Interest, x = Condition, fill = Condition)) +\n  geom_boxplot() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7)) + \n  scale_fill_viridis_d(option = \"E\", \n                       alpha = 0.6) + \n  guides(fill = FALSE)\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nOnce we start using a mixture of tidyverse functions, it is important to remember which uses a pipe %&gt;% between layers, and which uses +. Here, we tried using the + between the data object and the initial ggplot() layer. We need a pipe here or it thinks you are trying to set the data argument using aes().\n\nzhang_data_long %&gt;% \n  ggplot(aes(y = Interest, x = Condition, fill = Condition)) +\n  geom_boxplot() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7)) + \n  scale_fill_viridis_d(option = \"E\", \n                       alpha = 0.6) + \n  guides(fill = FALSE)\n\n\n\n\nQuestion 8. Copy the following code chunk into your R Markdown file and press knit. We want to change the order of the categories to present males then female. This code…works, but is it doing what we think it is doing?\n```{r}\nzhang_data_long %&gt;% \n  drop_na(Gender) %&gt;% \n  ggplot(aes(y = Interest, x = Gender)) +\n  geom_violin() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7)) + \n  scale_x_discrete(labels = c(\"Male\", \"Female\"))\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nWe have introduced this error several times, but we see it so often it is worth reinforcing. When we change the labels, this is really just to tidy things up. The underlying data does not change, we are just trying to communicate it clearer. If we want to change the order of categories, we must change the underlying order of the data as a factor or R will default to alphabetical/numerical. So, we mutate Gender as a factorm, then pipe to ggplot2.\n\nzhang_data_long %&gt;% \n  mutate(Gender = factor(Gender,\n                         levels = (c(\"Male\", \"Female\")))) %&gt;% \n  drop_na(Gender) %&gt;% \n  ggplot(aes(y = Interest, x = Gender)) +\n  geom_violin() + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7))"
  },
  {
    "objectID": "07-more-visualisation.html#words-from-this-chapter",
    "href": "07-more-visualisation.html#words-from-this-chapter",
    "title": "7  Scatterplots, boxplots, and violin-boxplots",
    "section": "\n7.6 Words from this Chapter",
    "text": "7.6 Words from this Chapter\nBelow you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the PsyTeachR Glossary. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter.\n\n\n\n\nterm\ndefinition\n\n\n\nboxplot\nVisualising a continuous variable by five summary statistics: the median centre line, the first and third quartile, and 1.5 times the first and third quartiles.\n\n\nscatterplot\nPlotting two variables on the x- and y-axis to show the correlation/relationship between the variables.\n\n\nviolin-boxplots\nA combination of a violin plot to show the density of data points and a boxplot to show summary statistics of distribution."
  },
  {
    "objectID": "07-more-visualisation.html#end-of-chapter",
    "href": "07-more-visualisation.html#end-of-chapter",
    "title": "7  Scatterplots, boxplots, and violin-boxplots",
    "section": "\n7.7 End of chapter",
    "text": "7.7 End of chapter\nWell done, you have completed the second chapter dedicated to data visualisation! This is a key area for psychology research and helping to communicate your findings to your audience. Data visualisation also comes with a lot of responsibility. There are lots of design choices to make and help communicate your findings as effectively and transparently as possible. We could dedicate a whole book to data visualisation possibilities in R and ggplot2, so we have added a range of further reading sources in the Additional Resources appendix.\nIn the next chapter, we start on inferential statistics introducing you to the concept of regression by focusing on one continuous predictor variable.\n\n\n\n\nZhang, T., Kim, T., Brooks, A. W., Gino, F., & Norton, M. I. (2014). A “Present” for the Future: The Unexpected Value of Rediscovery. Psychological Science, 25(10), 1851–1860. https://doi.org/10.1177/0956797614542274"
  },
  {
    "objectID": "08-lm-continuous.html#chapter-preparation",
    "href": "08-lm-continuous.html#chapter-preparation",
    "title": "\n8  Regression with one continuous predictor\n",
    "section": "\n8.1 Chapter preparation",
    "text": "8.1 Chapter preparation\n\n8.1.1 Introduction to the data set\nFor this chapter, we are using open data from Dawtry et al. (2015). The abstract of their article is:\n\nThe present studies provide evidence that social-sampling processes lead wealthier people to oppose redistribution policies. In samples of American Internet users, wealthier participants reported higher levels of wealth in their social circles (Studies 1a and 1b). This was associated, in turn, with estimates of higher mean wealth in the wider U.S. population, greater perceived fairness of the economic status quo, and opposition to redistribution policies. Furthermore, results from a large-scale, nationally representative New Zealand survey revealed that low levels of neighborhood-level socioeconomic deprivation?an objective index of wealth within participants’ social circles mediated the relation between income and satisfaction with the economic status quo (Study 2). These findings held controlling for relevant variables, including political orientation and perceived self-interest. Social-structural inequalities appear to combine with social-sampling processes to shape the different political attitudes of wealthier and poorer people.\n\nIn summary, the authors investigated why people with more money tend to oppose wealth redistribution policies like higher taxes for higher incomes to decrease inequality in society. We are using data from Study 1A where 305 people completed measures on household income, predicted population income, their predicted social circle income, in addition to measures on support for wealth redistribution and fairness and satisfaction with the current system.\nThey predicted people with higher incomes have social circles with higher incomes, so they are more satisfied with the current system of wealth redistribution and less interested in changing it. In essence, poorer people and richer people have different experiences of how rich and equal their country is. In this chapter, we will explore the relationship between a range of these variables.\n\n8.1.2 Organising your files and project for the chapter\nBefore we can get started, you need to organise your files and project for the chapter, so your working directory is in order.\n\nIn your folder for research methods and the book ResearchMethods1_2/Quant_Fundamentals, create a new folder called Chapter_08_regression_continuous. Within Chapter_08_regression_continuous, create two new folders called data and figures.\nCreate an R Project for Chapter_08_regression_continuous as an existing directory for your chapter folder. This should now be your working directory.\nCreate a new R Markdown document and give it a sensible title describing the chapter, such as 08 Correlations and Regression. Delete everything below line 10 so you have a blank file to work with and save the file in your Chapter_08_regression_continuous folder.\nWe are working with a new data set, so please save the following data file: Dawtry_2015.csv. Right click the link and select “save link as”, or clicking the link will save the files to your Downloads. Make sure that you save the file as “.csv”. Save or copy the file to your data/ folder within Chapter_08_regression_continuous.\n\nYou are now ready to start working on the chapter!\n\n8.1.3 Activity 1 - Read and wrangle the data\nAs the first activity, try and test yourself by completing the following task list to practice your data wrangling skills. Create a final object called dawtry_clean to be consistent with the tasks below. If you want to focus on correlations and regression, then you can just type the code in the solution.\n\n\n\n\n\n\nTry this\n\n\n\nTo wrangle the data, complete the following tasks:\n\n\nLoad the following packages (three of these are new, so revisit Chapter 1 if you need a refresher of installing R packages, but remember not to install packages on the university computers / online server):\n\ntidyverse\neffectsize\ncorrelation\nperformance\n\n\nRead the data file data/Dawtry_2015.csv to the object name dawtry_data.\nReverse code two items: redist2 and redist4 to create two new variables redist2_R and redist4_R. See the codebook below, but they are on a 1-6 scale.\nSummarise the data to calculate the mean fairness_satisfaction score, by taking the mean of two items: fairness and satisfaction.\nSummarise the data to calculate the mean redistribution score, by taking the mean of four items: redist1, redist2_R, redist3, and redist4_R.\nCreate a new object called dawtry_clean by joining dawtry_data with your two new variables fairness_satisfaction and redistribution.\nDecrease the number of columns in dawtry_clean by selecting PS, all the columns between Household_Income and redistribution, but removing the two reverse coded items redist2_R and redist4_R.\n\nYour data should look like this to be ready to analyse:\n\n\nRows: 305\nColumns: 11\n$ PS                                  &lt;dbl&gt; 233, 157, 275, 111, 52, 11, 76, 90…\n$ Household_Income                    &lt;dbl&gt; NA, 20.00, 100.00, 150.00, 500.00,…\n$ Political_Preference                &lt;dbl&gt; 5, 5, 5, 8, 5, 3, 4, 3, 2, 3, NA, …\n$ age                                 &lt;dbl&gt; 40, 59, 41, 59, 35, 34, 36, 39, 40…\n$ gender                              &lt;dbl&gt; 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, NA, …\n$ Population_Inequality_Gini_Index    &lt;dbl&gt; 38.78294, 37.21451, 20.75000, 35.3…\n$ Population_Mean_Income              &lt;dbl&gt; 29715, 123630, 60000, 59355, 15360…\n$ Social_Circle_Inequality_Gini_Index &lt;dbl&gt; 28.056738, 24.323388, 14.442577, 2…\n$ Social_Circle_Mean_Income           &lt;dbl&gt; 21150, 65355, 107100, 86640, 56850…\n$ fairness_satisfaction               &lt;dbl&gt; 1.0, 3.5, 5.0, 7.0, 4.5, 2.5, 3.0,…\n$ redistribution                      &lt;dbl&gt; 5.50, 3.25, 3.75, 2.75, 3.00, 3.75…\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# Load the packages below\nlibrary(tidyverse)\nlibrary(effectsize)\nlibrary(correlation)\nlibrary(performance)\n\n# Load the data file\n# This should be the Dawtry_2015.csv file \ndawtry_data &lt;- read_csv(\"data/Dawtry_2015.csv\")\n\n# Reverse code redist2 and redist4\ndawtry_data &lt;- dawtry_data %&gt;%\n  mutate(redist2_R = 7 - redist2,\n         redist4_R = 7 - redist4)\n\n# calculate mean fairness and satisfaction score  \nfairness_satisfaction &lt;- dawtry_data %&gt;% \n  pivot_longer(cols = fairness:satisfaction, \n               names_to = \"Items\", \n               values_to = \"Response\") %&gt;% \n  group_by(PS) %&gt;% \n  summarise(fairness_satisfaction = mean(Response)) %&gt;% \n  ungroup()\n\n# calculate mean wealth redistribution score  \nredistribution &lt;- dawtry_data %&gt;% \n  pivot_longer(cols = c(redist1, redist2_R, redist3, redist4_R), \n               names_to = \"Items\", \n               values_to = \"Response\") %&gt;% \n  group_by(PS) %&gt;% \n  summarise(redistribution = mean(Response)) %&gt;% \n  ungroup()\n\n# join data and select columns for focus\ndawtry_clean &lt;- dawtry_data %&gt;% \n  inner_join(fairness_satisfaction, by = \"PS\") %&gt;% \n  inner_join(redistribution, by = \"PS\") %&gt;% \n  select(PS, Household_Income:redistribution, -redist2_R, -redist4_R)\n\n\n\n\n\n8.1.4 Activity 2 - Explore the data\n\n\n\n\n\n\nTry this\n\n\n\nAfter the wrangling steps, try and explore dawtry_clean to see what variables you are working with. For example, opening the data object as a tab to scroll around, explore with glimpse(), or try plotting some of the individual variables using a histogram.\n\n\nIn dawtry_clean, we have the following variables:\n\n\n\n\n\n\n\nVariable\nType\nDescription\n\n\n\nPS\ndouble\nParticipant ID number.\n\n\nHousehold_Income\ndouble\nHousehold income in US Dollars ($).\n\n\nPolitical_Preference\ndouble\nPolitical attitudes: 1 = very liberal/very left-wing/strong Democrat to 7 = very conservative/very right-wing/strong Republican.\n\n\nage\ndouble\nAge in years.\n\n\ngender\ndouble\n1 = “Male”, 2 = “Female.\n\n\nPopulation_Inequality_Gini_Index\ndouble\nMeasure of income inequality from 0 (perfect equality) to 100 (perfect inequality), here where participants estimated population in equality.\n\n\nPopulation_Mean_Income\ndouble\nParticipant estimate of the mean household income in the population ($).\n\n\nSocial_Circle_Inequality_Gini_Index\ndouble\nMeasure of income inequality from 0 (perfect equality) to 100 (perfect inequality), here where participants estimated inequality in their social circle.\n\n\nSocial_Circle_Mean_Income\ndouble\nParticipant estimate of the mean household income in their social circle ($).\n\n\nfairness_satisfaction\ndouble\nPerceived fairness and satisfaction about the current system of wealth redistribution: Mean of two items (1 extremely fair – 9 extremely unfair)\n\n\nredistribution\ndouble\nSupport for wealth distribution: Mean of four items (1 strongly disagree – 6 strongly agree).\n\n\n\nWe will use this data set to demonstrate correlations and regression when you have one continuous predictor."
  },
  {
    "objectID": "08-lm-continuous.html#correlation",
    "href": "08-lm-continuous.html#correlation",
    "title": "\n8  Regression with one continuous predictor\n",
    "section": "\n8.2 Correlation",
    "text": "8.2 Correlation\nBefore we cover regression as a more flexible framework for inferential statistics, we think it is useful to start with correlation to get a feel for how we can capture the relationship between two variables. As a reminder from the course materials, correlations are standardised to range from -1 (a perfect negative correlation) to 1 (a perfect positive correlation). A value of 0 would mean there is no correlation between your variables.\n\n8.2.1 Activity 3 - Visualise the relationship\nTo explore the relationship between two variables, it is useful to create a scatterplot early for yourself, then provide a more professional looking version to help communicate your results. For most of the demonstrations in this chapter, we will try and answer the research question: “Is there a relationship between support for wealth redistribution and fairness and satisfaction with the current system?”\n\n\n\n\n\n\nTry this\n\n\n\nUsing your data visualisation skills from Chapter 7, recreate the scatterplot below using the variables fairness_satisfaction and redistribution from dawtry_clean.\n\n\n\n\n\n\n\n\nLooking at the graph, we can describe the relationship as \npositive\nlittle to no correlation\nnegative.\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThe scatterplot shows a negative correlation between the two variables. You need to be careful interpreting fairness and satisfaction as it is coded a little counterintuitive. Higher values mean great dissatisfaction.\nAs support for wealth redistribution increases to be more positive, perceived fairness and satisfaction tends to decrease. This makes sense as people who are more dissatisfied with the current system think there should be more wealth redistribution strategies.\nYou should have the following in a code chunk:\n\ndawtry_clean %&gt;% \n  ggplot(aes(x = fairness_satisfaction, y = redistribution)) + \n  geom_point() + \n  geom_smooth(method = \"lm\") + \n  scale_x_continuous(name = \"Perceived Fairness and Satisfaction\", \n                     breaks = c(1:9)) + \n  scale_y_continuous(name = \"Support for Wealth Redistribution\", \n                     breaks = c(1:6))\n\n\n\n\n\n8.2.2 Activity 4 - Calculate the correlation coefficient\nVisualising the relationship between two variables is great for our understanding, but it does not tell us anything about the inferential statistics for what we can learn from our sample in hypothesis testing and measures of effect size.\nA correlation is a specific application of the general linear model. We want to capture the covariation between two variables. If you are interested, see the Handy Workbook (McAleer, 2023) for the calculations behind different types of correlation and how it represents the covariance of two variables compared to their total variability. They are not the only methods, but the two most common versions of a correlation are:\n\nPearson’s product-moment correlation (often shortened to the Pearson correlation) and symbolised by r.\nSpearman’s rank correlation coefficient (often shortened to the Spearman correlation) and symbolised by \\(r_s\\) or sometimes the Greek letter rho \\(\\rho\\).\n\nThere is a function built into R (cor.test()) to calculate the correlation between two variables, but we tend to use the correlation() function from the correlation package as it has more consistent reporting features. The correlation() function requires:\n\nThe name of the data set you are using.\nThe name of the first variable you want to select for the correlation.\nThe name of the second variable you want to select for the correlation.\nThe type of correlation you want to run: e.g. pearson, spearman.\n\nFor our dawtry_clean data, we would run the following code for a two-tailed Pearson correlation:\n\ncorrelation(data = dawtry_clean, \n            select = \"fairness_satisfaction\", \n            select2 = \"redistribution\",  \n            method = \"pearson\", \n            alternative = \"two.sided\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\nCI\nCI_low\nCI_high\nt\ndf_error\np\nMethod\nn_Obs\n\n\nfairness_satisfaction\nredistribution\n-0.70034\n0.95\n-0.7533907\n-0.6382316\n-17.07843\n303\n&lt; .001\nPearson correlation\n305\n\n\n\n\n\nYour output will look a little different due to how our book renders tables, but you should get the same information. For the three key concepts of inferential statistics, we get\n\nHypothesis testing: p &lt; .001, suggesting we can reject the null hypothesis assuming \\(\\alpha\\) = .05.\nEffect size: r = -.70, suggesting a strong negative correlation.\nConfidence interval: [-0.75, -0.64], showing the precision around the effect size estimate.\n\nTo summarise: a Pearson correlation showed there was a strong, negative, statistically significant relationship between attitudes on wealth redistribution and perceived fairness and satisfaction, r (303) = -0.70, p &lt; .001, 95% CI = [-0.75, -0.64].\nIf we had reason to use a Spearman correlation instead, all we need to do is change the method argument.\n\ncorrelation(data = dawtry_clean, \n            select = \"fairness_satisfaction\", \n            select2 = \"redistribution\",  \n            method = \"spearman\", \n            alternative = \"two.sided\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nrho\nCI\nCI_low\nCI_high\nS\np\nMethod\nn_Obs\n\n\nfairness_satisfaction\nredistribution\n-0.6806667\n0.95\n-0.738182\n-0.6133274\n7947402\n&lt; .001\nSpearman correlation\n305\n\n\n\n\n\nSimilarly, we could report the results as: a Spearman correlation showed there was a strong, negative, statistically significant relationship between attitudes on wealth redistribution and perceived fairness and satisfaction, \\(r_s\\) (303) = -0.68, p &lt; .001, 95% CI = [-0.74, -0.61].\n\n\n\n\n\n\nTry this\n\n\n\nGreat work following along so far, but now it is time to test your understanding on a new set of variables. Use the variables age and redistribution from dawtry_clean. We can ask the question: “What is the relationship between age and attitudes on wealth redistribution?”\n\nCreate a scatterplot to visualise the relationship between age and redistribution from dawtry_clean.\n\nApply the Pearson correlation to get your inferential statistics and answer the following questions:\n\nHypothesis testing: Assuming \\(\\alpha\\) = .05, the relationship between age and wealth redistribution is \nstatistically significant\nnot statistically significant.\nEffect size: Rounded to 2 decimals, the value for Pearson’s correlation coefficient is \n-0.14\n-0.03\n0.08\n-0.49.\nConfidence interval: Rounded to 2 decimals, the lower bound is \n-0.14\n-0.03\n0.08\n-0.49 and the upper bound is \n-0.14\n-0.03\n0.08\n-0.49.\n\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThe scatterplot shows very little correlation between the two variables. The regression line is almost flat and there does not appear to be a clear pattern to the data points.\n\ndawtry_clean %&gt;% \n  ggplot(aes(x = age, y = redistribution)) + \n  geom_point() + \n  geom_smooth(method = \"lm\") + \n  scale_y_continuous(name = \"Attitudes on Wealth Distribution\", \n                     breaks = c(1:6))\n\n\n\n\n\n\n\nFor our inferential statistics, the relationship is not statistically significant and the Pearson correlation coefficient is very weak, r (302) = -0.03, p = .625, 95% CI = [-0.14, 0.08]. Note there is a missing value for age, so we have one few participant / degrees of freedom.\n\ncorrelation(data = dawtry_clean, \n            select = \"age\", \n            select2 = \"redistribution\",  \n            method = \"pearson\", \n            alternative = \"two.sided\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\nCI\nCI_low\nCI_high\nt\ndf_error\np\nMethod\nn_Obs\n\n\nage\nredistribution\n-0.0281749\n0.95\n-0.1402227\n0.0845855\n-0.4898215\n302\n0.6246159\nPearson correlation\n304"
  },
  {
    "objectID": "08-lm-continuous.html#linear-regression-with-one-continuous-predictor",
    "href": "08-lm-continuous.html#linear-regression-with-one-continuous-predictor",
    "title": "\n8  Regression with one continuous predictor\n",
    "section": "\n8.3 Linear regression with one continuous predictor",
    "text": "8.3 Linear regression with one continuous predictor\nNow you know how to calculate a correlation in R, we can turn to simple linear regression as a more flexible tool for modelling the relationship between variables.\nIn Research Methods 1, we focus on just two variables, before scaling up to more complicated models in Research Methods 2. In this chapter, we focus the relationship between a continuous outcome and one continuous predictor, before extending the framework to one categorical predictor in Chapter 9. There is also a chapter in the Handy Workbook (McAleer, 2023) dedicated to manually calculating simple linear regression.\n\n8.3.1 Activity 5- Calculating descriptive statistics\nFor all the information we want to include in a report, calculating descriptive statistics is helpful for the reader to show the context behind the results you present. Here, we can report the mean and standard deviation of our two variables.\n\ndawtry_clean %&gt;% \n  # pivot longer to avoid repeating yourself\n  pivot_longer(cols = fairness_satisfaction:redistribution,\n               names_to = \"Variable\", \n               values_to = \"Value\") %&gt;% \n  # group by Variable to get one value per variable\n  group_by(Variable) %&gt;% \n  # mean and SD, rounded to 2 decimals\n  summarise(mean_variable = round(mean(Value), 2),\n            sd_variable = round(sd(Value), 2))\n\n\n\n\nVariable\nmean_variable\nsd_variable\n\n\n\nfairness_satisfaction\n3.54\n2.02\n\n\nredistribution\n3.91\n1.15\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you want some reinforcement of how these skills apply to published research, look at Table 1 in Dawtry et al. (2015). The means and standard deviations here (and the correlation in Activity 4) exactly reproduce the values they report.\n\n\nIf other types of descriptive statistic would be more suitable to your data, then you can just replace the functions you use within summarise().\n\n8.3.2 Activity 6 - Using the lm() function\nFor our research question of “is there a relationship between support for wealth redistribution and fairness and satisfaction”, we can address it with simple linear regression.\nInstead of a standardised correlation coefficient, we can frame it as whether knowing fairness and satisfaction can predict values of support for wealth redistribution. The design is still correlational, so it does not tell us anything about a causal relationship in isolation. We use the word predict in the statistical sense, where we can ask whether knowing values of one variable help us predict values of another variable with a degree of error.\nThe first step is to create an object (lm_redistribution) for the linear model.\n\nlm_redistribution &lt;- lm(redistribution ~ fairness_satisfaction,\n                        data = dawtry_clean)\n\nThe function lm() is built into R and is incredibly flexible for creating linear regression models.\n\nThe first argument is to specify a formula which defines our model. The first component (redistribution) is our outcome variable for what we are interested in modelling.\nThe tilde (~) separates the equation, where everything on the right is your predictor variable(s). In simple linear regression, we just have one predictor, which is fairness_satisfaction in our model here. This is saying we want to predict redistribution as our outcome from fairness_satisfaction as our predictor.\nWe then specify the data frame we want to use.\n\n\n\n\n\n\n\nNote\n\n\n\nIn some resources, you might see people enter the same model as redistribution ~ 1 + fairness_satisfaction. The 1 + component explicitly tells R to fit an intercept, plus a slope from fairness_satisfaction. R includes an intercept by default, so you do not need to add it, but some people like to include it for clarity.\n\n\nWhen you create this object, it stores a bunch of information, but does not really tell us all the statistics we expect. If you simply print the object in the console, it will tell you the intercept and coefficient(s), but none of the model fitting nor hypothesis testing values. If you look at the object in the R environment, you will see it is a list containing several elements. It stores things like the model, the residuals, and other information you can use.\n\nlm_redistribution\n\n\nCall:\nlm(formula = redistribution ~ fairness_satisfaction, data = dawtry_clean)\n\nCoefficients:\n          (Intercept)  fairness_satisfaction  \n               5.3169                -0.3975  \n\n\nTo get that extra information, we need to call the summary() function around the linear model object to explore it’s properties like estimates and model fit.\n\nsummary(lm_redistribution)\n\n\nCall:\nlm(formula = redistribution ~ fairness_satisfaction, data = dawtry_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9193 -0.5279  0.0233  0.4782  3.3634 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)            5.31686    0.09488   56.04   &lt;2e-16 ***\nfairness_satisfaction -0.39754    0.02328  -17.08   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8218 on 303 degrees of freedom\nMultiple R-squared:  0.4905,    Adjusted R-squared:  0.4888 \nF-statistic: 291.7 on 1 and 303 DF,  p-value: &lt; 2.2e-16\n\n\nTo walk through the output, Call: summarises the model you specified. Residuals: provides a summary of the model residuals which we will come back to later. Coefficients: provides our model output, this time with inferential statistics. The two key lines are:\n\n\n(Intercept) - This is the value of the outcome when our predictor is set to 0. For a fairness and satisfaction value of 0, we would expect a value of 5.32 for redistribution. You get a p-value for this, but in isolation it is not too useful. It just compares the intercept estimate to 0 which typically you are not interested in.\n\n\n\nfairness_satisfaction - This is the regression slope or coefficient. This is the change in the outcome for every 1 unit change in the predictor. So, for every 1 unit increase in fairness and satisfaction, we expect support for wealth redistribution to decrease (as we have a negative value) by 0.40 units. This is consistent with the correlation as we have a negative relationship between the two variables. Looking at the p-value, this is statistically significant (p &lt; .001), suggesting we can reject the null hypothesis and conclude there is an effect here.\n\n\n\n\n\n\n\nDoes it matter if the slope is positive or negative?\n\n\n\nWhen you have a continuous predictor, the sign is important to keep in mind. A positive slope would mean an increase in the predictor is associated with increased values of your outcome. A negative slope would mean an increase in the predictor is associated with decreased values of your outcome. This is crucial for interpreting the coefficient.\n\n\nAt the bottom of the model output, you then get the fit statistics. Multiple \\(R^2\\) tells you how much variance in your outcome your predictor(s) explain. Adjusted \\(R^2\\) tends to be more conservative as it adjusts for the number of predictors in the model (something we will not cover until Chapter 14), but they will be very similar when you have one predictor. Adjusted \\(R^2\\) is .49, suggesting fairness and satisfaction explains 49% of the variance in support for wealth redistribution.\nFinally, we have the model fit statistics to tell us whether the model explains a significant amount of variance in the outcome. With one predictor, the p-value next to the coefficient and next to the model fit will be identical, as one predictor is the whole model. The F-statistic is 291.7, the model degrees of freedom is 1, the residual degrees of freedom is 303, and the p-value is p &lt; .001.\n\n\n\n\n\n\nWhat does 2e-16 mean?\n\n\n\nFor the p-value here, the output looks a little weird. R reports very small or very large numbers using scientific notation to save space. We normally report p-values to three decimals, so we report anything smaller as p &lt; .001 to say it is smaller than this.\nIf you want to see the real number, you can use the following function which shows just how small the p-value is:\n\nformat(2e-16, scientific = FALSE)\n\n[1] \"0.0000000000000002\"\n\n\n\n\n\n\n\n\n\n\nHow are correlation and regression the same?\n\n\n\n\n\nIf you are interested in the relationship between the two concepts, we said correlation was a specific application of the general linear model. It describes the - standardised - covariation between two variables compared to their total variability. For values of -1 and 1, knowing the value of one variable perfectly correlates to the value of your other variable. As you approach 0, the relationship between the variables is less perfect, meaning there is more variability left over compared to the covariance.\nIn regression, we frame it as how much variance you explain compared to the total amount of variance. The more variance your predictor explains, the less unexplained variance there is left over. We no longer calculate r, we calculate \\(R^2\\) as the proportion of variance in your outcome explained by your model. A value of 0 would be you explain no variance and a value of 1 means you explain all the variance.\nYou can see the connection between the two by comparing the value of Pearson’s r from Activity 4 (-.70) to the value of \\(R^2\\) = .4905. If you take the square root to get r (sqrt(.4905)), you get .70, which is exactly the same absolute value since \\(R^2\\) can only be positive.\nSo, when you have a single continuous predictor, it is the exact same process as correlation, just expressed slightly different.\n\n\n\n\n8.3.3 Activity 7 - Calculating confidence intervals\nIn the standard lm() and summary() output, we get most of the key values we need for our inferential statistics, but the one thing missing is confidence intervals around our estimates. Fortunately, R has a built-in function called confint() for calculating confidence intervals using your linear model object.\n\nconfint(lm_redistribution)\n\n                           2.5 %     97.5 %\n(Intercept)            5.1301581  5.5035664\nfairness_satisfaction -0.4433442 -0.3517332\n\n\nNormally, you focus on the confidence interval around your slope estimate as the intercept is not usually super useful for interpreting your findings when you have a continuous predictor. Now, we can summarise the three key concepts of inferential statistics as:\n\nHypothesis testing: p &lt; .001, suggesting we can reject the null hypothesis assuming \\(\\alpha\\) = .05. Fairness and satisfaction is a significant predictor of support for wealth redistribution.\nEffect size: \\(b_1\\) = -0.40, suggesting fairness and satisfaction is a negative predictor.\nConfidence interval: [-0.44, -0.35], showing the precision around the slope estimate.\n\n\n\n\n\n\n\nTry this\n\n\n\nGreat work following along so far, but now it is time to test your understanding on a new set of variables. This time, use redistribution as your outcome, age as your predictor, and use dawtry_clean as your data. We can ask the same question as before: “What is the relationship between age and attitudes on wealth redistribution?”.\nApply simple linear regression to get your inferential statistics and answer the following questions:\n\nHypothesis testing: Assuming \\(\\alpha\\) = .05, age is a \nstatistically significant\nnon-significant predictor of support for wealth redistribution.\nEffect size: Rounded to 2 decimals, the age coefficient is \n4.01\n-0.003\n0.005\n0.22.\nConfidence interval: Rounded to 2 decimals, the lower bound of the age coefficient is \n3.59\n-0.01\n4.44\n0.01 and the upper bound is \n3.59\n-0.01\n4.44\n0.01.\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThe conclusions are the same as when we calculated the correlation where age is not a statistically significant predictor of support for wealth redistribution. As a regression model, we get the same conclusions expressed in a slightly different way. Age is negative, but the size of the slope is very small (-0.003) and non-significant (p = .625). We explain pretty much no variance in support for wealth redistribution (\\(R^2\\) = .0008), so age is not very informative as a predictor.\n\n# Create lm object for age as a predictor\nlm_age &lt;- lm(redistribution ~ age,\n             data = dawtry_clean)\n\n# summary of the model object\nsummary(lm_age)\n\n# confidence intervals around estimates\nconfint(lm_age)\n\n\nCall:\nlm(formula = redistribution ~ age, data = dawtry_clean)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.93382 -0.69527  0.08099  0.84379  2.13621 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  4.011931   0.216042   18.57   &lt;2e-16 ***\nage         -0.002693   0.005499   -0.49    0.625    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.153 on 302 degrees of freedom\n  (1 observation deleted due to missingness)\nMultiple R-squared:  0.0007938, Adjusted R-squared:  -0.002515 \nF-statistic: 0.2399 on 1 and 302 DF,  p-value: 0.6246\n\n                  2.5 %     97.5 %\n(Intercept)  3.58679351 4.43706821\nage         -0.01351424 0.00812738\n\n\n\n\n\n\n8.3.4 Activity 8 - Centering and standardising predictors\nSo far, we have covered specifying your outcome and predictor variables as their raw values in the data. However, there are two variations that are useful to understand: centering and standardising predictors. These do not change the model fitting or p-values, but change how you interpret the intercept and/or slope.\n\n8.3.4.1 Centering predictors\nCentering predictors is where you change the values of your predictor, but not their scale. Typically, this means substracting the mean of your predictor from each observation. This changes how you interpret the intercept of your regression model.\nRemember the interpretation of the intercept is the predicted value of your outcome when your predictor is set to 0. If 0 is not present in your data or a value of 0 would be uninformative, the intercept can be difficult to interpret. When you center your predictor, 0 becomes the mean value of your predictor. So, the intercept is now the predicted value of your outcome for the mean value of your predictor, but the slope itself does not change. You can see the impact of this by plotting the data side by side in Figure 8.1.\n\ndawtry_clean &lt;- dawtry_clean %&gt;% \n  # subtract fairness values from mean of fairness\n  mutate(fairness_center = fairness_satisfaction - mean(fairness_satisfaction))\n\n\n\n\n\nFigure 8.1: Top: The relationship between wealth redistribution and perceived fairness and satisfaction using raw values. Bottom: The relationship after centering perceived fairness and satisfaction values.\n\n\n\nThe relationship between the two variables is exactly the same, but the values of fairness and satisfaction shifted so the mean is 0. If you create a new linear model object, you can see the difference this makes to the output.\n\nlm_center &lt;- lm(redistribution ~ fairness_center, \n                data = dawtry_clean)\n\nsummary(lm_center)\n\n\nCall:\nlm(formula = redistribution ~ fairness_center, data = dawtry_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9193 -0.5279  0.0233  0.4782  3.3634 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      3.90984    0.04706   83.09   &lt;2e-16 ***\nfairness_center -0.39754    0.02328  -17.08   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8218 on 303 degrees of freedom\nMultiple R-squared:  0.4905,    Adjusted R-squared:  0.4888 \nF-statistic: 291.7 on 1 and 303 DF,  p-value: &lt; 2.2e-16\n\n\nEvery single one of the values remains the same apart from the intercept. Now, we can interpret it as the predicted value of redistribution when fairness and satisfaction is set to 0, i.e., the mean value. So, for the mean value of fairness and satisfaction, we would predict a value of 3.91 for redistribution.\n\n8.3.4.2 Standardising predictors\nStandardising predictors is where you first convert your values to z-scores. This means you interpret the values as standard deviations rather than your original units. This is more useful in multiple regression (Chapter 14) to compare the magnitude of predictors, but it is useful to get used to now when you only have one predictor to focus on.\nThe first step is to standardise all your variables, not just the predictor this time. This involves subtracting the mean of your variable from each value, and dividing by the standard deviation of the variable. They now have a mean of 0 and a standard deviation of 1.\n\n# Be careful with the bracket placement to subtract the mean first\ndawtry_clean &lt;- dawtry_clean %&gt;% \n  mutate(redistribution_std = (redistribution - mean(redistribution)) / sd(redistribution),\n         fairness_std = (fairness_satisfaction - mean(fairness_satisfaction)) / sd(fairness_satisfaction))\n\nOnce we enter them into the model, we no longer have values in the original units of measurement, we now have them expressed as standard deviations.\n\nlm_standardised &lt;- lm(redistribution_std ~ fairness_std, \n                      data = dawtry_clean)\n\nsummary(lm_standardised)\n\n\nCall:\nlm(formula = redistribution_std ~ fairness_std, data = dawtry_clean)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.53979 -0.45930  0.02026  0.41604  2.92617 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -1.603e-16  4.094e-02    0.00        1    \nfairness_std -7.003e-01  4.101e-02  -17.08   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.715 on 303 degrees of freedom\nMultiple R-squared:  0.4905,    Adjusted R-squared:  0.4888 \nF-statistic: 291.7 on 1 and 303 DF,  p-value: &lt; 2.2e-16\n\n\nLike centering, the model fit and p-values do not change again, apart from the intercept. The relationship between the variables is exactly the same, but we changed their units. The intercept is tiny and close enough to zero that the p-value is 1.\nMore importantly, the slope is now expressed in standard deviations. Annoyingly, R prints the values in scientific notation, so this can be awkward to read (remember the format() function). Now, for every 1 standard deviation increase in our predictor, we predict the outcome to decrease by 0.70 standard deviations.\n\n\n\n\n\n\nTip\n\n\n\nIt is important to demonstrate the underlying concepts first but if you want a shortcut without needing to standardise all your variables, the effectsize package has a handy function called standardize_parameters() which you can apply to your initial lm() object.\n\nstandardize_parameters(lm_redistribution)\n\n\n\n\nParameter\nStd_Coefficient\nCI\nCI_low\nCI_high\n\n\n\n(Intercept)\n0.00000\n0.95\n-0.0805627\n0.0805627\n\n\nfairness_satisfaction\n-0.70034\n0.95\n-0.7810351\n-0.6196449"
  },
  {
    "objectID": "08-lm-continuous.html#checking-assumptions",
    "href": "08-lm-continuous.html#checking-assumptions",
    "title": "\n8  Regression with one continuous predictor\n",
    "section": "\n8.4 Checking assumptions",
    "text": "8.4 Checking assumptions\nFor the inferential statistics to work as intended, the model makes certain assumptions about the data you are putting into it and the accuracy of the inferences depends on how sensible these assumption are. Remember these functions will always work even if the numbers you enter are nonsense, so it’s important for you as the researcher to recognise when it’s appropriate to use these techniques and when it is not.\n\n8.4.1 Activity 9 - Diagnostic plots for linear regression\nAs a reminder, the assumptions for simple linear regression are:\n\nThe outcome is interval/ratio level data.\nThe predictor variable is interval/ratio or categorical (with two levels at a time).\nAll values of the outcome variable are independent (i.e., each score should come from a different participant/observation).\nThe predictors have non-zero variance.\nThe relationship between the outcome and predictor is linear.\nThe residuals should be normally distributed.\nThere should be homoscedasticity.\n\nAssumptions 1-4 are pretty straight forward as they relate to your understanding of the design or a simple check on the data for non-zero variance (the responses are not all the exact same value).\nAssumptions 5-7 require diagnostic checks on the residuals from the model. The residuals are the difference between your observed values in the data and the values your model predicts given it’s assumptions. If you remember back, we highlighted the model output mentioned Residuals: and they are saved within the model object.\n\n# head shows the first 6 values \nhead(lm_redistribution$residuals)\n\n         1          2          3          4          5          6 \n 0.5806764 -0.6754769  0.4208311  0.2159084 -0.5279383 -0.5730156 \n\n\n\n\n\n\n\n\nWhat does the $ symbol mean?\n\n\n\nWe have not used this symbol in the book yet, but it is a base R operator for extracting information. You use it to access specific components within a data frame or object.\nTry the following in the console to see what it does:\n\ndawtry_clean$age\nlm_redistribution$coefficients\n\nIf you type an object name into the console and add the $, you will see all the components appear to auto complete.\n\n\nIn your reading, you might see individual statistical tests to check these assumptions, but they have more limitations than benefits. The best way to check the assumptions is through diagnostic plots which express the model residuals in different ways. We want to walk through this longer way of checking assumptions to develop a solid understanding before showing you a shortcut to see them all below.\nIn the code below, we use a format you will be less familiar with as all these functions come from base R. If you just run the code for the diagnostic plots plot(lm_redistribution), each one gets individually printed to your Plots window. Here, we create a 2x2 panel to show them all together.\n\n# Change the panel layout to 2 x 2\npar(mfrow=c(2,2))\n\n# plot the diagnostic plots \nplot(lm_redistribution)\n\n\n\n\n\n\n\nFor more information on each of these plots, see this great resource by Kim (2015) via the University of Virginia, but we will break the key ones down below.\n\n8.4.2 Checking linearity\nTo isolate each plot, we can use the which argument. Plot 1 is a residuals vs fitted plot and helps us check linearity by showing the residuals on the y-axis and the fitted (predicted) values on the x-axis.\n\nplot(lm_redistribution, \n     which = 1)\n\n\n\n\n\n\n\nHere, you are looking out for a roughly flat horizontal red line. Common patterns to look out for if there is a problem are when the line has an obvious curve to look like a hump or several bends to look like an S.\nThe only downside to using diagnostic plots is it takes experience to recognise when there is nothing wrong with a regression model compared to when it violates the assumptions. It is easy to see a little deviation and think there is some drastically wrong. Our advice is if you squint and it looks fine, it is probably fine. You are looking for clear and obvious deviations from what you expect and all the models we use in Chapters 8 and 9 are intentionally fine to develop foundational skills. In Chapter 11, we then introduce you to more problematic cases and what your options are.\n\n\n\n\n\n\nError mode\n\n\n\nIf you want to save these plots to add into a report, you might try using ggsave() like we have covered in the data visualisation chapters. However, it will not work as these plots have not been created by ggplot2.\nTo save these plots, you can either right click and choose save as to save on your computer. Alternatively, if they open in the Plots window, you can click on Export and save them as an image or PDF to insert into your documents.\n\n\n\n8.4.3 Checking normality\nPlot 2 is a qq-plot (quantile-quantile plot) and helps us check the normality of the model residuals by showing the standardised residuals on the y-axis and the theoretical quantiles on the x-axis. A common misconception is your variables should all be normally distributed, but it is actually the model residuals which should be normal.\n\nplot(lm_redistribution, \n     which = 2)\n\n\n\n\n\n\n\nIn this plot, you are looking for the data points to roughly follow the dashed line. The idea is there should be a linear relationship between the residuals and the values we would expect under a normal distribution.\nLike the other diagnostic plots, it is tempting to think there are problems where there are none. The vast majority of the points here follow the line nicely, but tail off a little at the extremes. It flags the points with the largest deviations but there do not appear to be any obvious problems.\nWhen there are problems with normality, you are looking for obvious deviations, like the points curving around in a banana shape, or snaking around like an S.\n\n8.4.4 Checking homoscedasticity\nPlot 3 is a scale-location plot and helps us check homoscedasticity by showing the square root of the standardised residuals on the y-axis and the fitted values on the x-axis. Homoscedasticity is where the variance of the residuals is approximately equal across the range of your predictor(s).\n\nplot(lm_redistribution, \n     which = 3)\n\n\n\n\n\n\n\nIn this plot, you are looking out for a roughly random spread of points as you move from one end of the x-axis to the other. The red line should be roughly flat and horizontal.\nWhen there is heteroscedasticity, the characteristic patterns to look out for are a kind of arrow shape where there is a wide spread of points at one end and decreases to a denser range at the other end, or a bow tie where there is a wide spread of points at each end and dense in the middle.\n\n8.4.5 Checking influential cases\nFinally, there are two main plots to help us identify influential cases. You might have heard of the term outlier before and this is one way of classifying data points that are different enough to the rest of the data in a regression model. It is not strictly an assumption of linear regression, but it can affect the other assumptions. Identifying outliers is a complex decision and we will explore your options in the course materials and Chapter 11 on data screening.\nIf you only run plot(lm_redistribution) and cycle through the plots, you do not see this version. This plot shows values of Cook’s distance for each observation in your data along the x-axis. Cook’s distance measures the influence of deleting a given observation, where higher values mean deleting that observation results in a larger change to the model estimates. There are different thresholds in the literature, but estimates range from 1, 0.5, to 4/n. We explore the decision making around this and your options in Chapter 11.\n\nplot(lm_redistribution, \n     which = 4)\n\n\n\n\n\n\n\nFinally, we get a residuals vs leverage plot to show influential cases in a slightly different way. Instead of just the Cook’s distance value of each observation, it plots the standardised residuals against leverage values.\n\nplot(lm_redistribution, \n     which = 5)\n\n\n\n\n\n\n\nInfluential points and potential outliers would have high leverage values and the plot will show a threshold of Cook’s distance as red dashed lines. In this plot, they are not visible as there is no value with a big enough leverage value, but you would be looking for data points outside this threshold to identify influential values.\n\n8.4.6 Checking all the assumptions\nNow we have covered the individual diagnostic plots, there is a handy function called check_model() from the performance package. This function reports all the diagnostic checks from plot(), but tidies up the presentation and has some useful reminders of what you are looking for.\n\ncheck_model(lm_redistribution)\n\n\n\n\n\n\n\nThe key difference is you get a posterior predictive check (essentially comparing values you observe compared to what your model predicts) and the qq-plot for normality of residuals looks a little different. Instead of a kind of angled line, the residuals are expressed as deviations instead, so the points should be close to a flat horizontal line. This version can make smaller deviations look worse, so keep in mind again you are looking for clear deviations in the overall pattern.\n\n\n\n\n\n\nNote\n\n\n\nThe performance version of the diagnostic plots are actually created using ggplot2, so the function ggsave() would work here if you need to save the plot to add into your report.\n\n\n\n\n\n\n\n\nTry this\n\n\n\nIn activity 7, you should have calculated the relationship between age and support for redistribution for your independent task. Using the model object lm_age, work through assumptions for simple linear regression and make a note of whether you think it meets the assumptions, or there might be any problems. Some of the assumptions you consider what you know about the design, while others you need the diagnostic plots.\n\nThe outcome is interval/ratio level data.\nThe predictor variable is interval/ratio or categorical (with two levels at a time).\nAll values of the outcome variable are independent (i.e., each score should come from a different participant/observation).\nThe predictors have non-zero variance.\nThe relationship between the outcome and predictor is linear.\nThe residuals should be normally distributed.\nThere should be homoscedasticity.\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\n\nThe outcome is interval/ratio level data.\n\nThere is a debate here we cover in the course materials, but there is an argument you can treat the average of multiple Likert items as interval, but you need to be careful.\n\nThe predictor variable is interval/ratio or categorical (with two levels at a time).\n\nOur predictor age is nicely ratio.\n\nAll values of the outcome variable are independent (i.e., each score should come from a different participant/observation).\n\nYou need to know this from the design / data collection, but it appears to be the case in this study.\n\nThe predictors have non-zero variance.\n\nThere are a range of ages in the data.\n\nThe relationship between the outcome and predictor is linear.\n\nLooking at the first plot, the red line is pretty flat and horizontal, so we are happy with this.\n\nplot(lm_age, which = 1)\n\n\n\n\n\n\n\n\nThe residuals should be normally distributed.\n\nThe qq-plot is fine for the vast majority of the range. We just have a few deviations in the extreme ends of the x-axis, but this is a byproduct of using a scale score as our outcome as responses cannot go beyond 1-6.\n\nplot(lm_age, which = 2)\n\n\n\n\n\n\n\n\nThere should be homoscedasticity.\n\nThe red line is pretty flat and it looks like there is a fairly even range of values across the x-axis range.\n\nplot(lm_age, which = 3)\n\n\n\n\n\n\n\nAll in all, there do not appear to be any issues with the assumptions here."
  },
  {
    "objectID": "08-lm-continuous.html#reporting-your-results",
    "href": "08-lm-continuous.html#reporting-your-results",
    "title": "\n8  Regression with one continuous predictor\n",
    "section": "\n8.5 Reporting your results",
    "text": "8.5 Reporting your results\nNow we have some results to go with, there are a few recommendations on how to communicate that information. In psychology (and other disciplines), we tend to follow the American Psychological Association (APA) formatting guidelines as they provide a comprehensive standardised style to make sure information is being reported as easily digestible and consistent as possible. You can see this PDF online for a little cheat sheet for numbers and statistics, but we will outline some key principles to ensure you provide your reader with enough information.\n\nExplain to the reader what your linear regression model was. For example, what was your outcome and predictor variable?\nReport descriptive statistics to help contextualise your findings. For example, the mean/standard deviation for your outcome and continuous predictor.\nProvide an appropriate data visualisation to help communciate key patterns to the reader. For example, a scatterplot for the relationship between your outcome and predictor.\nReport all three key inferential statistics concepts for the coefficient: the slope, the confidence interval around your slope, and the p-value for hypothesis testing. When you have one predictor in simple linear regression, you typically focus on the slope as your key effect size that helps address your research question and hypothesis. APA style rounds numbers to 2 decimal places when numbers can be bigger than 1, and 3 decimals with no leading zero when it cannot be bigger than 1. When you report the unstandardised slope, you use the symbol \\(b_1\\) but for the standardised slope, you use Beta instead \\(\\beta_1\\).\nProvide an overview of the model fit statistics for whether your model explained a significant amount of variance in your outcome. Remember: the p-value for your model will be the same as for the slope in simple linear regression.\n\nFor our main example, we could summarise the findings as:\n“Our research question was: is there a relationship between support for wealth redistribution and fairness and satisfaction with the current system? To test this, we applied simple linear regression using fairness and satisfaction as a predictor and support for wealth redistribution as our outcome. Figure 1 shows a scatterplot of the relationship.\n\n\n\n\n\n\n\n\nOur model explained a statistically significant amount of variance in our outcome (adjusted \\(R^2\\) = .489, F(1, 303) = 291.70, p &lt; .001). Fairness and satisfaction was a negative predictor, where for every 1-unit increase we expect support for redistribution to decrease by 0.40 (\\(b_1 = -0.40\\), 95% CI = [-0.44, -0.35], p &lt; .001).”\nNote: we have not included an APA formatted Figure title here as it is not easy to format in our book, so refer to the course materials for guidance."
  },
  {
    "objectID": "08-lm-continuous.html#test-yourself",
    "href": "08-lm-continuous.html#test-yourself",
    "title": "\n8  Regression with one continuous predictor\n",
    "section": "\n8.6 Test Yourself",
    "text": "8.6 Test Yourself\nTo end the chapter, we have some knowledge check questions to test your understanding of the concepts we covered in the chapter. We then have some error mode tasks to see if you can find the solution to some common errors in the concepts we covered in this chapter.\n\n8.6.1 Knowledge check\nFor this chapter’s knowledge check section, we have something a little different. Instead of purely conceptual questions about functions, we have another example of linear regression from Dawtry et al. (2015). Feel free to create this model yourself, but we will show you some output and ask you questions based on it.\nFor this model, we focus on the two variables estimated population inequality index (Population_Inequality_Gini_Index) and support for wealth redistribution (redistribution). Check back to the code book in Activity 2 if you need a reminder of what the variables mean.\nQuestion 1. In the scatterplot of the relationship below, this shows a negative relationship between the inequality index and support for redistribution: \nTRUE\nFALSE.\n\n\n\n\n\n\n\n\nQuestion 2 For the next few questions, we have the output from a linear regression model and we would like you to interpret it.\n\n\n\nCall:\nlm(formula = redistribution ~ Population_Inequality_Gini_Index, \n    data = dawtry_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9478 -0.6384  0.1389  0.8511  2.3854 \n\nCoefficients:\n                                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                      3.097452   0.316914   9.774  &lt; 2e-16 ***\nPopulation_Inequality_Gini_Index 0.022879   0.008734   2.619  0.00925 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.139 on 303 degrees of freedom\nMultiple R-squared:  0.02214,   Adjusted R-squared:  0.01892 \nF-statistic: 6.861 on 1 and 303 DF,  p-value: 0.009251\n\n\nThe outcome variable in this model is \nAttitudes on Wealth Redistribution\nPopulation Inequality Index and the predictor variable is \nAttitudes on Wealth Redistribution\nPopulation Inequality Index.\nQuestion 3 Rounded to 2 decimals, when the predictor is 0, we predict a value of  for our outcome variable.\nQuestion 4 The predictor is \nsignificant\nnon-significant with a p-value of .\nQuestion 5 The predictor is \npositive\nnegative, where we expect for every 1-unit increase in the predictor a  -unit \nincrease\ndecrease in the outcome.\n\n8.6.2 Error mode\nThe following questions are designed to introduce you to making and fixing errors. For this topic, we focus on simple linear regression between two continuous variables. There are not many outright errors that people make here, more misspecifications that are not doing what you think they are doing.\nCreate and save a new R Markdown file for these activities. Delete the example code, so your file is blank from line 10. Create a new code chunk to load tidyverse and wrangle the data files:\n\n# Load the packages below\nlibrary(tidyverse)\nlibrary(effectsize)\nlibrary(correlation)\nlibrary(performance)\n\n# Load the data file\n# This should be the Dawtry_2015.csv file \ndawtry_data &lt;- read_csv(\"data/Dawtry_2015.csv\")\n\n# Reverse code redist2 and redist4\ndawtry_data &lt;- dawtry_data %&gt;%\n  mutate(redist2_R = 7 - redist2,\n         redist4_R = 7 - redist4)\n\n# calculate mean fairness and satisfaction score  \nfairness_satisfaction &lt;- dawtry_data %&gt;% \n  pivot_longer(cols = fairness:satisfaction, \n               names_to = \"Items\", \n               values_to = \"Response\") %&gt;% \n  group_by(PS) %&gt;% \n  summarise(fairness_satisfaction = mean(Response)) %&gt;% \n  ungroup()\n\n# calculate mean wealth redistribution score  \nredistribution &lt;- dawtry_data %&gt;% \n  pivot_longer(cols = c(redist1, redist2_R, redist3, redist4_R), \n               names_to = \"Items\", \n               values_to = \"Response\") %&gt;% \n  group_by(PS) %&gt;% \n  summarise(redistribution = mean(Response)) %&gt;% \n  ungroup()\n\n# join data and select columns for focus\ndawtry_clean &lt;- dawtry_data %&gt;% \n  inner_join(fairness_satisfaction, by = \"PS\") %&gt;% \n  inner_join(redistribution, by = \"PS\") %&gt;% \n  select(PS, Household_Income:redistribution, -redist2_R, -redist4_R)\n\nBelow, we have several variations of a misspecification. Copy and paste them into your R Markdown file below the code chunk to wrangle the data. Once you have copied the activities, click knit and look at the output you receive. See if you can identify the mistake and fix it before checking the answer.\nQuestion 6. Copy the following code chunk into your R Markdown file and press knit. We want to create a simple linear regression model to specify fairness_satisfaction as our outcome variable and Political_Preference as our predictor. Have we expressed that accurately?\n```{r}\nlm_fairness &lt;- lm(Political_Preference ~ fairness_satisfaction,\n                        data = dawtry_clean)\n\nsummary(lm_fairness)\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nIn this example, we mixed up the variables. The formula in lm() has the form outcome ~ predictor, so we mixed up the order. In simple linear regression, it makes no difference to the slope, but it is important to be able to express your model accurately and it would make a difference once you scale up to multiple linear regression.\n\nlm_fairness &lt;- lm(fairness_satisfaction ~ Political_Preference,\n                        data = dawtry_clean)\n                        \nsummary(lm_fairness)\n\n\n\n\nQuestion 7. Copy the following code chunk into your R Markdown file and press knit. We want to standardise the outcome and predictors, so that we get the intercept and slope estimates in standard deviations. Have we expressed that accurately?\n```{r}\ndawtry_clean &lt;- dawtry_clean %&gt;% \n  mutate(fairness_std = (fairness_satisfaction - mean(fairness_satisfaction)) / sd(fairness_satisfaction))\n\nlm_fairness &lt;- lm(fairness_std ~ Political_Preference,\n                        data = dawtry_clean)\n                        \nsummary(lm_fairness)\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nIn this example, we only standardised the outcome. When we standardise predictors, we must standardise both the outcome and predictor so they are expressed in standard deviations. It is just when we center, we only center the predictor.\n\ndawtry_clean &lt;- dawtry_clean %&gt;% \n  mutate(fairness_std = (fairness_satisfaction - mean(fairness_satisfaction)) / sd(fairness_satisfaction),\n         Political_std = (Political_Preference - mean(Political_Preference, na.rm = TRUE)) / sd(Political_Preference, na.rm = TRUE))\n\nlm_fairness &lt;- lm(fairness_std ~ Political_std,\n                        data = dawtry_clean)\n                        \nsummary(lm_fairness)"
  },
  {
    "objectID": "08-lm-continuous.html#words-from-this-chapter",
    "href": "08-lm-continuous.html#words-from-this-chapter",
    "title": "\n8  Regression with one continuous predictor\n",
    "section": "\n8.7 Words from this Chapter",
    "text": "8.7 Words from this Chapter\nBelow you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the PsyTeachR Glossary. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter.\n\n\n\nterm\ndefinition\n\n\n\ncentered-predictors\nUsually, centering a predictor means subtracting the mean from each value, so the mean is 0. You can then interpret the intercept as the value of your outcome for the mean value of your predictor(s).\n\n\nlist\nA container data type that allows items with different data types to be grouped together.\n\n\noutcome\nThe outcome (also known as the dependent variable) is the variable you are interested in seeing a potential change in.\n\n\npearson\nA standardised measure of the linear relationship between two variables that makes stringent assumptions about the population.\n\n\npredictor\nThe predictor (also known as an independent variable) is the variable you measure or manipulate to see how it is associated with changes in the outcome variable.\n\n\nresiduals\nThe difference between the observed value in the data and the predicted value from the model given its assumptions.\n\n\nspearman\nA standardised measure of the relationship between two variables that assumes a monotonic - but not necessarily a linear - relationship and makes less stringent assumptions about the population.\n\n\nstandardised-predictors\nStandardising involves substracting the variable mean from each value and dividing it by the variable standard deviation. It then has the property of a mean of 0 and standard deviation of 1, so you interpret the units as standard deviations."
  },
  {
    "objectID": "08-lm-continuous.html#end-of-chapter",
    "href": "08-lm-continuous.html#end-of-chapter",
    "title": "\n8  Regression with one continuous predictor\n",
    "section": "\n8.8 End of chapter",
    "text": "8.8 End of chapter\nGreat work, that was your first chapter working on inferential statistics!\nWe have spent so long developing your data wrangling and visualisation skills that the code for statistical models is pretty short. Hopefully, you now believe us when we said almost all the work goes into wrangling your data into a format you can analyse. Once it comes to inferential statistics, it shifts from wrangling the data being the most difficult to being able to express your research question/design and interpret the outcome being the most difficult.\nIn the next chapter, we reinforce most of the content by applying simple linear regression to a categorical predictor. This is when you want to test for differences between two groups on your outcome instead of testing the relationship between two continuous variables.\n\n\n\n\nDawtry, R. J., Sutton, R. M., & Sibley, C. G. (2015). Why Wealthier People Think People Are Wealthier, and Why It Matters: From Social Sampling to Attitudes to Redistribution. Psychological Science, 26(9), 1389–1400. https://doi.org/10.1177/0956797615586560"
  },
  {
    "objectID": "09-lm-categorical.html#chapter-preparation",
    "href": "09-lm-categorical.html#chapter-preparation",
    "title": "\n9  Regression with one categorical predictor\n",
    "section": "\n9.1 Chapter preparation",
    "text": "9.1 Chapter preparation\n\n9.1.1 Introduction to the data set\nFor most of this chapter, we are using open data from Lopez et al. (2023). The abstract of their article is:\n\nImagine a bowl of soup that never emptied, no matter how many spoonfuls you ate—when and how would you know to stop eating? Satiation can play a role in regulating eating behavior, but research suggests visual cues may be just as important. In a seminal study by Wansink et al. (2005), researchers used self-refilling bowls to assess how visual cues of portion size would influence intake. The study found that participants who unknowingly ate from self-refilling bowls ate more soup than did participants eating from normal (not self-refilling) bowls. Despite consuming 73% more soup, however, participants in the self-refilling condition did not believe they had consumed more soup, nor did they perceive themselves as more satiated than did participants eating from normal bowls. Given recent concerns regarding the validity of research from the Wansink lab, we conducted a preregistered direct replication study of Wansink et al. (2005) with a more highly powered sample (N = 464 vs. 54 in the original study). We found that most results replicated, albeit with half the effect size (d = 0.45 instead of 0.84), with participants in the self-refilling bowl condition eating significantly more soup than those in the control condition. Like the original study, participants in the selfrefilling condition did not believe they had consumed any more soup than participants in the control condition. These results suggest that eating can be strongly controlled by visual cues, which can even override satiation.\n\nIn summary, they replicated an (in)famous experiment that won the Ig-Nobel prize. Participants engaged in a intricate setting (seriously, go and look at the diagrams in the article) where they ate soup from bowls on a table. In the control group, participants could eat as much soup as they wanted and could ask for a top-up from the researchers. In the experimental group, the soup bowls automatically topped up through a series of hidden tubes under the table. The idea behind the control group is they get an accurate visual cue by the soup bowl reducing, and the experimental group get an inaccurate visual cue by the soup bowl seemingly never reducing. So, the inaccurate visual cue would interfere with natural signs of getting full and lead to people eating more.\nIn the original article, participants in the experimental group ate more soup than participants in the control group, but the main author was involved in a series of research misconduct cases. Lopez et al. (2023) wanted to see if the result would replicate in an independent study, so they predicted they would find the same results. In this chapter, we will explore the difference between the control and experimental groups on several variables in their data set.\n\n9.1.2 Organising your files and project for the chapter\nBefore we can get started, you need to organise your files and project for the chapter, so your working directory is in order.\n\nIn your folder for research methods and the book ResearchMethods1_2/Quant_Fundamentals, create a new folder called Chapter_09_regression_categorical. Within Chapter_09_regression_categorical, create two new folders called data and figures.\nCreate an R Project for Chapter_09_regression_categorical as an existing directory for your chapter folder. This should now be your working directory.\nCreate a new R Markdown document and give it a sensible title describing the chapter, such as 09 t-tests and Regression. Delete everything below line 10 so you have a blank file to work with and save the file in your Chapter_09_regression_categorical folder.\nWe are working with a new data set, so please save the following data file: Lopez_2023.csv. Right click the link and select “save link as”, or clicking the link will save the files to your Downloads. Make sure that you save the file as “.csv”. Save or copy the file to your data/ folder within Chapter_09_regression_categorical.\n\nYou are now ready to start working on the chapter!\n\n9.1.3 Activity 1 - Read and wrangle the data\nAs the first activity, try and test yourself by completing the following task list to practice your data wrangling skills. In this example, there is not loads to do, you just need to tidy up some variables. Create a final object called lopez_clean to be consistent with the tasks below. If you want to focus on t-tests and regression, then you can just type the code in the solution.\n\n\n\n\n\n\nTry this\n\n\n\nTo wrangle the data, complete the following tasks:\n\n\nLoad the following packages:\n\ntidyverse\neffectsize\nperformance\n\n\nRead the data file data/Lopez_2023.csv to the object name lopez_data.\n\nCreate a new object called lopez_clean based on lopez_data:\n\nModify the variable Condition to turn it into a factor.\nCreate a new variable called Condition_label by recoding Condition. “0” is the “Control” group and “1” is the “Experimental” group.\n\n\n\nYour data should look like this to be ready to analyse:\n\n\nRows: 464\nColumns: 10\n$ ParticipantID      &lt;dbl&gt; 1002, 1004, 1007, 1016, 1018, 1021, 1022, 1024, 102…\n$ Sex                &lt;dbl&gt; 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, …\n$ Age                &lt;dbl&gt; 18, 19, 19, 21, 20, 20, 21, 21, 19, 20, 21, 20, 21,…\n$ Ethnicity          &lt;dbl&gt; 7, 3, 3, 4, 1, 3, 1, 6, 4, 7, 1, 3, 3, 4, 7, 2, 3, …\n$ OzEstimate         &lt;dbl&gt; 3.0, 2.0, 1.0, 3.0, 5.0, 1.0, 1.0, 3.0, 4.0, 1.0, 4…\n$ CalEstimate        &lt;dbl&gt; 65, 10, 20, 25, 50, 5, 20, 180, 470, 50, 130, 100, …\n$ M_postsoup         &lt;dbl&gt; 3.3, 3.1, 43.4, 5.5, 6.0, 0.8, 3.8, 4.5, 7.9, 8.1, …\n$ F_CaloriesConsumed &lt;dbl&gt; 73.19441, 68.75839, 962.61743, 121.99069, 133.08075…\n$ Condition          &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Condition_label    &lt;chr&gt; \"Control\", \"Control\", \"Control\", \"Control\", \"Contro…\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# load the relevant packages\nlibrary(effectsize)\nlibrary(performance)\nlibrary(tidyverse)\n\n# Read the Lopez_2023.csv file \nlopez_data &lt;- read_csv(\"data/Lopez_2023.csv\")\n\n# turn condition into a factor and recode\nlopez_clean &lt;- lopez_data %&gt;% \n  mutate(Condition = as.factor(Condition),\n         Condition_label = case_match(Condition,\n                                      \"0\" ~ \"Control\",\n                                      \"1\" ~ \"Experimental\"))\n\n\n\n\n\n9.1.4 Activity 2 - Explore the data\n\n\n\n\n\n\nTry this\n\n\n\nAfter the wrangling steps, try and explore lopez_clean to see what variables you are working with. For example, opening the data object as a tab to scroll around, explore with glimpse(), or try plotting some of the individual variables.\n\n\nIn lopez_clean, we have the following variables:\n\n\n\n\n\n\n\nVariable\nType\nDescription\n\n\n\nParticipantID\ndouble\nParticipant ID number.\n\n\nSex\ndouble\nParticipant sex.\n\n\nAge\ndouble\nParticipant age in years.\n\n\nEthnicity\ndouble\nParticipant ethnicity.\n\n\nOzEstimate\ndouble\nEstimated soup consumption in ounces (Oz).\n\n\nCalEstimate\ndouble\nEstimated soup consumption in calories (kcals).\n\n\nM_postsoup\ndouble\nActual soup consumption in ounces (Oz).\n\n\nF_CaloriesConsumed\ndouble\nActual soup consumption in calories (kcals).\n\n\nCondition\ninteger\nCondition labelled numerically as 0 (Control) and 1 (Experimental).\n\n\nCondition_label\ncharacter\nCondition as a direct label: Control and Experimental.\n\n\n\nWe will use this data set to demonstrate t-tests and regression when you have one categorical predictor."
  },
  {
    "objectID": "09-lm-categorical.html#comparing-differences-using-the-t-test",
    "href": "09-lm-categorical.html#comparing-differences-using-the-t-test",
    "title": "\n9  Regression with one categorical predictor\n",
    "section": "\n9.2 Comparing differences using the t-test",
    "text": "9.2 Comparing differences using the t-test\nLike correlations are a specific application of the general linear model for the relationship between two continuous variables, t-tests are a specific application for the difference between two groups. Before we demonstrate how you can express this kind of design as a regression model, we cover t-tests so you know how to calculate and interpret them when you come across them in your research.\n\n9.2.1 Activity 3 - Visualising the difference\nTo visualise the difference between two groups, it is useful to create something like a boxplot early for yourself, then provide a more professional looking violin-boxplot to help communicate your results. For most of the demonstrations in this chapter, we will try and answer the research question: “Is there a difference in actual calories consumed between the control and experimental groups?”\n\n\n\n\n\n\nTry this\n\n\n\nUsing your data visualisation skills from Chapter 7, recreate the violin-boxplot below using the variables F_CaloriesConsumed and Condition_label from lopez_clean.\n\n\n\n\n\n\n\n\nLooking at the graph, the \nControl\nExperimental group consumed more calories on average.\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThe violin-boxplot shows the experimental group who had the biased visual cues consumed more soup in calories than the control group who had the accurate visual cues.\nYou should have the following in a code chunk:\n\nlopez_clean %&gt;% \n  ggplot(aes(y = F_CaloriesConsumed, x = Condition_label, fill = Condition_label)) +\n  geom_violin(alpha = 0.5) + \n  geom_boxplot(width = 0.2, \n               fatten = NULL) + \n  stat_summary(fun = \"mean\", \n               geom = \"point\") +\n  stat_summary(fun.data = \"mean_cl_boot\", # confidence interval\n               geom = \"errorbar\", \n               width = 0.1) +\n  scale_fill_viridis_d(option = \"E\") + \n  scale_y_continuous(name = \"Actual Calories Consumed (kcals)\") +\n  scale_x_discrete(name = \"Study Condition\") + \n  guides(fill = FALSE) + \n  theme_classic()\n\n\n\n\n\n9.2.2 Activity 4 - Using the t.test() function\nA t-test is a specific application of the general linear model. In this test, we express the difference in an outcome between two groups as a kind of standardised mean difference. If you are interested, see the Handy Workbook (McAleer, 2023) for the calculations behind the Student and Welch t-test. Conceptually, a t-test is the difference between two groups divided by the standard error of the difference. There are two main versions of a t-test:\n\nStudent t-test\nWelch t-test\n\nThere is a function built into R to calculate the t-test: t.test(). The function requires:\n\nA formula like lm() where you specify the outcome/dependent variable and the predictor/independent variable in the form outcome ~ predictor.\nThe data set you want to use.\n\nFor our lopez_clean data, we would run the following code for a two-tailed Welch t-test:\n\nt.test(formula = F_CaloriesConsumed ~ Condition_label, \n       data = lopez_clean)\n\n\n    Welch Two Sample t-test\n\ndata:  F_CaloriesConsumed by Condition_label\nt = -4.8578, df = 453.45, p-value = 1.638e-06\nalternative hypothesis: true difference in means between group Control and group Experimental is not equal to 0\n95 percent confidence interval:\n -88.55610 -37.54289\nsample estimates:\n     mean in group Control mean in group Experimental \n                  196.6818                   259.7313 \n\n\nFor the three key concepts of inferential statistics, we get\n\n\nHypothesis testing: p &lt; .001, suggesting we can reject the null hypothesis assuming \\(\\alpha\\) = .05.\n\n\n\n\n\n\n\nWhat does 1.638e-06 mean?\n\n\n\nRemember: R reports very small or very large numbers using scientific notation to save space. We normally report p-values to three decimals, so we report anything smaller as p &lt; .001 to say it is smaller than this.\nIf you want to see the real number, you can use the following function which shows just how small the p-value is:\n\nformat(1.638e-06, scientific = FALSE)\n\n[1] \"0.000001638\"\n\n\n\n\n\n\nEffect size: Somewhat annoyingly, we do not directly get the mean difference between groups as a raw/unstandardised mean difference. We must manually calculate it by subtracting the means of each group (196.6818 - 259.7313 = -63.05). So, those in the experimental group ate on average 63 more calories of soup than the control group.\n\n\n\n\n\n\n\nDoes it matter whether the difference is positive or negative?\n\n\n\nFor effect sizes describing the difference between two groups, it is the absolute difference which is important, providing it is consistent with your predictions (if applicable). If you entered the groups the other way around, the mean difference would become 259.7313 - 196.6818 = 63.05. The same applies when we calculate a standardised mean difference like Cohen’s d later.\n\n\n\n\nConfidence interval: [-88.56, -37.54], although we do not get the mean difference, we get the confidence interval around the mean difference.\n\nTo summarise: A Welch t-test showed participants in the experimental group ate significantly more calories of soup than participants in the control group, t (453.45) = -4.86, p &lt; .001. On average, those in the experimental group ate 63.05 (95% CI = [37.54, 88.56]) more calories than those in the control group.\nWhen you have statistics software like R to do the heavy lifting for you, there is not really a scenario where you would use the Student t-test anymore, but if you did, you can use the var.equal argument to say you assume there are equal variances in each group:\n\nt.test(formula = F_CaloriesConsumed ~ Condition_label, \n       data = lopez_clean, \n       var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  F_CaloriesConsumed by Condition_label\nt = -4.8625, df = 462, p-value = 1.591e-06\nalternative hypothesis: true difference in means between group Control and group Experimental is not equal to 0\n95 percent confidence interval:\n -88.52983 -37.56915\nsample estimates:\n     mean in group Control mean in group Experimental \n                  196.6818                   259.7313 \n\n\nYou can see the main difference between the two versions is the Welch t-test Student corrects the degrees of freedom, so they are a decimal. While the Student t-test does not correct the degrees of freedom, so they are predictably N - 2.\nTo summarise: A Student t-test showed participants in the experimental group ate significantly more calories of soup than participants in the control group, t (462) = -4.86, p &lt; .001. On average, those in the experimental group ate 63.05 (95% CI = [37.57, 88.53]) more calories than those in the control group.\nOne further useful argument is specifying a one-tailed test if you have a specific prediction. The only downside to using linear models later is there is not a simple argument to apply a one-tailed test.\n\nt.test(formula = F_CaloriesConsumed ~ Condition_label, \n       data = lopez_clean, \n       alternative = \"less\")\n\n\n    Welch Two Sample t-test\n\ndata:  F_CaloriesConsumed by Condition_label\nt = -4.8578, df = 453.45, p-value = 8.188e-07\nalternative hypothesis: true difference in means between group Control and group Experimental is less than 0\n95 percent confidence interval:\n     -Inf -41.6571\nsample estimates:\n     mean in group Control mean in group Experimental \n                  196.6818                   259.7313 \n\n\nThe difference here is specifying the alternative argument. You can use “less” or “greater” depending if you predict a negative (group A &lt; group B) or positive difference (group A &gt; group B).\n\n9.2.3 Activity 5 - Calculating Cohen’s d\nRaw/unstandardised effect sizes are great for putting results in context, particularly when the units are comparable across studies. For our outcome in this study, differences in calories are easy to put in context.\nAlternatively, it can be useful to calculate standardised effect sizes. This helps for power analyses (more on that in Chapter 10) and when you want to compare across comparable studies with slightly different measurement scales.\nThere are different formulas for calculating Cohen’s d, but if you know the t-value and degrees of freedom, you can calculate Cohen’s d through:\n\\(d = \\frac{2t}{\\sqrt{df}} = \\frac{-9.725}{21.49} = -0.45\\)\nIt is important to know the concepts before you use shortcuts, but there is the cohens_d() function from the effectsize package which uses the same format as t.test().\n\ncohens_d(F_CaloriesConsumed ~ Condition_label, \n         data = lopez_clean)\n\n\n\n\nCohens_d\nCI\nCI_low\nCI_high\n\n\n-0.4523004\n0.95\n-0.6366884\n-0.2674345\n\n\n\n\n\n\n\n\n\n\n\nTry this\n\n\n\nGreat work following along so far, but now it is time to test your understanding on a new set of variables. Use the variables CalEstimate and Condition_label from lopez_clean. We can ask the question: “What is the difference in estimated calories consumed between the experimental and control groups?”\n\nCreate a violin-boxplot to visualise the difference between CalEstimate and Condition_label from lopez_clean.\n\nApply the Welch t-test to get your inferential statistics and answer the following questions:\n\nHypothesis testing: Assuming \\(\\alpha\\) = .05, the difference between the experimental and control groups on estimated calories consumed was \nstatistically significant\nnot statistically significant.\nEffect size: Rounded to 2 decimals, the raw effect size was an average difference of  estimates calories between the two groups. Expressed as a standardised effect size, this difference equates to Cohen’s d = .\nConfidence interval: Rounded to 2 decimals, the 95% confidence interval for the mean difference is \n-4.08\n-0.03\n39.85\n0.33 to \n-4.08\n-0.03\n39.85\n0.33. The 95% confidence interval for Cohen’s d is \n-4.08\n-0.03\n39.85\n0.33 to \n-4.08\n-0.03\n39.85\n0.33.\n\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThe violin-boxplot shows little difference between the two groups on estimated calories consumed.\n\nlopez_clean %&gt;% \n  ggplot(aes(y = CalEstimate, x = Condition_label, fill = Condition_label)) +\n  geom_violin(alpha = 0.5) + \n  geom_boxplot(width = 0.2, \n               fatten = NULL) + \n  stat_summary(fun = \"mean\", \n               geom = \"point\") +\n  stat_summary(fun.data = \"mean_cl_boot\", # confidence interval\n               geom = \"errorbar\", \n               width = 0.1) +\n  scale_fill_viridis_d(option = \"E\") + \n  scale_y_continuous(name = \"Estimated Calories Consumed (kcals)\") +\n  scale_x_discrete(name = \"Study Condition\") + \n  guides(fill = FALSE) + \n  theme_classic()\n\n\n\n\n\n\n\nFor our inferential statistics, a Welch t-test showed the difference is not statistically significant, t (455.06) = 1.60, p = .110.\n\nt.test(formula = CalEstimate ~ Condition_label, \n       data = lopez_clean)\n\n\n    Welch Two Sample t-test\n\ndata:  CalEstimate by Condition_label\nt = 1.6001, df = 455.06, p-value = 0.1103\nalternative hypothesis: true difference in means between group Control and group Experimental is not equal to 0\n95 percent confidence interval:\n -4.080399 39.846433\nsample estimates:\n     mean in group Control mean in group Experimental \n                  133.0328                   115.1498 \n\n\nThe control group estimated they consumed 17.88 (95% CI = [-4.08, 39.85]) more calories than the experimental group, but the difference was not significant. Expressed as a standardised effect size, this equates to Cohen’s d = 0.15 (95% CI = [-0.03, 0.33]).\n\ncohens_d(CalEstimate ~ Condition_label, \n         data = lopez_clean)\n\n\n\n\nCohens_d\nCI\nCI_low\nCI_high\n\n\n0.1490887\n0.95\n-0.0341294\n0.332145"
  },
  {
    "objectID": "09-lm-categorical.html#09-categorical",
    "href": "09-lm-categorical.html#09-categorical",
    "title": "\n9  Regression with one categorical predictor\n",
    "section": "\n9.3 Linear regression with one categorical predictor",
    "text": "9.3 Linear regression with one categorical predictor\nNow you know how to calculate a t-test in R, we can turn to simple linear regression as a more flexible tool for modelling the difference between two groups. As a reminder, there is a chapter in the Handy Workbook (McAleer, 2023) dedicated to manually calculating simple linear regression if you want to work through what the functions are doing behind the scenes.\n\n9.3.1 Activity 6 - Descriptive statistics\nFor all the information we want to include in a report, calculating descriptive statistics is helpful for the reader to show the context behind the results you present. Here, we can report the mean and standard deviation of our outcome per group.\n\nlopez_clean %&gt;% \n  group_by(Condition_label) %&gt;% \n  summarise(mean_cals = round(mean(F_CaloriesConsumed), 2), \n            sd_cals = round(mean(F_CaloriesConsumed), 2))\n\n\n\n\nCondition_label\nmean_cals\nsd_cals\n\n\n\nControl\n196.68\n196.68\n\n\nExperimental\n259.73\n259.73\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you want some reinforcement of how these skills apply to published research, look at Table 1 in Lopez et al. (2023). The means and standard deviations here (and Cohen’s d from Activity 5) exactly reproduce the values they report, apart from the SD for the control group (maybe there is a typo in their article).\n\n\n\n9.3.2 Activity 7 - Using the lm() function\nFor our research question of “is there a difference in actual calories consumed between the control and experimental group?”, we can address it with simple linear regression. In this study, we can make causal conclusions as it was an experiment to randomly allocate people into one of two groups, but you can also use regression to compare two self-selecting groups when you cannot make a causal conclusion in isolation. Think carefully about what you can conclude from your design.\nLike Chapter 8, we start by defining our regression model with a formula in the pattern outcome ~ predictor and specify the data frame you want to use. We must then use the summary() function around your model object to get all the statistics you need.\nThere are two ways you can use a categorical predictor. First, we can code groups numerically which people called dummy coding. You code your first group 0 and you code your second group as 1, which maps on directly to how the regression model works. Let’s look at the output.\n\n# Condition as a factor containing 0 and 1\nlm_cals_numbers &lt;- lm(formula = F_CaloriesConsumed ~ Condition, \n                      data = lopez_clean)\n\nsummary(lm_cals_numbers)\n\n\nCall:\nlm(formula = F_CaloriesConsumed ~ Condition, data = lopez_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-230.90  -99.09  -24.15   62.83  828.04 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  196.682      8.888  22.130  &lt; 2e-16 ***\nCondition1    63.049     12.966   4.863 1.59e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 139.4 on 462 degrees of freedom\nMultiple R-squared:  0.04869,   Adjusted R-squared:  0.04663 \nF-statistic: 23.64 on 1 and 462 DF,  p-value: 1.591e-06\n\n\nCompared to when we had a continuous predictor in Chapter 8, the output is identical. We just need to remember what the key numbers represent. The intercept is the predicted value of your outcome when your predictor is set to 0. When we have two groups coded as 0 and 1, this means the intercept is essentially the mean value of group 0 (here, the control group). We call this the reference group. You can confirm this by comparing the intercept estimate 196.68 to the mean value of the control group we calculated in Activity 6.\nThe slope estimate then represents how we predict the outcome to change for every 1-unit increase in the predictor. Since we coded the predictor 0 and 1, this just represents the shift from group 1 to group 2. We call the group we code as 1 the target group. You see the target group appended to the variable name, which is Condition1 here. So, for a categorical predictor, the slope represents the mean difference between the reference group (0) and the target group (1): 63.05. In contrast to the t-test, this is our raw/unstandardised effect size for the mean difference we do not need to manually calculate.\n\n\n\n\n\n\nDoes it matter if the slope is positive or negative?\n\n\n\nWhen you have a categorical predictor, the sign is only important for interpreting which group is bigger or smaller. The absolute size is relevant for the effect size where a larger absolute value indicates a larger effect. Whether the slope is positive or negative depends on the order of the groups and which has a larger mean. If the reference is larger than the target, you will get a negative slope. If the target is larger than the reference, you will get a positive slope.\n\n\nLike the continuous predictor, we get values for \\(R^2\\) and adjusted \\(R^2\\), showing we explain .046 (in other words, 4.6%) variance in the outcome through our condition manipulation. We then get the model fit statistics, but with a single predictor, the p-value is identifical to the slope.\nAlternatively, you can use character labels for your categorical predictor and it will still work. This time, we use Condition_label. By default, it will set the order of the reference and target groups alphabetically, but you can manually specify the order by setting factor levels.\n\n# Condition_label as characters\nlm_cals_labels &lt;- lm(formula = F_CaloriesConsumed ~ Condition_label, \n                     data = lopez_clean)\n\nsummary(lm_cals_labels)\n\n\nCall:\nlm(formula = F_CaloriesConsumed ~ Condition_label, data = lopez_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-230.90  -99.09  -24.15   62.83  828.04 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                  196.682      8.888  22.130  &lt; 2e-16 ***\nCondition_labelExperimental   63.049     12.966   4.863 1.59e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 139.4 on 462 degrees of freedom\nMultiple R-squared:  0.04869,   Adjusted R-squared:  0.04663 \nF-statistic: 23.64 on 1 and 462 DF,  p-value: 1.591e-06\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you want to test specifying the factor order to see how it affects the output, try running this code prior to the regression model:\n\n# Specify group order of Experimental then Control\nlopez_clean &lt;- lopez_clean %&gt;% \n  mutate(Condition_label = factor(Condition_label, \n                                  levels = c(\"Experimental\", \"Control\")))\n\n\n\n\n\n\n\n\n\nHow are t-tests and regression the same?\n\n\n\n\n\nIf you are interested in the relationship between the two concepts, we said a t-test was a specific application of the general linear model. In the t-test calculations, it expresses the mean difference between groups by the standard error of the difference. In essence, it describes the difference in standard errors, which we can describe with a t-distribution to calculate p-values.\nIn regression, we frame the model as how much variance you explain compared to the total amount of variance. The more variance your predictor explains, the less unexplained variance there is left over. For the slope estimate though, this is identical to the t-test as we estimate the mean difference between groups plus the standard error around the mean difference. We calculate a p-value for the slope from a t-distribution, so you get a t-value in the output.\nYou can see the process is identical by comparing the key values from the regression output to the Student t-test. We can recreate the mean difference to compare to the slope, the t-value is the same, the p-value is the same, the degrees of freedom are the same, and the 95% confidence intervals below are the same.\nSo, when you have a single categorical predictor, it is the exact same process as the Student t-test, just expressed slightly different. The only downside to this procedure is it is much more difficult to recreate the Welch t-test.\n\n\n\n\n9.3.3 Activity 8 - Calculating confidence intervals\nThe only thing we are missing is our confidence intervals around the estimates which we can calculate through the confint() function.\n\nconfint(lm_cals_numbers)\n\n                2.5 %    97.5 %\n(Intercept) 179.21657 214.14704\nCondition1   37.56915  88.52983\n\n\nNow, we can summarise the three key concepts of inferential statistics as:\n\nHypothesis testing: p &lt; .001, suggesting we can reject the null hypothesis assuming \\(\\alpha\\) = .05. The experimental group ate significantly more calories of soup than the control group.\nEffect size: \\(b_1\\) = 63.05, suggesting the experimental group ate on average 63 more calories than the control group.\nConfidence interval: [37.57, 88.53], showing the precision around the slope estimate.\n\n\n\n\n\n\n\nTry this\n\n\n\nNow it is time to test your understanding on a new set of variables. This time, use CalEstimate as your outcome, Condition_label as your predictor, and use lopez_clean as your data. We can ask the same question as Activity 5: “What is the difference in estimated calories consumed between the experimental and control groups?”.\nApply simple linear regression to get your inferential statistics and answer the following questions:\n\nHypothesis testing: Assuming \\(\\alpha\\) = .05, Condition is a \nstatistically significant\nnon-significant predictor of estimates calories consumed.\nEffect size: Rounded to 2 decimals, the Condition slope coefficient means there was a mean difference of \n133.03\n7.68\n-17.88\n11.19.\nConfidence interval: Rounded to 2 decimals, the lower bound of the slope is \n117.94\n-39.88\n148.12\n4.11 and the upper bound is \n117.94\n-39.88\n148.12\n4.11.\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThe conclusions are the same as when we calculated the t-test, where condition is not a statistically significant predictor of estimated calories consumed. As a regression model, we get the same conclusions expressed in a slightly different way. Condition is a negative but non-significant predictor (p = .111). The control group ate 17.88 (\\(b_1\\) = -17.88, 95% CI = [-39.88, 4.11]) more calories than the experimental group. We explain very little variance in estimated calories consumed (adjusted \\(R^2\\) = .003), so the condition manipulation had little effect.\n\n# Create lm object for condiiton label as a predictor\nlm_cal_est &lt;- lm(CalEstimate ~ Condition_label, \n                 data = lopez_clean)\n\n# summary of the model object\nsummary(lm_cal_est)\n\n# confidence intervals around estimates\nconfint(lm_cal_est)\n\n\nCall:\nlm(formula = CalEstimate ~ Condition_label, data = lopez_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-130.03  -83.03  -33.03   44.85  666.97 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                  133.033      7.679  17.324   &lt;2e-16 ***\nCondition_labelExperimental  -17.883     11.192  -1.598    0.111    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 119.9 on 459 degrees of freedom\n  (3 observations deleted due to missingness)\nMultiple R-squared:  0.005531,  Adjusted R-squared:  0.003365 \nF-statistic: 2.553 on 1 and 459 DF,  p-value: 0.1108\n\n                                2.5 %     97.5 %\n(Intercept)                 117.94256 148.123015\nCondition_labelExperimental -39.87763   4.111599\n\n\n\n\n\n\n9.3.4 Activity 9 - Standardising predictors\nFor simple linear regression with two levels of a categorical predictor, centering the variable does not help, but we can standardise our outcome to express the estimate in standard deviations rather than the raw units. This is analogous to calculating Cohen’s d as we express the standardised mean difference. In contrast to continuous predictors, we only need to standardise the outcome, rather than both the outcome and predictor(s). We then use the standardised variable as our outcome.\n\n# Be careful with the bracket placement to subtract the mean first\nlopez_clean &lt;-lopez_clean %&gt;% \n  mutate(actual_calories_std = (F_CaloriesConsumed - mean(F_CaloriesConsumed)) / sd(F_CaloriesConsumed))\n\n# Condition as a factor containing 0 and 1\nlm_cals_std &lt;- lm(formula = actual_calories_std ~ Condition, \n                      data = lopez_clean)\n\nsummary(lm_cals_std)\n\n\nCall:\nlm(formula = actual_calories_std ~ Condition, data = lopez_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.6173 -0.6941 -0.1692  0.4401  5.8000 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.20749    0.06225  -3.333 0.000928 ***\nCondition1   0.44163    0.09082   4.863 1.59e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9764 on 462 degrees of freedom\nMultiple R-squared:  0.04869,   Adjusted R-squared:  0.04663 \nF-statistic: 23.64 on 1 and 462 DF,  p-value: 1.591e-06\n\n\nNote, the estimate may be slightly different to directly calculating Cohen’s d as there are a few formulas. If you compare to Activity 5, we got d = 0.45 there and 0.44 here. Between the estimate and 95% confidence intervals, they are off by .02, so it does not have a material impact on the results.\n\n\n\n\n\n\nTip\n\n\n\nAs before, once you know how it works conceptually, there is a shortcut where you do not need to standardise all your variables first. The effectsize package has a handy function called standardize_parameters() which you can apply to your initial lm() object.\n\nstandardize_parameters(lm_cals_numbers)\n\n\n\n\nParameter\nStd_Coefficient\nCI\nCI_low\nCI_high\n\n\n\n(Intercept)\n-0.2074898\n0.95\n-0.3298249\n-0.0851547\n\n\nCondition1\n0.4416297\n0.95\n0.2631529\n0.6201065"
  },
  {
    "objectID": "09-lm-categorical.html#checking-assumptions",
    "href": "09-lm-categorical.html#checking-assumptions",
    "title": "\n9  Regression with one categorical predictor\n",
    "section": "\n9.4 Checking assumptions",
    "text": "9.4 Checking assumptions\nFor the inferential statistics to work as intended, the model makes certain assumptions about the data you are putting into it and the accuracy of the inferences depends on how sensible these assumption are.\n\n9.4.1 Activity 10 - Diagnostic plots for linear regression\nWe have the same assumptions for simple linear regression now we have a categorical predictor:\n\nThe outcome is interval/ratio level data.\nThe predictor variable is interval/ratio or categorical (with two levels at a time).\nAll values of the outcome variable are independent (i.e., each score should come from a different participant/observation).\nThe predictors have non-zero variance.\nThe relationship between the outcome and predictor is linear.\nThe residuals should be normally distributed.\nThere should be homoscedasticity.\n\nAssumptions 1-4 are pretty straight forward as they relate to your understanding of the design or a simple check on the data for non-zero variance (the responses are not all the exact same value).\nAssumptions 5-7 require diagnostic checks on the residuals from the model. In contrast to continuous predictors, they are a little harder to identify patterns in. As we only have two values on the x-axis (0 and 1), all the residuals will be organised into vertical lines and the trend lines to help spot patterns do not look quite right.\n\n9.4.2 Checking linearity\nWhen you have a categorical predictor with two levels, you meet linearity by default, so you do not need to check this assumption directly. When you have two levels, you can only fit a straight line between the values.\n\nplot(lm_cals_numbers, \n     which = 1)\n\n\n\n\n\n\n\n\n9.4.3 Checking normality\nThe qq-plot is still the same to interpret. Now, this example presents a useful case of decision making in data analysis we explore more in Chapter 11. The plot here is approaching signs of violating normality as there is a clear curve to the data points with 3 and 118 the largest deviations (you can see these on the violin-boxplot as the two highest values in the control group). For this chapter, we are sticking with it and it would be consistent with how the original authors analysed the data, but note this would be a key decision to make and justify when reporting the analysis.\n\nplot(lm_cals_numbers, \n     which = 2)\n\n\n\n\n\n\n\n\n9.4.4 Checking homoscedasticity\nThe scale-location plot is harder to interpret when you have a categorical predictor. Like linearity, the points are all arranged in two vertical lines as we only have two levels. You are looking out for the spread of the two lines to be roughly similar. They look fine here, just points 118 and 3 separated a little from the other points.\n\nplot(lm_cals_numbers, \n     which = 3)\n\n\n\n\n\n\n\n\n9.4.5 Checking influential cases\nFinally, we have our plots for identifying influential cases. First, we get Cook’s distance for all the observations in your data. We see points 3 and 118 come up yet again, but although they are the largest deviations, they do not necessarily have worrying Cook’s distance values. There are different thresholds in the literature, but estimates range from 1, 0.5, to 4/n. It would only be under this final most conservative estimate (0.009) we would highlight several observations for further inspection.\n\nplot(lm_cals_numbers, \n     which = 4)\n\n\n\n\n\n\n\nFinally, the fifth plot shows residual values against leverage. Like Chapter 8, we cannot see the Cook’s distance threshold it uses in the plot as none of the points are a large enough deviation, despite 3 and 188 sticking out again.\n\nplot(lm_cals_numbers, \n     which = 5)\n\n\n\n\n\n\n\n\n9.4.6 Checking all the assumptions\nNow we have covered the individual diagnostic plots, there is a handy function called check_model() from the performance package. Like the plot() function, the output for linearity, homoscedasticity, and influential observations does not plot right as we only have two values for the predictor and the plot lines do not really work. Do not worry, you have not done anything wrong.\n\ncheck_model(lm_cals_numbers)\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat might explain the funky normality?\n\n\n\n\n\nIf you are interested, the posterior predictive check here provides an insight into why we get potential problems with normality. The outcome is ratio but cannot be smaller than 0 as we cannot have negative calories. So, in the green line for the observed data, the data are a little skewed as it drops off prior to 0. However, the model does not know that and it happily predicts normally distributed values which go below 0, creating a mismatch between what the model predicts and the values we enter into it.\nRemember the models will work regardless of the data you put into them, it is important to keep your role in mind to recognise when you need to be cautious about what you can learn from the model.\n\n\n\n\n\n\n\n\n\nTry this\n\n\n\nIn activity 8, you should have calculated the effect of condition (Condition_label) on estimated calories consumed (CalEstimate) for your independent task. Using the model object lm_cal_est, work through assumptions for simple linear regression and make a note of whether you think it meets the assumptions, or there might be any problems. Some of the assumptions you consider what you know about the design, while others you need the diagnostic plots.\n\nThe outcome is interval/ratio level data.\nThe predictor variable is interval/ratio or categorical (with two levels at a time).\nAll values of the outcome variable are independent (i.e., each score should come from a different participant/observation).\nThe predictors have non-zero variance.\nThe relationship between the outcome and predictor is linear.\nThe residuals should be normally distributed.\nThere should be homoscedasticity.\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\n\nThe outcome is interval/ratio level data.\n\nThe outcome is nicely ratio as estimated calories have a logical 0 point (no calories) and the units are in equal measurements..\n\nThe predictor variable is interval/ratio or categorical (with two levels at a time).\n\nOur predictor is categorical with two levels.\n\nAll values of the outcome variable are independent (i.e., each score should come from a different participant/observation).\n\nThe short answer is this appears to be the case in this study. The longer answer is there might have been an issue with the participants apparently completing the study in groups of 3. It is not entirely clear in the data how they recorded this, but grouped data collection does present a potential problem with independence we do not tackle in this course and the original authors did not seem to address it.\n\nThe predictors have non-zero variance.\n\nWe have observations from both levels of the predictor.\n\nThe relationship between the outcome and predictor is linear.\n\nWe meet linearity by default with two levels, so we do not need the plot here.\n\nThe residuals should be normally distributed.\n\nLike the actual calories consumed, this is firmly a clear deviation from what we expect and provides a good example of when it does not look right. If we were to analyse the data fully, we would explore the impact of this and alternative models, but for this chapter, we are going to note our concern and remember the authors analysed the data like this.\n\nplot(lm_cal_est, \n     which = 2)\n\n\n\n\n\n\n\n\nThere should be homoscedasticity.\n\nLooking at the spread of each group, it looks fine with a similar range until both groups are more sparsely distributed above 1.\n\nplot(lm_cal_est, \n     which = 3)\n\n\n\n\n\n\n\nIn summary, normality is a clear concern and something we will return to for your options in Chapter 11 and the course materials. For now, we will stick with the model but recognise we should be cautious."
  },
  {
    "objectID": "09-lm-categorical.html#reporting-your-results",
    "href": "09-lm-categorical.html#reporting-your-results",
    "title": "\n9  Regression with one categorical predictor\n",
    "section": "\n9.5 Reporting your results",
    "text": "9.5 Reporting your results\nNow we have some results to go with, there are a few recommendations on how to communicate that information. If you need a reminder of APA style for formatting numbers, you can see this PDF online for a little cheat sheet for numbers and statistics.\n\nExplain to the reader what your linear regression model was. For example, what was your outcome and predictor variable?\nReport descriptive statistics to help contextualise your findings. For example, the mean/standard deviation for your outcome per group.\nProvide an appropriate data visualisation to help communciate key patterns to the reader. For example, a violin-boxplot for how each group responded on your outcome.\nReport all three key inferential statistics concepts for the coefficient: the slope, the confidence interval around your slope, and the p-value for hypothesis testing. When you have one predictor in simple linear regression, you typically focus on the slope as your key effect size that helps address your research question and hypothesis. APA style rounds numbers to 2 decimal places when numbers can be bigger than 1, and 3 decimals with no leading zero when it cannot be bigger than 1. When you report the unstandardised slope, you use the symbol \\(b_1\\) but for the standardised slope, you use Beta instead \\(\\beta_1\\).\nProvide an overview of the model fit statistics for whether your model explained a significant amount of variance in your outcome. Remember: the p-value for your model will be the same as for the slope in simple linear regression.\n\nFor our main example, we could summarise the findings as:\n“Our research question was: is there a difference in actual calories consumed between the control and experimental group? To test this, we applied simple linear regression using condition as a predictor with two levels (control and experimental) and actual calories consumed as our outcome. Figure 1 shows a violin-boxplot of the difference between the control and experimental groups.\n\n\n\n\n\n\n\n\nOur model explained a statistically significant amount of variance in our outcome (adjusted \\(R^2\\) = .047, F(1, 462) = 23.64, p &lt; .001). Condition was a positive predictor, where the experimental group consumed on average 63 more calories than the control group (\\(b_1\\) = 63.05, 95% CI = [37.57, 88.53], p &lt; .001). Expressed as a standardised effect size, the experimental group consumed 0.44 (95% CI = [0.26, 0.62]) more standard deviations than the control group.”\nNote: we have not included an APA formatted Figure title here as it is not easy to format in our book, so refer to the course materials for guidance."
  },
  {
    "objectID": "09-lm-categorical.html#09-bonus",
    "href": "09-lm-categorical.html#09-bonus",
    "title": "\n9  Regression with one categorical predictor\n",
    "section": "\n9.6 Bonus section - One- and paired-samples tests",
    "text": "9.6 Bonus section - One- and paired-samples tests\nIn this course, we focus on correlational and between-subjects designs, but you might find yourself in a situation where you want to test a continuous variable against a fixed value or compare conditions in the same participants. This is a bonus section if you have time, so you can skip to the Test Yourself section to finish the chapter if you do not.\nFor this demonstration, we will use data from experiment 1 of Bem (2011), an (in)famous study that almost single-handedly started the replication crisis in psychology. Briefly, participants completed a computer task adapted from priming experiments where they could select one of two windows. They had to guess which window had an image hidden behind it and the images contained different stimuli like erotic or neutral/control images. Across many trials of the participants guessing the location, Bem calculated the proportion of successful trials which could range between 0 (never correct), 50 (50%, chance), and 100 (always correct). The headline finding was participants demonstrated precognition - or the ability to see into the future - to guess above chance levels, but what does the data look like?\nWe are working with a new data set, so please save the following data file: Bem_2011.csv. Right click the link and select “save link as”, or clicking the link will save the files to your Downloads. Make sure that you save the file as “.csv”. Save or copy the file to your data/ folder within Chapter_09_regression_categorical. Read in the data file to the object bem_data to be consistent with the tasks below.\n\n9.6.1 One-sample comparing against a fixed value\nThere are scenarios where you want to compare a single continuous variable against a fixed value. For example, do your participants respond significantly above or below chance?\n\n9.6.1.1 Expressed as a t-test\nAs a t-test, we need to specify two arguments:\n\nx - This is the continuous variable you want to analyse and compare the mean value of. We must use the base R operator $ to specify the column from your data.\nmu - This is the fixed value you want to test your variable against.\n\nIn this scenario, we want to compare the hit rate to erotic images against a value of 50. This will tell us if the hit rate is significantly above or below chance.\n\nt.test(x = bem_data$Erotic.Hits.PC,\n       mu = 50)\n\n\n    One Sample t-test\n\ndata:  bem_data$Erotic.Hits.PC\nt = 2.5133, df = 99, p-value = 0.01358\nalternative hypothesis: true mean is not equal to 50\n95 percent confidence interval:\n 50.66075 55.61703\nsample estimates:\nmean of x \n 53.13889 \n\n\nThe output is similar to the independent samples t-test. We get the p-value for hypothesis testing, the mean estimate of the variable, and it’s 95% confidence interval. To express it as an effect size, you can subtract 50 from each value. So, participants responded 3.14% above chance, statistically significant, but hardly convincing evidence for precognition.\n\n9.6.1.2 Expressed as a linear model\nWe can also express this as a linear model, but we must first add a small wrangling step. In the one-sample t-test, we can manually enter a fixed value to compare the mean against. In a linear model, we must compare against 0 by subtracting the fixed value from your variable. So, we subtract 50 from all the observations, so they become a kind of deviation from 50.\n\nbem_data &lt;- bem_data %&gt;% \n  mutate(erotic_deviation = Erotic.Hits.PC - 50)\n\nIn contrast to previous linear models, we only add a fixed intercept and do not add a predictor. This recreates the one-sample t-test by estimating the mean value of your outcome.\n\nlm_erotic &lt;- lm(erotic_deviation ~ 1, \n                data = bem_data)\n\nsummary(lm_erotic)\n\n\nCall:\nlm(formula = erotic_deviation ~ 1, data = bem_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-28.139  -8.694   2.417   7.972  30.194 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)    3.139      1.249   2.513   0.0136 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.49 on 99 degrees of freedom\n\n\nThis process has the benefit of directly producing your effect size, as the intercept estimate is the deviation from your fixed value (here, 50). As we calculated manually before, the erotic hit rate is 3.14% above your fixed value. If you remember back to the linear model explanations, this is where the p-value for the intercept is finally useful as it tests against 0.\nIf you compare to the one-sample t-test, all of these values are identical. You also have the option of calculating confidence intervals around the estimate, calculating a standardised effect size, and checking assumptions by applying the previous linear regression activities.\n\n9.6.2 Paired-samples comparing conditions\nAlternatively, you might want to compare two conditions from the same participants in paired samples/within-subjects design. For example, is the hit-rate significantly higher for erotic images compared to control images?\n\n9.6.2.1 Expressed as a t-test\nTo conduct a paired-samples t-test, we must specify three arguments:\n\nx - This is the first level of your condition as a column. You need your data in wide format, so the condition levels are spread across two columns per participant. We must use the base R operator $ to specify the column from your data.\ny - This is the second level of your condition as a column.\npaired - This instructs R you want a paired-samples t-test to compare conditions within participants.\n\nIn this scenario, we want to compare the hit rate for erotic images to control images.\n\nt.test(x = bem_data$Erotic.Hits.PC,\n       y = bem_data$Control.Hits.PC, \n       paired = TRUE)\n\n\n    Paired t-test\n\ndata:  bem_data$Erotic.Hits.PC and bem_data$Control.Hits.PC\nt = 1.8563, df = 99, p-value = 0.06638\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -0.2277431  6.8388542\nsample estimates:\nmean difference \n       3.305556 \n\n\nThe output is almost identical to the one-sample t-test, but this time the effect size is the mean difference between conditions, not just the mean per condition. Behind the scenes, a paired-samples t-test is actually a one-sample t-test in disguise as it uses the difference between conditions as the outcome.\nAs an aside, Bem (2011) reported a significant difference here, but only because he reported a one-tailed test (alternative = \"greater\"). This is an example where you ideally need a strong (ideally pre-registered) prediction as it makes a material impact on the inferences you would make.\n\n9.6.2.2 Expressed as a linear model\nFinally, we can express a paired-samples t-test as a linear model. We must apply a small data wrangling step to calculate a difference score between conditions. This is so the linear model compares the estimate against 0 of no difference. So, for this example, we create a variable for the difference between erotic and control images.\n\nbem_data &lt;- bem_data %&gt;% \n  mutate(erotic_control = Erotic.Hits.PC - Control.Hits.PC)\n\nLike the one-sample scenario, we only add a fixed intercept for the new difference variance and do not add a predictor. This recreates the paired-samples t-test by estimating the mean value of your difference score.\n\nlm_paired &lt;- lm(erotic_control ~ 1, \n                data = bem_data)\n\nsummary(lm_paired)\n\n\nCall:\nlm(formula = erotic_control ~ 1, data = bem_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-58.861  -9.556   2.250   9.194  35.583 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)    3.306      1.781   1.856   0.0664 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 17.81 on 99 degrees of freedom\n\n\nThis process directly produces your effect size again, as the intercept estimate is the deviation from 0 for your difference score. As we saw in the paired-samples t-test output, there was a 3.31% higher hit rate for erotic images compared to control (as we calculated erotic - control).\nIf you compare to the paired-samples t-test, all of these values are identical. You also have the option of calculating confidence intervals around the estimate, calculating a standardised effect size, and checking assumptions by applying the previous linear regression activities."
  },
  {
    "objectID": "09-lm-categorical.html#09-test",
    "href": "09-lm-categorical.html#09-test",
    "title": "\n9  Regression with one categorical predictor\n",
    "section": "\n9.7 Test Yourself",
    "text": "9.7 Test Yourself\nTo end the chapter, we have some knowledge check questions to test your understanding of the concepts we covered in the chapter. Compared to previous chapters, there are no error mode questions as the content is so similar to Chapter 8. We are just going to test your understanding of the concepts rather than potential errors.\n\n9.7.1 Knowledge check\nFor this chapter’s knowledge check section, we have something a little different. Instead of purely conceptual questions about functions, we have another example of linear regression from Lopez et al. (2023). Feel free to create this model yourself, but we will show you some output and ask you questions based on it.\nFor this model, we focus on ounces of soup consumed (M_postsoup) rather than calories by each Condition group (Condition_label). You might have a good idea about the results based on the chapter, but you will still need to interpret the output accurately.\nQuestion 1. In the violin-boxplot below, the experimental group consumed more soup in ounces than the control group: \nTRUE\nFALSE.\n\n\n\n\n\n\n\n\nQuestion 2 For the next few questions, we have the output from a linear regression model and we would like you to interpret it.\n\n\n\nCall:\nlm(formula = M_postsoup ~ Condition_label, data = lopez_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-10.410  -4.467  -1.089   2.833  37.333 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                   8.8675     0.4007  22.130  &lt; 2e-16 ***\nCondition_labelExperimental   2.8426     0.5846   4.863 1.59e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.285 on 462 degrees of freedom\nMultiple R-squared:  0.04869,   Adjusted R-squared:  0.04663 \nF-statistic: 23.64 on 1 and 462 DF,  p-value: 1.591e-06\n\n\nThe outcome variable in this model is \nActual ounces of soup consumed\nExperimental condition and the predictor variable is \nActual ounces of soup consumed\nExperimental condition.\nQuestion 3 In this model, the reference group is \nControl\nExperimental and the target group is \nControl\nExperimental\nQuestion 4 Rounded to 2 decimals, we predict a value of  for our reference group.\nQuestion 5 The predictor is \nstatistically significant\nnon-significant and \npositive\nnegative.\nQuestion 6 The target group consumed on average  ounces \nless\nmore soup than the reference group."
  },
  {
    "objectID": "09-lm-categorical.html#words-from-this-chapter",
    "href": "09-lm-categorical.html#words-from-this-chapter",
    "title": "\n9  Regression with one categorical predictor\n",
    "section": "\n9.8 Words from this Chapter",
    "text": "9.8 Words from this Chapter\nBelow you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the PsyTeachR Glossary. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter.\n\n\n\n\nterm\ndefinition\n\n\n\ndummy-coding\nEntering a categorical predictor using two values such as 0 and 1.\n\n\nreference-group\nIn a dummy-coded variable, the first level of your variable, typically 0.\n\n\nstudent-t-test\nCalculating a t-value based on the mean difference divided by the pooled standard deviation. In the Student t-test, we times the pooled standard deviation by a term containing the sample sizes of each group.\n\n\ntarget-group\nIn a dummy-coded variable, the second level of your variable, typically 1.\n\n\nwelch-t-test\nCalculating a t-value based on the mean difference divided by a term containing the variance of each group. We also correct the degrees of freedom for the difference in variances."
  },
  {
    "objectID": "09-lm-categorical.html#end-of-chapter",
    "href": "09-lm-categorical.html#end-of-chapter",
    "title": "\n9  Regression with one categorical predictor\n",
    "section": "\n9.9 End of chapter",
    "text": "9.9 End of chapter\nWell done, you have now completed the first core set of chapters for inferential statistics!\nAt this point, you can now address a range of research questions by applying variations of the general linear model. As a researcher, the most important thing is starting with your research question (and where applicable, your hypothesis), designing a study to address that research question, and using an appropriate statistical model for your design and research question. But, before you can identify an appropriate statistical model, you need to know what they look like! This is everything we cover in Research Methods 1 to focus on a select range of foundational skills. You will then build on these modelling techniques in Chapters 12-14 for Research Methods 2.\nYou are now ready to complete the second data analysis journey chapter: Simple Linear Regression. This is where you can test your new skills in a slightly less structured way, from wrangling data, to answering a research question.\nIn the next core chapter, we turn to statistical power and work on how you can conduct a power analysis in R/RStudio.\n\n\n\n\nBem, D. J. (2011). Feeling the future: Experimental evidence for anomalous retroactive influences on cognition and affect. Journal of Personality and Social Psychology, 100(3), 407–425. https://doi.org/10.1037/a0021524\n\n\nLopez, A., Choi, A. K., Dellawar, N. C., Cullen, B. C., Avila Contreras, S., Rosenfeld, D. L., & Tomiyama, A. J. (2023). Visual cues and food intake: A preregistered replication of Wansink et al (2005). Journal of Experimental Psychology: General. https://doi.org/10.1037/xge0001503.supp"
  },
  {
    "objectID": "10-power.html#chapter-preparation",
    "href": "10-power.html#chapter-preparation",
    "title": "\n10  Statistical Power and Effect Sizes\n",
    "section": "\n10.1 Chapter preparation",
    "text": "10.1 Chapter preparation\n\n10.1.1 Organising your files and project for the chapter\nIn contrast to previous chapters, there will be no data wrangling in this chapter, so we do not need to worry about downloading files. We will still be working around some key studies, but we will introduce them as needed. However, you will still be working in an R Markdown document, so you need to make sure your working directory is in order.\n\nIn your folder for research methods and the book ResearchMethods1_2/Quant_Fundamentals, create a new folder called Chapter_10_power.\nCreate an R Project for Chapter_10_power as an existing directory for your chapter folder. This should now be your working directory.\nCreate a new R Markdown document and give it a sensible title describing the chapter, such as 10 Statistical Power and Effect Sizes. Delete everything below line 10 so you have a blank file to work with and save the file in your Chapter_10_power folder.\nIn a code chunk, load the pwr and tidyverse packages. If you need to install any packages, revisit Chapter 1 if you need a refresher, but remember not to install packages on the university computers / online server.\n\nYou are now ready to start working on the chapter!"
  },
  {
    "objectID": "10-power.html#nhst-and-statistical-power-recap",
    "href": "10-power.html#nhst-and-statistical-power-recap",
    "title": "\n10  Statistical Power and Effect Sizes\n",
    "section": "\n10.2 NHST and statistical power recap",
    "text": "10.2 NHST and statistical power recap\nGiven there is no data wrangling for this chapter and the functions for power analysis are pretty straight forward, we have a little space to recap the key concepts behind power analysis. Almost all the work here comes into thinking and justifying your decisions, rather than spending lots of time on wrangling and analysis.\nThe branch of statistics we are using here is Null Hypothesis Significance Testing (NHST). There are two types of hypotheses and what you are trying to establish is the probability of rejecting the null hypothesis. Those two hypotheses are:\n\nThe null hypothesis which states that there is no difference (\\(H_0: \\mu_1 = \\mu_2\\)) or no relationship (\\(H_0: r = 0\\)).\nThe alternative hypothesis which states that there is a difference (\\(H_1: \\mu_1 \\ne \\mu_2\\)) or there is a relationship (\\(H_1: r \\ne 0\\)).\n\nNHST is designed to control error rates associated with two main decisions around these hypotheses:\n\nType I error - or false positive, is the probability of rejecting the null hypothesis when it should not be rejected (otherwise called alpha or \\(\\alpha\\)). In other words, you conclude that there is a real “effect” when in fact there is no effect. The field standard rate of acceptable false positives is \\(\\alpha = .05\\), meaning that we would accept 1 in 20 studies may be a false positive.\nType II error - or false negative, is the probability of retaining the null hypothesis when it should be rejected (otherwise called beta or \\(\\beta\\)). In other words, you conclude that there was no real “effect” when in fact there was one. There is less tradition around this, but the most common rule of thumb you will come across is \\(\\beta = .20\\), meaning that we would accept 1 in 5 studies may be a false negative.\n\nStatistical power is the opposite of beta and represents the long-run probability of correctly rejecting the null hypothesis when there is a real effect to detect. In other words, how likely are you to detect an effect that is really there? You calculate Power as \\(1-\\beta\\), meaning that if the field standard for beta is \\(\\beta = .20\\), then the field standard for power is \\(1 - .20 = .80\\) (80%).\nIn addition to alpha and beta/power, there are two other key concepts (there are more depending on the test, but we will add them in when we need them):\n\nEffect size - A number that expresses the magnitude of the phenomenon relevant to your research question. In Chapters 8 and 9, we introduced you to different standardised effect sizes such as Pearson’s r and Cohen’s d. \nSample size - The number of observations (usually participants, but it might be animals or stimuli depending on your topic) in your study.\n\nCritically, there is a relationship between these four concepts, where if you know three, you can calculate the fourth in a process called power analysis. The two most useful types of power analysis are:\n\nA priori power analysis: How many participants do I need, for a given alpha, beta/power, and smallest effect size of interest? This is most useful in the design stage to help you plan how many participants you need to design an informative study.\nSensitivity power analysis: What effect size can I detect, for a given alpha, beta/power, and sample size? This is most useful after you finish collecting data or when you are using secondary data as the sample size is not longer under your control and it helps put your findings in context.\n\nYou may now be thinking though, if there is a relationship between all four concepts, could we calculate power for a given alpha, sample size, and effect size? It is a tempting idea and you might see some articles report it, but unfortunately is is misleading and tells you nothing more than the p-value does. The short version is we are typically using a sample to learn something about a population, so there is uncertainty in the estimate. Using the observed effect size in your study assumes this is the true population effect, which is rarely a good assumption. If you are interested, Lakens (2022) is a great resource for sample size justification in general, but also explains why post-hoc power is not a good idea.\nAfter the brief recap, we will now focus on a priori and sensitivity power analyses applied to different statistical models."
  },
  {
    "objectID": "10-power.html#power-analysis-for-t-tests-categorical-predictors",
    "href": "10-power.html#power-analysis-for-t-tests-categorical-predictors",
    "title": "\n10  Statistical Power and Effect Sizes\n",
    "section": "\n10.3 Power analysis for t-tests / categorical predictors",
    "text": "10.3 Power analysis for t-tests / categorical predictors\n\n10.3.1 Introduction to the study\nIn this section, imagine we are designing a study to build on Irving et al. (2022) who tested an intervention to correct statistical misinformation. Participants read an article about a new fictional study where one passage falsely concludes watching TV causes cognitive decline. In the correction group, participants receive an extra passage where the fictional researcher explains they only reported a correlation, not a causal relationship. In the no-correction group, the extra passage just explains the fictional researcher was not available to comment. Irving et al. then tested participants’ comprehension of the story and coded their answers for mistaken causal inferences. They expected participants in the correction group to make fewer causal inferences than those in the no-correction group, and found evidence supporting this prediction with an effect size equivalent to Cohen’s d = 0.64, 95% CI = [0.28, 0.99]. Inspired by their study, we want to design an experiment to correct another type of misinformation in articles.\nIrving et al. (2022) themselves provide an excellent example of explaining and justifying the rationale behind their power analysis, so we will walk through the decision making process and how it changes the outputs. For our smallest effect size of interest, our starting point is the estimate of d = 0.64. However, it is worth consulting other sources to calibrate our understanding of effects in the area, such as Irving et al. citing a meta-analysis. For debunking, the average effect across 30 studies was d = 1.14, 95% CI = [0.68, 1.61], so we could use the lower bound of the confidence interval, but this may still represent an overestimate. Irving et al. used the smallest effect (d = 0.54) from the studies most similar to their design which was included in the meta-analysis. As a value slightly smaller than the other estimates, we will also use this as the smallest effect of interest for our study.\nNow we have settled on our smallest effect size of interest, we will use d = 0.54 in the following demonstrations. We start with a priori and sensitivity power analysis for two independent samples, exploring how the outputs change as we alter inputs like alpha, power, and the number of tails in the test.\n\n10.3.2 A priori power analysis\nFor an independent samples t-test (we will cover regression shortly), there is the function pwr.t.test(). We can enter the following arguments:\n\nn: The number of observations.\nd: The effect size as Cohen’s d. \nsig.level: The alpha level.\npower: The power value as 1-\\(\\beta\\).\ntype: Whether you want power for a one-, paired-, or independant-samples t-test.\nalternative: Whether you have a one- or two-sided hypothesis.\n\nRemember, power analysis works by leaving one argument blank, so for calculating the sample size, we leave n blank or enter NULL as the argument. As our starting point, we enter d = 0.54, sig.level = .05, power = .90, type = two.sample and alternative = two-sided.\n\npwr.t.test(n = NULL, \n           d = 0.54, \n           sig.level = .05, \n           power = .90, \n           type = \"two.sample\", \n           alternative = \"two.sided\")\n\n\n     Two-sample t test power calculation \n\n              n = 73.04123\n              d = 0.54\n      sig.level = 0.05\n          power = 0.9\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nAs the note warns us, for an independent-samples t-test, n represents the number of observations per group, so we need 74 per group (we round up as we cannot have .04 of a person) or N = 148.\nIf you wanted to use these values in inline code, you can save the power analysis object and pick out values to work with.\n\nirving_samplesize &lt;- pwr.t.test(n = NULL, \n                           d = 0.54, \n                           sig.level = .05, \n                           power = .90, \n                           type = \"two.sample\", \n                           alternative = \"two.sided\") %&gt;% \n  pluck(\"n\") %&gt;% \n  ceiling()\n\nIn this code, we save the power analysis function to an object, use the pluck() function to pick out a specific component (the argument name must be spelt exactly), and use the ceiling() function to round up. This helps to avoid manually calculating the values as you can use the object.\n\n# sample size per group\nirving_samplesize\n\n# total sample size\nirving_samplesize * 2\n\n[1] 74\n[1] 148\n\n\nThe power analysis function is pretty straight forward to work with, it is the thinking and decision making that goes into selecting the value for each argument that is the hardest part here. It is ultimately a subjective decision you must be able to justify in a report and there will always be compromises. You never have unlimited resources, so you are trying to balance designing the most informative study with maximizing the resources available to you.\n\n\n\n\n\n\nTry this\n\n\n\nWith decision making in mind, we can tweak the arguments to see how it affects the sample size we need. We will tweak one argument at a time, so your starting point will be the arguments we started with above.\n\nIf we used a one-tailed test predicting a positive effect (\"greater\"), we would need  participants per group (N = ).\nIf we wanted to make fewer type I errors and reduce alpha to .005, we would need  participants per group (N = ).\nIf we were happy with a larger beta and reduce power to .80 (80%), we would need  participants per group (N = ).\nIf we wanted to decrease our smallest effect size of interest and set d = .40, we would need  participants per group (N = ).\nIf we thought it was appropriate to change the design to within-subjects and use a paired-samples t-test instead (\"paired\"), we would need  participants.\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\n\nWe can calculate sample size for a one-tailed test by entering alternative = \"greater\" or alternative = \"less\". This must match the effect size direction or you will receive an error.\n\n\npwr.t.test(n = NULL, \n           d = 0.54, \n           sig.level = .05, \n           power = .90, \n           type = \"two.sample\", \n           alternative = \"greater\") %&gt;% \n  pluck(\"n\") %&gt;% \n  ceiling()\n\n[1] 60\n\n\n\nWe can decrease alpha by entering alpha = .005 to calculate the sample size for reducing the type I error rate.\n\n\npwr.t.test(n = NULL, \n           d = 0.54, \n           sig.level = .005, \n           power = .90, \n           type = \"two.sample\", \n           alternative = \"two.sided\") %&gt;% \n  pluck(\"n\") %&gt;% \n  ceiling()\n\n[1] 117\n\n\n\nWe can decrease power if we were happy with a larger beta / type II error rate by entering power = .80.\n\n\npwr.t.test(n = NULL, \n           d = 0.54, \n           sig.level = .05, \n           power = .80, \n           type = \"two.sample\", \n           alternative = \"two.sided\") %&gt;% \n  pluck(\"n\") %&gt;% \n  ceiling()\n\n[1] 55\n\n\n\nWe can decrease the smallest effect size of interest if we wanted the study to be more sensitive by entering d = .40.\n\n\npwr.t.test(n = NULL, \n           d = 0.40, \n           sig.level = .05, \n           power = .90, \n           type = \"two.sample\", \n           alternative = \"two.sided\") %&gt;% \n  pluck(\"n\") %&gt;% \n  ceiling()\n\n[1] 133\n\n\n\nIf we changed the design and test to within-subjects, we can enter type = \"paired\".\n\n\npwr.t.test(n = NULL, \n           d = 0.54, \n           sig.level = .05, \n           power = .90, \n           type = \"paired\", \n           alternative = \"two.sided\") %&gt;% \n  pluck(\"n\") %&gt;% \n  ceiling()\n\n[1] 39\n\n\n\n\n\nThese are important lessons to recognise which inputs increase and which decrease the sample size you need. For an a priori power analysis in the design phase, you can tweak the inputs depending on how sensitive you want your study given the resources available to you. Holding everything else constant, we can summarise the patterns as:\n\nUsing a one-tailed test \nincreases\ndecreases the sample size you need.\nReducing alpha \nincreases\ndecreases the sample size you need.\nReducing power / increasing beta \ndecreases\nincreases the sample size you need.\nReducing the smallest effect size of interest \nincreases\ndecreases the sample size you need.\nSwitching to a within-subjects design \nincreases\ndecreases the sample size you need.\n\n10.3.3 Sensitivity power analysis\nNow imagine you already knew the sample size or had access to a population of a known size. In this scenario, you would conduct a sensitivity power analysis. This would tell you what effect sizes your study would be powered to detect for a given alpha, power, and sample size. This is helpful for interpreting your results as you can outline what effect sizes your study was sensitive to and which effects would be too small for you to reliably detect.\nImagine we had finished collecting data and we knew we had 40 participants in each group but did not conduct an a priori power analysis when designing the study. Instead of leaving n blank, we can leave d blank.\n\npwr.t.test(n = 40, \n           d = NULL, \n           sig.level = .05, \n           power = .90, \n           type = \"two.sample\", \n           alternative = \"two.sided\")\n\n\n     Two-sample t test power calculation \n\n              n = 40\n              d = 0.7339255\n      sig.level = 0.05\n          power = 0.9\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nThe output tells us that the study is sensitive to detect effect sizes of d = 0.73 with 90% power. This helps us to interpret the results if we did not plan with power in mind. If the effect size we could detect with 90% power is larger than our smallest effect size of interest, our study was potentially underpowered. This might sound like post-hoc power we warned you about, but the key difference is you are comparing the effect size your study was sensitive to against your smallest effect size of interest, not your observed effect size.\nFor a sensitivity power analysis, you will often find yourself with unequal sample sizes. The previous function assumes equal sample sizes, but pwr.t2n.test() lets you set n1 and n2. For example, imagine we ended up with two groups of 39 and 43 participants.\n\npwr.t2n.test(n1 = 39, \n             n2 = 43,\n             d = NULL, \n             sig.level = .05, \n             power = .90, \n             alternative = \"two.sided\") %&gt;% \n  pluck(\"d\") %&gt;% \n  round(digits = 2)\n\n[1] 0.73\n\n\nOne other key point here is power exists along a curve, there is not just a single value for power once your sample size is fixed. We can visualise this through something called a power curve. Figure 10.1 shows statistical power against Cohen’s d as the effect size for a fixed sample of 40 participants per group. We would have 90% power to detect a Cohen’s d of 0.75 (the value is a little different here as we set the effect size, rather than calculate it as the output), shown where the two lines meet. You would have more and more power to detect effects larger than 0.75 (follow the curve to the right), but less power to detect effects smaller than 0.75 (follow the curve to the left). The grey shaded region highlights the effects your study would be less sensitive to than your desired value for power.\n\n\n\n\nFigure 10.1: Power curve for 40 participants per group and 90% power.\n\n\n\nOn the other hand, Figure 10.2 shows statistical power against Cohen’s d as the effect size for a fixed sample of 80 participants per group. This time, we would have 90% power to detect effects of d = 0.53 and there is a smaller grey region. We would have more power to detect effects larger than d = 0.53 but less power to detect effects smaller than 0.53.\n\n\n\n\nFigure 10.2: Power curve for 80 participants per group and 90% power.\n\n\n\nHopefully, these demonstrations reinforce the idea of sensitivity and how power exists along a curve once you have a fixed sample size.\n\n10.3.4 Power for regression with a categorical predictor\nIn Chapters 8 and 9, we recommended expressing your designs as linear regression models. They have many benefits, but one downside is the effect size and process we need for power analysis is not the most intuitive. Typically, people report effect sizes like Cohen’s d when comparing groups, but here we need Cohen’s \\(f^2\\). You can convert between effect sizes and we recommend the website psychometrica.de which has an online calculator for converting effect sizes in section 14. Alternatively, you can use the following code to save \\(f^2\\) as an object.\n\n# enter your Cohen's d value\nd &lt;- 0.54\n\n# This calculates f2 from d\nf2 &lt;- (d / 2)^2\n\nNow we have \\(f^2\\), we can use the function pwr.f2.test() which calculates power for regression models. For the equivalent of a t-test, we have the following new arguments:\n\nu: The numerator degrees of freedom, the number of predictors in your model.\nv: The denominator degrees of freedom, a little more awkward but the sample size minus u minus 1.\nf2: The effect size \\(f^2\\), which is a kind of transformed version of \\(R^2\\) for the amount of variance explained by the model.\n\nFor our power analysis, we will save the inputs as objects to make it easier to reuse them, and enter them in the following arguments:\n\n# number of predictors\nu &lt;- 1\n\n# alpha for type I error rate\nalpha &lt;- .05\n\n# power for 1-beta\npower &lt;-  .90\n\npwr.f2.test(u = u, \n            v = NULL, \n            sig.level = alpha, \n            power = power, \n            f2 = f2)\n\n\n     Multiple regression power calculation \n\n              u = 1\n              v = 144.0824\n             f2 = 0.0729\n      sig.level = 0.05\n          power = 0.9\n\n\nUsing the objects from the power analysis, we can calculate the sample size we need with a little reorganising.\n\nirving_v &lt;- pwr.f2.test(u = 1, \n                        v = NULL, \n                        sig.level = .05, \n                        power = .90, \n                        f2 = f2) %&gt;% \n  pluck(\"v\") \n\nceiling(irving_v + u + 1)\n\n[1] 147\n\n\nIn the t-test power analysis function, we needed 148 participants in total, so this is off by 1 participant. There are a few steps for rounding errors here, so this is close enough to show it is the equivalent but more awkward process.\nIf you wanted to use this function for a sensitivity power analysis, you can convert \\(f^2\\) back to Cohen’s d using psychometrica.de or use the following code:\n\n# f2 from the output\nf2 &lt;- .073\n\n# convert to d by square root of f2 times 2\nd &lt;- sqrt(f2) * 2"
  },
  {
    "objectID": "10-power.html#power-analysis-for-correlations-continuous-predictors",
    "href": "10-power.html#power-analysis-for-correlations-continuous-predictors",
    "title": "\n10  Statistical Power and Effect Sizes\n",
    "section": "\n10.4 Power analysis for correlations / continuous predictors",
    "text": "10.4 Power analysis for correlations / continuous predictors\n\n10.4.1 Introduction to the study\nFor this section, we need a new study to work with for a correlation / continuous predictor. Wingen et al. (2020) were interested in the relationship between the replication rate in psychology studies and the public trust in psychology research. The replication crisis has led to a lot of introspection in the field to consider how we conduct robust research. However, being honest about the state of the field might be good for science, but perhaps it is related to lower public trust in science. We will focus on study 1 which asked the question: does trust in psychology correlate with expected replicability?\nWingen et al. (2020) reported a power analysis and they aimed for 95% power, 5% alpha, and their smallest effect size of interest was r = .20. Like Irving et al. (2022), they chose this value based on a meta-analysis which summarised hundreds of studies across social psychology. We will use these values as a starting point and adapt them to see it’s impact on the sample size we need.\n\n10.4.2 A priori power analysis\nFor Pearson’s r correlation, there is the function pwr.r.test(). All the arguments are the same as for the t-test, apart from we specify r as an effect size instead of Cohen’s d and we do not need to specify the type of test.\n\npwr.r.test(n = NULL, \n           r = .20, \n           sig.level = .05, \n           power = .95, \n           alternative = \"two.sided\")\n\n\n     approximate correlation power calculation (arctangh transformation) \n\n              n = 318.2637\n              r = 0.2\n      sig.level = 0.05\n          power = 0.95\n    alternative = two.sided\n\n\nAs before, we can isolate the sample size we would need for a study sensitive to these inputs.\n\npwr.r.test(n = NULL, \n           r = .20, \n           sig.level = .05, \n           power = .95, \n           alternative = \"two.sided\") %&gt;% \n  pluck(\"n\") %&gt;% \n  ceiling()\n\n[1] 319\n\n\nOur starting point is 319 participants to detect our smallest effect size of interest r = .20 with 95% power and 5% alpha.\n\n\n\n\n\n\nTry this\n\n\n\nWith decision making in mind, we can tweak the arguments to see how it affects the sample size we need. We will tweak one argument at a time, so your starting point will be the arguments we started with above.\n\nIf we used a one-tailed test predicting a positive relationship, we would need  participants. This reproduces the power analysis from Wingen et al., as they used a one-tailed test.\nIf we wanted to make fewer type I errors and reduce alpha to .005, we would need  participants.\nIf we were happy with a larger beta and reduce power to .80 (80%), we would need  participants.\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\n\nWe can calculate sample size for a one-tailed test by entering alternative = \"greater\" or alternative = \"less\". This must match the effect size direction or you will receive an error.\n\n\npwr.r.test(n = NULL, \n           r = .20, \n           sig.level = .05, \n           power = .95, \n           alternative = \"greater\") %&gt;% \n  pluck(\"n\") %&gt;% \n  ceiling()\n\n[1] 266\n\n\n\nWe can decrease alpha by entering alpha = .005 to calculate the sample size for reducing the type I error rate.\n\n\npwr.r.test(n = NULL, \n           r = .20, \n           sig.level = .005, \n           power = .95, \n           alternative = \"two.sided\") %&gt;% \n  pluck(\"n\") %&gt;% \n  ceiling()\n\n[1] 485\n\n\n\nWe can decrease power if we were happy with a larger beta / type II error rate by entering power = .80.\n\n\npwr.r.test(n = NULL, \n           r = .20, \n           sig.level = .05, \n           power = .80, \n           alternative = \"two.sided\") %&gt;% \n  pluck(\"n\") %&gt;% \n  ceiling()\n\n[1] 194\n\n\n\n\n\nLike for the independent samples t-test, the design phase allows you to carefully consider the inputs you choose and tweak them depending on how sensitive you want your study given the resources available to you. Holding everything else constant, we can summarise the patterns here as:\n\nUsing a one-tailed test \nincreases\ndecreases the sample size you need.\nReducing alpha \nincreases\ndecreases the sample size you need.\nReducing power / increasing beta \ndecreases\nincreases the sample size you need.\n\n10.4.3 Sensitivity power analysis\nWingen et al. (2020) is a great example of a sensitivity power analysis in the wild as they are relatively rare to see in published research. They explain they recruited participants online, so they ended up with more participants than they aimed for.\n\n\n\n\n\n\nTry this\n\n\n\nTheir final sample size was 271, so try and adapt the function to calculate the effect size r they were sensitive to. Both of these answers assume 5% alpha and a one-sided test.\nTo 2 decimal places, they could detect an effect of r =  with 80% power and r =  with 95% power.\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have had this in a code chunk for 80% power:\n\npwr.r.test(n = 271, \n           r = NULL, \n           sig.level = .05, \n           power = .80, \n           alternative = \"greater\") %&gt;% \n  pluck(\"r\") %&gt;% \n  round(digits = 2)\n\n[1] 0.15\n\n\nAnd this in a code chunk for 95% power:\n\npwr.r.test(n = 271, \n           r = NULL, \n           sig.level = .05, \n           power = .95, \n           alternative = \"greater\") %&gt;% \n  pluck(\"r\") %&gt;% \n  round(digits = 2)\n\n[1] 0.2\n\n\n\n\n\n\n10.4.4 Power for regression with a continuous predictor\nLike the categorical predictor, we have a mismatch between the effect size you typically see reported (Pearson’s r) and the effect size we need for a regression power analysis (\\(f^2\\)). The website psychometrica.de still works for converting effect sizes in section 14. Alternatively, you can use the following code to save \\(f^2\\) as an object.\n\n# effect size as Pearson's r\nr &lt;- .20\n\n# convert to f2 by squaring r values\nf2 &lt;- r^2 / (1 - r^2)\n\nNow we have \\(f^2\\), we can use the function pwr.f2.test() which calculates power for regression models.\n\n# number of predictors\nu &lt;- 1\n\n# alpha for type I error rate\nalpha &lt;- .05\n\n# power for 1-beta\npower &lt;-  .95\n\npwr.f2.test(u = u, \n            v = NULL, \n            sig.level = alpha, \n            power = power, \n            f2 = f2)\n\n\n     Multiple regression power calculation \n\n              u = 1\n              v = 311.807\n             f2 = 0.04166667\n      sig.level = 0.05\n          power = 0.95\n\n\nUsing the objects from the power analysis, we can calculate the sample size we need with a little reorganising.\n\nwingen_v &lt;- pwr.f2.test(u = 1, \n                        v = NULL, \n                        sig.level = .05, \n                        power = .95, \n                        f2 = f2) %&gt;% \n  pluck(\"v\") \n\nceiling(wingen_v + u + 1)\n\n[1] 314\n\n\nIn the Pearson’s r power analysis function, we needed 319 participants in total, so the estimate is off by 5 participants this time. We still have a few steps for rounding error, so this is close enough to show it is the equivalent but more awkward process.\nIf you wanted to use this function for a sensitivity power analysis, you can convert \\(f^2\\) back to Pearson’s \\(r\\) using psychometrica.de or use the following code:\n\n# f2 from the output\nf2 &lt;- .042\n\n# convert to r from the square root of f2 / f2 + 1\nr &lt;- sqrt(f2 / (f2 + 1))"
  },
  {
    "objectID": "10-power.html#reporting-a-power-analysis",
    "href": "10-power.html#reporting-a-power-analysis",
    "title": "\n10  Statistical Power and Effect Sizes\n",
    "section": "\n10.5 Reporting a power analysis",
    "text": "10.5 Reporting a power analysis\nBakker et al. (2020) warned that only 20% of power analyses contained enough information to be fully reproducible. To report your power analysis, the reader needs the following four key pieces of information:\n\nThe type of test you based the power analysis on (e.g., t-test, correlation, regression),\nThe software used to calculate power (i.e., cite the pwr package, see How to cite R),\nThe inputs that you used (alpha, power, effect size, sample size, tails), and\nWhy you chose those inputs.\n\nIn this chapter, we will only cover the first three. The justification for your inputs comes under evaluation skills, so we will work on that in the course materials. Please note there is no single ‘correct’ way to report a power analysis, we just provide examples. Just be sure that you have the four key pieces of information.\n\n10.5.1 Reporting a t-test power analysis\nFor a t-test, the key distinctive input is Cohen’s d as the effect size.\n\n“To detect an effect size of Cohen’s d = 0.54 with 90% power (alpha = .05, two-tailed), the pwr package (Champely, 2020) in R (R Core Team, 2024) suggests we would need 74 participants per group (N = 148) for an independent samples t-test.”\n\nAlternatively, if you reported a sensitivity power analysis, the emphasis goes to the effect size your study would be sensitive to.\n\n“With our final sample size of 40 participants per group, a sensitivity power analysis for an independent samples t-test using the pwr package (Champely, 2020; R Core Team, 2024) showed we could detect an effect size of d = 0.73 with 90% power (5% alpha, two-sided).”\n\n\n10.5.2 Reporting a correlation power analysis\nFor a correlation, the key distinctive input is Pearson’s r as the effect size.\n\n“To detect an effect size of r = .20 with 95% power (alpha = .05, one-tailed), the pwr package (Champely, 2020) in R (R Core Team, 2024) suggests we would need 266 participants for a Pearson’s r correlation.”\n\nAnd for a sensitivity power analysis.\n\n“With our final sample size of 271 participants, a sensitivity power analysis for a Pearson’s r correlation using the pwr package (Champely, 2020; R Core Team, 2024) showed we could detect an effect size of r = .20 with 95% power (5% alpha, one-sided).”\n\n\n10.5.3 Reporting a regression power analysis\nFor regression, the key distinctive inputs are \\(f^2\\) as the effect size, including any details of converting effect sizes, plus the number of predictors.\n\n“To detect an effect size of Cohen’s \\(f^2\\) = .073, we first converted the effect size from d = 0.54. For 90% power (alpha = .05, two-tailed), the pwr package (Champely, 2020) in R (R Core Team, 2024) suggests we would need 147 participants split into two groups for a regression model with one categorical predictor.”\n\nFor a sensitivity power analysis, remember to include a note of any effect size conversions.\n\n“We used the pwr package (Champely, 2020; R Core Team, 2024) to conduct a sensitivity power analysis for linear regression with one predictor. With a final sample size of 319, we would be able to detect an effect size of Cohen’s \\(f^2\\) = .041 (95% power, 5% alpha). Converted to Pearson’s r, this would be an effect size of r = .20.”"
  },
  {
    "objectID": "10-power.html#test-yourself",
    "href": "10-power.html#test-yourself",
    "title": "\n10  Statistical Power and Effect Sizes\n",
    "section": "\n10.6 Test Yourself",
    "text": "10.6 Test Yourself\nTo end the chapter, we have some knowledge check questions to test your understanding of the concepts we covered in the chapter. We then have some error mode tasks to see if you can find the solution to some common errors in the concepts we covered in this chapter.\n\n10.6.1 Knowledge check\nQuestion 1. If you want to conduct an a priori power analysis , what input do you leave blank to solve for?\n\nsample sizeeffect sizepoweralpha\n\nQuestion 2. If you want to conduct a sensitivity power analysis , what input do you leave blank to solve for?\n\nsample sizealphapowereffect size\n\nRead the following output for an a priori power analysis. The next two questions are based on this output.\n\n\n\n     Two-sample t test power calculation \n\n              n = 89.95986\n              d = 0.42\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nQuestion 3. Our smallest effect size of interest is:\n\nd = 0.80r = .80r = .42d = 0.42\n\nQuestion 4. For these inputs, we would need to recruit how many participants per group?\n\n89428090\n\nRead the following output for a sensitivity power analysis. The next two questions are based on this output.\n\n\n\n     approximate correlation power calculation (arctangh transformation) \n\n              n = 72\n              r = 0.3695127\n      sig.level = 0.05\n          power = 0.9\n    alternative = two.sided\n\n\nQuestion 5. Our final sample size was:\n\n72509036\n\nQuestion 6. For these inputs, what effect size would we be sensitive to detect?\n\nr = .05r = .90r = .37r = .72\n\n\n10.6.2 Error mode\nThe following questions are designed to introduce you to making and fixing errors. For this topic, we focus on simple linear regression between two continuous variables. There are not many outright errors that people make here, more misspecifications that are not doing what you think they are doing.\nCreate and save a new R Markdown file for these activities. Delete the example code, so your file is blank from line 10. Create a new code chunk to load the packages tidyverse and pwr.\nBelow, we have several variations of a code chunk error or misspecification. Copy and paste them into your R Markdown file below the code chunk to load tidyverse and pwr. Once you have copied the activities, click knit and look at the error message you receive. See if you can fix the error and get it working before checking the answer.\n\nunconverted effect sizes\n\nQuestion 7. Copy the following code chunk into your R Markdown file and press knit. You should get a cryptic sounding error like Error in uniroot(function(n) eval(p.body) - power, c(4 + 1e-10, 1e+09)): f() values at end points not of opposite sign.\n```{r}\npwr.r.test(n = NULL, \n           r = .20, \n           sig.level = .05, \n           power = .95, \n           alternative = \"less\")\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nIn this example, we specified a positive effect size but negative one-tailed test. They must be consistent, so you either need to make the hypothesis the same:\n\npwr.r.test(n = NULL, \n           r = .20, \n           sig.level = .05, \n           power = .95, \n           alternative = \"greater\")\n\nOr the effect size the same:\n\npwr.r.test(n = NULL, \n           r = -.20, \n           sig.level = .05, \n           power = .95, \n           alternative = \"less\")\n\nBoth will produce the same sample size as it is the absolute effect which is important, but we recommend making it consistent with your research question / hypothesis.\n\n\n\nQuestion 8. Copy the following code chunk into your R Markdown file and press knit. You want to conduct a sensitivity power analysis when you have unequal sample sizes. You should get the following error: Error in pwr.t.test(n1 = 40, n2 = 50, d = NULL, sig.level = 0.05, power = 0.9,  : unused arguments (n1 = 40, n2 = 50).\n```{r}\npwr.t.test(n1 = 40, \n           n2 = 50,\n           d = NULL, \n           sig.level = .05, \n           power = .90, \n           alternative = \"two.sided\")\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nIn this example, we used the wrong function. pwr.t.test() only accepts n as a single argument. If you want a sensitivity power analysis for unequal sample sizes, you need the function pwr.t2n.test():\n\npwr.t2n.test(n1 = 40, n2 = 50,\n           d = NULL, \n           sig.level = .05, \n           power = .90, \n           alternative = \"two.sided\")\n\n\n\n\nQuestion 9. Copy the following code chunk into your R Markdown file and press knit. In your research to establish your smallest effect size of interest, you found a meta-analysis which found the average effect size for your topic was d = 0.54. For your correlational study, you use this effect size for your a priori power analysis. This…works, but is this all consistent?\n```{r}\npwr.r.test(n = NULL, \n           r = .54, \n           sig.level = .05, \n           power = .95, \n           alternative = \"two.sided\")\n```\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nIn this example, we used the wrong effect size. We see this error a lot when people are looking for past studies to inform their smallest effect size of interest. You find a meta-analysis which is perfect, but it reports Cohen’s d when you want Pearson’s r for your study. You can convert between effect sizes (with the caveat the studies should be comparable), but the same number means different things. Mistaking d = 0.54 for Pearson’s r is going to vastly underestimate the sample size you need, as it would be converted to r = .26.\n\npwr.r.test(n = NULL, \n           r = .26, \n           sig.level = .05, \n           power = .95, \n           alternative = \"two.sided\")"
  },
  {
    "objectID": "10-power.html#words-from-this-chapter",
    "href": "10-power.html#words-from-this-chapter",
    "title": "\n10  Statistical Power and Effect Sizes\n",
    "section": "\n10.7 Words from this Chapter",
    "text": "10.7 Words from this Chapter\nBelow you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the PsyTeachR Glossary. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter.\n\n\n\n\nterm\ndefinition\n\n\n\nalpha\n(stats) The cutoff value for making a decision to reject the null hypothesis; (graphics) A value between 0 and 1 used to control the levels of transparency in a plot\n\n\nbeta\nThe false negative rate we accept for a statistical test.\n\n\nfalse-negative\nWhen a test concludes there is no effect when there really is an effect\n\n\nfalse-positive\nWhen a test concludes there is an effect when there really is no effect\n\n\nhypothesis\nA proposed explanation made on the basis of limited evidence as a starting point for further investigation.\n\n\npower\nThe probability of rejecting the null hypothesis when it is false.\n\n\nprobability\nA number between 0 and 1 where 0 indicates impossibility of the event and 1 indicates certainty"
  },
  {
    "objectID": "10-power.html#end-of-chapter",
    "href": "10-power.html#end-of-chapter",
    "title": "\n10  Statistical Power and Effect Sizes\n",
    "section": "\n10.8 End of Chapter",
    "text": "10.8 End of Chapter\nGreat work, being able to conduct a power analysis is a great skill to have for designing an informative study. Although things have improved over the years, it is still relatively rare to see a study in the wild report a power analysis to justify their sample size. Keep in mind they involve a lot of subjective decision making as the values you choose for alpha, power, and your smallest effect size have flexibility. A larger sample - and hence more powerful study - would always be useful, but you are never working with unlimited resources. You must make compromises and think about whether you can conduct an informative study with the resources available to you. This means the hard work comes into making decisions about the values you enter, rather than the data skills for power analysis being difficult.\nIn the next - and final for the Research Methods 1 component - chapter, we cover screening data and decision making in data analysis. In Chapters 8 and 9, we covered topics like diagnostic checks for statistical models. Some of them looked fine, whereas some looked potentially problematic. In the next chapter, we work through the decisions you must make when analysing data like checking for missing data, outliers, and issues with diagnostic checks. Importantly, we outline the kind of solutions you can consider for those problems which we omitted in previous chapters.\n\n\n\n\nBakker, M., Veldkamp, C. L. S., Akker, O. R. van den, Assen, M. A. L. M. van, Crompvoets, E., Ong, H. H., & Wicherts, J. M. (2020). Recommendations in pre-registrations and internal review board proposals promote formal power analyses but do not increase sample size. PLoS ONE, 15(7), e0236079. https://doi.org/10.1371/journal.pone.0236079\n\n\nBartlett, J., & Charles, S. (2022). Power to the People: A Beginner’s Tutorial to Power Analysis using jamovi. Meta-Psychology, 6. https://doi.org/10.15626/MP.2021.3078\n\n\nChampely, S. (2020). Pwr: Basic functions for power analysis. https://CRAN.R-project.org/package=pwr\n\n\nIrving, D., Clark, R. W. A., Lewandowsky, S., & Allen, P. J. (2022). Correcting statistical misinformation about scientific findings in the media: Causation versus correlation. Journal of Experimental Psychology. Applied. https://doi.org/10.1037/xap0000408\n\n\nLakens, D. (2022). Sample Size Justification. Collabra: Psychology, 8(1), 33267. https://doi.org/10.1525/collabra.33267\n\n\nR Core Team. (2024). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nWingen, T., Berkessel, J. B., & Englich, B. (2020). No Replication, No Trust? How Low Replicability Influences Trust in Psychology. Social Psychological and Personality Science, 11(4), 454–463. https://doi.org/10.1177/1948550619877412"
  },
  {
    "objectID": "11-screening-data.html#the-set-up-and-the-data",
    "href": "11-screening-data.html#the-set-up-and-the-data",
    "title": "\n11  Screening Data\n",
    "section": "\n11.1 The Set-Up and the Data",
    "text": "11.1 The Set-Up and the Data\nAs always we first need to start with setting up our working environment, bringing in our data and looking at it.\n\n11.1.0.1 Activity 1: Set-up\n\nOpen RStudio and set the working directory to your chapter folder. Ensure the environment is clear.\n\nIf you’re using the Rserver, avoid a number of issues by restarting the session - click Session - Restart R\n\n\n\nOpen a new R Markdown document and save it in your working directory. Call the file “screeningdata”.\n\nDownload messy.csv and save it in your Screening Data folder. Make sure that you do not change the file name at all.\n\nIf you prefer you can download the data in a zip folder by clicking here\n\nRemember not to change the file names at all and that data.csv is not the same as data (1).csv.\n\n\nDelete the default R Markdown welcome text and insert a new code chunk that loads the following packages, in this specific order, using the library() function. Remember the solutions if needed.\n\nLoad the packages in this order, psych then tidyverse\n\nagain we have not used some of these packages so you will likely need to install some of them using install.packages(). Remember though that you should only do this on your own machine and only in the console window. If you are using the RServer you will not need to install them.\n\n\nFinally, load the data held in messy.csv as a tibble into an object named messy using read_csv(). If unsure, have a look at the solution at the end of the chapter\n\n11.1.0.2 Activity 2: Look at the data\nmessy is simulated data for an experiment looking at the effect of note-taking on test performance and whether this is affected by being first language English. Participants are first given a pre-test to judge their baseline knowledge, then they watch a lecture and take notes. Immediately after the lecture is finished they take another test. Finally, they are tested after a week’s delay. The maximum score for any test is 30. Participants lose marks for incorrect answers so minus scores are also possible. The dataset has six variables:\n\n\nid showing the participant ID number\n\nage showing the age of the participant\n\nspeakershowing if the participant are first language English or not\n\n\ngender showing if the participant is male, female, or non-binary\n\n\npre showing pre-test score before any notes were taken\n\n\npost showing post-test score immediately after the lecture\n\n\ndelay showing test score after one week delay"
  },
  {
    "objectID": "11-screening-data.html#missing-data",
    "href": "11-screening-data.html#missing-data",
    "title": "\n11  Screening Data\n",
    "section": "\n11.2 Missing data",
    "text": "11.2 Missing data\nThe first issue we will cover is missing data. There is a whole host of reasons that your data could have missing values. For example:\n\nData can be missing because your participants accidentally didn’t fill in a question.\nData can be missing because participants intentionally didn’t want to answer a question.\nData can be missing because participants didn’t turn up to a final testing session.\nData can be missing because you did something wrong whilst setting up your questionnaire/experiment and it didn’t save.\n\nIn truth, real data frequently contains missing values and it’s important that you know how to identify missing data and what you can do with it. Which is what we want to show you a little of in this chapter.\n\n11.2.0.1 Activity 3: summary() and is.na()\n\nMissing data is normally shown in your tibbles and objects as NA - usually taken to mean something like “Not Available”. We have already seen a couple of approaches to find NAs in our data and we will quickly recap them.\nThe first approach is to use a pipeline of functions we have used before including summarise(), is.na(), sum(), and pluck(). For instance:\n\nmessy_na &lt;- messy %&gt;% \n  summarise(find_nas = is.na(speaker)) %&gt;%\n  summarise(count_nas = sum(find_nas)) %&gt;%\n  pluck(\"count_nas\")\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\nWhich reads as use is.na() to find all the NAs in messy (i.e the first summarise()) and then count up all those NAs (i.e. the second summarise() - which works because NAs are either TRUE, summed as 1, or FALSE, summed as 0), and then pluck out that number (i.e. the pluck()). And if you look at messy_na you see there are 20 NAs in speaker. That code looks quite long but it could actually be written as below if you prefer and you can follow the pipe inside the summarise().\n\nmessy_na &lt;- messy %&gt;% \n  summarise(count_nas = is.na(speaker) %&gt;% sum()) %&gt;% \n  pluck(\"count_nas\")\n\nThis approach, using is.na(), is a good approach if you are only interested in one column or maybe a couple of columns, but if you want a snapshot of all your columns then we can use summary() which we have seen previously. First, however, because speaker and gender are character/text rather than numerical, in order to see how many values are missing we first need to convert these two columns into factors using the below code\n\nmessy &lt;- messy %&gt;%\n  mutate(speaker = as.factor(speaker), \n         gender = as.factor(gender))\n\nsummary(messy)\n\nIf you run the code, you can see, there are 20 data points missing (NAs) in each of speaker, gender, and delay. However, and the important part if you look at the actual data, the missing data is not in the same 20 participants and that gives us some issues about how to deal with these different participants. Fortunately, there are several different approaches to dealing with missing data and we will cover a few here."
  },
  {
    "objectID": "11-screening-data.html#listwise-deletion",
    "href": "11-screening-data.html#listwise-deletion",
    "title": "\n11  Screening Data\n",
    "section": "\n11.3 Listwise Deletion",
    "text": "11.3 Listwise Deletion\nOne method for dealing with missing data is listwise. This approach removes any participant who have a missing value (i.e. a NA) in any variable. So if there is missing data in any of the columns in the dataset, that participant will be removed and you will only be left with participants with complete datasets. For example the below participants would be removed along with all others with a similar profile:\n\n\n\n\nid\nage\nspeaker\ngender\npre\npost\ndelay\n\n\n\nS008\n48\nenglish\nNA\n12\n15\n17\n\n\nS009\n22\nNA\nmale\n5\n18\n5\n\n\nS010\n31\nNA\nfemale\n13\n35\n17\n\n\nS011\n26\nenglish\nNA\n18\n19\n16\n\n\n\n\n\nWe can achieve this using the drop_na() function from the tidyr package that comes in as part of tidyverse.\n\n11.3.0.1 Activity 4: Listwise deletion\n\nRun the below code and then view the tibble in the object called messy_listwise.\n\n\nmessy_listwise &lt;- drop_na(messy)\n\nAs you can see messy_listwise now only contains data from participants with a complete set of data - i.e. responses in each column.\nNow, however, whilst this might seem like a good thing, and sometimes it is the most appropriate option, there are a couple of important points to consider.\n\nFirst, gender might not be part of our experiment; it might just be there as demographic information. So whilst we might not include gender in any of our analyses, because of the listwise deletion approach we have deleted experimental data if the participant was missing gender which means we are removing participants we could actual use.\nRelatedly, using a listwise deletion approach may result in the loss of a lot of data. Compare messy to messy_listwise. The original dataset had 200 participants. After using drop_na() we only have 143 participants meaning that we have lost over 25% of our data with this approach which is a lot of data.\n\n\n\nNote: It is worth mentioning that if you do use a listwise approach you should check that the missing values are not coming from one particular group (i.e., non-random attrition).\n\nTo counter these issues, one option is to amend the use of drop_na() so that it doesn’t include gender, or any column for that matter that we don’t want to exclude people based on. We can do this using a similar approach to what we have seen when using select(). For example, run the below code, have a look at the output and then answer the question:\n\nmessy_listwise2 &lt;- drop_na(messy, -gender)\n\n\nHow many observations does messy_listwise2 have? \n\n\nSo that approach says “remove participants with NAs from messy based on all columns except gender”. Alternatively, you could do “remove participants with NAs from messy based on only the columns of speaker and delay” as follows:\n\nmessy_listwise3 &lt;- drop_na(messy, speaker, delay)\n\nSo you actually have a lot of control with drop_na() as long as you plan your approach in advance."
  },
  {
    "objectID": "11-screening-data.html#pairwise-deletion",
    "href": "11-screening-data.html#pairwise-deletion",
    "title": "\n11  Screening Data\n",
    "section": "\n11.4 Pairwise Deletion",
    "text": "11.4 Pairwise Deletion\nThe alternative to listwise deletion is pairwise. This is when cases are removed depending upon the analysis. For example, if we were to calculate the correlations between pre, post, and delay without first removing participants with missing data, we would basically just use different numbers of participants in each correlation depending on missing data. For example, if you compare the degrees of freedom for the following two correlations:\n\ncor.test(messy$pre, messy$post)\n\n\n    Pearson's product-moment correlation\n\ndata:  messy$pre and messy$post\nt = 7.0493, df = 198, p-value = 2.924e-11\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.3296550 0.5523276\nsample estimates:\n      cor \n0.4479101 \n\n\n\ncor.test(messy$pre, messy$delay)\n\n\n    Pearson's product-moment correlation\n\ndata:  messy$pre and messy$delay\nt = 7.9619, df = 178, p-value = 1.927e-13\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.3958642 0.6127887\nsample estimates:\n      cor \n0.5124561 \n\n\nYou can see that the correlation of pre versus post has df = 198 whereas pre versus delay has df = 178. Meaning that the correlation is by default run only on the participants who have data in both columns - pairwise deletion. The problem here is remembering to write up the output accordingly as the dfs are changing and they may be different from the number of participants you stated in your methods section. Again it is about looking at your data!"
  },
  {
    "objectID": "11-screening-data.html#summarising-data-with-missing-values",
    "href": "11-screening-data.html#summarising-data-with-missing-values",
    "title": "\n11  Screening Data\n",
    "section": "\n11.5 Summarising data with missing values",
    "text": "11.5 Summarising data with missing values\nSo when running inferential tests like correlations, the analysis will usually know when to ignore missing values. However, if you’re calculating descriptive statistics or if you want to calculate the average score of a number of different items, you need to explicitly state to ignore the missing values. We can do this through na.rm = TRUE\n\n11.5.0.1 Activity 5: na.rm = TRUE\n\n\nRun the below code to calculate the mean score for each testing condition.\n\n\nsummarise(messy, \n          pre_mean = mean(pre),\n          post_mean = mean(post),\n          delay_mean = mean(delay)\n          )\n\nThis gives a table similar to below. We have rounded all the values to two decimal places but yours might have more decimal places.\n\n\n\n\npre_mean\npost_mean\ndelay_mean\n\n\n10.02\n17.27\nNA\n\n\n\n\nAs you can see, the mean score for delay shows as NA. This is because we are trying to calculate an average of a variable that has missing data and that just isn’t doable. As such we need to calculate the mean but ignoring the missing values by adding na.rm = TRUE - which you can read this as “remove the NAs? Yes”.\n\nRun the below code and then answer the question.\n\n\nsummarise(messy, \n          pre_mean = mean(pre),\n          post_mean = mean(post),\n          delay_mean = mean(delay, na.rm = TRUE)\n          )\n\n\nWhat is the mean score for the delay condition to 2 decimal places? \n\n\n\n\n\nIt’s really important that you think about whether you want to calculate your descriptives from participants that have missing data. For example, if you are calculating the average reaction time from hundreds of trials, a few missing data points won’t affect the validity of the mean. However, if you are using a standardised questionnaire that has been validated using complete responses but your participants didn’t answer 3/10 questions, it may not be appropriate to calculate a mean score from the remaining data."
  },
  {
    "objectID": "11-screening-data.html#implausible-values",
    "href": "11-screening-data.html#implausible-values",
    "title": "\n11  Screening Data\n",
    "section": "\n11.6 Implausible values",
    "text": "11.6 Implausible values\nAlong with looking for missing values, an additional crucial step of data screening is checking for implausible values - values that should not exist in your data. What is implausible depends on the data you’ve collected!\n\n11.6.0.1 Activity 6: Implausible values\nAdditional functions we can put inside a summarise() function are min() and max().\n\nRun the below code and look at the output and answer the questions below:\n\n\nmessy %&gt;%\n  summarise(max_age = max(age, na.rm = TRUE),\n            min_age = min(age, na.rm = TRUE),\n            max_pre = max(pre, na.rm = TRUE),\n            min_pre = min(pre, na.rm = TRUE),\n            max_post = max(post, na.rm = TRUE),\n            min_post = min(post, na.rm = TRUE),\n            max_delay = max(delay, na.rm = TRUE),\n            min_delay = min(delay, na.rm = TRUE))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmax_age\nmin_age\nmax_pre\nmin_pre\nmax_post\nmin_post\nmax_delay\nmin_delay\n\n\n470\n18\n26\n-5\n40\n3\n29\n-3\n\n\n\n\n\n\nDoes the max value of age look plausible? \nYes\nNo\n\nDoes the max value of pre look plausible? \nYes\nNo\n\nDo the max value of post look plausible? \nYes\nNo\n\nDo the min value of delay look plausible? \nNo\nYes\n\n\n\n\nExplain these answers\n\n\nThe maximum value for age is 470, this is unlikely to be correct!\nThe maximum value for pre, post, and delay should be 30, as we described at the start of the chapter. However, for post, the maximum value is 40 so something is wrong. This is a very important check to do on your data, not just for the raw data but if you’ve calculated a total score.\nThe min value for delay is plausible, given the explanation at the start of the chapter. Remember that participants can be deducted points for incorrect answers, so negative values are possible.\n\n\nThat code above does look a bit long and could be written quicker as below. We won’t go into detail as to how this works but see if you can figure it out by comparing the output to the version above:\n\nmessy %&gt;% \n  summarise_at(c(\"age\",\"pre\",\"post\",\"delay\"),\n               c(max, min),\n               na.rm = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nage_fn1\npre_fn1\npost_fn1\ndelay_fn1\nage_fn2\npre_fn2\npost_fn2\ndelay_fn2\n\n\n470\n26\n40\n29\n18\n-5\n3\n-3\n\n\n\n\n\nAnd there is always summary(messy) if you prefer. But the main point is that we should always check our values to make sure they are allowed in our data. But whilst looking at the values is useful, it can be easier to visualise the data.\n\n11.6.0.2 Activity 7: Visualising implausible values\nThere are a number of different ways to visualise the data as you know and this depends on the data, and your preferences. You could produce violin-boxplots with the data points on top to check the distributions as follows:\n\nmessy %&gt;%\n  pivot_longer(cols = c(\"pre\", \"post\", \"delay\"), \n               names_to = \"test\", \n               values_to = \"score\") %&gt;%\n  ggplot(aes(x = test, y = score)) +\n  geom_violin() +\n  geom_boxplot() +\n  geom_jitter(width = .2)\n\n\n\nData screening plots\n\n\n\nAnd if it helped, you could add some max and min lines to help spot issues using geom_hline() as follows:\n\nmessy %&gt;%\n  pivot_longer(cols = c(\"pre\", \"post\", \"delay\"), \n               names_to = \"test\", \n               values_to = \"score\") %&gt;%\n  ggplot(aes(x = test, y = score)) +\n  geom_violin() +\n  geom_boxplot() +\n  geom_jitter(width = .2) +\n  geom_hline(yintercept = c(0,30), color = \"red\", linetype = 2)\n\n\n\nData screening plots\n\n\n\nAlternatively you could also use a histogram to spot an outlier:\n\nggplot(messy, aes(x = age)) +\n  geom_histogram()\n\n\n\nHistogram of age for data screening\n\n\n\nAnd we can make use of facet_wrap() which we have seen before to help split figures based on different conditions:\n\nmessy %&gt;%\n  pivot_longer(cols = c(\"pre\", \"post\", \"delay\"), \n               names_to = \"test\", \n               values_to = \"score\") %&gt;%\n  ggplot(aes(x = score)) +\n  geom_histogram(binwidth = 1) +\n  facet_wrap(~test)\n\n\n\nHistogram of the DVs for data screening\n\n\n\nWhatever method you choose, make sure that you look at your data before trying to work with it and that you know in advance what range your values should take (for example, if your Likert scale is 1-7, you shouldn’t have a score of 8, for reaction times, 50ms is unlikely to reflect a real response)."
  },
  {
    "objectID": "11-screening-data.html#dealing-with-implausible-values-or-missing-data",
    "href": "11-screening-data.html#dealing-with-implausible-values-or-missing-data",
    "title": "\n11  Screening Data\n",
    "section": "\n11.7 Dealing with implausible values or missing data",
    "text": "11.7 Dealing with implausible values or missing data\nOnce we have spotted some implausible or missing values we then need to decide what to do with them. However, there is no hard and fast rule about what to do with missing data. You should review the missing data to see if there are any patterns, for example, is all the missing data from one condition? A pattern may indicate a problem with your design. Alternatively, does a single participant have a lot of missing data and should they be removed? This might indicate they were not paying attention.\nOne way of dealing with implausible values is to use the replace() and mutate() functions to change such values to Na.\n\nFor age, we know that we have one very specific data point that is implausible, an age of 470 so we can specify just to replace this one value with NA.\nFor post, there are multiple missing values so we specify to replace any data point that is over the maximum plausible value (30) with NA.\n\n\nmessy_screen &lt;-  messy %&gt;% \n  mutate(age = replace(age, age == 470, NA),\n         post = replace(post, post &gt; 30, NA))\n\nAn alternative method for dealing with implausible data is to impute the data, i.e., to replace missing data with substituted values. There are many methods of doing this, for example, you can replace missing values with the mean value of the distribution. We won’t go into which method you should choose this in this chapter but there’s more information available online about the various options if you’re interested. The code for imputing missing data is relatively simple and uses mutate() and replace_na().\n\nYou can read the below code as “create a new variable named post_impute that replaces the values of post if they’re NA with the mean of the values in post.\n\n\nmessy_impute &lt;- messy_screen %&gt;%\n  mutate(post_impute = replace_na(post, \n                                  mean(post, na.rm = TRUE)))\n\nAnd if we look at a participant who had a NA for post we can see the change:\n\n\n\n\nid\nage\nspeaker\ngender\npre\npost\ndelay\npost_impute\n\n\nS016\n40\nenglish\nfemale\n21\nNA\n12\n16.71134\n\n\n\n\nSo you can see that they have been given the value of the mean of the distribution in this new variable and then can be used in different analyses!"
  },
  {
    "objectID": "11-screening-data.html#alternative-function-for-descriptive-statistics",
    "href": "11-screening-data.html#alternative-function-for-descriptive-statistics",
    "title": "\n11  Screening Data\n",
    "section": "\n11.8 Alternative function for descriptive statistics",
    "text": "11.8 Alternative function for descriptive statistics\nAnd before we end this chapter we wanted to just add a small section on an alternative function for calculating some useful descriptives that you can use to check your data. So far in this book, we’ve calculated descriptive statistics using summarise() from the tidyverse. There’s a good reason we’ve done this - the output of summarise() works well with ggplot() and the code is very flexible. However, it can be hard to calculate descriptives such as skew and kurtosis within summarise() and it can be useful to know of other functions that help create these descriptives. For example, the psych package contains many functions that are useful for psychology research. One of the functions of psych is describe().\n\nRun the below code and look at the output as shown below.\n\n\ndescriptives &lt;- describe(messy)\ndescriptives\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvars\nn\nmean\nsd\nmedian\ntrimmed\nmad\nmin\nmax\nrange\nskew\nkurtosis\nse\n\n\n\nid*\n1\n200\n100.500000\n57.8791845\n100.5\n100.500000\n74.1300\n1\n200\n199\n0.0000000\n-1.2180144\n4.0926764\n\n\nage\n2\n200\n36.075000\n32.3102015\n34.0\n33.931250\n13.3434\n18\n470\n452\n12.0951922\n159.6718805\n2.2846763\n\n\nspeaker*\n3\n180\n1.511111\n0.5012709\n2.0\n1.513889\n0.0000\n1\n2\n1\n-0.0440855\n-2.0091259\n0.0373625\n\n\ngender*\n4\n180\n1.688889\n0.7268889\n2.0\n1.611111\n1.4826\n1\n3\n2\n0.5452331\n-0.9643153\n0.0541791\n\n\npre\n5\n200\n10.015000\n5.0039959\n10.0\n9.987500\n4.4478\n-5\n26\n31\n0.0555773\n0.2559528\n0.3538359\n\n\npost\n6\n200\n17.270000\n6.3386110\n17.0\n16.968750\n5.9304\n3\n40\n37\n0.5802699\n0.7133158\n0.4482075\n\n\ndelay\n7\n180\n13.600000\n5.1563271\n14.0\n13.645833\n4.4478\n-3\n29\n32\n-0.0462551\n0.4985955\n0.3843299\n\n\n\n\n\nAs you can see describe() produces a full set of descriptive statistics, including skew, kurtosis and standard error for the entire dataset! Run ?describe to see a full explanation of all the statistics it calculates.\nYou may notice that id, speaker and gender all have a star next to their name. This star signifies that these variables are factors, and so it is not really appropriate to calculate these statistics, but we asked it to apply describe() to the entire dataset so it’s done what you asked. However, we could describe()with select() to remove these variables and just get the data we want:\n\ndescriptives2 &lt;- messy %&gt;%\n  select(-id, -speaker, -gender) %&gt;%\n  describe()\n\ndescriptives2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvars\nn\nmean\nsd\nmedian\ntrimmed\nmad\nmin\nmax\nrange\nskew\nkurtosis\nse\n\n\n\nage\n1\n200\n36.075\n32.310201\n34\n33.93125\n13.3434\n18\n470\n452\n12.0951922\n159.6718805\n2.2846763\n\n\npre\n2\n200\n10.015\n5.003996\n10\n9.98750\n4.4478\n-5\n26\n31\n0.0555773\n0.2559528\n0.3538359\n\n\npost\n3\n200\n17.270\n6.338611\n17\n16.96875\n5.9304\n3\n40\n37\n0.5802699\n0.7133158\n0.4482075\n\n\ndelay\n4\n180\n13.600\n5.156327\n14\n13.64583\n4.4478\n-3\n29\n32\n-0.0462551\n0.4985955\n0.3843299\n\n\n\n\n\nThe output of describe() is a little harder to work with in terms of manipulating the table and using the data in subsequent plots and analyses, so we still strongly recommend that you use summarise() and group_by() for these operations, however, for getting a comprehensive overview of your data, describe() is a good function to know about."
  },
  {
    "objectID": "11-screening-data.html#screening-fin",
    "href": "11-screening-data.html#screening-fin",
    "title": "\n11  Screening Data\n",
    "section": "\n11.9 Finished!",
    "text": "11.9 Finished!\nAnd you’re done! Excellent work today! This isn’t a comprehensive tutorial on every type of dataset you will come across and the concept of tidy data will take practice but hopefully this should give you a good starting point for when you have your own real, messy data."
  },
  {
    "objectID": "11-screening-data.html#screening-sols",
    "href": "11-screening-data.html#screening-sols",
    "title": "\n11  Screening Data\n",
    "section": "\n11.10 Activity solutions",
    "text": "11.10 Activity solutions\n\n11.10.1 Activity 1\n\nlibrary(psych)\nlibrary(tidyverse)\nmessy &lt;- read_csv(\"messy.csv\")"
  },
  {
    "objectID": "11-screening-data.html#words-from-this-chapter",
    "href": "11-screening-data.html#words-from-this-chapter",
    "title": "\n11  Screening Data\n",
    "section": "\n11.11 Words from this Chapter",
    "text": "11.11 Words from this Chapter\nBelow you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the PsyTeachR Glossary. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter.\n\n\n\n\nterm\ndefinition\n\n\n\nimpute\n\n\n\nlistwise\n\n\n\npairwise\n\n\n\n\n\n\nThat is end of this chapter. Be sure to look again at anything you were unsure about and make some notes to help develop your own knowledge and skills. It would be good to write yourself some questions about what you are unsure of and see if you can answer them later or speak to someone about them. Good work today!"
  },
  {
    "objectID": "12-anova.html#chapter-preparation",
    "href": "12-anova.html#chapter-preparation",
    "title": "\n12  One-way ANOVA\n",
    "section": "\n12.1 Chapter preparation",
    "text": "12.1 Chapter preparation\n\n12.1.1 Introduction to the data set\nFor this chapter, we are using open data from experiment 2 in James et al. (2015). The abstract of their article is:\n\nMemory of a traumatic event becomes consolidated within hours. Intrusive memories can then flash back repeatedly into the mind’s eye and cause distress. We investigated whether reconsolidation - the process during which memories become malleable when recalled - can be blocked using a cognitive task and whether such an approach can reduce these unbidden intrusions. We predicted that reconsolidation of a reactivated visual memory of experimental trauma could be disrupted by engaging in a visuospatial task that would compete for visual working memory resources. We showed that intrusive memories were virtually abolished by playing the computer game Tetris following a memory-reactivation task 24 hr after initial exposure to experimental trauma. Furthermore, both memory reactivation and playing Tetris were required to reduce subsequent intrusions (Experiment 2), consistent with reconsolidation-update mechanisms. A simple, non-invasive cognitive-task procedure administered after emotional memory has already consolidated (i.e., &gt; 24 hours after exposure to experimental trauma) may prevent the recurrence of intrusive memories of those emotional events.\n\nIn summary, they were interested in whether you can reduce intrusive memories associated with a traumatic event. Participants were randomly allocated to one of four groups and watched a video designed to be traumatic:\n\nControl\nReactivation + Tetris\nTetris\nReactivation\n\nThey measured the number of intrusive memories prior to the start of the study, then participants kept a diary to record intrusive memories about the film in the 7 days after watching it. The authors were interested in whether the combination of reactivation and playing Tetris would lead to the largest reduction in intrusive memories. You will recreate their analyses using a one-way ANOVA.\n\n12.1.2 Organising your files and project for the chapter\nBefore we can get started, you need to organise your files and project for the chapter, so your working directory is in order.\n\nIn your folder for research methods and the book ResearchMethods1_2/Quant_Fundamentals, create a new folder called Chapter_12_ANOVA. Within Chapter_12_ANOVA, create two new folders called data and figures.\nCreate an R Project for Chapter_12_ANOVA as an existing directory for your chapter folder. This should now be your working directory.\nCreate a new R Markdown document and give it a sensible title describing the chapter, such as 12 ANOVA. Delete everything below line 10 so you have a blank file to work with and save the file in your Chapter_12_ANOVA folder.\nWe are working with a new data set, so please save the following data file: James_2015.csv. Right click the link and select “save link as”, or clicking the link will save the files to your Downloads. Make sure that you save the file as “.csv”. Save or copy the file to your data/ folder within Chapter_12_ANOVA.\n\nYou are now ready to start working on the chapter!\n\n12.1.3 Activity 1 - Read and wrangle the data\nAs the first activity, try and test yourself by completing the following task list to practice your data wrangling skills. Create a final object called james_data to be consistent with the tasks below.\n\n\n\n\n\n\nTry this\n\n\n\nTo wrangle the data, complete the following tasks:\n\n\nLoad the following packages (several of these are new, so revisit Chapter 1 if you need a refresher of installing R packages, but remember not to install packages on the university computers / online server):\n\npwr\neffectsize\nbroom\nafex\nemmeans\nperformance\ntidyverse\n\n\nRead the data file data/James_2015.csv to the object name james_data.\nCreate a new variable called PID that equals row_number() to act as a participant ID which is currently missing from the data set.\nConvert Condition to a factor.\n\nSelect and rename the following three variables as we do not need the others:\n\nPID\nCondition\nRename Days_One_to_Seven_Image_Based_Intrusions_in_Intrusion_Diary to intrusions.\n\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# Load packages\nlibrary(pwr)\nlibrary(effectsize)\nlibrary(broom)\nlibrary(afex)\nlibrary(emmeans)\nlibrary(performance)\nlibrary(tidyverse)\n\n# Read data and add new column\njames_data &lt;- read_csv(\"data/James_2015.csv\") %&gt;%\n  mutate(PID = row_number(),\n         Condition = as.factor(Condition)) %&gt;% \n  select(PID, \n         Condition, \n         intrusions = Days_One_to_Seven_Image_Based_Intrusions_in_Intrusion_Diary)\n\n\n\n\n\n12.1.4 Activity 2 - Create summary statistics\nNext, we want to calculate some descriptive statistics to see some overall trends in the data. We are really interested in the scores from each experimental group rather than overall.\n\n\n\n\n\n\nTry this\n\n\n\n\nSummarise the data to show the mean, standard deviation, and standard error for the number of intrusive memories (intrusions) grouped by Condition.\nYour table should have four columns, Condition, mean, sd, and se.\n\nHint: You can calculate the standard error through: sd/sqrt(n) or sd/sqrt(length(some_variable_name).\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\njames_data %&gt;%\n  group_by(Condition) %&gt;%\n  summarise(mean = round(mean(intrusions), 2), \n            sd = round(sd(intrusions), 2), \n            se = round(sd/sqrt(length(intrusions)), 2))\n\n\n\n\nCondition\nmean\nsd\nse\n\n\n\n1\n5.11\n4.23\n1.00\n\n\n2\n1.89\n1.75\n0.41\n\n\n3\n3.89\n2.89\n0.68\n\n\n4\n4.83\n3.33\n0.78\n\n\n\n\n\n\n\n\n\n\n12.1.5 Activity 3 - Visualisation\nNow we can visualise the data. In the original paper they use a bar plot, but let’s use a better plot that gives us more information about the data.\n\n\n\n\n\n\nTry this\n\n\n\n\nCreate a violin-boxplot with the number of intrusive memories on the y-axis and condition on the x-axis (See Chapter 7 if you need a reminder).\nChange the labels on the x-axis to something more informative for the condition names.\n\nYour plot should look like this:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\njames_data %&gt;% \n  ggplot(aes(x = Condition, y = intrusions))+\n  geom_violin()+\n  geom_boxplot(width = .2) + \n  scale_y_continuous(name = \"Number of Intrusions\") + \n  scale_x_discrete(labels = c(\"Control\", \"Reactivation + Tetris\", \"Tetris\", \"Reactivation\")) + \n  theme_classic()\n\nWe can see from this plot that there are a few potential outliers in each of the groups. This information is not present in the bar plot, which is why it’s not a good idea to use them for this kind of data."
  },
  {
    "objectID": "12-anova.html#anova-a6",
    "href": "12-anova.html#anova-a6",
    "title": "\n12  One-way ANOVA\n",
    "section": "\n12.2 One-way ANOVA",
    "text": "12.2 One-way ANOVA\nNow we can run the one-way ANOVA using aov_ez() from the afex package and save it to the object mod. As well as running the ANOVA, the aov_ez() function also conducts a Levene’s test for homogeneity of variance so that we can test our final assumption.\n\n12.2.1 Activity 4 - Running a one-way ANOVA using afex\naov_ez() will likely produce some messages that look like errors, do not worry about these, they are just letting you know what it’s done. Run the code below to view the results of the ANOVA.\n\nmod &lt;- aov_ez(id = \"PID\", # the column containing the participant IDs\n              dv = \"intrusions\", # the DV \n              between = \"Condition\", # the between-subject variable\n              es = \"pes\", # sets effect size to partial eta-squared\n              type = 3, # this affects how the sum of squares is calculated, set this to 3\n              include_aov = TRUE,\n              data = james_data)\n\nmod\n\nAnova Table (Type 3 tests)\n\nResponse: intrusions\n     Effect    df   MSE      F  ges p.value\n1 Condition 3, 68 10.09 3.79 * .143    .014\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n\n\nJust like with the t-tests and correlations, we can use tidy() to make the output easier to work with. Run the below code to transform the output. Do not worry about the warning message, it is just telling you it does not know how to automatically rename the columns so it will keep the original names.\n\nmod_output &lt;- mod$anova_table %&gt;% \n  tidy()\n\nWarning in tidy.anova(.): The following column names in ANOVA output were not\nrecognized or transformed: num.Df, den.Df, MSE, ges\n\nmod_output\n\n\n\n\nterm\nnum.Df\nden.Df\nMSE\nstatistic\nges\np.value\n\n\nCondition\n3\n68\n10.08578\n3.794762\n0.1434073\n0.0140858\n\n\n\n\n\n\n\nterm = the IV\n\n\nnum.Df = degrees of freedom effect\n\nden.Df = degrees of freedom residuals\n\nMSE = Mean-squared errors\n\nstatistic = F-statistic\n\nges = effect size\n\n\np.value = p.value\n\nYou should refer to the lecture for more information on what each variable means and how it is calculated.\n\nIs the overall effect of Condition significant? \nYes\nNo\nWhat is the F-statistics to 2 decimal places? \nAccording to the rules of thumb, the effect size is \nSmall\nMedium\nLarge\n\n12.2.2 Activity 5 - Checking assumptions for ANOVA\nTo test the assumptions, we must use the model we created with aov_ez(). For a one-way independent ANOVA, the assumptions are the same as for a Student t-test / regression model with a categorical predictor:\n\nThe DV is interval or ratio data.\nThe observations should be independent.\nThe residuals should be normally distributed.\nThere should be homogeneity of variance between the groups.\n\nWe know that 1 and 2 are met because of the design of our study. To test 3, we can look at the qq-plot of the residuals. Instead of saving just the model object, we must specifically select the aov component and run our diagnostic plots.\n\nplot(mod$aov, \n     which = 2)\n\n\n\nFigure 12.1: qq-plot for model residuals.\n\n\n\nThe qq-plot shows the assumption of normality might not be ideal. Is this a problem? If the sample sizes for each group are equal, then ANOVA is robust to violations of both normality and of homogeneity of variance. If you are interested, there is a good discussion of these issues in Blanca et al. (2018) and Knief & Forstmeier (2021). We can check how many participants are in each condition using count():\n\njames_data %&gt;% \n  count(Condition)\n\n\n\n\nCondition\nn\n\n\n\n1\n18\n\n\n2\n18\n\n\n3\n18\n\n\n4\n18\n\n\n\n\n\n\nThankfully, the sample sizes are equal, so we should be OK to proceed with the ANOVA. It is not clear whether normality was checked in the original paper.\nFor the last assumption, we can test homogeneity of variance by checking the third diagnostic plot for the scale against location.\n\nplot(mod$aov, \n     which = 3)\n\n\n\nFigure 12.2: Diagnostic plot for homogeneity of variance.\n\n\n\nCompared to normality, this assumption looks closer to being supported as the variance of each group is approximately equal. James et al. (2015) suspect there might be issues with this assumption as they mention that the ANOVAs do not assume equal variance, however, the results of the ANOVA that are reported are identical to our results above where no correction has been made although the post-hoc tests are Welch t-tests (you can tell this because the degrees of freedom have been adjusted and are not whole numbers).\nWhile all of this might seem very confusing - we imagine you might be wondering what the point of assumption testing is given that it seems to be ignored - we are showing you this for three reasons:\n\nTo reassure you that sometimes the data can fail to meet the assumptions and it is still ok to use the test. To put this in statistical terms, many tests are robust to mild deviations of normality and unequal variance, particularly with equal sample sizes.\nAs a critical thinking point, to remind you that just because a piece of research has been published does not mean it is perfect and you should always evaluate whether the methods used are appropriate.\nTo reinforce the importance of pre-registration where these decisions could be made in advance, and/or open data and code so that analyses can be reproduced exactly to avoid any ambiguity about exactly what was done. In this example, given the equal sample sizes and the difference in variance between the groups isn’t too extreme, it looks like it is still appropriate to use an ANOVA but the decisions and justification for those decisions could have been more transparent.\n\n\n\n\n\n\n\nNote\n\n\n\nThe check_model() function from performance also works here, so you can see what it looks like if you run:\n\ncheck_model(mod$aov)\n\n\n\n\n12.2.3 Activity 6 - Post-hoc tests\nFor post-hoc comparisons, the paper appears to have computed Welch t-tests but there is no mention of any multiple comparison correction. We could reproduce these results by using t.test() for each of the contrasts.\nFor example, to compare condition 1 (the control group) with condition 2 (the reactivation plus tetris group) we could run:\n\njames_data %&gt;%\n  filter(Condition %in% c(\"1\", \"2\")) %&gt;%\n  droplevels() %&gt;% # ignore unused factor levels\n  t.test(intrusions ~ Condition, \n         data = .)\n\n\n    Welch Two Sample t-test\n\ndata:  intrusions by Condition\nt = 2.9893, df = 22.632, p-value = 0.006627\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n 0.990331 5.454113\nsample estimates:\nmean in group 1 mean in group 2 \n       5.111111        1.888889 \n\n\n\n\n\n\n\n\nImportant\n\n\n\nBecause Condition has four levels, we cannot just specify intrustion ~ Condition because a t-test compares two groups and it would not know which of the four to compare so first we have to filter the data and use a new function droplevels(). It’s important to remember that when it comes to R there are two things to consider, the data you can see and the underlying structure of that data. In the above code we use filter() to select only conditions 1 and 2 so that we can compare them. However, that does not change the fact that R “knows” that Condition has four levels - it does not matter if two of those levels do not have any observations any more, the underlying structure still says there are four groups. droplevels() tells R to remove any unused levels from a factor. Try running the above code but without droplevels() and see what happens.\n\n\nHowever, a quicker and better way of doing this that allows you apply a correction for multiple comparisons easily is to use emmeans() which computes all possible pairwise comparison t-tests and applies a correction to the p-value.\nFirst, we use emmeans() to run the comparisons and then we can pull out the contrasts and use tidy() to make it easier to work with.\nRun the code below. Which conditions are significantly different from each other? Are any of the comparisons different from the ones reported in the paper now that a correction for multiple comparisons has been applied?\n\nmod_pairwise &lt;-emmeans(mod, \n                       pairwise ~ Condition, \n                       adjust = \"bonferroni\")\n\nmod_contrasts &lt;- mod_pairwise$contrasts %&gt;% \n  tidy()\n\nmod_contrasts\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\ncontrast\nnull.value\nestimate\nstd.error\ndf\nstatistic\nadj.p.value\n\n\n\nCondition\nCondition1 - Condition2\n0\n3.2222222\n1.058604\n68\n3.0438406\n0.0199179\n\n\nCondition\nCondition1 - Condition3\n0\n1.2222222\n1.058604\n68\n1.1545602\n1.0000000\n\n\nCondition\nCondition1 - Condition4\n0\n0.2777778\n1.058604\n68\n0.2624001\n1.0000000\n\n\nCondition\nCondition2 - Condition3\n0\n-2.0000000\n1.058604\n68\n-1.8892804\n0.3787128\n\n\nCondition\nCondition2 - Condition4\n0\n-2.9444444\n1.058604\n68\n-2.7814405\n0.0419783\n\n\nCondition\nCondition3 - Condition4\n0\n-0.9444444\n1.058604\n68\n-0.8921602\n1.0000000\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe inquisitive among you may have noticed that mod is a list of 5 and seemingly contains the same thing three times: anova_table, aov and Anova. The reasons behind the differences are too complex to go into detail on this course (see The R Companion website here for more information) but the simple version is that anova_table and Anova use one method of calculating the results (type 3 sum of squares) and aov uses a different method (type 1 sum of squares). What’s important for your purposes is that you need to use anova_table to view the overall results (and replicate the results from papers) and aovto run the follow-up tests and to get access to the residuals (or lm() for factorial ANOVA). As always, precision and attention to detail is key.\n\n\n\n12.2.4 Activity 7 - Power and effect sizes\nFinally, we can replicate their power analysis using pwr.anova.testfrom the pwr package.\n\nOn the basis of the effect size of d = 1.14 from Experiment 1, we assumed a large effect size of f = 0.4. A sample size of 18 per condition was required in order to ensure an 80% power to detect this difference at the 5% significance level.\n\n\npwr.anova.test(k = 4, \n               f = .4, \n               sig.level = .05, \n               power = .8)\n\n\n     Balanced one-way analysis of variance power calculation \n\n              k = 4\n              n = 18.04262\n              f = 0.4\n      sig.level = 0.05\n          power = 0.8\n\nNOTE: n is number in each group\n\n\nWe have already got the effect size for the overall ANOVA, however, we should also really calculate Cohen’s d using cohens_d() from effectsize for each of the pairwise comparisons. This code is a little long because you need to do it separately for each comparison, bind them all together and then add them to mod_contrasts - just make sure your understand which bits of the code you would need to change to run this on different data. As we are binding rows and columns rather than joining, it is critical the comparisons are already in the correct order.\n\n# Calculate Cohen's d for all comparisons\nd_1_2 &lt;- cohens_d(intrusions ~ Condition, \n                 data = filter(james_data, \n                               Condition %in% c(1, 2)) %&gt;% \n                   droplevels())\n\nd_1_3 &lt;- cohens_d(intrusions ~ Condition, \n                 data = filter(james_data, \n                               Condition %in% c(1, 3)) %&gt;% \n                   droplevels()) \n\nd_1_4 &lt;- cohens_d(intrusions ~ Condition, \n                 data = filter(james_data, \n                               Condition %in% c(1, 4)) %&gt;% \n                   droplevels())\n\nd_2_3 &lt;- cohens_d(intrusions ~ Condition, \n                 data = filter(james_data, \n                               Condition %in% c(2, 3)) %&gt;% \n                   droplevels())\n\nd_2_4 &lt;- cohens_d(intrusions ~ Condition, \n                 data = filter(james_data, \n                               Condition %in% c(2, 4)) %&gt;% \n                   droplevels())\n\nd_3_4 &lt;- cohens_d(intrusions ~ Condition, \n                 data = filter(james_data, \n                               Condition %in% c(3, 4)) %&gt;% \n                   droplevels())\n\n# Bind all the comparisons in the order of mod_contrasts\npairwise_ds &lt;- bind_rows(d_1_2, \n                         d_1_3, \n                         d_1_4,\n                         d_2_3, \n                         d_2_4, \n                         d_3_4)\n\n# Bind this object to the mod_contrasts object\nmod_contrasts &lt;- mod_contrasts %&gt;%\n  bind_cols(pairwise_ds)\n\n\n\n\n\n\n\nWarning\n\n\n\nWhat are your options if the data do not meet the assumptions and it’s really not appropriate to continue with a regular one-way ANOVA? As always, there are multiple options and it is a judgement call.\n\nYou could run a non-parametric test, the Kruskal-Wallis for between-subject designs and the Friedman test for within-subject designs.\nIf normality is the problem, you could try transforming the data.\nYou could use bootstrapping, which is not something we will cover in this course at all."
  },
  {
    "objectID": "12-anova.html#anova-a10",
    "href": "12-anova.html#anova-a10",
    "title": "\n12  One-way ANOVA\n",
    "section": "\n12.3 Reporting the results of your ANOVA",
    "text": "12.3 Reporting the results of your ANOVA\nThe below code replicates the write-up in the paper, although has changed the Welch t-test to the pairwise comparisons from emmeans().\n\nSecond, and critically, for the 7-day diary postintervention, there was a significant difference between groups in overall intrusion frequency in daily life, F(`r mod_output$num.Df`, `r mod_output$den.Df`) = `r mod_output$statistic %&gt;% round(2)`, p = `r mod_output$p.value %&gt;% round(3)`, ηp2 = .`r mod_output$ges %&gt;% round(2)`. Planned comparisons demonstrated that relative to the no-task control group, only those in the reactivation-plus-Tetris group, t(`r mod_contrasts$df[1]`) = `r mod_contrasts$statistic[1] %&gt;% round(2)`, p = `r mod_contrasts$adj.p.value[1] %&gt;% round(2)`, d = `r mod_contrasts$Cohens_d[1] %&gt;% round(2)`, experienced significantly fewer intrusive memories; this finding replicated Experiment 1. The reactivation-plus-Tetris group had significantly fewer intrusive thoughts than the reactivation-only group, t(`r mod_contrasts$df[5]`) = `r mod_contrasts$statistic[5] %&gt;% round(2)`, p = `r mod_contrasts$adj.p.value[5] %&gt;% round(2)`, d = `r mod_contrasts$Cohens_d[5] %&gt;% round(2)`. Further, there were no significant differences between the reactivation-plus-Tetris group and the Tetris-only group, t(`r mod_contrasts$df[4]`) = `r mod_contrasts$statistic[4] %&gt;% round(2)`, p = `r mod_contrasts$adj.p.value[4] %&gt;% round(2)`, d = `r mod_contrasts$Cohens_d[4] %&gt;% round(2)`, the no-task control group and the reactivation-only group, t(`r mod_contrasts$df[3]`) = `r mod_contrasts$statistic[3] %&gt;% round(2)`, p = `r mod_contrasts$adj.p.value[3] %&gt;% round(2)`, or between the no-task control group and the Tetris-only group, t(`r mod_contrasts$df[2]`) = `r mod_contrasts$statistic[2] %&gt;% round(2)`, p = `r mod_contrasts$adj.p.value[2] %&gt;% round(2)`\n\nIf you add that code to your R Markdown document, knitting it should create the following:\n\nSecond, and critically, for the 7-day diary postintervention, there was a significant difference between groups in overall intrusion frequency in daily life, F(3, 68) = 3.79, p = 0.014, ηp2 = .0.14. Planned comparisons demonstrated that relative to the no-task control group, only those in the reactivation-plus-Tetris group, t(68) = 3.04, p = 0.02, d = 1, experienced significantly fewer intrusive memories; this finding replicated Experiment 1. Critically, as predicted by reconsolidation theory, the reactivation-plus-Tetris group had significantly fewer intrusive memories than the Tetris-only group, t(68) = -1.89, p = 0.38, d = -0.84, as well as the reactivation-only group, t(68) = -2.78, p = 0.04, d = -1.11. Further, there were no significant differences between the no-task control group and the reactivation-only group, t(68) = 0.26, p = 1, or between the no-task control group and the Tetris-only group, t(68) = 1.15, p = 1"
  },
  {
    "objectID": "12-anova.html#end-of-chapter",
    "href": "12-anova.html#end-of-chapter",
    "title": "\n12  One-way ANOVA\n",
    "section": "\n12.4 End of chapter",
    "text": "12.4 End of chapter\nWell done! You have now covered how to run a one-way ANOVA using the afex package. Linear regression models are great for their flexibility, but it is not always simple for expressing a design with several levels. Combining afex and emmeans is a powerful combination when you have categorical independent variables / predictors with several levels.\nIn the next chapter, we will extend this to when you have multiple independent variables and you want to investigate the interaction between them for how they affect your dependent variable / outcome.\n\n\n\n\nBlanca, M. J., Alarcón, R., Arnau, J., Bono, R., & Bendayan, R. (2018). Effect of variance ratio on ANOVA robustness: Might 1.5 be the limit? Behavior Research Methods, 50(3), 937–962. https://doi.org/10.3758/s13428-017-0918-2\n\n\nJames, E. L., Bonsall, M. B., Hoppitt, L., Tunbridge, E. M., Geddes, J. R., Milton, A. L., & Holmes, E. A. (2015). Computer Game Play Reduces Intrusive Memories of Experimental Trauma via Reconsolidation-Update Mechanisms: Psychological Science, 26(8), 1201–1215. https://doi.org/10.1177/0956797615583071\n\n\nKnief, U., & Forstmeier, W. (2021). Violating the normality assumption may be the lesser of two evils. Behavior Research Methods, 53(6), 2576–2590. https://doi.org/10.3758/s13428-021-01587-5"
  },
  {
    "objectID": "13-factorial-anova.html#chapter-preparation",
    "href": "13-factorial-anova.html#chapter-preparation",
    "title": "\n13  Factorial ANOVA\n",
    "section": "\n13.1 Chapter preparation",
    "text": "13.1 Chapter preparation\n\n13.1.1 Introduction to the data set\nFor this chapter, we are using open data from experiment 3 in Zhang et al. (2014) which you might remember from Chapter 7. Now you have developed your inferential skills, we can return to reproduce their analyses. The abstract of their article is:\n\nAlthough documenting everyday activities may seem trivial, four studies reveal that creating records of the present generates unexpected benefits by allowing future rediscoveries. In Study 1, we used a time-capsule paradigm to show that individuals underestimate the extent to which rediscovering experiences from the past will be curiosity provoking and interesting in the future. In Studies 2 and 3, we found that people are particularly likely to underestimate the pleasure of rediscovering ordinary, mundane experiences, as opposed to extraordinary experiences. Finally, Study 4 demonstrates that underestimating the pleasure of rediscovery leads to time-inconsistent choices: Individuals forgo opportunities to document the present but then prefer rediscovering those moments in the future to engaging in an alternative fun activity. Underestimating the value of rediscovery is linked to people’s erroneous faith in their memory of everyday events. By documenting the present, people provide themselves with the opportunity to rediscover mundane moments that may otherwise have been forgotten.\n\nIn summary, they were interested in whether people could predict how interested they would be in rediscovering past experiences. They call it a “time capsule” effect, where people store photos or messages to remind themselves of past events in the future. They predicted participants in the ordinary group would underestimate their future feelings (i.e., there would be a bigger difference between time 1 and time 2 measures) compared to participants in the extraordinary group.\nNow we are focusing on the analysis rather than just visualisation, we can describe the experiment as a 2 x 2 mixed design. The first IV is time (time1, time2) and is within-subjects. The second IV is type of event (ordinary vs. extraordinary) and is a between-subjects factor. We will then use interest as a DV for a composite measure which took the mean of items on interest, meaningfulness, and enjoyment\n\n13.1.2 Organising your files and project for the chapter\nBefore we can get started, you need to organise your files and project for the chapter, so your working directory is in order.\n\nIn your folder for research methods and the book ResearchMethods1_2/Quant_Fundamentals, create a new folder called Chapter_13_F_ANOVA. Within Chapter_13_F_ANOVA, create two new folders called data and figures.\nCreate an R Project for Chapter_13_F_ANOVA as an existing directory for your chapter folder. This should now be your working directory.\nCreate a new R Markdown document and give it a sensible title describing the chapter, such as 13 Factorial ANOVA. Delete everything below line 10 so you have a blank file to work with and save the file in your Chapter_13_F_ANOVA folder.\nIf you must download the data again, please save the following file: Zhang_2014.csv. Right click the link and select “save link as”, or clicking the link will save the files to your Downloads. Make sure that you save the file as “.csv”. Save or copy the file to your data/ folder within Chapter_13_F_ANOVA.\n\nYou are now ready to start working on the chapter!\n\n13.1.3 Activity 1 - Load the packages and read the data\nWe already worked on the data wrangling in Chapter 7, so please type or copy and paste the following code to prepare for the chapter.\n\n# Load the packages below\n#library(\"rcompanion\")\nlibrary(effectsize)\n#library(\"car\")\nlibrary(broom)\nlibrary(afex)\nlibrary(emmeans)\nlibrary(tidyverse)\nlibrary(performance)\n\n# Load the data file\n# This should be the Zhang_2014.csv file \nzhang_data &lt;- read_csv(\"data/Zhang_2014.csv\")\n\n# Wrangle the data for plotting. \n# select and rename key variables\n# mutate to add participant ID and recode\nzhang_wide &lt;- zhang_data %&gt;%\n  select(Gender, \n         Age, \n         Condition, \n         time1_interest = T1_Predicted_Interest_Composite, \n         time2_interest = T2_Actual_Interest_Composite) %&gt;%\n  mutate(participant_ID = row_number(),\n         Condition = case_match(Condition, \n                            1 ~ \"Ordinary\", \n                            2 ~ \"Extraordinary\"))\n\nzhang_long &lt;- zhang_wide %&gt;% \n  pivot_longer(cols = time1_interest:time2_interest,\n               names_to = \"Time\",\n               values_to = \"Interest\")\n\nFor different functions, we need the data in wide- or long-format, so we have two versions of the data prepared for the chapter. Pay careful attention to when you need one version or the other.\n\n13.1.4 Activity 2 - Calculate descriptive statistics\n\n\n\n\n\n\nTry this\n\n\n\nBefore we start on the inferential statistics, one key part of understanding your data and reporting for context in a report is calculating descriptive statistics like the mean and standard deviation.\nFor the combination of Condition and Time, calculate the mean and standard deviation of Interest. We will need this at the end of the chapter, so save your results to the object name zhang_descriptives.\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\nzhang_descriptives &lt;- zhang_long %&gt;%\n  group_by(Condition, Time) %&gt;%\n  summarise(mean = round(mean(Interest, na.rm = TRUE), 2),\n            sd = round(sd(Interest, na.rm = TRUE), 2))\n\n`summarise()` has grouped output by 'Condition'. You can override using the\n`.groups` argument.\n\nzhang_descriptives\n\n\n\n\nCondition\nTime\nmean\nsd\n\n\n\nExtraordinary\ntime1_interest\n4.36\n1.13\n\n\nExtraordinary\ntime2_interest\n4.65\n1.14\n\n\nOrdinary\ntime1_interest\n4.04\n1.09\n\n\nOrdinary\ntime2_interest\n4.73\n1.24\n\n\n\n\n\n\n\n\n\n\n13.1.5 Activity 3 - Create a violin-boxplot\nTo communicate your findings, it is also important to visualise your data. Initially, this might be a quick boxplot for exploratory data analysis, but something like a violin-boxplot would be great for communicating your findings in a report.\n\n\n\n\n\n\nTry this\n\n\n\nTry and recreate the following violin-boxplot that you learnt how to create in Chapter 7. The finer details like the colour scheme are not important, but see how many features you can recreate before checking the code.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# specify as an object, so we only change it in one place\ndodge_value &lt;- 0.9\n\nzhang_long %&gt;% \n  mutate(Time = case_match(Time,\n                           \"time1_interest\" ~ \"Time 1\",\n                           \"time2_interest\" ~ \"Time 2\")) %&gt;% \n  ggplot(aes(y = Interest, x = Condition, fill = Time)) +\n  geom_violin(alpha = 0.5) + \n  geom_boxplot(width = 0.2, \n               alpha = 0.7,\n               fatten = NULL,\n               position = position_dodge(dodge_value)) + \n  stat_summary(fun = \"mean\", \n               geom = \"point\",\n               position = position_dodge(dodge_value)) +\n  stat_summary(fun.data = \"mean_cl_boot\", \n               geom = \"errorbar\", \n               width = .1,\n               position = position_dodge(dodge_value)) +\n  scale_fill_viridis_d(option = \"E\") + \n  scale_y_continuous(name = \"Interest score (1-7)\", \n                     breaks = c(1:7)) + \n  theme_classic()"
  },
  {
    "objectID": "13-factorial-anova.html#factorial-a5",
    "href": "13-factorial-anova.html#factorial-a5",
    "title": "\n13  Factorial ANOVA\n",
    "section": "\n13.2 Factorial ANOVA",
    "text": "13.2 Factorial ANOVA\nTo run the factorial ANOVA, we will be using the afex package again. Remember that you must specify both IVs, one of which is between-subjects and the other is within-subjects. Look up the help documentation for aov_ez if you need further information.\n\n13.2.1 Activity 4 - Using the aov_ez() function.\nBefore we show you the code, try and complete the following skeleton version first. Think about what variable in the data corresponds to each argument.\nSave the ANOVA model to an object called mod_factorial to be consistent with explanations below. For making it easier to report the results later, pull out the mod_factorial$anova_table component and apply the tidy() function from broom as a second step.\n\nmod_factorial &lt;- aov_ez(id = \"NULL\",\n               data = NULL, \n               between = \"NULL\", \n               within = \"NULL\",\n               dv = \"NULL\", \n               type = 3,\n               es = \"NULL\") \n\nfactorial_output &lt;- NULL\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\nmod_factorial &lt;- aov_ez(id = \"participant_ID\",\n               data = zhang_long, \n               between = \"Condition\", \n               within = \"Time\",\n               dv = \"Interest\", \n               type = 3,\n               include_aov = TRUE,\n               es = \"pes\") \n\nfactorial_output &lt;- mod_factorial$anova_table %&gt;% \n  tidy()\n\nWe can look at the results of the factorial ANOVA by printing the object.\n\nmod_factorial\n\nAnova Table (Type 3 tests)\n\nResponse: Interest\n          Effect     df  MSE         F  ges p.value\n1      Condition 1, 128 2.05      0.46 .003    .498\n2           Time 1, 128 0.61 25.88 *** .044   &lt;.001\n3 Condition:Time 1, 128 0.61    4.44 * .008    .037\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n\n\n\n\n\nLook at the results. Remember the pre-class information about how to read p-values in scientific notation.\n\nIs the main effect of Condition significant? \nYes\nNo\nIs the main effect of Time significant? \nYes\nNo\nIs the two-way interaction significant? \nYes\nNo\n\n13.2.2 Activity 5 - Checking assumptions for factorial ANOVA\nThe assumptions for a factorial ANOVA are the same as the one-way ANOVA.\n\nThe DV is interval or ratio data.\nThe observations should be independent.\nThe residuals should be normally distributed.\nThere should be homogeneity of variance between the groups.\n\nAs before, we know assumption 2 is met from the design of the study. Assumption 1 throws up an interesting issue which is the problem of ordinal data. Ordinal data are the kind of data that come from Likert scales and are very common in psychology. The problem is that ordinal data are not interval or ratio data, there’s a fixed number of integer values they can take (the values of the Likert scale) and you cannot claim that the distance between the values is equal (is the difference between strongly agree and agree the same as the difference between agree and neutral?).\nTechnically, we should not use an ANOVA to analyse ordinal data - but almost everyone does. Many people argue that if you take the average of multiple Likert scale items, you can interpret the data as if they are interval and they can be normally distributed. Other people argue you should use non-parametric methods or more complex models such as ordinal regression for this type of data, but it is beyond the scope of what we cover in this course (if you are super interested, there is a PsyTeachR book for another course - Statistics and Research Design - which covers ordinal regression). Whichever route you choose, you should understand the data you have and you should be able to justify your decision.\nTo test assumption 3, you can run check_model() from performance on the model object (mod_factorial). Unless you add the argument re_formula = NA, you get a little warning saying the function does it anyway. The background of this argument is beyond the scope of this course, but expressed as a linear model, a mixed ANOVA looks like something called a mixed-effects model, so this argument is saying that there is not a formula for it, since we did not have one.\n\ncheck_model(mod_factorial, \n            re_formula = NA) # Specify or you get a warning \n\n\n\n\n\n\n\nDoes it look like we have any obvious problems with normality here? \nYes\nNo\nThe one annoying thing here is we do not get a diagnostic plot for checking homogeneity of variance / homoscedasticity. We can create our own using the lm component of the model object (mod_factorial$lm), but it takes a few steps. In the code below:\n\nWe first isolate the standardised residuals of the model object. We must convert it to a data frame and rename the two columns.\nWe combine the residuals with the wide version of the data.\nWe pivot the data longer so all the residuals are in one column and create a new variable to take the square root of the absolute residuals. This recreates how the diagnostic plots you saw in Chapters 8, 9, and 12 look.\nFinally, we plot the standardised residuals and add a line to join the means of each group. If the line is roughly flat, we support homoscedasticity. If the line angles up or down substantially, then this points to signs of heteroscedasticity.\n\n\n# Isolate standardised residuals as a data frame\nresiduals &lt;- as.data.frame(rstandard(mod_factorial$lm)) %&gt;% \n  select(residuals_time1 = time1_interest,\n         residuals_time2 = time2_interest)\n\n# add residuals to the wide version of the data, so we have the groups\nzhang_wide &lt;- zhang_wide %&gt;% \n  bind_cols(residuals)\n\n# Pivot longer and calculate the square root of absolute standardised residuals\nresiduals_long &lt;- zhang_wide %&gt;% \n  pivot_longer(cols = residuals_time1:residuals_time2, \n               names_to = \"Time\", \n               values_to = \"Residuals\") %&gt;% \n  mutate(std_residuals = sqrt(abs(Residuals)))\n\n# Plot the residuals\nresiduals_long %&gt;%\n  # we need groups as numbers for the line to plot \n  mutate(Condition = case_match(Condition,\n                                \"Ordinary\" ~ 1,\n                                \"Extraordinary\" ~ 2)) %&gt;% \n  ggplot(aes(x = Condition, y = std_residuals)) + \n  geom_point() + \n  # add line joining the mean of residuals per group\n  stat_summary(geom = \"line\", \n               fun = mean, \n               color = \"blue\", \n               linewidth = 1.5) + \n    labs(x = \"Condition\", y = \"Standardised Residuals\")\n\n\n\n\n\n\n\nDoes it look like we have any obvious problems with homoscedasticity here? \nYes\nNo\n\n13.2.3 Activity 6 - Post-hoc tests\nBecause the interaction is significant, we should follow this up with post-hoc tests using emmeans() to determine which comparisons are significant. If the overall interaction is not significant, you should not conduct additional tests.\nemmeans() requires you to specify the aov object, and then the factors you want to contrast. For an interaction, we use the notation pairwise ~ IV1 | IV2 and you specify which multiple comparison correction you want to apply.\nRun the below code and view the results.\n\n# run the tests\nposthoc_factorial &lt;- emmeans(mod_factorial, \n                             pairwise ~ Time | Condition, \n                             adjust = \"bonferroni\")\n\nposthoc_factorial\n\n$emmeans\nCondition = Extraordinary:\n Time           emmean    SE  df lower.CL upper.CL\n time1_interest   4.36 0.137 128     4.09     4.63\n time2_interest   4.65 0.147 128     4.36     4.94\n\nCondition = Ordinary:\n Time           emmean    SE  df lower.CL upper.CL\n time1_interest   4.04 0.139 128     3.76     4.31\n time2_interest   4.73 0.149 128     4.44     5.03\n\nConfidence level used: 0.95 \n\n$contrasts\nCondition = Extraordinary:\n contrast                        estimate    SE  df t.ratio p.value\n time1_interest - time2_interest   -0.288 0.136 128  -2.123  0.0357\n\nCondition = Ordinary:\n contrast                        estimate    SE  df t.ratio p.value\n time1_interest - time2_interest   -0.695 0.138 128  -5.049  &lt;.0001\n\n\nIn the output, we first get the estimated marginal means for the combination of IVs. We then get the contrasts we requested. This looks at the difference in levels of the first IV for each level of the second IV.\nYou can use tidy() to tidy up the output of the contrasts and save it into a tibble which makes it easier to use in inline code later.\n\n# tidy up the output of the tests\ncontrasts_factorial &lt;- posthoc_factorial$contrasts %&gt;%\n  tidy()\n\ncontrasts_factorial\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCondition\nterm\ncontrast\nnull.value\nestimate\nstd.error\ndf\nstatistic\np.value\n\n\n\nExtraordinary\nTime\ntime1_interest - time2_interest\n0\n-0.2878788\n0.1356011\n128\n-2.122983\n0.0356806\n\n\nOrdinary\nTime\ntime1_interest - time2_interest\n0\n-0.6953125\n0.1377035\n128\n-5.049343\n0.0000015\n\n\n\n\n\n\nNote that because there are two IVs/factors, we could also reverse the order. Above, we get the results contrasting time 1 and time 2 for each event condition. Instead, we could look at the difference between ordinary and extraordinary events at each time point.\nRun the code below and compare the output to contrast_factorial. Look at how the contrasts are expressed subtly different when you switch the order. Think carefully about your research question and hypotheses for which way around is the most informative.\n\nposthoc_factorial2 &lt;- emmeans(mod_factorial, \n                             pairwise ~ Condition | Time, \n                             adjust = \"bonferroni\") \n\nposthoc_factorial2\n\ncontrasts_factorial2 &lt;- posthoc_factorial2$contrasts %&gt;%\n  tidy()\n\ncontrasts_factorial2\n\n$emmeans\nTime = time1_interest:\n Condition     emmean    SE  df lower.CL upper.CL\n Extraordinary   4.36 0.137 128     4.09     4.63\n Ordinary        4.04 0.139 128     3.76     4.31\n\nTime = time2_interest:\n Condition     emmean    SE  df lower.CL upper.CL\n Extraordinary   4.65 0.147 128     4.36     4.94\n Ordinary        4.73 0.149 128     4.44     5.03\n\nConfidence level used: 0.95 \n\n$contrasts\nTime = time1_interest:\n contrast                 estimate    SE  df t.ratio p.value\n Extraordinary - Ordinary   0.3246 0.195 128   1.661  0.0992\n\nTime = time2_interest:\n contrast                 estimate    SE  df t.ratio p.value\n Extraordinary - Ordinary  -0.0829 0.209 128  -0.397  0.6923\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTime\nterm\ncontrast\nnull.value\nestimate\nstd.error\ndf\nstatistic\np.value\n\n\n\ntime1_interest\nCondition\nExtraordinary - Ordinary\n0\n0.3245739\n0.1954025\n128\n1.6610529\n0.0991504\n\n\ntime2_interest\nCondition\nExtraordinary - Ordinary\n0\n-0.0828598\n0.2088845\n128\n-0.3966778\n0.6922656\n\n\n\n\n\n\nBecause our main effects (condition and time) only have two levels, we do not need to do any post-hoc tests to determine which conditions differ from each other, however, if one of our factors had three levels then we could use emmeans() to calculate the contrast for the main effects, like we did for the one-way ANOVA.\nFinally, to calculate standardised effect sizes for the pairwise comparisons, we again need to do this individually using cohens_d() from effectsize.\nAs we have a mixed design, we must follow a slightly different process for each comparison. Cohen’s d has a different calculation for between-subjects and within-subjects contrasts, so we must express it differently. For the first comparison, we are interested in the difference between time 1 and time 2 for each group, so this represents a within-subjects comparison.\n\n# time 1 vs time 2 for Extraordinary group\nd_extraordinary &lt;- cohens_d(x = \"time1_interest\", \n                            y = \"time2_interest\", \n                            paired = TRUE,\n                            data = filter(zhang_wide, \n                                          Condition == \"Extraordinary\"))\n# time 1 vs time 2 for Ordinary group\nd_ordinary &lt;- cohens_d(x = \"time1_interest\", \n                       y = \"time2_interest\", \n                       paired = TRUE,\n                       data = filter(zhang_wide, \n                                     Condition == \"Ordinary\"))\n\n# bind together the two contrasts\nCondition_ds &lt;- bind_rows(d_extraordinary, \n                          d_ordinary)\n\n# add the contrasts to the emmeans tidy table\ncontrasts_factorial &lt;- contrasts_factorial %&gt;%\n  bind_cols(Condition_ds)\n\ncontrasts_factorial\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCondition\nterm\ncontrast\nnull.value\nestimate\nstd.error\ndf\nstatistic\np.value\nCohens_d\nCI\nCI_low\nCI_high\n\n\n\nExtraordinary\nTime\ntime1_interest - time2_interest\n0\n-0.2878788\n0.1356011\n128\n-2.122983\n0.0356806\n-0.3086922\n0.95\n-0.554559\n-0.0605597\n\n\nOrdinary\nTime\ntime1_interest - time2_interest\n0\n-0.6953125\n0.1377035\n128\n-5.049343\n0.0000015\n-0.5552045\n0.95\n-0.816696\n-0.2898832\n\n\n\n\n\n\nFor the second comparison, we are interested in the difference between ordinary and extraordinary at each time point, so this represents a between-subjects comparison.\n\n# Extraordinary vs ordinary at time 1\nd_time1 &lt;- cohens_d(time1_interest ~ Condition,\n                       data = zhang_wide)\n\n# Extraordinary vs ordinary at time 2\nd_time2 &lt;- cohens_d(time2_interest ~ Condition,\n                       data = zhang_wide)\n\n# bind the two contrasts together\nTime_ds &lt;- bind_rows(d_time1,\n                     d_time2)\n\n# add the contrasts to the emmeans tidy table\ncontrasts_factorial2 &lt;- contrasts_factorial2 %&gt;%\n  bind_cols(Time_ds)\n\ncontrasts_factorial2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTime\nterm\ncontrast\nnull.value\nestimate\nstd.error\ndf\nstatistic\np.value\nCohens_d\nCI\nCI_low\nCI_high\n\n\n\ntime1_interest\nCondition\nExtraordinary - Ordinary\n0\n0.3245739\n0.1954025\n128\n1.6610529\n0.0991504\n0.2914024\n0.95\n-0.0548458\n0.6365251\n\n\ntime2_interest\nCondition\nExtraordinary - Ordinary\n0\n-0.0828598\n0.2088845\n128\n-0.3966778\n0.6922656\n-0.0695901\n0.95\n-0.4134010\n0.2744922\n\n\n\n\n\n\n\n13.2.4 Activity 7 - Creating an interaction plot\nWhen you have a factorial design, one powerful way of visualising the data is through an interaction plot. This is essentially a line graph where the x-axis has one IV and separate lines for a second IV. However, once you have the factorial ANOVA model, you can add confidence intervals to the plot to visualise uncertainty. afex has it’s own function called afex_plot() which you can use with the model object you created.\nIn the code below, there are a few key argument to highlight:\n\nobject is the afex model you created.\nx is the variable you want on the x-axis.\ntrace is the variable you want to plot as separate lines.\nerror controls whether the error bars show confidence intervals for between-subjects or within-subjects. In a mixed design, these have different properties, so you must think about which you want to plot and highlight to the reader.\nfactor_levels lets you edit the levels of factors you plot, such as renaming or reordering them. You add each factor into a list but check the documentation and vignettes for other options.\n\n\nafex_plot(object = mod_factorial, \n          x = \"Condition\", \n          trace = \"Time\", \n          error = \"between\",\n          factor_levels = list(Time = c(\"Time 1\", \"Time 2\")))\n\n\n\n\n\n\n\nOne handy feature about this function is it uses ggplot2 in the background, so you can add layers to the initial function like other plots that you have created.\n\nafex_plot(mod_factorial, \n          x = \"Condition\", \n          trace = \"Time\", \n          error = \"between\",\n          factor_levels = list(Time = c(\"Time 1\", \"Time 2\"))) + \n  theme_classic() + \n  scale_y_continuous(breaks = 1:7)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nSince afex_plot() uses ggplot2, you can use ggsave() to save your plots and insert them into your work."
  },
  {
    "objectID": "13-factorial-anova.html#factorial-a8",
    "href": "13-factorial-anova.html#factorial-a8",
    "title": "\n13  Factorial ANOVA\n",
    "section": "\n13.3 Reporting the results of your factorial ANOVA",
    "text": "13.3 Reporting the results of your factorial ANOVA\nNow you have all your values, we can work on the write-up of your results.\nIn the in-line code demonstration below, we manually entered p-values where they are &lt; .001. There is a way to get R to produce this formatting but it’s overly complicated for our purposes in this course. If you want to push yourself, look up the papaja package for creating reproducible manuscripts.\nThe values of partial eta-squared do not match between our analysis and those reported in the paper. We have not figured out why this is yet, so if you know, please get in touch!\nWe have also replaced the simple effects in the main paper with our pairwise comparisons.\nCopy and paste the text and inline code below into white-space in your R Markdown document. If you saved all the descriptives, model, and contrasts using the same object names as us, this should knit.\n\nWe conducted the same repeated measures ANOVA with interest as the dependent measure and again found a main effect of time, F(`r factorial_output$num.Df[2]`, `r factorial_output$den.Df[2]`) = `r factorial_output$statistic[2] %&gt;% round(2)`, p &lt; .001, ηp2 = `r factorial_output$ges[2] %&gt;% round(3)`; anticipated interest at Time 1 (M = `r zhang_descriptives$mean[1] %&gt;% round(2)`), SD = `r zhang_descriptives$sd[1]%&gt;% round(2)`)) was lower than actual interest at Time 2 (M = `r zhang_descriptives$mean[2]%&gt;% round(2)`, SD = `r zhang_descriptives$sd[2]%&gt;% round(2)`). We also observed an interaction between time and type of experience, F(`r factorial_output$num.Df[3]`, `r factorial_output$den.Df[3]`) = `r factorial_output$statistic[3] %&gt;% round(3)`, p = `r factorial_output$p.value[3] %&gt;% round(2)`, ηp2 = `r factorial_output$ges[3] %&gt;% round(3)`. Pairwise comparisons revealed that for ordinary events, predicted interest at Time 1 (M = `r zhang_descriptives$mean[3]%&gt;% round(2)`, SD = `r zhang_descriptives$sd[3]%&gt;% round(2)`) was lower than experienced interest at Time 2 (M = `r zhang_descriptives$mean[4]%&gt;% round(2)`, SD = `r zhang_descriptives$sd[4]%&gt;% round(2)`), t(`r contrasts_factorial$df[2]%&gt;% round(2)`) = `r contrasts_factorial$statistic[2]%&gt;% round(2)`, p &lt; .001, d = `r contrasts_factorial$Cohens_d[2]%&gt;% round(2)`. Although predicted interest for extraordinary events at Time 1 (M = `r zhang_descriptives$mean[1]%&gt;% round(2)`, SD = `r zhang_descriptives$sd[1]%&gt;% round(2)`) was lower than experienced interest at Time 2 (M = `r zhang_descriptives$mean[2]%&gt;% round(2)`, SD = `r zhang_descriptives$sd[2]%&gt;% round(2)`), t(`r contrasts_factorial$df[1]%&gt;% round(2)`) = `r contrasts_factorial$statistic[1]%&gt;% round(2)`, p &lt; .001, d = `r contrasts_factorial$Cohens_d[1]%&gt;% round(2)`, the magnitude of underestimation was smaller than for ordinary events.\n\n\nWe conducted the same repeated measures ANOVA with interest as the dependent measure and again found a main effect of time, F(1, 128) = 25.88, p &lt; .001, ηp2 = 0.044; anticipated interest at Time 1 (M = 4.36), SD = 1.13)) was lower than actual interest at Time 2 (M = 4.65, SD = 1.14). We also observed an interaction between time and type of experience, F(1, 128) = 4.445, p = 0.04, ηp2 = 0.008. Pairwise comparisons revealed that for ordinary events, predicted interest at Time 1 (M = 4.04, SD = 1.09) was lower than experienced interest at Time 2 (M = 4.73, SD = 1.24), t(128) = -5.05, p &lt; .001, d = -0.56. Although predicted interest for extraordinary events at Time 1 (M = 4.36, SD = 1.13) was lower than experienced interest at Time 2 (M = 4.65, SD = 1.14), t(128) = -2.12, p &lt; .001, d = -0.31, the magnitude of underestimation was smaller than for ordinary events."
  },
  {
    "objectID": "13-factorial-anova.html#end-of-chapter",
    "href": "13-factorial-anova.html#end-of-chapter",
    "title": "\n13  Factorial ANOVA\n",
    "section": "\n13.4 End of Chapter",
    "text": "13.4 End of Chapter\nWell done, you have now covered the ANOVA section of the course to learn how to express experimental designs into statistical models. ANOVA and factorial ANOVA are incredibly flexible tools where you can start to combine multiple independent variables. You might have between-subject factors, within-subject factors, or a combination of the two in a mixed design. The most important thing to keep in mind is your research question, hypothesis, and design come first. Factorial ANOVA can get arbitrarily more complicated but try and avoid the temptation to create complex models just because you can. You do not get extra points for complication, it is better to think about which model will let you address your research question.\nIn the next chapter, we finish the core chapters on the final extension of the general linear model we cover in this course. In Research Methods 1, you learnt about simple linear regression when you only have one predictor. In multiple linear regression, you can add two or more predictors, and even the interaction between predictors.\n\n\n\n\nZhang, T., Kim, T., Brooks, A. W., Gino, F., & Norton, M. I. (2014). A “Present” for the Future: The Unexpected Value of Rediscovery. Psychological Science, 25(10), 1851–1860. https://doi.org/10.1177/0956797614542274"
  },
  {
    "objectID": "14-multiple-regression.html#chapter-preparation",
    "href": "14-multiple-regression.html#chapter-preparation",
    "title": "\n14  Multiple Regression\n",
    "section": "\n14.1 Chapter preparation",
    "text": "14.1 Chapter preparation\n\n14.1.1 Introduction to the data set\nFor this chapter, we are using open data from Przybylski & Weinstein (2017). The abstract of their article is:\n\nAlthough the time adolescents spend with digital technologies has sparked widespread concerns that their use might be negatively associated with mental well-being, these potential deleterious influences have not been rigorously studied. Using a preregistered plan for analyzing data collected from a representative sample of English adolescents (n = 120,115), we obtained evidence that the links between digital-screen time and mental well-being are described by quadratic functions. Further, our results showed that these links vary as a function of when digital technologies are used (i.e., weekday vs. weekend), suggesting that a full understanding of the impact of these recreational activities will require examining their functionality among other daily pursuits. Overall, the evidence indicated that moderate use of digital technology is not intrinsically harmful and may be advantageous in a connected world. The findings inform recommendations for limiting adolescents’ technology use and provide a template for conducting rigorous investigations into the relations between digital technology and children’s and adolescents’ health.\n\nIn summary, this was a large-scale study that found support for the “Goldilocks” hypothesis among adolescents: that there is a “just right” amount of screen time, such that any amount more or less than this amount is associated with lower well-being. This was a huge survey study: the data contain responses from over 120,000 participants! In this chapter, we will look at whether the relationship between screen time and well-being is moderated by participants’ (self-reported) gender.\nThe outcome/dependant variable used in the study was the Warwick-Edinburgh Mental Well-Being Scale (WEMWBS). This is a 14-item scale with 5 response categories, summed together to form a single score ranging from 14-70.\nPrzybylski & Weinstein (2017) looked at multiple measures of screen time, but we will be focusing on smartphone use. They found that decrements in well-being started to appear when respondents reported more than one hour of weekly smartphone use. Our research question is: Does the negative association between hours of use and well-being (beyond the one-hour point) differ for boys and girls?\n\n14.1.2 Organising your files and project for the chapter\nBefore we can get started, you need to organise your files and project for the chapter, so your working directory is in order.\n\nIn your folder for research methods and the book ResearchMethods1_2/Quant_Fundamentals, create a new folder called Chapter_14_multiple_regression. Within Chapter_14_multiple_regression, create two new folders called data and figures.\nCreate an R Project for Chapter_14_multiple_regression as an existing directory for your chapter folder. This should now be your working directory.\nCreate a new R Markdown document and give it a sensible title describing the chapter, such as 14 Multiple Regression. Delete everything below line 10 so you have a blank file to work with and save the file in your Chapter_14_multiple_regression folder.\n\nFor this chapter, there are three data files you need. Please save the following files:\n\nPrzybylski_2017_participants.csv.\nPrzybylski_2017_screentime.csv\nPrzybylski_2017_wellbeing.csv\n\n\n\nRight click the link and select “save link as”, or clicking the link will save the files to your Downloads. Make sure that you save the files as “.csv”. Save or copy the files to your data/ folder within Chapter_14_multiple_regression.\nYou are now ready to start working on the chapter!\n\n14.1.3 Activity 1 - Load the packages and read the data\nAs the first activity, try and test yourself by completing the following task list.\n\n\n\n\n\n\nTry this\n\n\n\nTo prepare for wrangling the data, complete the following tasks:\n\n\nLoad the following packages (one of these is new, so revisit Chapter 1 if you need a refresher of installing R packages, but remember not to install packages on the university computers / online server):\n\npwr\nsjPlot\nperformance\ntidyverse\n\n\nRead the three data files to the following object names to be consistent with the tasks below.\n\n\n# load packages here\n?\n\n# read the three data files \n# this should be Przybylski_2017_participants.csv\npinfo &lt;- ?\n\n# this should be Przybylski_2017_wellbeing.csv\nwellbeing &lt;- ?\n\n# this should be Przybylski_2017_screentime.csv\nscreen &lt;- ?\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# load packages here\nlibrary(pwr)\nlibrary(sjPlot)\nlibrary(performance)\nlibrary(tidyverse)\n\n# read the three data files \n# this should be Przybylski_2017_participants.csv\npinfo &lt;- read_csv(\"data/Przybylski_2017_participants.csv\")\n\n# this should be Przybylski_2017_wellbeing.csv\nwellbeing &lt;- read_csv(\"data/Przybylski_2017_wellbeing.csv\")\n\n# this should be Przybylski_2017_screentime.csv\nscreen &lt;- read_csv(\"data/Przybylski_2017_screentime.csv\")\n\n\n\n\n\n14.1.4 Activity 2 - Explore the data\nTake a look at the resulting tibbles pinfo, wellbeing, and screen. Use functions like glimpse() to look at what the data frames contain.\n\nThe pinfo data has information on the participant’s background.\nThe wellbeing data has information from the well-being questionnaire.\n\nThe screen data has information about screen time use on weekends (variables ending with we) and weekdays (variables ending with wk) for four types of activities:\n\nUsing a computer (variables starting with Comph; Q10 on the survey)\nPlaying video games (variables starting with Comp; Q9 on the survey)\nUsing a smartphone (variables starting with Smart; Q11 on the survey)\nWatching TV (variables starting with Watch; Q8 on the survey).\n\n\n\nIf you want more information about these variables, look at the items 8-11 on pages 4-5 of the the PDF version of the survey on the authors’ OSF project.\nOnce you have explored the objects, try and answer the following questions:\n\nThe variable corresponding to gender is located in the object named \npinfo\nwellbeing\nscreen and this variable is called .\nThe well-being data is in \nlong\nwide format and contains observations from  participants on  items.\nIndividual participants in this data set are identified by the variable called . This variable will allow us to link information across the three tables.\nIf you run the function summary() on the three data sets, are there any missing data points? \nYes\nNo\n\n14.1.5 Activity 3 - Compute the well-being score for each respondent\n\n\n\n\n\n\nTry this\n\n\n\nThe WEMWBS well-being score is simply the sum of all the items.\nWrangle the data to create a new table called wemwbs. The data should have two variables:\n\nSerial - the participant ID.\ntotal_wellbeing - the total WEMWBS score.\n\nThink about what wrangling steps you need to apply to achieve this.\n\n\n\n\n\n\n\n\nShow me some hints\n\n\n\n\n\n\nGather the data and pivot from wide to long.\nGroup the data by a variable.\nSummarise the data to calculate the sum score per participant.\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\nwemwbs &lt;- wellbeing %&gt;%\n  pivot_longer(cols = WBOptimf:WBCheer,\n               names_to = \"var\", \n               values_to = \"score\") %&gt;%\n  group_by(Serial) %&gt;%\n  summarise(total_wellbeing = sum(score))\n\n\n\n\nFor a sanity check, verify for yourself that the scores all fall in the 14-70 range. Przybylski & Weinstein (2017) reported a mean of 47.52 with a standard deviation of 9.55. Can you reproduce these values?\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\nwemwbs %&gt;% \n  summarise(mean = mean(total_wellbeing),\n            sd = sd(total_wellbeing),\n            min = min(total_wellbeing),\n            max = max(total_wellbeing))\n\n\n\n\nmean\nsd\nmin\nmax\n\n\n47.52189\n9.546374\n14\n70\n\n\n\n\n\n\n\n\nNow, visualise the distribution of tot_wellbeing in a histogram using ggplot2. The distribution of well-being scores is \nsymmetric\nnegatively skewed\npositively skewed.\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\nwemwbs %&gt;% \n  ggplot(aes(x = total_wellbeing)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\n\n14.1.6 Activity 4 - Wrangle and visualise the data\nBefore we move onto the final modelling stages, we can wrangle the data to plot the data like the original article. We can plot the relationship between well-being and hours of technology use, split into four categories of technology (video games, computers, smartphones, TV).\nFor this step, we are going to give you the code as there are a few new functions we have not taught you about. Make sure as you type the code to question what each line of the code is doing. The functions might be unfamiliar but you should be able to follow what it is doing. We are working with many rows here, so the code might take longer to run than you are used to.\n\n# Pivot the screen data longer\n# Separate the variable into the category and day of the week\n# Recode the new variables \nscreen_long &lt;- screen %&gt;%\n  pivot_longer(cols = Comph_we:Watch_wk,\n               names_to = \"var\", \n               values_to = \"hours\") %&gt;%\n  separate(col = var, # split variable name\n           into = c(\"variable\", \"day\"), # split into two components\n           sep = \"_\") %&gt;%  # split when it sees a _\n  mutate(variable = case_match(variable,\n                               \"Watch\" ~ \"Watching TV\",\n                               \"Comp\" ~ \"Playing Video Games\",\n                               \"Comph\" ~ \"Using Computers\",\n                               \"Smart\" ~ \"Using Smartphone\"),\n         day = case_match(day,\n                          \"wk\" ~ \"Weekday\",\n                          \"we\" ~ \"Weekend\"))\n\n# Join the two data sets together \n# group by three variables\n# calculate the mean well-being score\ndat_means &lt;- wemwbs %&gt;% \n  inner_join(screen_long, \n             by = \"Serial\") %&gt;%\n  group_by(variable, \n           day, \n           hours) %&gt;%\n  summarise(mean_wellbeing = mean(total_wellbeing))\n\nWe now have data at the group level rather than per participant. Each row of dat_means is a value for mean well-being split by each level of variable (technology type), day (weekday or weekend), and hours of technology use. If you run the following code, we get a line graph showing the relationship split between technology type and day.\n\ndat_means %&gt;% \n  ggplot(aes(x = hours, y = mean_wellbeing, linetype = day)) +\n  geom_line() +\n  geom_point() +\n  facet_wrap(~ variable, nrow = 2) + \n  theme_classic() + \n  labs(x = \"Hours of Technology Use\",\n       y = \"Mean Well-Being Score\")\n\n\n\n\n\n\n\nThe graph shows that smartphone use of more than 1 hour per day is associated with increasingly negative well-being. Note that we have combined the tables using an inner_join(), such that we only include data for which we have observations across the wemwbs and screen_long tables.\nIn the next step, we are going to focus on the smartphone/well-being relationship for our multiple linear regression demonstration."
  },
  {
    "objectID": "14-multiple-regression.html#mulregression-a5",
    "href": "14-multiple-regression.html#mulregression-a5",
    "title": "\n14  Multiple Regression\n",
    "section": "\n14.2 Multiple linear regression",
    "text": "14.2 Multiple linear regression\nNow that we have explored the data, we can start preparing for the analysis. Note that in this analysis, we have:\n\nA continuous\\(^*\\) outcome: well-being.\nOne continuous\\(^*\\) predictor: screen time.\nOne categorical predictor: gender.\n\n\\(^*\\)these variables are only quasi-continuous as only discrete values are possible. This returns up to the ordinal dilemma, particularly for the outcome of well-being. However, there are a sufficient number of discrete values that we can treat them as effectively continuous.\nWe want to estimate two slopes relating screen time to well-being, one for girls and one for boys, and then statistically compare these slopes. So, this problem seems simultaneously like a situation where you would run a regression (to estimate the slopes) but also one where you would need a t-test (to compare two groups). This is the power of regression models as you can look at the interaction between one continuous and one categorical predictor, something that is not possible in factorial ANOVA.\n\n14.2.1 Activity 5 - Complete the final wrangling steps\nFor this analysis, we are going to average weekday and weekend use for smartphones. We need one final round of wrangling to prepare for creating a multiple linear regression model.\n\n\n\n\n\n\nTry this\n\n\n\nStep 1. Create a new data object smarttot that has the mean number of hours per day of smartphone use for each participant, averaged over weekends/weekdays. Then filter the data to only include those who use a smart phone for more than one hour per day.\nTo do this, you will need to:\n\nFilter the data screen_long to only include smartphone use and not other technologies.\nGroup the results by the participant ID (Serial).\nSummarise the data to calculate the mean number of hours per participant. Call this variable total_hours.\nFilter the data to only include participants who use a smartphone for more than 1 hour per day.\n\nThe data smarttot should have two variables: Serial (the participant) and total_hours.\nStep 2. Once you have smarttot, combine (join) this data object with the information in wemwbs and pinfo. Call this new object smart_wb. This is the final object you need for the multiple linear regression model.\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\nsmarttot &lt;- screen_long %&gt;%\n  filter(variable == \"Using Smartphone\") %&gt;%\n  group_by(Serial) %&gt;%\n  summarise(total_hours = mean(hours)) %&gt;% \n  filter(total_hours &gt; 1)\n\nsmart_wb &lt;- smarttot %&gt;%\n  inner_join(wemwbs, \n             by = \"Serial\") %&gt;%\n  inner_join(pinfo, \n             by = \"Serial\") \n\n\n\n\n\n14.2.2 Activity 6 - Mean-centering variables\nAs we discussed in the course materials, when you have continuous variables in a regression model, it is often sensible to transform them by mean centering. We covered this in Chapter 8, but it is particularly important in multiple linear regression. You mean center a predictor X by subtracting the mean of the predictor (X_centered = X - mean(X)). This has two useful consequences:\n\nThe model intercept reflects the prediction for \\(Y\\) at the mean value of the predictor variable, rather than at the zero value of the unscaled variable.\nIf there are interactions in the model, any lower-order effects can be given the same interpretation as they receive in ANOVA (main effects, rather than simple effects).\n\nFor categorical predictors with two levels, these become coded as -.5 and .5 (because the mean of these two values is 0).\n\n\n\n\n\n\nTry this\n\n\n\nUse mutate() to add two new variables to smart_wb:\n\ntotal_hours_c: calculated as a mean-centered version of the total_hours predictor\nmale_c: recoded as -.5 for female and .5 for male, and then converts both male and male_c as factors, so that R knows not to treat them as real numbers.\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\nsmart_wb &lt;- smart_wb %&gt;%\n  mutate(total_hours_c = total_hours - mean(total_hours),\n         male_c = case_when(male == 1 ~ .5, \n                            male == 0 ~ -.5),\n         male_c = as.factor(male_c),\n         male = as.factor(male))\n\n\n\n\n\n14.2.3 Activity 7 - Running the regression\nFor the data in smart_wb, use the lm() function to calculate the multiple regression model:\n\\(Y_i = \\beta_0 + \\beta_1 X_{1i} + \\beta_2 X_{2i} + \\beta_3 X_{3i} + e_i\\)\nwhere\n\n\\(Y_i\\) is the well-being score for participant \\(i\\);\n\\(X_{1i}\\) is the mean-centered smartphone use variable for participant \\(i\\);\n\\(X_{2i}\\) is gender (-.5 = female, .5 = male);\n\\(X_{3i}\\) is the interaction between smartphone use and gender (\\(= X_{1i} \\times X_{2i}\\))\n\n\n\n\n\n\n\nTry this\n\n\n\nSave your model to the object ml_model.\nSave the summary() of your model to the object model_summary.\nPrint the model_summary to see the results and answer the following questions:\n\nThe interaction between smartphone use and gender is shown by the variable \nthours_c\nmale_c\nthours_c:male_c, and this interaction was \nsignificant\nnon-significant at the \\(\\alpha = .05\\) level.\nTo 2 decimal places, adjusted \\(R^2\\) suggests the overall model explains what percentage of the variance in well-being scores? \nThe p-value for the overall model fit is &lt;2e-16. Is this statistically significant? \nYes\nNo\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\nml_model &lt;- lm(formula = total_wellbeing ~ total_hours_c * male_c, \n               data = smart_wb)\n\nmod_summary &lt;- summary(ml_model)\n\nmod_summary\n\n\nCall:\nlm(formula = total_wellbeing ~ total_hours_c * male_c, data = smart_wb)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-36.881  -5.721   0.408   6.237  27.264 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)             44.86740    0.04478 1001.87   &lt;2e-16 ***\ntotal_hours_c           -0.77121    0.02340  -32.96   &lt;2e-16 ***\nmale_c0.5                5.13968    0.07113   72.25   &lt;2e-16 ***\ntotal_hours_c:male_c0.5  0.45205    0.03693   12.24   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.135 on 71029 degrees of freedom\nMultiple R-squared:  0.09381,   Adjusted R-squared:  0.09377 \nF-statistic:  2451 on 3 and 71029 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n14.2.4 Activity 8 - Visualising interactions\nIt is very difficult to understand an interaction from the coefficient alone, so your best bet is visualising the interaction to help you understand the results and communicate your results to your readers.\nThere is a great package called sjPlot which takes regression models and helps you plot them in different ways. We will demonstrate plotting interactions, but for further information and options, see the online documentation.\nTo plot the interaction, you need the model object (not the summary), specify “pred” as the type as we want to plot predictions, and add the terms you want to plot.\n\nplot_model(ml_model, \n           type = \"pred\", \n           terms = c(\"total_hours_c\", \"male_c\"))\n\n\n\n\n\n\n\nWhat is the most reasonable interpretation of the interaction?\n\nsmartphone use harms girls more than boyssmartphone use was more negatively associated with wellbeing for girls than for boysthere is no evidence for gender differences in the relationship between smartphone use and well-beingsmartphone use harms boys more than girls\n\nThis is fine for helping you to interpret your model, but you would need to customise it before adding it into a report. Like afex_plot() we introduced you to in Chapter 13, plot_model() uses ggplot2 in the background. You can add further customisation by adding layers after the initial function.\n\n\n\n\n\n\nNote\n\n\n\nSince plot_model() uses ggplot2, you can use ggsave() to save your plots and insert them into your work.\n\n\nFor example, we can tidy up the axis labels and remove the title, and set a theme.\n\nplot_model(ml_model, \n           type = \"pred\", \n           terms = c(\"total_hours_c\", \"male_c\")) + \n  labs(x = \"Total Hours Smartphone Use\",\n       y = \"Total Well-Being Score\",\n       title = \"\") + \n  theme_classic()\n\n\n\n\n\n\n\nFor communicating interactions, it is normally better to plot a version using the raw predictors instead of the mean centered versions as the interaction does not change and it will be easier for your readers to understand.\n\n14.2.5 Activity 9 - Assumption checking\nNow it’s time to test those pesky assumptions. The assumptions for multiple regression are the same as simple regression but there is one additional assumption, that of multicollinearity. This is the idea that predictor variables should not be too highly correlated.\n\nThe outcome/DV is a interval/ratio level data.\nThe predictor variable is interval/ratio or categorical (with two levels).\nAll values of the outcome variable are independent (i.e., each score should come from a different participant).\nThe predictors have non-zero variance.\nThe relationship between outcome and predictor is linear.\nThe residuals should be normally distributed.\nThere should be homoscedasticity (homogeneity of variance, but for the residuals).\nMulticollinearity: predictor variables should not be too highly correlated.\n\nFrom the work we have done so far, we know that we meet assumptions 1 - 4 and we can use the plot() function for diagnostic plots, plus check_model() from the performance package.\nOne difference from when we used check_model() previously is that rather than just letting it run all the tests it wants, we are going to specify which tests to stop it throwing an error. A word of warning - these assumption tests will take longer than usual to run because it’s such a big data set. The first line of code will run the assumption tests and save it to an object, calling the object name will then display the plots.\n\nassumptions &lt;- check_model(ml_model, \n                           check = c(\"vif\", \n                                     \"qq\", \n                                     \"normality\", \n                                     \"linearity\", \n                                     \"homogeneity\"))\n\nassumptions\n\n\n\nFigure 14.1: Assumption plots from the performance package.\n\n\n\nFor assumption 5, linearity, we already know from looking at the scatterplot that the relationship is linear, but the residual plot also confirms this.\nFor assumption 6, normality of residuals, the residuals look good in both plots and this provides an excellent example of why it’s often better to visualise than rely on statistics. With a sample size this large, any statistical diagnostic tests will be highly significant as they are sensitive to sample size.\nFor assumption 7, homoscedasticity, the plot is missing the reference line. Fun fact, this took us several days of our lives and asking for help on social media to figure out. The reason the line is not there is because the data set is so large that is creates a memory issue. However, if you use the plot() version, it does show the reference line.\n\nplot(ml_model,\n     which = 3)\n\n\n\n\n\n\n\nIt is not perfect, but the reference line is roughly flat to suggest there are no serious issues with homoscedasticity.\nFinally, for assumption 8, multicollinearity, the plot also indicates no issues but we can also test this statistically using check_collinearity() to produce VIF (variance inflation factor) and tolerance values.\nEssentially, this function estimates how much the variance of a coefficient is “inflated” because of linear dependence with other predictors, i.e., that a predictor is not actually adding any unique variance to the model, it’s just really strongly related to other predictors. You can read more about this online. Thankfully, VIF is not affected by large samples like other statistical diagnostic tests.\nThere are various rules of thumb, but most converge on a VIF of above 2 - 2.5 for any one predictor being problematic.\n\ncheck_collinearity(ml_model)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTerm\nVIF\nVIF_CI_low\nVIF_CI_high\nSE_factor\nTolerance\nTolerance_CI_low\nTolerance_CI_high\n\n\n\ntotal_hours_c\n1.721968\n1.704219\n1.740165\n1.312238\n0.5807308\n0.5746582\n0.5867789\n\n\nmale_c\n1.035552\n1.028488\n1.044369\n1.017621\n0.9656682\n0.9575159\n0.9723014\n\n\ntotal_hours_c:male_c\n1.716349\n1.698683\n1.734463\n1.310095\n0.5826319\n0.5765474\n0.5886915\n\n\n\n\n\n\n\n14.2.6 Activity 10 - Power and effect sizes\nFinally, we will calculate power and an effect size specific to multiple linear regression. Your coefficients represent the effect size for individual variables, but you can summarise the whole regression model with \\(R^2\\) and \\(f^2\\).\nUsing your understanding of power analysis from Chapter 10 and the function specific to regression models, calculate the minimum effect size we could reliably observe given our sample size and design but for 99% power and 5% alpha.\nHint: for v, it is the sample size minus u minus 1 (N - u - 1)\n\npwr.f2.test(u = ?, \n            v = ?, \n            f2 = NULL, \n            sig.level = ?, \n            power = ?)\n\nTo 2 decimals, what is the value of \\(f^2\\) the study would be sensitive to? \n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\npwr.f2.test(u = 3, \n            v = 71029, \n            f2 = NULL, \n            sig.level = .05, \n            power = .99)\n\n\n     Multiple regression power calculation \n\n              u = 3\n              v = 71029\n             f2 = 0.0003673651\n      sig.level = 0.05\n          power = 0.99\n\n\nThe study was incredibly sensitive, where they would detect effects of \\(f^2\\) = .0004 with 99% power.\n\n\n\nThe effect size \\(f^2\\) is a kind of transformed version of \\(R^2\\). You can calculate it through the equation:\n\\(f^2 = \\frac{adj R^2}{1 - adj R^2}\\)\nOr as code:\n\nf2 &lt;- adj_R2/(1 - adj_R2)\n\n\n\n\n\n\n\nTry this\n\n\n\nCalculate the \\(f^2\\) value from the multiple regression model using one of these methods. Try and use the values directly from the model object to avoid typing in the values.\nWhat is the observed effect size (in \\(f^2\\)) for the study to 2 decimal places? \n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\nf2 &lt;- mod_summary$adj.r.squared/(1 - mod_summary$adj.r.squared)\n\nf2\n\n[1] 0.1034697\n\n\n\n\n\nComparing the observed effect size against the effect size the study was sensitive to with 99% power, do you think the study was sufficiently powered? \nYes\nNo"
  },
  {
    "objectID": "14-multiple-regression.html#mulregression-a11",
    "href": "14-multiple-regression.html#mulregression-a11",
    "title": "\n14  Multiple Regression\n",
    "section": "\n14.3 Reporting the results of multiple linear regression",
    "text": "14.3 Reporting the results of multiple linear regression\nThe same as previous chapters like ANOVA and factorial ANOVA, we can use inline code to help with the write-up. First, copy and paste the code below into white-space in your R Markdown document and then knit. Note that we enter the p-values manually because of the APA “p &lt; .001” formatting.\n\nAll continuous predictors were mean-centered and deviation coding was used for categorical predictors. The results of the regression indicated that the model significantly predicted course engagement (F(`r mod_summary$fstatistic[2]`, `r mod_summary$fstatistic[3] %&gt;% round(2)`) = `r mod_summary$fstatistic[1] %&gt;% round(2)`, p &lt; .001, Adjusted R2 = `r mod_summary$adj.r.squared %&gt;% round(2)`, f^2^ = `r f2%&gt;% round(2)`), accounting for `r (mod_summary$adj.r.squared %&gt;% round(2))*100`% of the variance. Total screen time was a significant negative predictor of wellbeing scores (β = `r ml_model$coefficients[2] %&gt;% round(2)`, *p* &lt; .001, as was gender (β = `r ml_model$coefficients[3] %&gt;% round(2)`, *p* &lt; .001, with girls having lower wellbeing scores than boys. Importantly, there was a significant interaction between screentime and gender (β = `r ml_model$coefficients[4] %&gt;% round(2)`, *p* &lt; .001), smartphone use was more negatively associated with wellbeing for girls than for boys. \n\n\nAll continuous predictors were mean-centered and deviation coding was used for categorical predictors. The results of the regression indicated that the model significantly predicted course engagement (F(3, 7.1029^{4}) = 2450.89, p &lt; .001, Adjusted R2 = 0.09, f2 = 0.1), accounting for 9% of the variance. Total screen time was a significant negative predictor of wellbeing scores (β = -0.77, p &lt; .001, as was gender (β = 5.14, p &lt; .001, with girls having lower wellbeing scores than boys. Importantly, there was a significant interaction between screentime and gender (β = 0.45, p &lt; .001), smartphone use was more negatively associated with wellbeing for girls than for boys."
  },
  {
    "objectID": "14-multiple-regression.html#mulregression-fin",
    "href": "14-multiple-regression.html#mulregression-fin",
    "title": "\n14  Multiple Regression\n",
    "section": "\n14.4 End of Chapter",
    "text": "14.4 End of Chapter\nYou are done!\nNot just with this chapter but with the R/RStudio component of Research Methods 2. The progress that you have made is truly astonishing. Even if you struggled with R/RStudio and have not quite understood every single line of code, what you are capable of with data wrangling and visualisation alone makes you some of the most highly competitive psychology graduates in the world. Try and think of everything you have learnt from week 1 of Research Methods 1 to now. Hopefully, you have proved to yourself you can do this.\nRegardless of whether you continue with quantitative methods and using R/RStudio, remember the more important critical skills that you have learned as part of this process. The next time you see a data set or you see data being talked about in the news, think about all the work that was put into getting the data into the final format. More importantly, think about all the decisions that the researcher needed to make along the way and how that might have affected the outcome.\n\n\n\n\nPrzybylski, A. K., & Weinstein, N. (2017). A Large-Scale Test of the Goldilocks Hypothesis: Quantifying the Relations Between Digital-Screen Use and the Mental Well-Being of Adolescents. Psychological Science, 28(2), 204–215. https://doi.org/10.1177/0956797616678438"
  },
  {
    "objectID": "17-analysis-journey-1.html#task-preparation",
    "href": "17-analysis-journey-1.html#task-preparation",
    "title": "15  Analysis Journey 1: Data Wrangling",
    "section": "\n15.1 Task preparation",
    "text": "15.1 Task preparation\n\n15.1.1 Introduction to the data set\nFor this task, we are using open data from Bartlett et al. (2022). The abstract of their article is:\n\nBoth daily and non-daily smokers find it difficult to quit smoking long-term. One factor associated with addictive behaviour is attentional bias, but previous research in daily and non-daily smokers found inconsistent results and did not report the reliability of their cognitive tasks. Using an online sample, we compared daily (n = 106) and non-daily (n = 60) smokers in their attentional bias towards smoking pictures. Participants completed a visual probe task with two picture presentation times: 200ms and 500ms. In confirmatory analyses, there were no significant effects of interest, and in exploratory analyses, equivalence testing showed the effects were statistically equivalent to zero. The reliability of the visual probe task was poor, meaning it should not be used for repeated testing or investigating individual differences. The results can be interpreted in line with contemporary theories of attentional bias where there are unlikely to be stable trait-like differences between smoking groups. Future research in attentional bias should focus on state-level differences using more reliable measures than the visual probe task.\n\nTo summarise, they compared two daily and non-daily smokers on something called attentional bias. This is the idea that when people use drugs often, things associated with those drugs grab people’s attention.\nTo measure attentional bias, participants completed a dot probe task. This is a computer task where participants see two pictures side-by-side: one related to smoking like someone holding a cigarette and one unrelated to smoking like someone holding a fork. Both the images disappear and a small dot appears in the location of one of the images. Participants must press left or right on the keyboard to identify where the dot appeared. This process is repeated many times for different images, different locations of the dot, and different durations of showing the images. The idea is if smoking images grab people’s attention, they will be able to identify the dot location faster on average when it appears in the location of the smoking images compared to when it appears in the location of the the non-smoking images.\nResponse time tasks like this are incredibly common in psychology and cognitive neuroscience, and being able to wrangle hundreds of trials is a great demonstration of your new data skills. After setting up your files and project for the chapter, we will outline the kind of problems you are trying to solve.\n\n15.1.2 Organising your files and project for the task\nBefore we can get started, you need to organise your files and project for the task, so your working directory is in order.\n\nIn your folder for research methods and the book ResearchMethods1_2/Quant_Fundamentals, create a new folder for the data analysis journey called Journey_01_wrangling. Within Journey_01_wrangling, create two new folders called data and figures.\nCreate an R Project for Journey_01_wrangling as an existing directory for your chapter folder. This should now be your working directory.\nCreate a new R Markdown document and give it a sensible title describing the chapter, such as Analysis Journey 1 - Data Wrangling. Delete everything below line 10 so you have a blank file to work with and save the file in your Journey_01_wrangling folder.\nWe are working with data separated into two files. The links are data file one (Bartlett_demographics.csv) and data file two (Bartlett_trials.csv). Right click the links and select “save link as”, or clicking the links will save the files to your Downloads. Make sure that both files are saved as “.csv”. Save or copy the file to your data/ folder within Journey_01_wrangling.\n\nYou are now ready to start working on the task!"
  },
  {
    "objectID": "17-analysis-journey-1.html#overview",
    "href": "17-analysis-journey-1.html#overview",
    "title": "15  Analysis Journey 1: Data Wrangling",
    "section": "\n15.2 Overview",
    "text": "15.2 Overview\n\n15.2.1 Load tidyverse and read the data files\nBefore we explore what wrangling we need to do, load tidyverse and read the two data files. As a prompt, save the data files to these object names to be consistent with the activities below, but you can check the solution if you are stuck.\n\n# Load the tidyverse package below\nlibrary(tidyverse)\n\n# Load the data files\n# This should be the Bartlett_demographics.csv file \ndemog &lt;- ?\n\n# This should be the Bartlett_trials.csv file \ntrials &lt;- ?\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# Load the tidyverse package below\nlibrary(tidyverse)\n\n# Load the data files\n# This should be the Bartlett_demographics.csv file \ndemog &lt;- read_csv(\"data/Bartlett_demographics.csv\")\n\n# This should be the Bartlett_trials.csv file \ntrials &lt;- read_csv(\"data/Bartlett_trials.csv\")\n\n\n\n\n\n15.2.2 Explore demog and trials\n\nThe data from Bartlett et al. (2022) is split into two data files. In demog, we have the participant ID (participant_private_id) and several demographic variables.\n\n\nRows: 205\nColumns: 20\n$ participant_private_id &lt;dbl&gt; 631737, 631738, 631741, 631739, 631749, 631746,…\n$ consent_given          &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ age                    &lt;dbl&gt; 46, 54, 23, 34, 38, 19, 25, 21, 28, 35, 47, 45,…\n$ cigarettes_per_week    &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"…\n$ smoke_everyday         &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"…\n$ past_four_weeks        &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"…\n$ age_started_smoking    &lt;chr&gt; \"12\", \"17\", \"17\", \"16\", \"15\", \"16\", \"22\", \"11\",…\n$ country_of_origin      &lt;chr&gt; \"United Kingdom\", \"Germany\", \"Poland\", \"Austral…\n$ cpd                    &lt;chr&gt; \"6\", \"5\", \"10\", \"20\", \"10\", \"1\", \"6\", \"15\", \"12…\n$ ethnicity              &lt;chr&gt; \"White / Caucasian\", \"White / Caucasian\", \"Mixe…\n$ gender                 &lt;chr&gt; \"Female\", \"Female\", \"Male\", \"Female\", \"Female\",…\n$ last_cigarette         &lt;chr&gt; \"60\", \"780\", \"90\", \"5\", \"60\", \"720\", \"10\", \"10\"…\n$ level_education        &lt;chr&gt; \"Graduated University / College\", \"Graduated Un…\n$ technical_issues       &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\",…\n$ FTND_1                 &lt;dbl&gt; 2, 0, 0, 3, 3, 0, 1, 2, 1, 3, 2, 2, 2, 1, 2, 0,…\n$ FTND_2                 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,…\n$ FTND_3                 &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0,…\n$ FTND_4                 &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1,…\n$ FTND_5                 &lt;dbl&gt; 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0,…\n$ FTND_6                 &lt;dbl&gt; 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0,…\n\n\nThe columns (variables) we have in the data set are:\n\n\n\n\n\n\n\nVariable\nType\nDescription\n\n\n\nparticipant_private_id\ndouble\nParticipant number.\n\n\nconsent_given\ndouble\n1 = informed consent, 2 = no consent.\n\n\nage\ndouble\nAge in Years.\n\n\ncigarettes_per_week\ncharacter\nDo you smoke every week? Yes or No.\n\n\nsmoke_everyday\ncharacter\nDo you smoke everyday? Yes or No.\n\n\npast_four_weeks\ncharacter\nHave you smoked in the past four weeks? Yes or No.\n\n\nage_started_smoking\ncharacter\nAge started smoking in years.\n\n\ncountry_of_origin\ncharacter\nCountry of origin.\n\n\ncpd\ncharacter\nHow many cigarettes do you smoke per day?\n\n\nethnicity\ncharacter\nWhat is your ethniciity?\n\n\ngender\ncharacter\nWhat is your gender?\n\n\nlast_cigarette\ncharacter\nHow long in minutes since your last cigarette?\n\n\nlevel_education\ncharacter\nWhat is your highest level of education?\n\n\ntechnical_issues\ncharacter\nDid you experience any technical issues? Yes or No\n\n\nFTND_1 to FTND_6\ndouble\nSix items of the Fagerstrom Test for Nicotine Dependence\n\n\n\nIn trials, we then have the participant ID (participant_private_id) and trial-by-trial information from the software Gorilla (an online experiment service). This is probably the biggest data set you have come across so far as we have hundreds of trials per participant.\n\n\nRows: 244,847\nColumns: 15\n$ participant_private_id &lt;dbl&gt; 631737, 631737, 631737, 631737, 631737, 631737,…\n$ trial_number           &lt;chr&gt; \"BEGIN TASK\", \"1\", \"1\", \"1\", \"1\", \"2\", \"2\", \"2\"…\n$ reaction_time          &lt;dbl&gt; NA, 8007.015, 249.823, 199.765, 1999.671, 249.8…\n$ response               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ correct                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ display                &lt;chr&gt; NA, \"instructions\", \"practice\", \"practice\", \"pr…\n$ answer                 &lt;chr&gt; NA, NA, \"right\", \"right\", \"right\", \"left\", \"lef…\n$ soa                    &lt;dbl&gt; NA, NA, 200, 200, 200, 200, 200, 200, 500, 500,…\n$ screen_name            &lt;chr&gt; NA, \"instructions_continue\", \"Screen 1\", \"Scree…\n$ image_left             &lt;chr&gt; NA, NA, \"p1.jpg\", \"p1.jpg\", \"p1.jpg\", \"p1.jpg\",…\n$ image_right            &lt;chr&gt; NA, NA, \"p2.jpg\", \"p2.jpg\", \"p2.jpg\", \"p2.jpg\",…\n$ dot_left               &lt;chr&gt; NA, NA, \"nodot.jpg\", \"nodot.jpg\", \"nodot.jpg\", …\n$ dot_right              &lt;chr&gt; NA, NA, \"dot.jpg\", \"dot.jpg\", \"dot.jpg\", \"nodot…\n$ trial_type             &lt;chr&gt; NA, NA, \"practice\", \"practice\", \"practice\", \"pr…\n$ block                  &lt;dbl&gt; NA, NA, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n\n\nThe columns (variables) we have in the data set are:\n\n\n\n\n\n\n\nVariable\nType\nDescription\n\n\n\nparticipant_private_id\ndouble\nParticipant number.\n\n\ntrial_number\ncharacter\nTrial number as an integer, plus start and end task.\n\n\nreaction_time\ndouble\nParticipant response time in milliseconds (ms)\n\n\nresponse\ncharacter\nKeyboard response from participant. Left or Right.\n\n\ncorrect\ndouble\nWas the response correct? 1 = correct, 0 = incorrect.\n\n\ndisplay\ncharacter\nTrial display: e.g., practice, trials, instructions, breaks.\n\n\nanswer\ncharacter\nWhat is the correct answer? Left or Right.\n\n\nsoa\ndouble\nStimulus onset asynchrony. How long the images were shown for: 200ms or 500ms.\n\n\nscreen_name\ncharacter\nName of the screen: e.g., screen 1, fixation, stimuli, response.\n\n\nimage_left\ncharacter\nName of the image file in the left area.\n\n\nimage_right\ncharacter\nName of the image file in the right area.\n\n\ndot_left\ncharacter\nName of the dot image file in the left area.\n\n\ndot_right\ncharacter\nName of the dot image file in the right area.\n\n\ntrial_type\ncharacter\nCategory of the trial: practice, neutral, nonsmoking, smoking.\n\n\nblock\ndouble\nNumber of the trial block.\n\n\n\n\n\n\n\n\n\nTry this\n\n\n\nNow we have introduced the two data sets, explore them using different methods we introduced. For example, opening the data objects as a tab to scroll around, explore with glimpse(), or even try plotting some of the variables to see what they look like using visualisation skills from Chapter 3.\nDo you notice any variables that look the wrong type? Can you see any responses in there that are going to cause problems?"
  },
  {
    "objectID": "17-analysis-journey-1.html#wrangling-demographics",
    "href": "17-analysis-journey-1.html#wrangling-demographics",
    "title": "15  Analysis Journey 1: Data Wrangling",
    "section": "\n15.3 Wrangling demographics",
    "text": "15.3 Wrangling demographics\nFor this kind of data, we recommend wrangling each file first, before joining them together. Starting with the demographics file, there are a few wrangling steps before the data are ready to summarise. We are going to show you a preview of the starting data set and the end product we are aiming for.\n\n\nRaw data\nWrangled data\n\n\n\n\n\nRows: 205\nColumns: 20\n$ participant_private_id &lt;dbl&gt; 631737, 631738, 631741, 631739, 631749, 631746,…\n$ consent_given          &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ age                    &lt;dbl&gt; 46, 54, 23, 34, 38, 19, 25, 21, 28, 35, 47, 45,…\n$ cigarettes_per_week    &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"…\n$ smoke_everyday         &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"…\n$ past_four_weeks        &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"…\n$ age_started_smoking    &lt;chr&gt; \"12\", \"17\", \"17\", \"16\", \"15\", \"16\", \"22\", \"11\",…\n$ country_of_origin      &lt;chr&gt; \"United Kingdom\", \"Germany\", \"Poland\", \"Austral…\n$ cpd                    &lt;chr&gt; \"6\", \"5\", \"10\", \"20\", \"10\", \"1\", \"6\", \"15\", \"12…\n$ ethnicity              &lt;chr&gt; \"White / Caucasian\", \"White / Caucasian\", \"Mixe…\n$ gender                 &lt;chr&gt; \"Female\", \"Female\", \"Male\", \"Female\", \"Female\",…\n$ last_cigarette         &lt;chr&gt; \"60\", \"780\", \"90\", \"5\", \"60\", \"720\", \"10\", \"10\"…\n$ level_education        &lt;chr&gt; \"Graduated University / College\", \"Graduated Un…\n$ technical_issues       &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\",…\n$ FTND_1                 &lt;dbl&gt; 2, 0, 0, 3, 3, 0, 1, 2, 1, 3, 2, 2, 2, 1, 2, 0,…\n$ FTND_2                 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,…\n$ FTND_3                 &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0,…\n$ FTND_4                 &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1,…\n$ FTND_5                 &lt;dbl&gt; 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0,…\n$ FTND_6                 &lt;dbl&gt; 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0,…\n\n\n\n\n\n\nRows: 205\nColumns: 22\n$ participant_private_id &lt;dbl&gt; 631737, 631738, 631741, 631739, 631749, 631746,…\n$ consent_given          &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ age                    &lt;dbl&gt; 46, 54, 23, 34, 38, 19, 25, 21, 28, 35, 47, 45,…\n$ cigarettes_per_week    &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"…\n$ smoke_everyday         &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"…\n$ past_four_weeks        &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"…\n$ age_started_smoking    &lt;int&gt; 12, 17, 17, 16, 15, 16, 22, 11, 18, 15, 18, 19,…\n$ country_of_origin      &lt;fct&gt; United Kingdom, Germany, Poland, Australia, Spa…\n$ cpd                    &lt;int&gt; 6, 5, 10, 20, 10, 1, 6, 15, 12, 20, 20, 15, 20,…\n$ ethnicity              &lt;fct&gt; White / Caucasian, White / Caucasian, Mixed / m…\n$ gender                 &lt;fct&gt; Female, Female, Male, Female, Female, Male, Fem…\n$ last_cigarette         &lt;dbl&gt; 60, 780, 90, 5, 60, 720, 10, 10, 30, 0, 10, 30,…\n$ level_education        &lt;fct&gt; Graduated University / College, Graduated Unive…\n$ technical_issues       &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\",…\n$ FTND_1                 &lt;dbl&gt; 2, 0, 0, 3, 3, 0, 1, 2, 1, 3, 2, 2, 2, 1, 2, 0,…\n$ FTND_2                 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,…\n$ FTND_3                 &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0,…\n$ FTND_4                 &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1,…\n$ FTND_5                 &lt;dbl&gt; 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0,…\n$ FTND_6                 &lt;dbl&gt; 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0,…\n$ daily_smoker           &lt;fct&gt; Daily Smoker, Daily Smoker, Daily Smoker, Daily…\n$ FTND_sum               &lt;dbl&gt; 3, 0, 2, 7, 5, 3, 3, 5, 4, 6, 7, 5, 6, 3, 4, 1,…\n\n\n\n\n\n\n\n\n\n\n\nTry this\n\n\n\nBefore we give you a task list, try and switch between the raw data and the wrangled data. Make a list of all the differences you can see between the two data objects.\n\nWhat type is each variable? Has it changed from the raw data?\nDo we have any new variables? How could you create these from the variables available to you?\n\nFor the variable daily_smoker, this has two levels which you cannot see in the preview: “Daily Smoker” and “Non-daily Smoker”. Which variable could this be based on?\nTry and wrangle the data based on all the differences you notice to create a new object demog_tidy.\nWhen you get as far as you can, check the task list which explains all the steps we applied, but not how to do them. Then, you can check the solution for our code.\n\n\n\n15.3.1 Task list\n\n\n\n\n\n\nShow me the task list\n\n\n\n\n\nThese are all the steps we applied to create the wrangled data object:\n\nConvert age_started_smoking to an integer (as age is a round number).\nConvert cpd to an integer (as cigarettes per day is a round number). You will notice a warning about introducing an NA as some nonsense responses cannot be converted to a number.\nConvert country_of_origin to a factor (as we have distinct categories).\nConvert ethnicity to a factor (as we have distinct categories).\nConvert gender to a factor (as we have distinct categories).\nConvert last_cigarette to an integer (as time since last cigarette in minutes is a round number). You will notice a warning about introducing an NA as some nonsense responses cannot be converted to a number.\nConvert level_education to a factor (as we have distinct categories).\nCreate a new variable daily_smoker by recoding an existing variable. The new variable should have two levels: “Daily Smoker” and “Non-daily Smoker”. In the process, convert daily_smoker to a factor (as we have distinct categories).\nCreate a new variable FTND_sum by taking the sum of the six items FTND_1 to FTND_6 per participant.\n\nFor some advice, think of everything we covered in Chapters 4 to 6. How could you complete these steps as efficiently as possible? Could you string together functions using pipes, or do you need some intermediary objects? If it’s easier for you to complete steps with longer but accurate code, there is nothing wrong with that. You recognise ways to make your code more efficient over time.\n\n\n\n\n15.3.2 Solution\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThis is the code we used to create the new object demog_tidy using the original object demog. As long as you get the same end result, the exact code is not important. In coding, there are multiple ways of getting to the same end result. Maybe you found a more efficient way to complete some of the steps compared to us. Maybe your code was a little longer. As long as it worked, that is the most important thing.\n\n# Using demog, create a new object demog_tidy\n# apply mutate to convert or create variables\ndemog_tidy &lt;- demog %&gt;% \n  mutate(age_started_smoking = as.integer(age_started_smoking),\n         cpd = as.integer(cpd),\n         country_of_origin = as.factor(country_of_origin),\n         ethnicity = as.factor(ethnicity),\n         gender = as.factor(gender),\n         last_cigarette = as.integer(last_cigarette),\n         level_education = as.factor(level_education),\n         # we used smoke_everyday to create our daily_smoker variable\n         daily_smoker = as.factor(case_match(smoke_everyday,\n                                             \"Yes\" ~ \"Daily Smoker\",\n                                             \"No\" ~ \"Non-daily Smoker\")))\n# To calculate the sum of the 6 FTND items, \n# pivot longer, group by ID, then sum responses. \nFTND_sum &lt;- demog_tidy %&gt;% \n  pivot_longer(cols = FTND_1:FTND_6,\n               names_to = \"Item\",\n               values_to = \"Response\") %&gt;% \n  group_by(participant_private_id) %&gt;% \n  summarise(FTND_sum = sum(Response))\n\n# Join this new column back to demog_tidy\ndemog_tidy &lt;- demog_tidy %&gt;% \n  inner_join(y = FTND_sum,\n             by = \"participant_private_id\")"
  },
  {
    "objectID": "17-analysis-journey-1.html#wrangling-trials",
    "href": "17-analysis-journey-1.html#wrangling-trials",
    "title": "15  Analysis Journey 1: Data Wrangling",
    "section": "\n15.4 Wrangling trials",
    "text": "15.4 Wrangling trials\nTurning to the trials file, there are a few wrangling steps and you will probably need the task list more for this part than you did for demographics. Some of the steps might not be as obvious but it is still important to compare the objects and see if you can identify the changes. We are going to show you a preview of the starting data set, and the end product we are aiming for in step 3.\n\n\nOriginal raw data\nStep 1\nStep 2\nStep 3\n\n\n\n\n\nRows: 244,847\nColumns: 15\n$ participant_private_id &lt;dbl&gt; 631737, 631737, 631737, 631737, 631737, 631737,…\n$ trial_number           &lt;chr&gt; \"BEGIN TASK\", \"1\", \"1\", \"1\", \"1\", \"2\", \"2\", \"2\"…\n$ reaction_time          &lt;dbl&gt; NA, 8007.015, 249.823, 199.765, 1999.671, 249.8…\n$ response               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ correct                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ display                &lt;chr&gt; NA, \"instructions\", \"practice\", \"practice\", \"pr…\n$ answer                 &lt;chr&gt; NA, NA, \"right\", \"right\", \"right\", \"left\", \"lef…\n$ soa                    &lt;dbl&gt; NA, NA, 200, 200, 200, 200, 200, 200, 500, 500,…\n$ screen_name            &lt;chr&gt; NA, \"instructions_continue\", \"Screen 1\", \"Scree…\n$ image_left             &lt;chr&gt; NA, NA, \"p1.jpg\", \"p1.jpg\", \"p1.jpg\", \"p1.jpg\",…\n$ image_right            &lt;chr&gt; NA, NA, \"p2.jpg\", \"p2.jpg\", \"p2.jpg\", \"p2.jpg\",…\n$ dot_left               &lt;chr&gt; NA, NA, \"nodot.jpg\", \"nodot.jpg\", \"nodot.jpg\", …\n$ dot_right              &lt;chr&gt; NA, NA, \"dot.jpg\", \"dot.jpg\", \"dot.jpg\", \"nodot…\n$ trial_type             &lt;chr&gt; NA, NA, \"practice\", \"practice\", \"practice\", \"pr…\n$ block                  &lt;dbl&gt; NA, NA, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n\n\n\n\n\n\nRows: 50,510\nColumns: 15\n$ participant_private_id &lt;dbl&gt; 631737, 631737, 631737, 631737, 631737, 631737,…\n$ trial_number           &lt;chr&gt; \"1\", \"2\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"11\", \"…\n$ reaction_time          &lt;dbl&gt; 1486.850, 720.640, 739.635, 668.730, 578.015, 5…\n$ response               &lt;chr&gt; \"right\", \"left\", \"right\", \"right\", \"left\", \"lef…\n$ correct                &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ display                &lt;chr&gt; \"trials\", \"trials\", \"trials\", \"trials\", \"trials…\n$ answer                 &lt;chr&gt; \"right\", \"left\", \"right\", \"right\", \"left\", \"lef…\n$ soa                    &lt;dbl&gt; 200, 500, 500, 200, 200, 200, 200, 200, 500, 50…\n$ screen_name            &lt;chr&gt; \"response\", \"response\", \"response\", \"response\",…\n$ image_left             &lt;chr&gt; \"N14.jpg\", \"F14.jpg\", \"F14.jpg\", \"N4.jpg\", \"N19…\n$ image_right            &lt;chr&gt; \"F14.jpg\", \"N14.jpg\", \"N14.jpg\", \"F4.jpg\", \"F19…\n$ dot_left               &lt;chr&gt; \"nodot.jpg\", \"dot.jpg\", \"nodot.jpg\", \"nodot.jpg…\n$ dot_right              &lt;chr&gt; \"dot.jpg\", \"nodot.jpg\", \"dot.jpg\", \"dot.jpg\", \"…\n$ trial_type             &lt;chr&gt; \"smoking\", \"smoking\", \"nonsmoking\", \"smoking\", …\n$ block                  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n\n\n\n\n\n\nRows: 820\nColumns: 5\n$ participant_private_id &lt;dbl&gt; 631737, 631737, 631737, 631737, 631738, 631738,…\n$ soa                    &lt;dbl&gt; 200, 200, 500, 500, 200, 200, 500, 500, 200, 20…\n$ trial_type             &lt;chr&gt; \"nonsmoking\", \"smoking\", \"nonsmoking\", \"smoking…\n$ median_RT              &lt;dbl&gt; 444.6275, 452.8675, 456.8900, 449.6650, 638.000…\n$ condition              &lt;chr&gt; \"nonsmoking200\", \"smoking200\", \"nonsmoking500\",…\n\n\n\n\n\n\nRows: 205\nColumns: 5\n$ participant_private_id &lt;dbl&gt; 631737, 631738, 631739, 631741, 631746, 631748,…\n$ nonsmoking200          &lt;dbl&gt; 444.6275, 638.0000, 516.5375, 410.8250, 375.272…\n$ smoking200             &lt;dbl&gt; 452.8675, 703.5000, 529.1300, 433.3175, 367.365…\n$ nonsmoking500          &lt;dbl&gt; 456.8900, 700.0000, 517.4775, 427.4100, 363.195…\n$ smoking500             &lt;dbl&gt; 449.6650, 725.0000, 514.5050, 421.2250, 355.777…\n\n\n\n\n\n\n\n\n\n\n\nTry this\n\n\n\nBefore we give you a task list, try and switch between the raw data and the three steps we took for wrangling the data. Make a list of all the differences you can see across the steps.\nThis part of the data wrangling is quite difficult if you are unfamiliar with dealing with response time tasks as you need to know what the end product should look like to work with later. Essentially, we want the median response time per participant per condition (across trial type and soa). There are rows we do not need, variables to create, and data to restructure. So, it takes all your wrangling skills you have learnt so far.\n\nIn step 1, how many observations do we have compared to the raw data? Knowing the design is important here, so look at the columns correct, screen_name, and trial_type. What function might reduce the number of observations like this?\nIn step 2, how many observations do we have compared to step 1? How many observations do we have per participant ID? What new variables do we have and how could you make them? Hint: for condition, we have not covered this, so look up a function called paste0().\nIn step 3, how many observations do we have compared to step 2? Have we removed any columns compared to step 2? Have the data been restructured?\n\nTry and wrangle the data based on all the differences you notice to create a new object RT_wide shown in step 3.\nWhen you get as far as you can, check the task list which explains all the steps we applied, but not how to do them. Then, you can check the solution for our code.\n\n\n\n15.4.1 Task list\nFor this part, we will separate the task list into the three steps in case you want to test yourself at each stage.\n\n\n\n\n\n\nShow me the step 1 task list\n\n\n\n\n\nThese are all the steps we applied to create the wrangled data object:\n\nCreate an object trials_tidy using the original trials data.\n\nFilter observations using three variables:\n\nscreen_name should only include “response”.\ntrial_type should only include “nonsmoking” and “smoking”.\ncorrect should only include 1 (correct responses).\n\n\n\n\n\n\n\n\n\n\n\n\nShow me the step 2 task list\n\n\n\n\n\nThese are all the steps we applied to create the wrangled data object:\n\nCreate an object average_trials using the trials_tidy object from step 1.\nGroup observations by three variables: participant_private_id, soa, and trial_type.\nSummarise the data to create a new variable median_RT by calculating the median reaction_time.\nCreate a new variable called condition by combining the names of the trial_type and soa columns. Hint: this is a new concept, so try this paste0(trial_type, soa). There are a few ways of dealing with this problem, but we are trying to avoid turning soa into variable names, as R does not like having variable names start with or be completely numbers.\nUngroup to avoid the groups carrying over into future objects.\n\n\n\n\n\n\n\n\n\n\nShow me the step 3 task list\n\n\n\n\n\nThese are all the steps we applied to create the wrangled data object:\n\nCreate an object RT_wide using the average_trials object from step 2.\nRemove the variables soa and trial_type to avoid problems with restructuring. You could use the argument,\nRestructure the data so your condition variable is spread across columns.\n\n\n\n\n\n15.4.2 Solution\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThis is the code we used to create the new object RT_wide by following three steps. You could do it in two to combine the first two steps, but we wanted to make the change between filtering and grouping/summarising more obvious before showing you the task list.\nRemember: As long as you get the same end result, the exact code is not important. In coding, there are multiple ways of getting to the same end result.\n\n# filter trials to focus on correct responses and key trials\ntrials_tidy &lt;- trials %&gt;% \n  filter(screen_name == \"response\",\n         trial_type %in% c(\"nonsmoking\", \"smoking\"),\n         correct == 1)\n\n# Calculate median RT per ID, SOA, and trial type\naverage_trials &lt;- trials_tidy %&gt;% \n  group_by(participant_private_id, soa, trial_type) %&gt;% \n  summarise(median_RT = median(reaction_time)) %&gt;% \n  mutate(condition = paste0(trial_type, soa)) %&gt;% \n  ungroup() # ungroup to avoid it carrying over\n\n# Create wide data by making a new condition variable\n# remove soa and trial type\n# pivot wider for four columns per participant\nRT_wide &lt;- average_trials %&gt;% \n  select(-soa, -trial_type) %&gt;% \n  pivot_wider(names_from = condition,\n              values_from = median_RT)"
  },
  {
    "objectID": "17-analysis-journey-1.html#combining-objects-and-exclusion-criteria",
    "href": "17-analysis-journey-1.html#combining-objects-and-exclusion-criteria",
    "title": "15  Analysis Journey 1: Data Wrangling",
    "section": "\n15.5 Combining objects and exclusion criteria",
    "text": "15.5 Combining objects and exclusion criteria\nGreat work so far! You should now have two wrangled objects: demog_tidy and RT_wide. The next step is combining them and applying exclusion criteria from the study.\nWe are going to give you the task list immediately for this as you need to understand the methods to know what criteria to use. We still challenge you to complete the tasks though, before checking your answers against the code we used.\n\n\n\n\n\n\nTask list\n\n\n\nComplete the following tasks to apply the final data wrangling steps:\n\nCreate a new object called full_data by joining your two data objectsdemog_tidy and RT_wide using a common identifier.\n\nFilter observations using the following criteria:\n\nconsent_given should only include 1. We only want people who consented.\nage range only between 18 and 60. We do not want people younger or older than this range.\npast_four_weeks should only include “Yes”. We do not want people who have not smoked in the past four weeks.\ntechnical_issues should only include “No”. We do not want people who experienced technical issues during the study.\n\n\n\n\n\n\n15.5.1 Solution\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThis is the code we used to create the new object full_data by joining demog_tidy and RT_wide, and filtering observations based on our four criteria.\nAs long as you get the same end result, the exact code is not important. In coding, there are multiple ways of getting to the same end result.\n\n# create full_data by joining the two objects\n# filter data by four criteria\nfull_data &lt;- demog_tidy %&gt;% \n  inner_join(y = RT_wide,\n             by = \"participant_private_id\") %&gt;% \n  filter(consent_given == 1,\n         age &gt;= 18 & age &lt;= 60,\n         past_four_weeks == \"Yes\",\n         technical_issues == \"No\")"
  },
  {
    "objectID": "17-analysis-journey-1.html#summarisingvisualising-your-data",
    "href": "17-analysis-journey-1.html#summarisingvisualising-your-data",
    "title": "15  Analysis Journey 1: Data Wrangling",
    "section": "\n15.6 Summarising/visualising your data",
    "text": "15.6 Summarising/visualising your data\nThat is all the wrangling complete! Hopefully, this reinforces the role of reproducibility and data skills. If you did this in other software like Excel, you might not have a paper trail of all the steps. Like this, you have the full code to apply all the wrangling steps from raw data which you can run every time you need to, and edit it if you found a mistake or wanted to add something new. You can also come back to the file later to add more code (such as after Chapter 7 to plot more of the data, or Chapter 13 for some inferential statistics).\nTo finish the journey, we have some practice tasks for summarising and visualising the data. The whole purpose of Bartlett et al. (2022) was to compare daily and non-daily smokers, so we will explore some of the key variables.\nAll of the questions are based on the final full_data object. If your answers differ, check the wrangling steps above. If you are really struggling to identify the difference, or you just wanted to complete these tasks, you can download a spreadsheet version of full_data here: Bartlett_full_data.csv.\n\n15.6.1 Demographics\n\nHow many daily and non-daily smokers were there? There were  daily smokers and  non-daily smokers.\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\n\nfull_data %&gt;% \n  count(daily_smoker)\n\n\n\n\ndaily_smoker\nn\n\n\n\nDaily Smoker\n115\n\n\nNon-daily Smoker\n63\n\n\n\n\n\n\n\n\n\n\nTo 2 decimal places, the mean age of all the participants was  (SD = ).\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\n\nfull_data %&gt;% \n  summarise(mean_age = round(mean(age), 2),\n            sd_age = round(sd(age), 2))\n\n\n\n\nmean_age\nsd_age\n\n\n31.07\n9.22\n\n\n\n\n\n\n\n\n\nA histogram of all the participants’ ages looks like:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\n\nfull_data %&gt;% \n  ggplot(aes(x = age)) + \n  geom_histogram() + \n  scale_x_continuous(name = \"Age\") + \n  scale_y_continuous(name = \"Frequency\") + \n  theme_classic()\n\n\n\n\n\nA bar plot of the gender breakdown of the sample would look like:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\n\nfull_data %&gt;% \n  ggplot(aes(x = gender)) + \n  geom_bar() +\n  scale_x_discrete(name = \"Gender\") + \n  scale_y_continuous(name = \"Frequency\") + \n  theme_classic()\n\n\n\n\n\n15.6.2 Measures of smoking dependence\n\nTo 2 decimal places, for daily smokers the mean number of cigarettes per day was  (SD = ) and for non-daily smokers the mean number of cigarettes per day was  (SD = ).\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\n\nfull_data %&gt;% \n  group_by(daily_smoker) %&gt;% \n  summarise(mean_cpd = round(mean(cpd, na.rm = TRUE), 2),\n            sd_cpd = round(sd(cpd, na.rm = TRUE), 2))\n\n\n\n\ndaily_smoker\nmean_cpd\nsd_cpd\n\n\n\nDaily Smoker\n8.85\n6.51\n\n\nNon-daily Smoker\n2.32\n2.69\n\n\n\n\n\n\n\n\n\n\nTo 2 decimal places, for daily smokers the mean FTND sum score was  (SD = ) and for non-daily smokers the mean number of cigarettes per day was  (SD = ).\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\n\nfull_data %&gt;% \n  group_by(daily_smoker) %&gt;% \n  summarise(mean_FTND = round(mean(FTND_sum, na.rm = TRUE), 2),\n            sd_FTND = round(sd(FTND_sum, na.rm = TRUE), 2))\n\n\n\n\ndaily_smoker\nmean_FTND\nsd_FTND\n\n\n\nDaily Smoker\n2.61\n2.20\n\n\nNon-daily Smoker\n0.49\n1.28\n\n\n\n\n\n\n\n\n\n\n15.6.3 Attentional bias\n\n\nBefore answering the following questions, complete one extra data wrangling step to create difference scores where positive values mean attentional bias towards smoking images (faster responses to smoking compared to non-smoking stimuli):\n\nCreate a new variable called difference_200 by calculating nonsmoking200 - smoking200.\nCreate a new variable called difference_500 by by calculating nonsmoking500 - smoking500.\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\n\nfull_data &lt;- full_data %&gt;% \n  mutate(difference_200 = nonsmoking200 - smoking200,\n         difference_500 = nonsmoking500 - smoking500)\n\n\n\n\n\nTo 2 decimal places, the mean difference in attentional bias in the 200ms condition was  (SD = ) for daily smokers and  (SD = ) for non-daily smokers.\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\n\nfull_data %&gt;% \n  group_by(daily_smoker) %&gt;% \n  summarise(mean_bias_200 = round(mean(difference_200, na.rm = TRUE), 2),\n            sd_bias_200 = round(sd(difference_200, na.rm = TRUE), 2))\n\n\n\n\ndaily_smoker\nmean_bias_200\nsd_bias_200\n\n\n\nDaily Smoker\n1.25\n23.91\n\n\nNon-daily Smoker\n-2.74\n21.27\n\n\n\n\n\n\n\n\n\n\nTo 2 decimal places, the mean difference in attentional bias in the 500ms condition was  (SD = ) for daily smokers and  (SD = ) for non-daily smokers.\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\n\nfull_data %&gt;% \n  group_by(daily_smoker) %&gt;% \n  summarise(mean_bias_500 = round(mean(difference_500, na.rm = TRUE), 2),\n            sd_bias_500 = round(sd(difference_500, na.rm = TRUE), 2))\n\n\n\n\ndaily_smoker\nmean_bias_500\nsd_bias_500\n\n\n\nDaily Smoker\n0.76\n21.66\n\n\nNon-daily Smoker\n-1.19\n14.51\n\n\n\n\n\n\n\n\n\nIf you are currently completing this after Chapter 6, we have not covered visualising continuous data or inferential statistics yet. Try coming back to these tasks to compare these measures when you have finished Chapter 7 for more advanced visualisation and Chapter 13 for factorial ANOVA.\nA difference score of 0 means no bias towards smoking or non-smoking images. So, you can see the paper did not find either group showed much attentional bias towards smoking images nor much difference between the groups, hence why it was published in the Journal of Trial and Error."
  },
  {
    "objectID": "17-analysis-journey-1.html#conclusion",
    "href": "17-analysis-journey-1.html#conclusion",
    "title": "15  Analysis Journey 1: Data Wrangling",
    "section": "\n15.7 Conclusion",
    "text": "15.7 Conclusion\nWell done! Hopefully you recognised how far your skills have come to be able to do this independently, regardless of how many hints you needed.\nThese are real skills people use in research. If you are curious, Bartlett et al. (2022) shared their code as a reproducible manuscrupt, so you can see all the wrangling steps they completed by looking at this file on the Open Science Framework. We did not include all of them here as there are concepts like outliers we had not covered by Chapter 6.\n\n\n\n\nBartlett, J. E., Jenks, R., & Wilson, N. (2022). No Meaningful Difference in Attentional Bias Between Daily and Non-Daily Smokers. Journal of Trial & Error. https://doi.org/10.36850/e11"
  },
  {
    "objectID": "18-analysis-journey-2.html#task-preparation",
    "href": "18-analysis-journey-2.html#task-preparation",
    "title": "16  Analysis Journey 2: Simple Linear Regression",
    "section": "\n16.1 Task preparation",
    "text": "16.1 Task preparation\n\n16.1.1 Introduction to the data set\nFor this task, we are using open data from Binfet et al. (2022), where the authors used the data set to write a separate article on repurposing it for statistics education (Evans et al., 2023), inspiring us to use it in the chapter here. The abstract of their article is:\n\nResearchers have claimed that canine-assisted interventions (CAIs) contribute significantly to bolstering participants’ wellbeing, yet the mechanisms within interactions have received little empirical attention. The aim of this study was to assess the impact of client–canine contact on wellbeing outcomes in a sample of 284 undergraduate college students (77% female; 21% male, 2% non-binary). Participants self-selected to participate and were randomly assigned to one of two canine interaction treatment conditions (touch or no touch) or to a handler-only condition with no therapy dog present. To assess self-reports of wellbeing, measures of flourishing, positive and negative affect, social connectedness, happiness, integration into the campus community, stress, homesickness, and loneliness were administered. Exploratory analyses were conducted to assess whether these wellbeing measures could be considered as measuring a unidimensional construct. This included both reliability analysis and exploratory factor analysis. Based on the results of these analyses we created a composite measure using participant scores on a latent factor. We then conducted the tests of the four hypotheses using these factor scores. Results indicate that participants across all conditions experienced enhanced wellbeing on several measures; however, only those in the direct contact condition reported significant improvements on all measures of wellbeing. Additionally, direct interactions with therapy dogs through touch elicited greater wellbeing benefits than did no touch/indirect interactions or interactions with only a dog handler. Similarly, analyses using scores on the wellbeing factor indicated significant improvement in wellbeing across all conditions (handler-only, d=0.18, p=0.041; indirect, d=0.38, p&lt;0.001; direct, d=0.78, p&lt;0.001), with more benefit when a dog was present (d=0.20, p&lt;0.001), and the most benefit coming from physical contact with the dog (d=0.13, p=0.002). The findings hold implications for post-secondary wellbeing programs as well as the organization and delivery of CAIs.\n\nIn summary, they were interested in the effect of therapy dogs on well-being in undergraduate students. Participants were randomly allocated to one of three groups:\n\nCanine interaction touching the dogs (Direct).\nCanine interaction not touching the dogs (Indirect).\nHandler-only with no dogs present (Control).\n\nThey measured 9 outcomes before and after the intervention including social connectedness, stress, and loneliness. For this journey chapter, we will focus on a constrained set of variables and analyses so it does not take forever, but the process would apply to all the outcomes. The authors posed three hypotheses which we will test after some data wrangling:\n\nAll treatment groups would have significantly higher measures of well-being and lower measures of ill-being after treatment.\nThe treatment groups that interact with dogs would have significantly higher measures of well-being and lower measures of ill-being compared to the handler-only treatment.\nDirect contact with a therapy dog would yield greater benefits than indirect contact treatment.\n\n16.1.2 Organising your files and project for the task\nBefore we can get started, you need to organise your files and project for the task, so your working directory is in order.\n\nIn your folder for research methods and the book ResearchMethods1_2/Quant_Fundamentals, create a new folder for the data analysis journey called Journey_02_regression. Within Journey_02_regression, create two new folders called data and figures.\nCreate an R Project for Journey_02_regression as an existing directory for your chapter folder. This should now be your working directory.\nCreate a new R Markdown document and give it a sensible title describing the chapter, such as Analysis Journey 2 - Simple Linear Regression. Delete everything below line 10 so you have a blank file to work with and save the file in your Journey_02_regression folder.\nWe are working with a new data set, so please save the following data file: Evans_2023_raw.csv. Right click the link and select “save link as”, or clicking the link will save the files to your Downloads. Make sure that you save the file as “.csv”. Save or copy the file to your data/ folder within Journey_02_regression.\n\nYou are now ready to start working on the task!"
  },
  {
    "objectID": "18-analysis-journey-2.html#overview",
    "href": "18-analysis-journey-2.html#overview",
    "title": "16  Analysis Journey 2: Simple Linear Regression",
    "section": "\n16.2 Overview",
    "text": "16.2 Overview\n\n16.2.1 Load tidyverse and read the data file\nBefore we explore what wrangling we need to do, complete the following task list and check the solution if you are stuck.\n\n\n\n\n\n\nTry this\n\n\n\nComplete the following steps:\n\nLoad the tidyverse package.\nRead the data file data/Evans_2023_raw.csv to the object name evans_data.\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\n# load the relevant packages\nlibrary(tidyverse)\n\n# Read the Evans_2023_raw.csv file \nevans_data &lt;- read_csv(\"data/Evans_2023_raw.csv\")\n\n\n\n\n\n16.2.2 Explore evans_data\n\nIn evans_data, we have the participant ID (RID), several demographic variables, and pre- and post-test items for stress, loneliness, and social connectedness. There are 88 variables which would take up loads of space, so we are just showing a preview of the first 20 here. If you use glimpse(), you will see all 88.\n\n\nRows: 284\nColumns: 20\n$ RID             &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,…\n$ GroupAssignment &lt;chr&gt; \"Control\", \"Direct\", \"Indirect\", \"Control\", \"Direct\", …\n$ Age_Yrs         &lt;dbl&gt; 21, 19, 18, 18, 19, 20, 26, 17, 21, 22, 19, 20, 19, 19…\n$ Year_of_Study   &lt;dbl&gt; 3, 1, 1, 1, 1, 2, 2, 1, 3, 4, 2, 2, 2, 2, 3, 1, 1, 1, …\n$ Live_Pets       &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, NA, 2, 2, 1,…\n$ Consumer_BARK   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, …\n$ S1_1            &lt;dbl&gt; 2, 2, 4, 2, 3, 4, 4, 3, 2, 2, 3, 2, 3, 4, 3, 2, 4, 2, …\n$ L1_1            &lt;dbl&gt; 3, 3, 3, 4, 2, 4, 3, 2, 3, 4, 3, 3, 4, 4, 4, 2, 3, 4, …\n$ L1_2            &lt;dbl&gt; 3, 2, 3, 2, 3, 3, 2, 3, 4, 1, 3, 3, 2, 3, 1, 4, 3, 2, …\n$ L1_3            &lt;dbl&gt; 4, 3, 2, 2, 3, 3, 1, 3, 3, 1, 2, 2, 1, 3, 1, 3, 3, 1, …\n$ L1_4            &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 3, 3, 4, 1, 2, 3, 2, 3, 2, 4, 3, 2, …\n$ L1_5            &lt;dbl&gt; 2, 4, 3, 4, 4, 3, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 3, 4, …\n$ L1_6            &lt;dbl&gt; 3, 3, 4, 4, 3, 2, 3, 3, 3, 4, 3, 3, 4, 3, 4, 2, 2, 4, …\n$ L1_7            &lt;dbl&gt; 1, 2, 2, 1, 2, 2, 4, 2, 2, 1, 3, 2, 3, 2, 2, 2, 3, 3, …\n$ L1_8            &lt;dbl&gt; 2, 2, 3, 3, 2, 3, 2, 3, 3, 2, 3, 2, 2, 3, 2, 4, 3, 2, …\n$ L1_9            &lt;dbl&gt; 3, 4, 3, 3, 3, 3, 3, 3, 2, 4, 3, 3, 4, 4, 4, 3, 2, 3, …\n$ L1_10           &lt;dbl&gt; 4, 3, 3, 4, 2, 2, 3, 3, 3, 4, 4, 3, 4, 4, 4, 2, 2, 3, …\n$ L1_11           &lt;dbl&gt; 3, 2, 2, 2, 4, 3, 4, 2, 2, 1, 3, 2, 2, 2, 2, 4, 3, 2, …\n$ L1_12           &lt;dbl&gt; 1, 2, 2, 1, 4, 3, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 3, 1, …\n$ L1_13           &lt;dbl&gt; 3, 1, 2, 2, 4, 3, 3, 3, 4, 1, 3, 4, 2, 2, 2, 4, 3, 2, …\n\n\nThe columns (variables) we have in the data set are:\n\n\n\n\n\n\n\nVariable\nType\nDescription\n\n\n\nRID\ndouble\nParticipant ID number.\n\n\nGroupAssignment\ncharacter\nRandomly allocated study group: Control, Indirect, Direct.\n\n\nAge_Yrs\ndouble\nAge in years.\n\n\nYear_of_Study\ndouble\nParticipant’s year in college: First (1), Second (2), Third (3), Fourth (4), Fifth or more (5).\n\n\nLive_Pets\ndouble\nDoes the participant have a pet back at home: Pet back home (1), no pet back home (2).\n\n\nConsumer_BARK\ndouble\nIs the participant a low (1), medium (2), or high (3) consumer of the BARK program - the therapy dog service.\n\n\nS1_1\ndouble\nStress scale pre-test, 1 item, 1 (not at all stressed) to 5 (very stressed).\n\n\nL1_1 to L1_20\ndouble\nLoneliness scale pre-test, 20 items, 1 (never) to 4 (often).\n\n\nSC1_1 to SC1_20\ndouble\nSocial connectedness scale pre-test, 20 items, 1 (strongly disagree) to 6 (strongly agree).\n\n\nS2_1\ndouble\nStress scale post-test, 1 item.\n\n\nL2_1 to L2_20\ndouble\nLoneliness scale post-test, 20 items.\n\n\nSC2_1 to SC2_20\ndouble\nSocial connectedness scale post-test, 20 items, 1 (strongly disagree) to 6 (strongly agree).\n\n\n\n\n\n\n\n\n\nTry this\n\n\n\nNow we have introduced the data set, explore them using different methods we introduced. For example, opening the data object as a tab to scroll around, explore with glimpse(), or even try plotting some of the individual variables to see what they look like."
  },
  {
    "objectID": "18-analysis-journey-2.html#wrangling",
    "href": "18-analysis-journey-2.html#wrangling",
    "title": "16  Analysis Journey 2: Simple Linear Regression",
    "section": "\n16.3 Wrangling",
    "text": "16.3 Wrangling\nWe are going to show you a preview of the starting data set and the end product we are aiming for. For the raw data, we have limited this to the first 20 rows again just so it does not take up the whole page, but if you use glimpse() you will see all 88 variables.\n\n\nRaw data\nWrangled data\n\n\n\n\n\nRows: 284\nColumns: 20\n$ RID             &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,…\n$ GroupAssignment &lt;chr&gt; \"Control\", \"Direct\", \"Indirect\", \"Control\", \"Direct\", …\n$ Age_Yrs         &lt;dbl&gt; 21, 19, 18, 18, 19, 20, 26, 17, 21, 22, 19, 20, 19, 19…\n$ Year_of_Study   &lt;dbl&gt; 3, 1, 1, 1, 1, 2, 2, 1, 3, 4, 2, 2, 2, 2, 3, 1, 1, 1, …\n$ Live_Pets       &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, NA, 2, 2, 1,…\n$ Consumer_BARK   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, …\n$ S1_1            &lt;dbl&gt; 2, 2, 4, 2, 3, 4, 4, 3, 2, 2, 3, 2, 3, 4, 3, 2, 4, 2, …\n$ L1_1            &lt;dbl&gt; 3, 3, 3, 4, 2, 4, 3, 2, 3, 4, 3, 3, 4, 4, 4, 2, 3, 4, …\n$ L1_2            &lt;dbl&gt; 3, 2, 3, 2, 3, 3, 2, 3, 4, 1, 3, 3, 2, 3, 1, 4, 3, 2, …\n$ L1_3            &lt;dbl&gt; 4, 3, 2, 2, 3, 3, 1, 3, 3, 1, 2, 2, 1, 3, 1, 3, 3, 1, …\n$ L1_4            &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 3, 3, 4, 1, 2, 3, 2, 3, 2, 4, 3, 2, …\n$ L1_5            &lt;dbl&gt; 2, 4, 3, 4, 4, 3, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 3, 4, …\n$ L1_6            &lt;dbl&gt; 3, 3, 4, 4, 3, 2, 3, 3, 3, 4, 3, 3, 4, 3, 4, 2, 2, 4, …\n$ L1_7            &lt;dbl&gt; 1, 2, 2, 1, 2, 2, 4, 2, 2, 1, 3, 2, 3, 2, 2, 2, 3, 3, …\n$ L1_8            &lt;dbl&gt; 2, 2, 3, 3, 2, 3, 2, 3, 3, 2, 3, 2, 2, 3, 2, 4, 3, 2, …\n$ L1_9            &lt;dbl&gt; 3, 4, 3, 3, 3, 3, 3, 3, 2, 4, 3, 3, 4, 4, 4, 3, 2, 3, …\n$ L1_10           &lt;dbl&gt; 4, 3, 3, 4, 2, 2, 3, 3, 3, 4, 4, 3, 4, 4, 4, 2, 2, 3, …\n$ L1_11           &lt;dbl&gt; 3, 2, 2, 2, 4, 3, 4, 2, 2, 1, 3, 2, 2, 2, 2, 4, 3, 2, …\n$ L1_12           &lt;dbl&gt; 1, 2, 2, 1, 4, 3, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 3, 1, …\n$ L1_13           &lt;dbl&gt; 3, 1, 2, 2, 4, 3, 3, 3, 4, 1, 3, 4, 2, 2, 2, 4, 3, 2, …\n\n\n\n\n\n\nRows: 284\nColumns: 12\n$ RID             &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,…\n$ GroupAssignment &lt;chr&gt; \"Control\", \"Direct\", \"Indirect\", \"Control\", \"Direct\", …\n$ Age_Yrs         &lt;dbl&gt; 21, 19, 18, 18, 19, 20, 26, 17, 21, 22, 19, 20, 19, 19…\n$ Year_of_Study   &lt;dbl&gt; 3, 1, 1, 1, 1, 2, 2, 1, 3, 4, 2, 2, 2, 2, 3, 1, 1, 1, …\n$ Live_Pets       &lt;chr&gt; \"Does not have a pet back home\", \"Does not have a pet …\n$ Consumer_BARK   &lt;chr&gt; \"Low\", \"Low\", \"Low\", \"Low\", \"Low\", \"Low\", \"Low\", \"Low\"…\n$ stress_pre      &lt;dbl&gt; 2, 2, 4, 2, 3, 4, 4, 3, 2, 2, 3, 2, 3, 4, 3, 2, 4, 2, …\n$ stress_post     &lt;dbl&gt; 2, 1, 3, 2, 4, 4, 3, 2, 2, 1, 2, 2, 1, 2, 4, 2, 2, 1, …\n$ lonely_pre      &lt;dbl&gt; 2.25, 1.90, 2.25, 1.75, 2.85, 2.70, 2.40, 2.25, 2.55, …\n$ lonely_post     &lt;dbl&gt; 1.70, 1.60, 2.25, 2.05, 2.70, 2.40, 2.25, 2.00, 2.55, …\n$ social_pre      &lt;dbl&gt; 3.90, 5.15, 4.10, 4.65, 3.65, 4.35, 4.75, 4.60, 4.20, …\n$ social_post     &lt;dbl&gt; 3.800000, 5.263158, 4.150000, 5.100000, 3.600000, 4.65…\n\n\n\n\n\n\n\n\n\n\n\nTry this\n\n\n\nBefore we give you a task list, try and switch between the raw data and the wrangled data. Make a list of all the differences you can see between the two data objects.\n\nDo the values of variables change from numbers? How might you recode them using the code book above?\nLooking at the codebook, are some variables the same but renamed?\nLooking at the codebook, have we calculated the mean of all the items for a scale?\n\nTry and wrangle the data based on all the differences you notice to create a new object evans_wide.\nFor one hint, unless you read the original paper, there are a bunch of items that first need reverse coding you would not know about:\n\nLoneliness pre-test: L1_1, L1_5, L1_6, L1_9, L1_10, L1_15, L1_16, L1_19, L1_20.\nLoneliness post-test: L2_1, L2_5, L2_6, L2_9, L2_10, L2_15, L2_16, L2_19, L2_20.\nSocial connectedness pre-test: SC1_3, SC1_6, SC1_7, SC1_9, SC1_11, SC1_13, SC1_15, SC1_17, SC1_18, SC1_20.\nSocial connectedness post-test: SC2_3, SC2_6, SC2_7, SC2_9, SC2_11, SC2_13, SC2_15, SC2_17, SC2_18, SC2_20.\n\nWhen you get as far as you can, check the task list which explains all the steps we applied, but not how to do them. Then, you can check the solution for our code.\n\n\n\n16.3.1 Task list\n\n\n\n\n\n\nShow me the task list\n\n\n\n\n\nThese are all the steps we applied to create the wrangled data object:\n\nRecode Live_Pets to the two labels outlined in the code book.\nRecode Consumer_BARK to the three labels outlined in the code book.\nReverse code the loneliness and social connectedness items outlined above. Think of previous examples where we explained reverse coding for how you can do this efficiently.\n\nAs one extra piece of advice if you do not want to recode 40 variables one by one, there is a more advanced function you can use within mutate(). The function across() lets you apply a function or calculation to several columns at once. For example, if we wanted to reverse score items on a 4-point scale, it would look like the following:\n\nmutate(across(.cols = c(column1, column2...), \n              .fns = ~ 5 - .x))\n\nIn .cols, we enter all the columns we want to apply the function to.\nIn .fns after the =, we add the function we want to apply to all the columns we selected. The code is a little awkward as we have a tilde ~, here the calculation we want to apply, and .x in place of the column name. You could summarise it as: for all the columns I select, subtract each value from 5. Once you get used to the format, across() is really helpful when you want to do the same thing to multiple columns.\n\nAfter reverse coding the items, calculate the subscale mean scores for loneliness and social connectedness. You must do this twice per scale, as we have the 20 items for the pre-test and 20 items for the post-test per scale.\nIf you calculated the subscale mean scores individually, join them back to the evans_clean object you mutated.\n\nSelect the following columns:\n\nRID to Consumer_BARK.\nRename S1_1 to stress_pre.\nRename S2_1 to stress_post.\nSelect your four subscale mean score variables.\n\n\n\nRemember: If it’s easier for you to complete steps with longer but accurate code, there is nothing wrong with that. You recognise ways to make your code more efficient over time.\n\n\n\n\n16.3.2 Solution\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThis is the code we used to create the new object evans_wide using the original object evans_data. As long as you get the same end result, the exact code is not important. In coding, there are multiple ways of getting to the same end result. Maybe you found a more efficient way to complete some of the steps compared to us. Maybe your code was a little longer. As long as it worked, that is the most important thing.\n\n# Initial cleaning step to recode pets and BARK\n# then reverse code a bunch of items \nevans_clean &lt;- evans_data %&gt;% \n  mutate(Live_Pets = case_match(Live_Pets,\n                                1 ~ \"Has a pet back home\",\n                                2 ~ \"Does not have a pet back home\"),\n         Consumer_BARK = case_match(Consumer_BARK,\n                                    1 ~ \"Low\",\n                                    2 ~ \"Medium\",\n                                    3 ~ \"High\"),\n         # across works with mutate to apply the same function to several columns\n         # So, take all the loneliness items to reverse code, then subtract them from 5\n         across(.cols = c(L1_1, L1_5, L1_6, L1_9, L1_10, L1_15, L1_16, L1_19, L1_20,\n                          L2_1, L2_5, L2_6, L2_9, L2_10, L2_15, L2_16, L2_19, L2_20),\n                .fns = ~ 5 - .x),\n         # take all the connectedness items to reverse code, then subtract them from 7\n         across(.cols = c(SC1_3, SC1_6, SC1_7, SC1_9, SC1_11, SC1_13, SC1_15, SC1_17, SC1_18, SC1_20, \n                          SC2_3, SC2_6, SC2_7, SC2_9, SC2_11, SC2_13, SC2_15, SC2_17, SC2_18, SC2_20),\n                .fns = ~ 7 - .x))\n\n# There are more elegant ways around this, but for each set, \n# take the 20 items, group by participant ID, and calculate the mean, ignoring missing values\nlonely_pre &lt;- evans_clean %&gt;% \n  pivot_longer(cols = L1_1:L1_20, \n               names_to = \"Item\", \n               values_to = \"Response\") %&gt;% \n  group_by(RID) %&gt;% \n  summarise(lonely_pre = mean(Response, na.rm = TRUE))\n\n# Same thing for post scores\nlonely_post &lt;- evans_clean %&gt;% \n  pivot_longer(cols = L2_1:L2_20, \n               names_to = \"Item\", \n               values_to = \"Response\") %&gt;% \n  group_by(RID) %&gt;% \n  summarise(lonely_post = mean(Response, na.rm = TRUE))\n\n# take the 20 items, group by participant ID, and calculate the mean, ignoring missing values\nsocial_pre &lt;- evans_clean %&gt;% \n  pivot_longer(cols = SC1_1:SC1_20, \n               names_to = \"Item\", \n               values_to = \"Response\") %&gt;% \n  group_by(RID) %&gt;% \n  summarise(social_pre = mean(Response, na.rm = TRUE))\n\n# Same thing for post scores\nsocial_post &lt;- evans_clean %&gt;% \n  pivot_longer(cols = SC2_1:SC2_20, \n               names_to = \"Item\", \n               values_to = \"Response\") %&gt;% \n  group_by(RID) %&gt;% \n  summarise(social_post = mean(Response, na.rm = TRUE))\n\n# join all four summary values to main data\n# select just the key variables we need\n# rename the two stress items\nevans_wide &lt;- evans_clean %&gt;% \n  inner_join(lonely_pre) %&gt;% \n  inner_join(lonely_post) %&gt;% \n  inner_join(social_pre) %&gt;% \n  inner_join(social_post) %&gt;% \n  select(RID:Consumer_BARK, \n         stress_pre = S1_1, \n         stress_post = S2_1, \n         lonely_pre:social_post)"
  },
  {
    "objectID": "18-analysis-journey-2.html#summarisingvisualising",
    "href": "18-analysis-journey-2.html#summarisingvisualising",
    "title": "16  Analysis Journey 2: Simple Linear Regression",
    "section": "\n16.4 Summarising/visualising",
    "text": "16.4 Summarising/visualising\nYou should now have an object called evans_wide containing 12 variables. If you struggled completing the wrangling steps, you can copy the code from the solution to follow along from this point. In this section, we will calculate some summary statistics and plot the data to see what we can learn. We present you with a list of questions to answer using your wrangling and visualisation skills, interspersed with the solutions to check if you are stuck.\n\n16.4.1 Demographics\nFor demographics, we will recreate some values from Table 1 from Binfet et al. (2022).\n\n\nHow many participants were in each group for GroupAssignment?\n\n Control\n Direct\n Indirect\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThis nicely reproduces their values.\n\nevans_wide %&gt;% \n  count(GroupAssignment)\n\n\n\n\nGroupAssignment\nn\n\n\n\nControl\n94\n\n\nDirect\n95\n\n\nIndirect\n95\n\n\n\n\n\n\n\n\n\n\n\nTo 2 decimals, what was the mean and standard deviation age per group?\n\nControl: M = , SD = .\nDirect: M = , SD = .\nIndirect: M = , SD = .\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nWeirdly, this reproduces the standard deviations from Table 1, but not the means.\n\nevans_wide %&gt;% \n  group_by(GroupAssignment) %&gt;% \n  summarise(mean_age = round(mean(Age_Yrs), 2),\n            sd_age = round(sd(Age_Yrs), 2))\n\n\n\n\nGroupAssignment\nmean_age\nsd_age\n\n\n\nControl\n19.95\n2.89\n\n\nDirect\n19.77\n1.94\n\n\nIndirect\n19.95\n2.23\n\n\n\n\n\n\n\n\n\n\n\nHow many participants in each group have a pet at home?\n\n Control\n Direct\n Indirect\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThis nicely reproduces their values.\n\nevans_wide %&gt;% \n  count(GroupAssignment, Live_Pets)\n\n\n\n\nGroupAssignment\nLive_Pets\nn\n\n\n\nControl\nDoes not have a pet back home\n72\n\n\nControl\nHas a pet back home\n21\n\n\nControl\nNA\n1\n\n\nDirect\nDoes not have a pet back home\n63\n\n\nDirect\nHas a pet back home\n30\n\n\nDirect\nNA\n2\n\n\nIndirect\nDoes not have a pet back home\n60\n\n\nIndirect\nHas a pet back home\n34\n\n\nIndirect\nNA\n1\n\n\n\n\n\n\n\n\n\n\nThis is not part of their article, but one interesting question might be how many people have a pet at home (Live_Pets) against how frequently they use the BARK program (Consumer_BARK). Try and recreate the following bar plot to visualise this as close as possible. We have intentionally used some features we have not covered in the data visualisation chapters to get you problem solving. For one hint though, we used option D for the viridis colour scheme.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThe new features we hoped you found independently were:\n\nSetting the factor order to show Consumer_BARK as low, medium, then high.\nSet position = \"dodge\" to avoid the stacked bar chart.\nEdited the legend title by using the name argument in the scale_fill layer.\n\n\nevans_wide %&gt;% \n  drop_na(Live_Pets, Consumer_BARK) %&gt;% \n  mutate(Consumer_BARK = factor(Consumer_BARK, \n                                levels = c(\"Low\", \"Medium\", \"High\"))) %&gt;% \n  ggplot(aes(x = Live_Pets, fill = Consumer_BARK)) + \n  geom_bar(position = \"dodge\") + \n  labs(x = \"Pets in Home\", \n       y = \"Frequency\") + \n  scale_fill_viridis_d(option = \"D\", \n                       name = \"BARK Program User\") + \n  theme_classic()\n\n\n\n\n\n16.4.2 Wellbeing measures\nFor wellbeing and ill-being measures, we will recreate some values from Table 2 from Binfet et al. (2022).\n\n\nIf you calculate the mean and standard deviation of each variable per group, answer the following questions:\n\nWhich group has the lowest post-test stress value? \nControl\nDirect\nIndirect\nWhich group has the lowest post-test loneliness value? \nIndirect\nDirect\nControl\nWhich group has the lowest post-test social connectedness value? \nIndirect\nControl\nDirect\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThis table calculates the mean and standard score for each variable per group. You can use this to answer the questions above.\n\nevans_wide %&gt;% \n  pivot_longer(cols = stress_pre:social_post, \n               names_to = \"Variable\", \n               values_to = \"Value\") %&gt;% \n  group_by(GroupAssignment, Variable) %&gt;% \n  summarise(mean_score = round(mean(Value), 2), \n            sd_score = round(sd(Value), 2))\n\n`summarise()` has grouped output by 'GroupAssignment'. You can override using\nthe `.groups` argument.\n\n\n\n\n\nGroupAssignment\nVariable\nmean_score\nsd_score\n\n\n\nControl\nlonely_post\n1.96\n0.57\n\n\nControl\nlonely_pre\n2.02\n0.55\n\n\nControl\nsocial_post\n4.49\n0.87\n\n\nControl\nsocial_pre\n4.47\n0.81\n\n\nControl\nstress_post\n2.76\n1.08\n\n\nControl\nstress_pre\n3.27\n1.04\n\n\nDirect\nlonely_post\n1.82\n0.51\n\n\nDirect\nlonely_pre\n2.05\n0.56\n\n\nDirect\nsocial_post\n4.64\n0.79\n\n\nDirect\nsocial_pre\n4.42\n0.88\n\n\nDirect\nstress_post\n1.84\n0.76\n\n\nDirect\nstress_pre\n3.15\n0.98\n\n\nIndirect\nlonely_post\n1.96\n0.52\n\n\nIndirect\nlonely_pre\n2.06\n0.48\n\n\nIndirect\nsocial_post\n4.50\n0.82\n\n\nIndirect\nsocial_pre\n4.37\n0.79\n\n\nIndirect\nstress_post\n2.53\n1.00\n\n\nIndirect\nstress_pre\n3.21\n0.90\n\n\n\n\n\n\n\n\n\n\nCreate a scatterplot of the relationship between post-test social connectedness and loneliness. The relationship between the two variables is \nnegative\npositive, meaning that as social connectedness increases, we expect loneliness to \nincrease\ndecrease.\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThe code here creates a scatterplot for the relationship between post-test social connectedness and loneliness.\n\nevans_wide %&gt;% \n  ggplot(aes(x = lonely_post, y = social_post)) + \n  geom_point() + \n  geom_smooth(method = \"lm\") + \n  theme_classic() + \n  labs(x = \"Loneliness Post-test\", y = \"Social Connectedness Post-test\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\nAs we start to think about inferential statistics, we can plot the difference between pre- and post-test for each group. For this question, try and recreate the boxplot to visualise stress. Hint: think about if you need to restructure the data, and how you can present the conditions in the appropriate order.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThere are two key steps before you can plot the data. First, you need to restructure the data to long form to get one variable for pre- and post-test. Second, post comes before pre due to alphabetical order, so you need to create a factor to specify the order here.\n\nevans_wide %&gt;% \n  pivot_longer(cols = stress_pre:stress_post, \n               names_to = \"Stress\", \n               values_to = \"Value\") %&gt;% \n  mutate(Stress = factor(Stress,\n                         levels = c(\"stress_pre\", \"stress_post\"), \n                         labels = c(\"Pre-test\", \"Post-test\"))) %&gt;% \n  ggplot(aes(x = GroupAssignment, y = Value, fill = Stress)) + \n  geom_boxplot(alpha = 0.7) + \n  labs(x = \"Group Assignment\", y = \"Stress Scale\") + \n  scale_fill_viridis_d(option = \"E\", \n                       name = \"Time\") + \n  theme_classic()\n\n\n\n\n\nTry and recreate the violin-boxplot to visualise loneliness. Hint: remember how to align the different elements from Chapter 7.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nThe same hints apply as question 7 as you need to restructure the data and create a new factor order so pre comes before post. As we have two grouping variables, we must specify a constant position dodge value so it does not plot weird.\n\n# specify as an object, so we only change it in one place\ndodge_value &lt;- 0.9\n\nevans_wide %&gt;% \n  pivot_longer(cols = lonely_pre:lonely_post, \n               names_to = \"Lonely\", \n               values_to = \"Value\") %&gt;% \n   mutate(Lonely = factor(Lonely,\n                          levels = c(\"lonely_pre\", \"lonely_post\"), \n                          labels = c(\"Pre-test\", \"Post-test\"))) %&gt;% \n  ggplot(aes(x = GroupAssignment, y = Value, fill = Lonely)) + \n  geom_violin(alpha = 0.5) + \n  geom_boxplot(width = 0.2, \n               alpha = 0.7,\n               fatten = NULL,\n               position = position_dodge(dodge_value)) + \n  stat_summary(fun = \"mean\", \n               geom = \"point\",\n               position = position_dodge(dodge_value)) +\n  stat_summary(fun.data = \"mean_cl_boot\", \n               geom = \"errorbar\", \n               width = .1,\n               position = position_dodge(dodge_value)) +\n  scale_fill_viridis_d(option = \"E\", \n                       name = \"Time\") + \n  labs(x = \"Group Assignment\", y = \"Loneliness Scale\") + \n  theme_classic()"
  },
  {
    "objectID": "18-analysis-journey-2.html#analysing",
    "href": "18-analysis-journey-2.html#analysing",
    "title": "16  Analysis Journey 2: Simple Linear Regression",
    "section": "\n16.5 Analysing",
    "text": "16.5 Analysing\nFinally, we turn to analysis for inferential statistics. In Evans et al. (2023), they organise the analyses from Binfet et al. (2022) into three hypotheses. You have not covered all the skills in Research Methods 1 to reproduce their analyses exactly, so we will work around an adapted set based on what we currently expect of you.\nWe present each analysis as an overview so you can think about what techniques from Chapters 8 and 9 would address it, give you instructions on what analysis we have in mind if you need guidance, then present the solution. We focus on one outcome per hypothesis, but once you are confident you are applying and interpreting the appropriate techniques, why not try the other outcomes yourself?\n\n16.5.1 Hypothesis 1\n\nHypothesis 1 is that each treatment group will increase measures of well-being (social connectedness) and decrease measures of ill-being (stress and loneliness). For this question, we focus on stress, so we expected stress to decrease.\n\n\n\n\n\n\n\nTry this\n\n\n\nThere are two ways you could approach this. Either as the whole sample, or like Evans et al. (2023) present to focus on each group separately. Think about what techniques from Chapters 8 and 9 would let you test the hypothesis that each treatment group will decrease stress at post-test compared to pre-test.\n\n\n\n\n\n\n\n\nShow me the task list\n\n\n\n\n\nFor the solution below, we are focusing on the whole sample to test whether everyone decreased stress in post-test, but you could approach it by separating the data into the three groups and then testing for the difference per group.\nTo test whether an outcome decreases between conditions in the same participants, we need a model suitable for a within-subjects design. In Chapter 9, we covered in the bonus section how to test the difference in conditions either through a paired samples-test or linear model with fixed intercept on the difference score.\n\nCalculate the difference between stress pre- and post-test.\nFit a linear model on the difference score with a fixed intercept and no predictor.\nLook at the intercept, is it positive or negative? If you calculated pre-test minus post-test, you would be looking for a postive difference as we expect lower stress at post-test. For hypothesis testing, is the p-value lower than alpha?\nWhat is the effect size? How much did stress change from pre-test to post-test? What is the confidence interval around the effect size?\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nIn the code below, we first calculate a difference score by substracting stress post-test from stress pre-test.\nWe then fit a linear model on this difference score and add a fixed intercept as we have no predictor.\nConsistent with hypothesis 1, stress was lower at post-test compared to pre-test across all participants. On average, participants decreased their stress score by 0.83 points (\\(b_0\\) = 0.83, 95% CI = [0.72, 0.95], p &lt; .001).\n\nevans_wide &lt;- evans_wide %&gt;% \n  mutate(stress_diff = stress_pre - stress_post)\n\nlm_stress &lt;- lm(stress_diff ~ 1, \n                data = evans_wide)\n\nsummary(lm_stress)\n\nconfint(lm_stress)\n\n\nCall:\nlm(formula = stress_diff ~ 1, data = evans_wide)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.8345 -0.8345  0.1655  0.1655  3.1655 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.83451    0.05657   14.75   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9534 on 283 degrees of freedom\n\n                2.5 %    97.5 %\n(Intercept) 0.7231517 0.9458623\n\n\n\n\n\n\n16.5.2 Hypothesis 2\n\nIn Hypothesis 2, we predict that the direct and indirect contact groups will have higher well-being and lower ill-being measures compared to the control group. For this question, we focus on social connectedness at post-test for a measure of well-being, so we expect higher scores in the direct and indirect groups.\n\n\n\n\n\n\n\nTry this\n\n\n\nThink about what techniques from Chapters 8 and 9 would let you test the hypothesis that the direct and indirect groups both increase social connectedness at post-test compared to the control group. Think of how you could focus on two groups at a time per analysis.\n\n\n\n\n\n\n\n\nShow me the task list\n\n\n\n\n\nFor the solution below, we apply two tests. We focus on the direct and control groups by filtering out indirect, then we focus on indirect and control by filtering out direct.\nTo test the difference between two groups on one outcome, we need a model suitable for a between-subjects design. In Chapter 9, we covered linear regression with one categorical predictor how to test the difference in an outcome between two groups.\n\nFit a linear model on the outcome social connectedness post-test with a categorical predictor of group. You will need to fit two models, one where you filter out the indirect group and one where you filter out the direct group.\nLook at the intercept, what is the predicted value for the reference group? Look at the slope, what is the estimated change to the target group? For hypothesis 2, is the direct/indirect group higher on social connectedness compared to control? For hypothesis testing, is the p-value lower than alpha?\nWhat is the effect size? How much did the two groups differ on social connectedness? What is the confidence interval around the effect size?\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nIn the code below, we first fit a linear model on social connectedness post-test and focus on the direct and control groups. There are different ways you could ignore the indirect group, but here we filter the data as we pass the data to the lm() function.\nThe direct group increased social connectedness post-test on average 0.15 points compared to the control group, but the difference was not statistically significant (\\(b_1\\) = 0.15, 95% CI = [-0.09, 0.39], p = .207).\n\nlm_direct &lt;- lm(social_post ~ GroupAssignment, \n                 data = filter(evans_wide,\n                               GroupAssignment != \"Indirect\"))\n\nsummary(lm_direct)\n\nconfint(lm_direct)\n\n\nCall:\nlm(formula = social_post ~ GroupAssignment, data = filter(evans_wide, \n    GroupAssignment != \"Indirect\"))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.2940 -0.5905  0.1338  0.6560  1.3560 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)            4.49054    0.08596  52.239   &lt;2e-16 ***\nGroupAssignmentDirect  0.15349    0.12125   1.266    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8334 on 187 degrees of freedom\nMultiple R-squared:  0.008497,  Adjusted R-squared:  0.003195 \nF-statistic: 1.603 on 1 and 187 DF,  p-value: 0.2071\n\n                            2.5 %    97.5 %\n(Intercept)            4.32096331 4.6601179\nGroupAssignmentDirect -0.08569829 0.3926749\n\n\nThe indirect group increased social connectedness post-test compared to the control group, but the difference was very small and not statistically significant (\\(b_1\\) = 0.01, 95% CI = [-0.23, 0.25], p = .936).\n\nlm_indirect &lt;- lm(social_post ~ GroupAssignment, \n                 data = filter(evans_wide,\n                               GroupAssignment != \"Direct\"))\n\nsummary(lm_indirect)\n\nconfint(lm_indirect)\n\n\nCall:\nlm(formula = social_post ~ GroupAssignment, data = filter(evans_wide, \n    GroupAssignment != \"Direct\"))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.70037 -0.59054  0.05946  0.64963  1.34963 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)             4.490541   0.087155   51.52   &lt;2e-16 ***\nGroupAssignmentIndirect 0.009833   0.122931    0.08    0.936    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.845 on 187 degrees of freedom\nMultiple R-squared:  3.422e-05, Adjusted R-squared:  -0.005313 \nF-statistic: 0.006398 on 1 and 187 DF,  p-value: 0.9363\n\n                             2.5 %    97.5 %\n(Intercept)              4.3186067 4.6624745\nGroupAssignmentIndirect -0.2326772 0.2523439\n\n\nIn Evans et al. (2023), the direct vs control comparison is significant, but they approached the analysis differently using a technique you will not learn until Research Methods 2. They control for pre-test scores by using it as an additional predictor, but you have not learnt about multiple regression yet.\n\n\n\n\n16.5.3 Hypothesis 3\n\nFinally, the third hypothesis focuses on the difference between the two contact groups. They predict that the direct contact group will lead to higher well-being and lower ill-being compared to the indirect contact group. For this question, we focus on loneliness post-test for a measure of ill-being, so we expect lower scores in the direct group.\n\n\n\n\n\n\n\nTry this\n\n\n\nThink about what techniques from Chapters 8 and 9 would let you test the hypothesis that the direct group decreases loneliness at post-test compared to the indirect group.\n\n\n\n\n\n\n\n\nShow me the task list\n\n\n\n\n\nFor this analysis, we focus on the final combination of groups, this time ignoring the control group.\nTo test the difference between two groups on one outcome, we need a model suitable for a between-subjects design. In Chapter 9, we covered linear regression with one categorical predictor how to test the difference in an outcome between two groups.\n\nFit a linear model on the outcome loneliness post-test with a categorical predictor of group. Filter the data to just focus on the direct and indirect contact groups.\nLook at the intercept, what is the predicted value for the reference group? Look at the slope, what is the estimated change to the target group? For hypothesis 3, is the direct group lower on loneliness compared to indirect? For hypothesis testing, is the p-value lower than alpha?\nWhat is the effect size? How much did the two groups differ on loneliness? What is the confidence interval around the effect size?\n\n\n\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nIn the code below, we first fit a linear model on loneliness post-test and focus on the direct and indirect groups. There are different ways you could ignore the indirect group, but here we filter the data as we pass the data to the lm() function.\nThe direct group decreased loneliness post-test on average 0.14 points compared to the indirect group, but the difference was not statistically significant (\\(b_1\\) = 0.14, 95% CI = [-0.01, 0.29], p = .060).\n\nlm_contact &lt;- lm(lonely_post ~ GroupAssignment, \n                 data = filter(evans_wide,\n                               GroupAssignment != \"Control\"))\n\nsummary(lm_contact)\n\nconfint(lm_contact)\n\n\nCall:\nlm(formula = lonely_post ~ GroupAssignment, data = filter(evans_wide, \n    GroupAssignment != \"Control\"))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.96457 -0.42130 -0.06457  0.32645  1.58543 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              1.82355    0.05267  34.625   &lt;2e-16 ***\nGroupAssignmentIndirect  0.14102    0.07448   1.893   0.0598 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5133 on 188 degrees of freedom\nMultiple R-squared:  0.01871,   Adjusted R-squared:  0.01349 \nF-statistic: 3.585 on 1 and 188 DF,  p-value: 0.05983\n\n                               2.5 %    97.5 %\n(Intercept)              1.719655160 1.9274363\nGroupAssignmentIndirect -0.005898489 0.2879484\n\n\nLike hypothesis 2, Evans et al. (2023) report the direct vs indirect comparison as significant, but they approached the analysis differently using a technique you will not learn until Research Methods 2. They control for pre-test scores by using it as an additional predictor, but you have not learnt about multiple regression yet."
  },
  {
    "objectID": "18-analysis-journey-2.html#conclusion",
    "href": "18-analysis-journey-2.html#conclusion",
    "title": "16  Analysis Journey 2: Simple Linear Regression",
    "section": "\n16.6 Conclusion",
    "text": "16.6 Conclusion\nWell done! Hopefully you recognised how far your skills have come to be able to do this independently, regardless of how many hints you needed. We are really starting to pile the skills up you have learnt so far, from simply using R Markdown files, to wrangling data, to visualising data, to finally applying modelling techniques for your inferential statistics.\nIf you are curious, you can read Evans et al. (2023) to see how they walk through wrangling and analysing the data. Some of the techniques we do not cover in Research Methods 1, but they have some great features like highlighting common student mistakes.\n\n\n\n\nBinfet, J.-T., Green, F. L. L., & Draper, Z. A. (2022). The Importance of Client–Canine Contact in Canine-Assisted Interventions: A Randomized Controlled Trial. Anthrozoös, 35(1), 1–22. https://doi.org/10.1080/08927936.2021.1944558\n\n\nEvans, C., Cipolli, W., Draper, Z. A., & Binfet, J.-T. (2023). Repurposing a Peer-Reviewed Publication to Engage Students in Statistics: An Illustration of Study Design, Data Collection, and Analysis. Journal of Statistics and Data Science Education, 0(0), 1–21. https://doi.org/10.1080/26939169.2023.2238018"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Alter, U., Dang, C., Kunicki, Z. J., & Counsell, A. (2024). The\nVSSL scale: A brief instructor tool for\nassessing students’ perceived value of software to learning statistics.\nTeaching Statistics, 46(3). https://doi.org/10.1111/test.12374\n\n\nBakker, M., Veldkamp, C. L. S., Akker, O. R. van den, Assen, M. A. L. M.\nvan, Crompvoets, E., Ong, H. H., & Wicherts, J. M. (2020).\nRecommendations in pre-registrations and internal review board proposals\npromote formal power analyses but do not increase sample size. PLoS\nONE, 15(7), e0236079. https://doi.org/10.1371/journal.pone.0236079\n\n\nBartlett, J. E., Jenks, R., & Wilson, N. (2022). No\nMeaningful Difference in\nAttentional Bias Between\nDaily and Non-Daily\nSmokers. Journal of Trial & Error. https://doi.org/10.36850/e11\n\n\nBartlett, J., & Charles, S. (2022). Power to the\nPeople: A Beginner’s\nTutorial to Power Analysis using\njamovi. Meta-Psychology, 6. https://doi.org/10.15626/MP.2021.3078\n\n\nBem, D. J. (2011). Feeling the future: Experimental\nevidence for anomalous retroactive influences on cognition and affect.\nJournal of Personality and Social Psychology, 100(3),\n407–425. https://doi.org/10.1037/a0021524\n\n\nBinfet, J.-T., Green, F. L. L., & Draper, Z. A. (2022). The\nImportance of Client–Canine\nContact in Canine-Assisted\nInterventions: A Randomized\nControlled Trial. Anthrozoös,\n35(1), 1–22. https://doi.org/10.1080/08927936.2021.1944558\n\n\nBlanca, M. J., Alarcón, R., Arnau, J., Bono, R., & Bendayan, R.\n(2018). Effect of variance ratio on ANOVA robustness:\nMight 1.5 be the limit? Behavior Research Methods,\n50(3), 937–962. https://doi.org/10.3758/s13428-017-0918-2\n\n\nChampely, S. (2020). Pwr: Basic functions for power analysis.\nhttps://CRAN.R-project.org/package=pwr\n\n\nDasu, T., & Johnson, T. (2003). Exploratory data mining and data\ncleaning. Wiley-Interscience.\n\n\nDawtry, R. J., Sutton, R. M., & Sibley, C. G. (2015). Why\nWealthier People Think\nPeople Are Wealthier, and\nWhy It Matters: From\nSocial Sampling to Attitudes to\nRedistribution. Psychological Science,\n26(9), 1389–1400. https://doi.org/10.1177/0956797615586560\n\n\nEvans, C., Cipolli, W., Draper, Z. A., & Binfet, J.-T. (2023).\nRepurposing a Peer-Reviewed\nPublication to Engage Students in\nStatistics: An Illustration of\nStudy Design, Data\nCollection, and Analysis. Journal of\nStatistics and Data Science Education, 0(0), 1–21. https://doi.org/10.1080/26939169.2023.2238018\n\n\nHoffman, H. J., & Elmi, A. F. (2021). Do Students\nLearn More from Erroneous\nCode? Exploring Student\nPerformance and Satisfaction in an\nError-Free Versus an\nError-full SAS® Programming\nEnvironment. Journal of Statistics and Data Science\nEducation, 0(0), 1–13. https://doi.org/10.1080/26939169.2021.1967229\n\n\nIrving, D., Clark, R. W. A., Lewandowsky, S., & Allen, P. J. (2022).\nCorrecting statistical misinformation about scientific findings in the\nmedia: Causation versus correlation. Journal of\nExperimental Psychology. Applied. https://doi.org/10.1037/xap0000408\n\n\nJames, E. L., Bonsall, M. B., Hoppitt, L., Tunbridge, E. M., Geddes, J.\nR., Milton, A. L., & Holmes, E. A. (2015). Computer\nGame Play Reduces\nIntrusive Memories of\nExperimental Trauma via\nReconsolidation-Update\nMechanisms: Psychological Science, 26(8),\n1201–1215. https://doi.org/10.1177/0956797615583071\n\n\nKnief, U., & Forstmeier, W. (2021). Violating the normality\nassumption may be the lesser of two evils. Behavior Research\nMethods, 53(6), 2576–2590. https://doi.org/10.3758/s13428-021-01587-5\n\n\nLakens, D. (2022). Sample Size Justification.\nCollabra: Psychology, 8(1), 33267. https://doi.org/10.1525/collabra.33267\n\n\nLopez, A., Choi, A. K., Dellawar, N. C., Cullen, B. C., Avila Contreras,\nS., Rosenfeld, D. L., & Tomiyama, A. J. (2023). Visual cues and food\nintake: A preregistered replication of Wansink\net al (2005). Journal of Experimental Psychology: General. https://doi.org/10.1037/xge0001503.supp\n\n\nNordmann, E., McAleer, P., Toivo, W., Paterson, H., & DeBruine, L.\nM. (2022). Data Visualization Using\nR for Researchers Who\nDo Not Use R.\nAdvances in Methods and Practices in Psychological Science,\n5(2), 25152459221074654. https://doi.org/10.1177/25152459221074654\n\n\nPrzybylski, A. K., & Weinstein, N. (2017). A\nLarge-Scale Test of the\nGoldilocks Hypothesis:\nQuantifying the Relations Between\nDigital-Screen Use and the\nMental Well-Being of\nAdolescents. Psychological Science,\n28(2), 204–215. https://doi.org/10.1177/0956797616678438\n\n\nR Core Team. (2024). R: A language and environment for statistical\ncomputing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nWeissgerber, T. L., Winham, S. J., Heinzen, E. P., Milin-Lazovic, J. S.,\nGarcia-Valencia, O., Bukumiric, Z., Savic, M. D., Garovic, V. D., &\nMilic, N. M. (2019). Reveal, Don’t Conceal.\nCirculation, 140(18), 1506–1518. https://doi.org/10.1161/CIRCULATIONAHA.118.037777\n\n\nWickham, H. (2014). Tidy Data. Journal of Statistical\nSoftware, 59, 1–23. https://doi.org/10.18637/jss.v059.i10\n\n\nWickham, H. (2017). Tidyverse: Easily install and load the\n’tidyverse’. https://CRAN.R-project.org/package=tidyverse\n\n\nWingen, T., Berkessel, J. B., & Englich, B. (2020). No\nReplication, No Trust?\nHow Low Replicability\nInfluences Trust in Psychology.\nSocial Psychological and Personality Science, 11(4),\n454–463. https://doi.org/10.1177/1948550619877412\n\n\nWitt, J. K., Tenhundfeld, N. L., & Tymoski, M. J. (2018). Is there a\nchastity belt on perception? Psychological Science,\n29(1), 139–146.\n\n\nWoodworth, R. J., O’Brien-Malone, A., Diamond, M. R., & Schüz, B.\n(2018). Data from, “Web-based Positive\nPsychology Interventions: A\nReexamination of Effectiveness.”\nJournal of Open Psychology Data, 6(1), 1. https://doi.org/10.5334/jopd.35\n\n\nZhang, T., Kim, T., Brooks, A. W., Gino, F., & Norton, M. I. (2014).\nA “Present” for the Future:\nThe Unexpected Value of\nRediscovery. Psychological Science,\n25(10), 1851–1860. https://doi.org/10.1177/0956797614542274"
  },
  {
    "objectID": "appendix-a2-additional-learning-resources.html",
    "href": "appendix-a2-additional-learning-resources.html",
    "title": "Appendix A — Additional Resources",
    "section": "",
    "text": "The truth about programming\n\n\n\nIf you would like additional practice, you can check out the other UofG PsyTeachR course books.\n\n\nLevel 1 - Intro to R (overlaps with Msc Conv book), data wrangling, data viz, descriptive statistics\n\n\nLevel 2 - Our second-year undergraduate course introduces statistical concepts such as permutation tests,t-tests, NHST, alpha, power, effect size, and sample size. Semester 2 focusses on correlations and the general linear model.\n\nLevel 3: This third-year undergraduate course teaches students how to specify, estimate, and interpret statistical models corresponding to various study designs, using a General Linear Models approach.\n\nMSc Data Skills: This course provides an overview of skills needed for reproducible research and open science using the statistical programming language R. Students will learn about data visualisation, data tidying and wrangling, archiving, iteration and functions, probability and data simulations, general linear models, and reproducible workflows.\n\nWe also highly recommend the following, they will help practice your data wrangling skills but also they’re great options if you’re enjoying R and want to stretch yourself:\n\n\nOpen Stats Lab - this wonderful resource gives you practice at running statistical tests by providing you with datasets from published papers.\n\nR for Data Science - written by the authors of the tidyverse, this is a great resource for additional data wrangling practice and more depth on many of the tidyverse functions.\n\nText Mining with R - Shows you how to use R to work with text. This isn’t something we cover in this course, but it uses the same data wrangling skills and be a very useful additional skill to have.\n\nHow to make BBC style graphics - Ever wondered how the BBC News makes their data visualisation? Well, now you can make your own!\n\nData Vizualisation - this is an entire book on data visualisation and goes into detail on how to take ggplot to its limits."
  },
  {
    "objectID": "appendix-a3-How-to-cite-R.html",
    "href": "appendix-a3-How-to-cite-R.html",
    "title": "Appendix B — Citing R and RStudio",
    "section": "",
    "text": "How to cite R and RStudio\nYou may be some way off writing a scientific report where you have to cite and reference R, however, when the time comes it is important to do so to give the people who built it (most of them for free!) credit. You should provide separate citations for R, RStudio, and the packages you use.\nTo get the citation for the version of R you are using, simply run the citation() function which will always provide you with the most recent citation.\n\ncitation()\n\nTo cite R in publications use:\n\n  R Core Team (2024). _R: A Language and Environment for Statistical\n  Computing_. R Foundation for Statistical Computing, Vienna, Austria.\n  &lt;https://www.R-project.org/&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Manual{,\n    title = {R: A Language and Environment for Statistical Computing},\n    author = {{R Core Team}},\n    organization = {R Foundation for Statistical Computing},\n    address = {Vienna, Austria},\n    year = {2024},\n    url = {https://www.R-project.org/},\n  }\n\nWe have invested a lot of time and effort in creating R, please cite it\nwhen using it for data analysis. See also 'citation(\"pkgname\")' for\nciting R packages.\n\n\nTo generate the citation for any packages you are using, you can also use the citation() function with the name of the package you wish to cite.\n\ncitation(\"tidyverse\")\n\nTo cite package 'tidyverse' in publications use:\n\n  Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R,\n  Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller\n  E, Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V,\n  Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H (2019). \"Welcome to\n  the tidyverse.\" _Journal of Open Source Software_, *4*(43), 1686.\n  doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Article{,\n    title = {Welcome to the {tidyverse}},\n    author = {Hadley Wickham and Mara Averick and Jennifer Bryan and Winston Chang and Lucy D'Agostino McGowan and Romain François and Garrett Grolemund and Alex Hayes and Lionel Henry and Jim Hester and Max Kuhn and Thomas Lin Pedersen and Evan Miller and Stephan Milton Bache and Kirill Müller and Jeroen Ooms and David Robinson and Dana Paige Seidel and Vitalie Spinu and Kohske Takahashi and Davis Vaughan and Claus Wilke and Kara Woo and Hiroaki Yutani},\n    year = {2019},\n    journal = {Journal of Open Source Software},\n    volume = {4},\n    number = {43},\n    pages = {1686},\n    doi = {10.21105/joss.01686},\n  }\n\n\nTo generate the citation for the version of RStudio you are using, you can use the RStudio.Vesion() function:\n\nRStudio.Version()\n\nFinally, here’s an example of how that might look in the write-up of your method section:\n\nAnalysis was conducted using R (R Core Team, 2020), RStudio (Rstudio Team, 2020), and the tidyverse package (Wickham, 2017).\n\nAs noted, you may not have to do this for a while, but come back to this when you do because it’s important to give the open-source community credit for their work."
  },
  {
    "objectID": "appendix-b-symbols.html",
    "href": "appendix-b-symbols.html",
    "title": "Appendix C — Symbols",
    "section": "",
    "text": "Symbol\npsyTeachR Term\nAlso Known As\n\n\n\n()\n(round) brackets\nparentheses\n\n\n[]\nsquare brackets\nbrackets\n\n\n{}\ncurly brackets\nsquiggly brackets\n\n\n&lt;&gt;\nchevrons\nangled brackets / guillemets\n\n\n&lt;\nless than\n\n\n\n&gt;\ngreater than\n\n\n\n&\nampersand\n“and” symbol\n\n\n#\nhash\npound / octothorpe\n\n\n/\nslash\nforward slash\n\n\n\\\nbackslash\n\n\n\n-\ndash\nhyphen / minus\n\n\n_\nunderscore\n\n\n\n*\nasterisk\nstar\n\n\n^\ncaret\npower symbol\n\n\n~\ntilde\ntwiddle / squiggle\n\n\n=\nequal sign\n\n\n\n==\ndouble equal sign\n\n\n\n.\nfull stop\nperiod / point\n\n\n!\nexclamation mark\nbang / not\n\n\n?\nquestion mark\n\n\n\n’\nsingle quote\nquote / apostrophe\n\n\n”\ndouble quote\nquote\n\n\n%&gt;%\npipe\nmagrittr pipe\n\n\n|\nvertical bar\npipe\n\n\n,\ncomma\n\n\n\n;\nsemi-colon\n\n\n\n:\ncolon\n\n\n\n@\n“at” symbol\nvarious hilarious regional terms\n\n\n…\nglossary(\"ellipsis\")\ndots\n\n\n\n\n\n\n\nImage by James Chapman/Soundimals"
  },
  {
    "objectID": "appendix-d-probability.html#introduction-to-probability",
    "href": "appendix-d-probability.html#introduction-to-probability",
    "title": "Appendix D — Probability",
    "section": "\nD.1 Introduction to probability?",
    "text": "D.1 Introduction to probability?\nProbability (p) is the extent to which an event is likely to occur and is represented by a number between 0 and 1. For example, the probability of flipping a coin and it landing on ‘heads’ would be estimated at p = .5, i.e., there is a 50% chance of getting a head when you flip a coin.\nIn fact, calculating the probability of any individual event occurring can be formulated as:\n\\[p = \\frac{number \\  of  \\ ways \\ the \\ event \\ could \\  arise}{number \\ of \\ possible \\ outcomes}\\] For example, what is the probability of randomly drawing your name out of a hat of 12 names where one name is definitely yours? Well, if there are 12 possible outcomes, and only 1 way for your name to arise, then it the above formula becomes:\n\\[p = \\frac{1}{12} = 0.0833333\\]\nMeaning that the probability is 0.0833333. Or, if you wanted to write that as a percentage then it would be 8.3333333%, meaning that out of every 100 draws from the hat you would expect your name to come out about 8.3 times. And if there had been four names in the hat and one was yours then it would be:\n\\[p = \\frac{1}{4} = 0.25\\]\nAnd if it had been 24 names in the hat and one was yours then it would have been:\n\\[p = \\frac{1}{24} = 0.0416667\\]\nSo you can see that the probability of an event occurring changes with the number of possible outcomes. Makes sense really! The more possible outcomes, the less likely any specific one outcome is going to happen. So far so good!\n\nD.1.0.1 Activity 1: Probability\nTry to answer these questions below to check your understanding.\n\nWhat would be the probability of selecting your name from a hat when there are ten names in the hat and your name is one of them? \n0.1\n0.25\n0.0416666666666667\n0.0833333333333333\n\nWhat would be the probability of selecting your name from a hat when there are 100 names in the hat and your name is not one of them? Be careful on this one! \n0.1\n0\n0.1\n0.01"
  },
  {
    "objectID": "appendix-d-probability.html#types-of-data",
    "href": "appendix-d-probability.html#types-of-data",
    "title": "Appendix D — Probability",
    "section": "\nD.2 Types of data",
    "text": "D.2 Types of data\nHow you tackle probability also depends on the type of data/variables you are working with (i.e. discrete or continuous). This is also referred to as Level of Measurements and here we will recap on those different types of data.\nDiscrete data can only take integer values (whole numbers). For example, the number of participants in an experiment would be discrete - we can’t have half a participant! Discrete variables can also be further broken down into nominal and ordinal variables.\n\n\nOrdinal data is a set of ordered categories; you know which is the top/best and which is the worst/lowest, but not the difference between categories. For example, you could ask participants to rate the attractiveness of different faces based on a 5-item Likert scale (very unattractive, unattractive, neutral, attractive, very attractive). You know that very attractive is better than attractive but we can’t say for certain that the difference between neutral and attractive is the same size as the distance between very unattractive and unattractive.\n\nNominal data is also based on a set of categories but the ordering doesn’t matter (e.g. left or right handed). Nominal is sometimes simply referred to as categorical data.\n\nContinuous data on the other hand can take any value. For example, we can measure age on a continuous scale (e.g. we can have an age of 26.55 years), other examples include reaction time or the distance you travel to university every day. Continuous data can be broken down into Interval or Ratio data.\n\n\nInterval data is data which comes in the form of a numerical value where the difference between points is standardised and meaningful. For example temperature, the difference in temperature between 10-20 degrees is the same as the difference in temperature between 20-30 degrees.\n\nRatio data is very like interval but has a true zero point. With our interval temperature example above, we have been experiencing negative temperatures (-1,-2 degrees) in Glasgow but with ratio data you don’t see negative values such as these i.e. you can’t be -10 cm tall.\n\n\nD.2.0.1 Activity 2: Types of data\nTry to answer these questions below to check your understanding. What types of data are the below measurements?\n\nTime taken to run a marathon (in seconds): \ncategorical\nratio\nordinal\ninterval\n\nFinishing position in marathon (e.g. 1st, 2nd, 3rd): \nratio\ncategorical\ninterval\nordinal\n\nWhich Sesame Street character a runner was dressed as: \nratio\ninterval\nordinal\ncategorical\n\nTemperature of a runner dressed in a cookie monster outfit (in degrees Celsius): \nratio\ninterval\ncategorical\nordinal"
  },
  {
    "objectID": "appendix-d-probability.html#probability-distributions",
    "href": "appendix-d-probability.html#probability-distributions",
    "title": "Appendix D — Probability",
    "section": "\nD.3 Probability distributions",
    "text": "D.3 Probability distributions\nOK great. So we know a bit more about probability and a bit more about data types. Next thing we need to think about are probability distributions! A probability distribution is the theoretical counterpart to the observed frequency distribution. A frequency distribution simply shows how many times a certain event actually occurred. A probability distribution says how many times it should have occurred. Say for example you run a test on how many times different flips of a coin produce either heads or tails. What you count yourself is the frequency distribution. What was expected, based on simulationsGenerating data, as opposed to collecting data, from summary parameters such as the mean and standard deviation by mathematicians, is the probability distribution. Mathematicians have actually simulated a number of different probability distributions, and we know that different types of data will tend to naturally fall into a known distribution. From this, we can use these distributions to help us calculate the probability of an event without having to run it ourselves. To say that in another way, we can determine the probability of an event by running a test many many times ourselves, or we can use one of these simulated probability distributions which would save us a lot of time and effort. And that is what we are going to show you here.\nThe three distributions we will look at, to help us understand probability, are:\n\nThe uniform distribution\n\nThe binomial distribution\n\nThe normal distribution"
  },
  {
    "objectID": "appendix-d-probability.html#the-uniform-distribution",
    "href": "appendix-d-probability.html#the-uniform-distribution",
    "title": "Appendix D — Probability",
    "section": "\nD.4 The uniform distribution",
    "text": "D.4 The uniform distribution\nThe uniform distribution is when each possible outcome has an equal chance of occurring. Let’s take the example from above, pulling your name out of a hat of 12 names. Each individual name has an equal chance of being drawn (p = .08). If we visualised this distribution, it would look like this distribution below - each outcome, in this case each name, has the same chance of occurring:\n\n\n\n\nThe Uniform distribution, where every outcome has an equal probability of occurring.\n\n\n\nThe uniform distribution does not feature that regularly in Psychology, except perhaps in experiments where you are randomising which block people get first or when performing a chi-square test, but it helps us start to understand that each outcome has a probability in a distribution."
  },
  {
    "objectID": "appendix-d-probability.html#the-binomial-distribution",
    "href": "appendix-d-probability.html#the-binomial-distribution",
    "title": "Appendix D — Probability",
    "section": "\nD.5 The binomial distribution",
    "text": "D.5 The binomial distribution\nThe next distribution we want to look at is the binomial distribution. The binomial (bi = two, nominal = categories) distribution, is used for discrete data, and is a probability distribution which calculates probabilities of success for situations where there are two possible outcomes e.g., flipping a coin; your outcomes are either heads or tails! A binomial distribution models the probability of any number of successes being observed (e.g. was it a heads when you wanted heads), given the probability of a success and the number of observations (e.g. how many times did you get heads (a success) over ten coin flips (the observations)). It is probably worth pointing out that you as the researcher determine what is the success (heads or tails) but for ease here we will try to stick to heads.\nLet’s say we flip a coin 10 times. Assuming the coin is fair (probability of heads = .5), how many heads should we expect to get? The below figure shows the results of a simulation for 10,000 coin flips (if you’d like to do this simulation yourself, you can see the code by clicking “Show the code”). However, what this distribution means is that we can use what we know about our data and the binomial distribution to work out the probability of different outcomes. For example, instead of running a whole bunch of tests, we could use the distribution to answer the question of what is the probability of getting at least 3 heads if you flip a coin 10 times?.\n\n\n\n\nProbability of no. of heads from 10 coin tosses\n\n\n\n\n\nShow the code\n\nNote that you are not expected to understand this code right now\n\nheads10000 &lt;- replicate(n = 10000, \n                        expr = sample(0:1, \n                                      10, \n                                      TRUE) %&gt;%\n                          sum())\n\ndata10000 &lt;- tibble(heads = heads10000) %&gt;%\n                group_by(heads) %&gt;%     \n                summarise(n = n(),\n                          p=n/10000)\n\nggplot(data10000, aes(x = heads,y = p)) + \n  geom_bar(stat = \"identity\") + \n  labs(x = \"Number of Heads\", \n       y = \"Probability of Heads in 10 flips (p)\") +\n  theme_bw() +\n  scale_x_continuous(breaks = c(0,1,2,3,4,5,6,7,8,9,10))\n\n\nAgain, the binomial distribution is not hugely common in Psychology but we are really starting to see how we can ask questions about outcomes based on probability distributions as opposed to running tests ourselves. Let’s then look at this in a distribution that is very common in psychology - the normal distribution"
  },
  {
    "objectID": "appendix-d-probability.html#the-normal-distribution",
    "href": "appendix-d-probability.html#the-normal-distribution",
    "title": "Appendix D — Probability",
    "section": "\nD.6 The normal distribution",
    "text": "D.6 The normal distribution\nThe normal distribution, reflects the probability of any value occurring for a continuous variable. Examples of continuous variables include height or age, where a single person can score anywhere along a continuum. For example, a person could be 21.5 years old and 176 cm tall.\nThe normal distribution looks like this:\n\n\n\n\nNormal Distribution of height. \\(\\mu\\) = the mean (average), \\(\\sigma\\) = standard deviation\n\n\n\nSomething to note is that the normal distribution is symmetrical, meaning there is an equal probability of observations above and below the mean occurring. This means that, if the mean in the above plot of heights is 170 cm, we could expect the number of people who have a height of 160 cm to be the same as the number of people who have a height of 180 cm. A second thing to note is that as the distribution is symmetrical, the mean, median, and mode of the distribution are all equal and in the middle of the distribution and have the highest probability of occurring. As you move away from the middle of the distribution, the probability of those outcomes occurring starts to reduce. This plays an important role in analyses as we will come on to see in later chapters.\nNow, however, in the same way that we could with the coin flips, we can then use what we know about our data and the normal distribution to estimate the probability of certain outcomes, such as what’s the probability that someone would be taller than 190cm?\nAs with any probabilities, real-world data will come close to the normal distribution, but will (almost certainly) never match it exactly. As we collect more observations from data that we might expect to be normally distributed, our data will get increasingly closer to a normal distribution. As an example, here’s a simulation of an experiment in which we collect heights from 5000 participants. As you can see, as we add more observations, our data starts to look more and more like the normal distribution in the previous figure.\n\n\n\n\nA simulation of an experiment collecting height data from 2000 participants\n\n\n\n\nD.6.0.1 Activity 3: Normal distribution\nComplete the sentences to make sure that you are understanding the above.\n\nIn a normal distribution, the mean, median, and mode \nare all equal\nare always different\nsum to zero.\nIn a normal distribution, the further away from the mean an observation is \nthe lower its probability of occuring\nthe higher its probability of occuring.\nWhereas the binomial distribution is based on situations in which there are two possible outcomes, the normal distribution is based on situations in which the data \nhas three possible values\nis a categorical variable\nis a continuous variable.\n\nD.6.0.2 Activity 4: Distribution test\nWhich distribution is likely to be associated with the following?\n\nScores on an IQ test \nUniform distribution\nBinomial distribution\nNormal distribution\n\nWhether a country has won or lost the Eurovision song contest \nUniform distribution\nBinomial distribution\nNormal distribution\n\nPicking a spade card out of a normal pack of playing cards\nUniform distribution\nBinomial distribution\nNormal distribution"
  },
  {
    "objectID": "appendix-d-probability.html#using-the-binomial-distribution",
    "href": "appendix-d-probability.html#using-the-binomial-distribution",
    "title": "Appendix D — Probability",
    "section": "\nD.7 Using the binomial distribution",
    "text": "D.7 Using the binomial distribution\nNow, we’re going to calculate probabilities based on the binomial distribution. In this chapter, for the first time we don’t need to load the tidyverse. All of the functions we need are contained in Base R. If you want a refresher on the difference between Base R and packages, see Programming Basics.\n\nD.7.0.1 Activity 5: Getting Set-Up\n\nOpen a new R Markdown document, call it “Probability” and save it in the relevant chapter folder, remembering to delete the default text which we do not need.\n\nWe’re going to use three Base R functions to work with the binomial distribution:\n\n\ndbinom() - the density function: gives you the probability of x successes given the number of trials and the probability of success on a single trial (e.g., what’s the probability of flipping 8/10 heads with a fair coin?).\n\npbinom() - the probability distribution function: gives you the cumulative probability of getting a number of successes below a certain cut-off point (e.g. probability of getting 0 to 5 heads out of 10 flips), given the size and the probability. This is known as the cumulative probability distribution function or the cumulative density function.\n\nqbinom() - the quantile function: is the opposite of pbinom() in that it gives you the x axis value for a given probability p, plus given the size and prob, that is if the probability of flipping a head is .5, how many heads would you expect to get with 10 flips?\n\nSo let’s try these functions out to answer two questions:\n\nWhat is the probability of getting exactly 5 heads on 10 flips?\nWhat is the probability of getting at most 2 heads on 10 flips?\n\nD.7.0.2 Activity 6: dbinom()\n\nLet’s start with question 1, what is the probability of getting exactly 5 heads on 10 flips?\nWe want to predict the probability of getting 5 heads in 10 trials (coin flips) where the probability of success on each flip is 0.5 (it’ll either be heads or tails so you have a 50/50 chance which we write as 0.5). We will use dbinom() to work this out:\nThe dbinom() (density) function has three arguments:\n\n\nx: the number of ‘heads’ we want to know the probability of. Either a single value, 3, or a series of values, 0:10. In this case we want to know about 5 heads, so we write 5.\n\nsize: the number of trials (flips) we are simulating; in this case, 10 flips.\n\nprob: the probability of ‘heads’ on one trial. Here chance is 50-50 which as a probability we state as 0.5 or .5\n\nType and run the below code in a new code chunk:\n\ndbinom(x = 5, size = 10, prob = 0.5)\n\nLooking at the outcome, answer the following questions:\n\nTo two decimal places, what is the probability of getting 5 heads out of 10 coin flips? \n\nWhat is this probability expressed in percent? \n0.25%\n2.5%\n25%\n\n\nD.7.0.3 Activity 7: pbinom()\n\nOK, question 2. What is the probability of getting at most 2 heads on 10 flips?\nThis time we use pbinom() as we want to know the cumulative probability of getting a maximum of 2 heads from 10 coin flips. So we have set a cut-off point of 2 but we still have a probability of getting a heads of 0.5.\n\n\nNote: pbinom() takes the arguments size and prob argument just like dbinom(). However, the first input argument is q rather than x. This is because in dbinom x is a fixed number, whereas q is all the possibilities up to and including a given number (e.g. 0, 1, 2).\n\nType and run the below code in a new code chunk:\n\npbinom(q = 2, size = 10, prob = 0.5)\n\nLooking at the outcome, answer the following question:\n\nWhat is the probability of getting a maximum of 2 heads on 10 coin flips to 2 decimal places? \n\nWhat is this probability expressed in percent? \n0.05%\n0.5%\n5%\n\n\nD.7.0.4 Activity 8: pbinom() 2\nLet’s try one more scenario with a cut-off point to make sure you have understood this. What is the probability of getting 7 or more heads on 10 flips?\nWe can use the same function as in the previous example, however, there’s an extra argument if we want to get the correct answer. Let’s try running the code we used above first but change q = 2 to q = 7 to see what we get.\n\npbinom(q = 7, size = 10, prob = .5) \n\n[1] 0.9453125\n\n\nThis tells us that the probability is .95 or 95% - that doesn’t seem right does it? It seems very high for getting 7 or more heads out of 10 coin flips! Why is that? Well, the default behaviour for pbinom() is to calculate the cumulative probability for the lower tail of the curve, i.e., if you specify q = 2 it calculates the probability of all outcomes up to and including 2. We specified q = 7 which means that we have calculated the probability of getting an outcome of 0, 1, 2, 3, 4, 5, 6, or 7 - shown here in the blue area in the below figure - which is obviously very high.\n\n\n\n\nLower and upper tails\n\n\n\nTo get the right answer, we have to add lower.tail = FALSE to our code as we are interested in the upper tail of the distribution. Because we want the cumulative probability to include 7, and because we know q words as up to and including, in order to get 7 or more, we set q = 6. This will now calculate the cumulative probability of getting 7, 8, 9, or 10 heads out of 10 coin flips. Remember, if we set q = 7 that would be up to including 7, and looking at the upper tail of the distribution would only give us 8, 9 and 10. We want 7, 8, 9 and 10, so we have to set up to and including 6, which leaves us 7 and more.\nTry and run the below code in a new code chunk:\n\npbinom(q = 6, size = 10, prob = .5, lower.tail = FALSE) \n\nLooking at the outcome, answer the following question:\n\nWhat is the probability of getting between 7 and 10 heads from 10 coin flips to 2 decimal places? \n\nWhat is this probability expressed in percent? \n0.017%\n0.17\n17%\n\n\nD.7.0.5 Activity 9: qbinom()\n\nOK great! You are doing excellent as this is tricky stuff. Remember though the whole point is to show you that using probability distributions you can ask all sorts of questions about the probability of any outcome or series of outcomes.\nNow let’s consider a scenario in which you’d use the quantile function qbinom. Imagine that you’ve been accosted by a street magician and they want to bet you that they can predict whether the coin will land on heads or tails. You suspect that they’ve done something to the coin so that it’s not fair and that the probability of the coin landing on a head is no longer .5 or 50/50 - you suspect the coin is now very much more likely to land on tails. Your null hypothesis is that the coin is not a trick coin and that the probability of heads or tails should be even. You are going to run a single experiment to test your hypothesis, with 10 trials. What is the minimum number of heads that is acceptable if p really does equal .5?\nYou have used the argument prob in the previous two functions, dbinom and pbinom, and it represents the probability of success on a single trial (here it is the probability of ‘heads’ in one coin flip, .5). For qbinom, prob still represents the probability of success in one trial, whereas p represents the overall probability of success across all trials. When you run pbinom, it calculates the number of heads that would give that probability.\nWe know from looking at the binomial distribution above that sometimes even when the coin is fair, we won’t get exactly 5/10 heads. Instead, we want to set a cut-off, a probability that below which we’ll say that it’s so unlikely we’d get that result if the coin was fair and in this example we will use the default cut-off for statistical significance in psychology, .05, or 5%.\nIn other words, you ask for the minimum number of successes (e.g. heads) to maintain an overall probability of .05, in 10 flips, when the probability of a success on any one flip is .5. To do that we use the below code:\n\nqbinom(p = .05, size = 10, prob = .5)\n\n[1] 2\n\n\nFrom the code we see that the answer is 2. That means that if the magician flipped fewer than two heads out of ten, you could conclude that there is a less than 5% probability that would happened if the coin was fair. You would reject the null hypothesis that the coin was unbiased against heads and very very politely ask the kind magician for your money back!\nHowever, ten trials is probably far too few if you want to accuse the magician of being a bit dodge. Run the below code and then answer the following questions:\n\nqbinom(p = .05, size = c(100, 1000, 10000), prob = .5)\n\n\nWhat would your cut-off be if you ran 100 trials? \n\nWhat would your cut-off be if you ran 1000 trials? \n\nWhat would your cut-off be if you ran 10,000 trials? \n\n\nNotice that the more trials you run, the more precise the estimates become, that is, the closer they are to the probability of success on a single flip (.5). Again this is a simplification, but think about how this relates to sample size in research studies, the more participants you have, the more precise your estimate will be.\nWe should also mention that qbinom also uses the lower.tail argument and it works in a similar fashion to pbinom. We won’t try that out here but it is good to know in case you ever need it.\n\nVisualise it!\nHave a go at playing around with different numbers of coin flips and probabilities in our dbinom() and pbinom() app!"
  },
  {
    "objectID": "appendix-d-probability.html#using-the-normal-distribution",
    "href": "appendix-d-probability.html#using-the-normal-distribution",
    "title": "Appendix D — Probability",
    "section": "\nD.8 Using the normal distribution",
    "text": "D.8 Using the normal distribution\nA similar set of functions exist to help us work with other distributions, including the normal distribution and we’re going to use three of these:\n\n\ndnorm()- the density function, for calculating the probability of a specific value\n\npnorm()- the probability or distribution function, for calculating the probability of getting at least or at most a specific value\n\nqnorm()- the quantile function, for calculating the specific value associated with a given probability\n\nAs you can probably see, these functions are very similar to the functions that are used to work with the binomial distribution. We will use data about height in Scottish people to show you how the above functions work in the normal distribution\n\nD.8.1 Probability of heights\nData from the Scottish Health Survey (2008) shows that:\n\nThe average height of a 16-24 year old Scottish man is 176.2 centimetres, with a standard deviation of 6.748.\nThe average height of a 16-24 year old Scottish woman is 163.8 cm, with a standard deviation of 6.931.\nAt the time of writing, there is currently no data on Scottish trans and non-binary people.\n\nThe below figure is a simulation of this information - again, you can see the code used to run this simulation by clicking the “Show me the code” button but note that you are not asked to understand this right now.\n\n\nShow me the code\n\n\nmen &lt;- rnorm(n = 100000, mean = 176.2, sd = 6.748)\nwomen &lt;- rnorm(n = 100000, mean = 163.8, sd = 6.931)\n\nheights &lt;- tibble(men, women) %&gt;%\n  pivot_longer(names_to = \"sex\", values_to = \"height\", men:women)\n\nggplot(heights, aes(x = height, fill = sex)) +\n  geom_density(alpha = .6) +\n  scale_fill_viridis_d(option = \"E\") +\n  theme_minimal()\n\n\n\n\n\n\nSimulation of Scottish height data\n\n\n\nSo to test the normal distribution, and to round off this chapter, we will use the above information to calculate the probability of observing at least or at most a specific height with pnorm(), and the heights that are associated with specific probabilities with qnorm().\n\nD.8.1.1 Activity 10:pnorm()\n\npnorm() requires three arguments:\n\n\nq is the value that you want to calculate the probability of. Note however you set this as exactly the number you want and not 1 less than the number you want. This is because the data is continuous and not discrete as in the binomial distribution.\n\nmean is the mean of the data\n\nsd is the standard deviation of the data\n\nlower.tail works as above and depends on whether you are interested in the upper or lower tail,\n\nType the code below into a code chunk and replace the NULLs to calculate the probability of meeting a 16-24 y.o. Scottish woman who is as tall or taller than the average 16-24 y.o. Scottish man.\n\n\nhint: You are asking about the female distribution so use that mean and sd\n\nhint: the average male is 176.2\n\nhint: tall or taller is upper.\n\nhint: the solution is at the end of the chapter if you are stuck.\n\n\npnorm(q = NULL, mean = NULL, sd = NULL, lower.tail = NULL)\n\nLooking at your outcome, answer the following questions.\n\nWhat is the probability of meeting a 16-24 y.o. Scottish woman who is taller than the average 16-24 y.o. Scottish man? \n\nWhat is this probability expressed in percent? \n0.04%\n0.4%\n4%\n\n\nD.8.1.2 Activity 11: pnorm 2\nFiona is a very tall Scottish woman (181.12 cm) in the 16-24 y.o. range who will only date men who are taller than her.\n\nUsing pnorm() again, what is the proportion of Scottish men Fiona would be willing to date to 2 decimal places? \n\nhint: you want to know about the male population\n\nhint: Fiona is 181.12 cm tall and you want taller than her.\n\n\nWhat is this probability expressed in percent? \n0.23%\n2.3%\n23%\n\n\nD.8.1.3 Activity 12: pnorm 3\nOn the other hand, Fiona is bisexual and will only date women who are shorter than her.\n\nWhat is the proportion of Scottish women would Fiona be willing to date to 2 decimal places? \n\nhint: female distribution, lower than Fiona.\n\n\nWhat is this probability expressed in percent? \n0.99%\n9.9%\n99%\n\n\nD.8.1.4 Activity 13: qnorm()\n\nFinally, in the previous examples we calculated the probability of a particular outcome. Now we want to calculate what outcome would be associated with a particular probability and we can use qnorm() to do this.\nqnorm() is very similar to pnorm() with one exception, rather than specifying q our known observation or quantile, instead we have to specify p, our known probability.\n\nqnorm(p = NULL, mean = NULL, sd = NULL, lower.tail = NULL)\n\nReplace the NULLs in the above code to calculate how tall a 16-24 y.o. Scottish man would have to be in order to be in the top 5% (i.e., p = .05) of the height distribution for Scottish men in his age group. Remember the solutions are at the end of the chapter. You can confirm if you are right or not by answering this question:\nThe answer to this last question was:\n\n175.352037231422193.581696140348187.299472274669176.2\n\n\nVisualise it!\nHave a go at playing around with different distributions in our dnorm() and pnorm() app - access it here"
  },
  {
    "objectID": "appendix-d-probability.html#finished",
    "href": "appendix-d-probability.html#finished",
    "title": "Appendix D — Probability",
    "section": "\nD.9 Finished",
    "text": "D.9 Finished\nAnd that’s it! The key concepts to take away from this chapter are that different types of data tend to follow known distributions, and that we can use these distributions to calculate the probability of particular outcomes. This is the foundation of many of the statistical tests that you will learn about in this course. For example, if you want to compare whether the scores from two groups are different, that is, whether they come from different distributions, you can calculate the probability that the scores from group 2 would be in the same distribution as group 1. If this probability is less than 5% (p = .05), you might conclude that the scores were significantly different. That’s an oversimplification obviously, but if you can develop a good understanding of probability distributions it will stand you in good stead for the rest of the statistics content.\nThis was a long read so there is no test yourself today but be sure to make notes and to check your understanding of different concepts. Please also remember to ask any questions you are unsure of."
  },
  {
    "objectID": "appendix-d-probability.html#prob-sols",
    "href": "appendix-d-probability.html#prob-sols",
    "title": "Appendix D — Probability",
    "section": "\nD.10 Activity solutions",
    "text": "D.10 Activity solutions\n\nD.10.0.1 Activity 6\n\nTo two decimal places, what is the probability of getting 5 heads out of 10 coin flips?\n\n\n.25\n\n\nD.10.0.2 Activity 7\n\nWhat is the probability of getting a maximum of 2 heads on 10 coin flips to 2 decimal places?\n\n\n.06\n\n\nD.10.0.3 Activity 8\n\nWhat is the probability of getting between 7 and 10 heads from 10 coin flips to 2 decimal places?\n\n\n.17\n\n\nD.10.0.4 Activity 10\n\nWhat is the probability of meeting a 16-24 y.o. Scottish woman who is taller than the average 16-24 y.o. Scottish man?\n\n\npnorm(q = 176.2, mean = 163.8, sd = 6.931, lower.tail = FALSE)\n\n\nD.10.0.5 Activity 11\n\nUsing pnorm() again, what is the proportion of Scottish men Fiona would be willing to date to 2 decimal places?\n\n\npnorm(q = 181.12, mean = 176.2, sd = 6.748, lower.tail = FALSE)\n\n\nD.10.0.6 Activity 12\n\nWhat is the proportion of Scottish women would Fiona be willing to date to 2 decimal places?\n\n\npnorm(q = 181.12, mean = 163.8, sd = 6.931, lower.tail = TRUE)\n\n\nD.10.0.7 Activity 13\nThe answer to this last question was:\n\nqnorm(p = .05, mean = 176.2, sd = 6.748, lower.tail = FALSE)"
  },
  {
    "objectID": "appendix-d-probability.html#words-from-this-chapter",
    "href": "appendix-d-probability.html#words-from-this-chapter",
    "title": "Appendix D — Probability",
    "section": "\nD.11 Words from this Chapter",
    "text": "D.11 Words from this Chapter\nBelow you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the PsyTeachR Glossary. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter.\n\n\n\n\nterm\ndefinition\n\n\n\nbinomial distribution\n\n\n\nchi-square\n\n\n\ncontinuous\n\n\n\ndiscrete\n\n\n\ndistribution\n\n\n\ninferential\n\n\n\ninteger\n\n\n\nInterval\n\n\n\nLikert\n\n\n\nnominal\n\n\n\nnormal distribution\n\n\n\nordinal\n\n\n\npopulation\n\n\n\nprobability\n\n\n\nRatio\n\n\n\nsample\n\n\n\nsimulation\nGenerating data, as opposed to collecting data, from summary parameters such as the mean and standard deviation\n\n\nuniform distribution\n\n\n\n\n\n\nThat is end of this chapter. Be sure to look again at anything you were unsure about and make some notes to help develop your own knowledge and skills. It would be good to write yourself some questions about what you are unsure of and see if you can answer them later or speak to someone about them. Good work today!"
  },
  {
    "objectID": "appendix-y-license.html#citation",
    "href": "appendix-y-license.html#citation",
    "title": "License",
    "section": "Citation",
    "text": "Citation\nBartlett, J.E. & Toivo, W. (2024). Fundamentals of Quantitative Analysis (Version 3.0). https://github.com/PsyTeachR/quant-fundamentals-v3"
  },
  {
    "objectID": "13-factorial-anova.html#factorial-anova",
    "href": "13-factorial-anova.html#factorial-anova",
    "title": "\n13  Factorial ANOVA\n",
    "section": "\n13.2 Factorial ANOVA",
    "text": "13.2 Factorial ANOVA\nTo run the factorial ANOVA, we will be using the afex package again. Remember that you must specify both IVs, one of which is between-subjects and the other is within-subjects. Look up the help documentation for aov_ez if you need further information.\n\n13.2.1 Activity 4 - Using the aov_ez() function.\nBefore we show you the code, try and complete the following skeleton version first. Think about what variable in the data corresponds to each argument.\nSave the ANOVA model to an object called mod_factorial to be consistent with explanations below. For making it easier to report the results later, pull out the mod_factorial$anova_table component and apply the tidy() function from broom as a second step.\n\nmod_factorial &lt;- aov_ez(id = \"NULL\",\n               data = NULL, \n               between = \"NULL\", \n               within = \"NULL\",\n               dv = \"NULL\", \n               type = 3,\n               es = \"NULL\") \n\nfactorial_output &lt;- NULL\n\n\n\n\n\n\n\nShow me the solution\n\n\n\n\n\nYou should have the following in a code chunk:\n\nmod_factorial &lt;- aov_ez(id = \"participant_ID\",\n               data = zhang_long, \n               between = \"Condition\", \n               within = \"Time\",\n               dv = \"Interest\", \n               type = 3,\n               include_aov = TRUE,\n               es = \"pes\") \n\nfactorial_output &lt;- mod_factorial$anova_table %&gt;% \n  tidy()\n\nWe can look at the results of the factorial ANOVA by printing the object.\n\nmod_factorial\n\nAnova Table (Type 3 tests)\n\nResponse: Interest\n          Effect     df  MSE         F  ges p.value\n1      Condition 1, 128 2.05      0.46 .003    .498\n2           Time 1, 128 0.61 25.88 *** .044   &lt;.001\n3 Condition:Time 1, 128 0.61    4.44 * .008    .037\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n\n\n\n\n\nLook at the results. Remember the pre-class information about how to read p-values in scientific notation.\n\nIs the main effect of Condition significant? \nYes\nNo\nIs the main effect of Time significant? \nYes\nNo\nIs the two-way interaction significant? \nYes\nNo\n\n13.2.2 Activity 5 - Checking assumptions for factorial ANOVA\nThe assumptions for a factorial ANOVA are the same as the one-way ANOVA.\n\nThe DV is interval or ratio data.\nThe observations should be independent.\nThe residuals should be normally distributed.\nThere should be homogeneity of variance between the groups.\n\nAs before, we know assumption 2 is met from the design of the study. Assumption 1 throws up an interesting issue which is the problem of ordinal data. Ordinal data are the kind of data that come from Likert scales and are very common in psychology. The problem is that ordinal data are not interval or ratio data, there’s a fixed number of integer values they can take (the values of the Likert scale) and you cannot claim that the distance between the values is equal (is the difference between strongly agree and agree the same as the difference between agree and neutral?).\nTechnically, we should not use an ANOVA to analyse ordinal data - but almost everyone does. Many people argue that if you take the average of multiple Likert scale items, you can interpret the data as if they are interval and they can be normally distributed. Other people argue you should use non-parametric methods or more complex models such as ordinal regression for this type of data, but it is beyond the scope of what we cover in this course (if you are super interested, there is a PsyTeachR book for another course - Statistics and Research Design - which covers ordinal regression). Whichever route you choose, you should understand the data you have and you should be able to justify your decision.\nTo test assumption 3, you can run check_model() from performance on the model object (mod_factorial). Unless you add the argument re_formula = NA, you get a little warning saying the function does it anyway. The background of this argument is beyond the scope of this course, but expressed as a linear model, a mixed ANOVA looks like something called a mixed-effects model, so this argument is saying that there is not a formula for it, since we did not have one.\n\ncheck_model(mod_factorial, \n            re_formula = NA) # Specify or you get a warning \n\n\n\n\n\n\n\nDoes it look like we have any obvious problems with normality here? \nYes\nNo\nThe one annoying thing here is we do not get a diagnostic plot for checking homogeneity of variance / homoscedasticity. We can create our own using the lm component of the model object (mod_factorial$lm), but it takes a few steps. In the code below:\n\nWe first isolate the standardised residuals of the model object. We must convert it to a data frame and rename the two columns.\nWe combine the residuals with the wide version of the data.\nWe pivot the data longer so all the residuals are in one column and create a new variable to take the square root of the absolute residuals. This recreates how the diagnostic plots you saw in Chapters 8, 9, and 12 look.\nFinally, we plot the standardised residuals and add a line to join the means of each group. If the line is roughly flat, we support homoscedasticity. If the line angles up or down substantially, then this points to signs of heteroscedasticity.\n\n\n# Isolate standardised residuals as a data frame\nresiduals &lt;- as.data.frame(rstandard(mod_factorial$lm)) %&gt;% \n  select(residuals_time1 = time1_interest,\n         residuals_time2 = time2_interest)\n\n# add residuals to the wide version of the data, so we have the groups\nzhang_wide &lt;- zhang_wide %&gt;% \n  bind_cols(residuals)\n\n# Pivot longer and calculate the square root of absolute standardised residuals\nresiduals_long &lt;- zhang_wide %&gt;% \n  pivot_longer(cols = residuals_time1:residuals_time2, \n               names_to = \"Time\", \n               values_to = \"Residuals\") %&gt;% \n  mutate(std_residuals = sqrt(abs(Residuals)))\n\n# Plot the residuals\nresiduals_long %&gt;%\n  # we need groups as numbers for the line to plot \n  mutate(Condition = case_match(Condition,\n                                \"Ordinary\" ~ 1,\n                                \"Extraordinary\" ~ 2)) %&gt;% \n  ggplot(aes(x = Condition, y = std_residuals)) + \n  geom_point() + \n  # add line joining the mean of residuals per group\n  stat_summary(geom = \"line\", \n               fun = mean, \n               color = \"blue\", \n               linewidth = 1.5) + \n    labs(x = \"Condition\", y = \"Standardised Residuals\")\n\n\n\n\n\n\n\nDoes it look like we have any obvious problems with homoscedasticity here? \nYes\nNo\n\n13.2.3 Activity 6 - Post-hoc tests\nBecause the interaction is significant, we should follow this up with post-hoc tests using emmeans() to determine which comparisons are significant. If the overall interaction is not significant, you should not conduct additional tests.\nemmeans() requires you to specify the aov object, and then the factors you want to contrast. For an interaction, we use the notation pairwise ~ IV1 | IV2 and you specify which multiple comparison correction you want to apply.\nRun the below code and view the results.\n\n# run the tests\nposthoc_factorial &lt;- emmeans(mod_factorial, \n                             pairwise ~ Time | Condition, \n                             adjust = \"bonferroni\")\n\nposthoc_factorial\n\n$emmeans\nCondition = Extraordinary:\n Time           emmean    SE  df lower.CL upper.CL\n time1_interest   4.36 0.137 128     4.09     4.63\n time2_interest   4.65 0.147 128     4.36     4.94\n\nCondition = Ordinary:\n Time           emmean    SE  df lower.CL upper.CL\n time1_interest   4.04 0.139 128     3.76     4.31\n time2_interest   4.73 0.149 128     4.44     5.03\n\nConfidence level used: 0.95 \n\n$contrasts\nCondition = Extraordinary:\n contrast                        estimate    SE  df t.ratio p.value\n time1_interest - time2_interest   -0.288 0.136 128  -2.123  0.0357\n\nCondition = Ordinary:\n contrast                        estimate    SE  df t.ratio p.value\n time1_interest - time2_interest   -0.695 0.138 128  -5.049  &lt;.0001\n\n\nIn the output, we first get the estimated marginal means for the combination of IVs. We then get the contrasts we requested. This looks at the difference in levels of the first IV for each level of the second IV.\nYou can use tidy() to tidy up the output of the contrasts and save it into a tibble which makes it easier to use in inline code later.\n\n# tidy up the output of the tests\ncontrasts_factorial &lt;- posthoc_factorial$contrasts %&gt;%\n  tidy()\n\ncontrasts_factorial\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCondition\nterm\ncontrast\nnull.value\nestimate\nstd.error\ndf\nstatistic\np.value\n\n\n\nExtraordinary\nTime\ntime1_interest - time2_interest\n0\n-0.2878788\n0.1356011\n128\n-2.122983\n0.0356806\n\n\nOrdinary\nTime\ntime1_interest - time2_interest\n0\n-0.6953125\n0.1377035\n128\n-5.049343\n0.0000015\n\n\n\n\n\n\nNote that because there are two IVs/factors, we could also reverse the order. Above, we get the results contrasting time 1 and time 2 for each event condition. Instead, we could look at the difference between ordinary and extraordinary events at each time point.\nRun the code below and compare the output to contrast_factorial. Look at how the contrasts are expressed subtly different when you switch the order. Think carefully about your research question and hypotheses for which way around is the most informative.\n\nposthoc_factorial2 &lt;- emmeans(mod_factorial, \n                             pairwise ~ Condition | Time, \n                             adjust = \"bonferroni\") \n\nposthoc_factorial2\n\ncontrasts_factorial2 &lt;- posthoc_factorial2$contrasts %&gt;%\n  tidy()\n\ncontrasts_factorial2\n\n$emmeans\nTime = time1_interest:\n Condition     emmean    SE  df lower.CL upper.CL\n Extraordinary   4.36 0.137 128     4.09     4.63\n Ordinary        4.04 0.139 128     3.76     4.31\n\nTime = time2_interest:\n Condition     emmean    SE  df lower.CL upper.CL\n Extraordinary   4.65 0.147 128     4.36     4.94\n Ordinary        4.73 0.149 128     4.44     5.03\n\nConfidence level used: 0.95 \n\n$contrasts\nTime = time1_interest:\n contrast                 estimate    SE  df t.ratio p.value\n Extraordinary - Ordinary   0.3246 0.195 128   1.661  0.0992\n\nTime = time2_interest:\n contrast                 estimate    SE  df t.ratio p.value\n Extraordinary - Ordinary  -0.0829 0.209 128  -0.397  0.6923\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTime\nterm\ncontrast\nnull.value\nestimate\nstd.error\ndf\nstatistic\np.value\n\n\n\ntime1_interest\nCondition\nExtraordinary - Ordinary\n0\n0.3245739\n0.1954025\n128\n1.6610529\n0.0991504\n\n\ntime2_interest\nCondition\nExtraordinary - Ordinary\n0\n-0.0828598\n0.2088845\n128\n-0.3966778\n0.6922656\n\n\n\n\n\n\nBecause our main effects (condition and time) only have two levels, we do not need to do any post-hoc tests to determine which conditions differ from each other, however, if one of our factors had three levels then we could use emmeans() to calculate the contrast for the main effects, like we did for the one-way ANOVA.\nFinally, to calculate standardised effect sizes for the pairwise comparisons, we again need to do this individually using cohens_d() from effectsize.\nAs we have a mixed design, we must follow a slightly different process for each comparison. Cohen’s d has a different calculation for between-subjects and within-subjects contrasts, so we must express it differently. For the first comparison, we are interested in the difference between time 1 and time 2 for each group, so this represents a within-subjects comparison.\n\n# time 1 vs time 2 for Extraordinary group\nd_extraordinary &lt;- cohens_d(x = \"time1_interest\", \n                            y = \"time2_interest\", \n                            paired = TRUE,\n                            data = filter(zhang_wide, \n                                          Condition == \"Extraordinary\"))\n# time 1 vs time 2 for Ordinary group\nd_ordinary &lt;- cohens_d(x = \"time1_interest\", \n                       y = \"time2_interest\", \n                       paired = TRUE,\n                       data = filter(zhang_wide, \n                                     Condition == \"Ordinary\"))\n\n# bind together the two contrasts\nCondition_ds &lt;- bind_rows(d_extraordinary, \n                          d_ordinary)\n\n# add the contrasts to the emmeans tidy table\ncontrasts_factorial &lt;- contrasts_factorial %&gt;%\n  bind_cols(Condition_ds)\n\ncontrasts_factorial\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCondition\nterm\ncontrast\nnull.value\nestimate\nstd.error\ndf\nstatistic\np.value\nCohens_d\nCI\nCI_low\nCI_high\n\n\n\nExtraordinary\nTime\ntime1_interest - time2_interest\n0\n-0.2878788\n0.1356011\n128\n-2.122983\n0.0356806\n-0.3086922\n0.95\n-0.554559\n-0.0605597\n\n\nOrdinary\nTime\ntime1_interest - time2_interest\n0\n-0.6953125\n0.1377035\n128\n-5.049343\n0.0000015\n-0.5552045\n0.95\n-0.816696\n-0.2898832\n\n\n\n\n\n\nFor the second comparison, we are interested in the difference between ordinary and extraordinary at each time point, so this represents a between-subjects comparison.\n\n# Extraordinary vs ordinary at time 1\nd_time1 &lt;- cohens_d(time1_interest ~ Condition,\n                       data = zhang_wide)\n\n# Extraordinary vs ordinary at time 2\nd_time2 &lt;- cohens_d(time2_interest ~ Condition,\n                       data = zhang_wide)\n\n# bind the two contrasts together\nTime_ds &lt;- bind_rows(d_time1,\n                     d_time2)\n\n# add the contrasts to the emmeans tidy table\ncontrasts_factorial2 &lt;- contrasts_factorial2 %&gt;%\n  bind_cols(Time_ds)\n\ncontrasts_factorial2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTime\nterm\ncontrast\nnull.value\nestimate\nstd.error\ndf\nstatistic\np.value\nCohens_d\nCI\nCI_low\nCI_high\n\n\n\ntime1_interest\nCondition\nExtraordinary - Ordinary\n0\n0.3245739\n0.1954025\n128\n1.6610529\n0.0991504\n0.2914024\n0.95\n-0.0548458\n0.6365251\n\n\ntime2_interest\nCondition\nExtraordinary - Ordinary\n0\n-0.0828598\n0.2088845\n128\n-0.3966778\n0.6922656\n-0.0695901\n0.95\n-0.4134010\n0.2744922\n\n\n\n\n\n\n\n13.2.4 Activity 7 - Creating an interaction plot\nWhen you have a factorial design, one powerful way of visualising the data is through an interaction plot. This is essentially a line graph where the x-axis has one IV and separate lines for a second IV. However, once you have the factorial ANOVA model, you can add confidence intervals to the plot to visualise uncertainty. afex has it’s own function called afex_plot() which you can use with the model object you created.\nIn the code below, there are a few key argument to highlight:\n\nobject is the afex model you created.\nx is the variable you want on the x-axis.\ntrace is the variable you want to plot as separate lines.\nerror controls whether the error bars show confidence intervals for between-subjects or within-subjects. In a mixed design, these have different properties, so you must think about which you want to plot and highlight to the reader.\nfactor_levels lets you edit the levels of factors you plot, such as renaming or reordering them. You add each factor into a list but check the documentation and vignettes for other options.\n\n\nafex_plot(object = mod_factorial, \n          x = \"Condition\", \n          trace = \"Time\", \n          error = \"between\",\n          factor_levels = list(Time = c(\"Time 1\", \"Time 2\")))\n\n\n\n\n\n\n\nOne handy feature about this function is it uses ggplot2 in the background, so you can add layers to the initial function like other plots that you have created.\n\nafex_plot(mod_factorial, \n          x = \"Condition\", \n          trace = \"Time\", \n          error = \"between\",\n          factor_levels = list(Time = c(\"Time 1\", \"Time 2\"))) + \n  theme_classic() + \n  scale_y_continuous(breaks = 1:7)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nSince afex_plot() uses ggplot2, you can use ggsave() to save your plots and insert them into your work."
  }
]