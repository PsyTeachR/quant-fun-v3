{
  "hash": "cedaf9cf2ad37d3898a9f3bd6d42f866",
  "result": {
    "markdown": "# Missing data, outliers, and checking assumptions\n\n\n\n\n\nIn this chapter...\n\n**Chapter Intended Learning Outcomes (ILOs)**\n\nBy the end of this chapter, you will be able to: \n\n- ILO1. \n\n## Chapter preparation\n\n### Organising your files and project for the chapter\n\nFor this chapter, we are going to revisit the data sets you worked with in Chapters 8 [@dawtry_why_2015] and 9 [@lopez_visual_2023]. They each presented some useful examples for checking statistical assumptions and the decisions that go into data analysis. We might not use both data sets for each topic we cover, but they will be useful to demonstrate some of the problems and decisions we highlighted in previous chapters, but did not explore solutions.\n\nBefore we can get started, you need to organise your files and project for the chapter, so your working directory is in order.\n\n1. In your folder for research methods and the book `ResearchMethods1_2/Quant_Fundamentals`, create a new folder called `Chapter_11_screening_data`. Within `CChapter_11_screening_data`, create two new folders called `data` and `figures`.\n\n2. Create an R Project for `Chapter_11_screening_data` as an existing directory for your chapter folder. This should now be your working directory.\n\n3. Create a new R Markdown document and give it a sensible title describing the chapter, such as `11 Missing Data, Outliers, and Assumptions`. Delete everything below line 10 so you have a blank file to work with and save the file in your `Chapter_11_screening_data` folder. \n\n4. The @dawtry_why_2015 data wrangling steps were quite long, so please save this clean version of the data to focus on screening data in this chapter: [Dawtry_2015_clean.csv](data/Dawtry_2015_clean.csv). You will also need to save the data from @lopez_visual_2023 if you have not downloaded it yet: [Lopez_2023.csv](data/Lopez_2023.csv). Right click the link and select \"save link as\", or clicking the link will save the files to your Downloads. Make sure that you save the files as \".csv\". Save or copy the files to your `data/` folder within `Chapter_11_screening_data`.\n\nYou are now ready to start working on the chapter! \n\n### Activity 1 - Read and wrangle the data\n\nAs the first activity, try and test yourself by completing the following task list to read and wrangle the two data files. There is nothing extra to do with this version of the Dawtry data and one small step for the Lopez data. \n\n::: {.callout-tip}\n#### Try this\n\nTo read and wrangle the data, complete the following tasks: \n\n1. Load the following packages:\n\n    - <pkg>performance</pkg>\n    \n    - <pkg>tidyverse</pkg>\n\n2. Read the data file `data/Dawtry_2015_clean.csv` to the object name `dawtry_clean`.\n\n2. Read the data file `data/Lopez_2023.csv` to the object name `lopez_data`.\n\n3. Create a new object called `lopez_clean` based on `lopez_data`:\n\n    - Create a new variable called `Condition_label` by recoding `Condition`. \"0\" is the \"Control\" group and \"1\" is the \"Experimental\" group. \n\n:::\n\n::: {.callout-caution collapse=\"true\"}\n#### Show me the solution\nYou should have the following in a code chunk: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# load the relevant packages\nlibrary(performance)\nlibrary(tidyverse)\n\n# Read the Dawtry_2015_clean.csv file \ndawtry_clean <- read_csv(\"data/Dawtry_2015_clean.csv\")\n\n# Read the Lopez_2023.csv file \nlopez_data <- read_csv(\"data/Lopez_2023.csv\")\n\n# recode condition\nlopez_clean <- lopez_data %>% \n  mutate(Condition_label = case_match(Condition,\n                                      0 ~ \"Control\",\n                                      1 ~ \"Experimental\"))\n```\n:::\n\n\n:::\n\n## Missing data\n\nChecking whether data are missing are relatively straight forward. Missing values in a spreadsheet will be recorded as NA and there are a few ways of identifying them. The much more difficult part of missing data is considering *why* they are missing in the first place. For example, it might be because: \n\n- Your participants accidentally missed a question.\n\n- You made a mistake while setting up your questionnaire/experiment and some responses did not save.\n\n- Your participants intentionally did not want to answer a question.\n\n- Your participants did not turn up to a final testing session.\n\nFor the first two reasons, it is not ideal as we are losing data but there is no systematic pattern to why the data is missing. For the latter two reasons, there might be a relationship between a key variable and whether the data are missing. This is where it is particularly important to consider the role of missing data. We are focusing on data skills here rather than the conceptual understanding, but missing data are commonly categorised as: \n\n- Missing completely at random.\n\n- Missing at random. \n\n- Missing not at random. \n\nFor this introductory course, we do not have time to investigate strategies to address missing data apart from focusing on complete cases and ignoring missing data, but you might find @jakobsen_when_2017 useful if you want to explore options like data imputation. \n\n### Identifying missing data\n\nReturning to data skills, the simplest way of getting an overview of whether any data are missing is using the `summary()` function. For this part, we will focus on @dawtry_why_2015.  \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(dawtry_clean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       PS      Household_Income Political_Preference      age      \n Min.   :  1   Min.   :    20   Min.   :1.000        Min.   :19.0  \n 1st Qu.: 77   1st Qu.: 25000   1st Qu.:3.000        1st Qu.:28.0  \n Median :153   Median : 42000   Median :4.000        Median :33.5  \n Mean   :153   Mean   : 54732   Mean   :4.465        Mean   :37.4  \n 3rd Qu.:229   3rd Qu.: 75000   3rd Qu.:6.000        3rd Qu.:46.0  \n Max.   :305   Max.   :350000   Max.   :9.000        Max.   :69.0  \n               NA's   :4        NA's   :4            NA's   :1     \n     gender     Population_Inequality_Gini_Index Population_Mean_Income\n Min.   :1.00   Min.   :14.26                    Min.   : 14205        \n 1st Qu.:1.00   1st Qu.:31.10                    1st Qu.: 47250        \n Median :1.00   Median :35.66                    Median : 58650        \n Mean   :1.48   Mean   :35.51                    Mean   : 58605        \n 3rd Qu.:2.00   3rd Qu.:40.73                    3rd Qu.: 67875        \n Max.   :2.00   Max.   :57.45                    Max.   :138645        \n NA's   :3                                                             \n Social_Circle_Inequality_Gini_Index Social_Circle_Mean_Income\n Min.   : 2.00                       Min.   : 12000           \n 1st Qu.:19.79                       1st Qu.: 36000           \n Median :25.59                       Median : 51060           \n Mean   :26.35                       Mean   : 54294           \n 3rd Qu.:33.27                       3rd Qu.: 66375           \n Max.   :61.36                       Max.   :148500           \n                                                              \n fairness_satisfaction redistribution\n Min.   :1.000         Min.   :1.00  \n 1st Qu.:2.000         1st Qu.:3.25  \n Median :3.000         Median :4.00  \n Mean   :3.539         Mean   :3.91  \n 3rd Qu.:5.000         3rd Qu.:4.75  \n Max.   :9.000         Max.   :6.00  \n                                     \n```\n:::\n:::\n\n\nWe get a range of summary statistics for each variable but importantly for our purposes here, the final entry is `NA's` where relevant. We can see there are 4 missing values for household income, 4 for political preference, 1 for age, and 3 for gender. \n\n::: {.callout-tip}\n#### Try this\nIf you explore `lopez_clean` from @lopez_visual_2023, do we have any missing data to worry about? <select class='webex-select'><option value='blank'></option><option value='answer'>Yes</option><option value=''>No</option></select>. \n:::\n\n::: {.callout-caution collapse=\"true\"} \n#### Solution\n\nYes, it looks like there is also a small amount of missing data here. There is 1 for sex, 2 for estimated ounces, and 3 for estimates calories. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(lopez_clean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n ParticipantID       Sex              Age          Ethnicity    \n Min.   :1001   Min.   :0.0000   Min.   :18.00   Min.   :1.000  \n 1st Qu.:1202   1st Qu.:1.0000   1st Qu.:19.00   1st Qu.:3.000  \n Median :1462   Median :1.0000   Median :20.00   Median :3.000  \n Mean   :1456   Mean   :0.8099   Mean   :20.47   Mean   :3.261  \n 3rd Qu.:1704   3rd Qu.:1.0000   3rd Qu.:21.00   3rd Qu.:4.000  \n Max.   :1928   Max.   :3.0000   Max.   :54.00   Max.   :8.000  \n                NA's   :1                                       \n   OzEstimate       CalEstimate      M_postsoup     F_CaloriesConsumed\n Min.   :  0.010   Min.   :  1.0   Min.   : 0.600   Min.   :  13.31   \n 1st Qu.:  2.000   1st Qu.: 50.0   1st Qu.: 5.575   1st Qu.: 123.65   \n Median :  4.000   Median : 90.0   Median : 8.700   Median : 192.97   \n Mean   :  6.252   Mean   :124.6   Mean   :10.203   Mean   : 226.30   \n 3rd Qu.:  8.000   3rd Qu.:160.0   3rd Qu.:13.125   3rd Qu.: 291.11   \n Max.   :100.000   Max.   :800.0   Max.   :46.200   Max.   :1024.72   \n NA's   :2         NA's   :3                                          \n   Condition      Condition_label   \n Min.   :0.0000   Length:464        \n 1st Qu.:0.0000   Class :character  \n Median :0.0000   Mode  :character  \n Mean   :0.4698                     \n 3rd Qu.:1.0000                     \n Max.   :1.0000                     \n                                    \n```\n:::\n:::\n\n\n:::\n\n### Removing missing data\n\nOnce we know whether missing data are present, we must consider what to do with them. For this chapter, we are only going to control removing participants, but you could apply a data imputation technique at this point. \n\nFor all the modelling techniques we apply in this book, the functions will remove participants who have one or more missing values from any variable involved in the analysis. The functions will give you a warning to highlight when this happens, but it is normally a good idea to remove participants with missing yourself so you have a note of how many participants you remove. \n\nFor `dawtry_clean`, the <pkg>tidyverse</pkg> function `drop_na()` is the easiest way of removing missing data, either participants with any missing data or by specifying individual variables. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndawtry_all_missing <- dawtry_clean %>% \n  drop_na()\n\ndawtry_income_missing <- dawtry_clean %>% \n  drop_na(Household_Income)\n```\n:::\n\n\nWe can compare the number of participants by using the `nrow()` function to count how many rows are in each object. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# How many rows in the full data? \nnrow(dawtry_clean)\n\n# How many rows when we remove missing data in one variable? \nnrow(dawtry_income_missing)\n\n# How many rows when we remove any missing value?\nnrow(dawtry_all_missing)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 305\n[1] 301\n[1] 294\n```\n:::\n:::\n\n\nLike most data skills and statistics concepts, the key skill here comes in decision making; documenting and justifying the approach that you take. \n\n## Outliers\n\nThe next data screening concept revolves around identifying potential outliers. @leys_how_2019 mention one study found 14 definitions and 39 unique ways of identifying outliers, so this is our second key area of decision making. \n\nRemember this is a crucial researcher degree of freedom, so pre-register your choice of outlier detection wherever possible, and document how many outliers you removed. \n\n## Checking assumptions\n\n## Test yourself\n\nTo end the chapter, we have some knowledge check questions to test your understanding of the concepts we covered in the chapter. We then have some error mode tasks to see if you can find the solution to some common errors in the concepts we covered in this chapter. \n\n### Knowledge check\n\n**Question 1**.\n\n### Error mode\n\nThe following questions are designed to introduce you to making and fixing errors. For this topic, we focus on the new types of data visualisation. Remember to keep a note of what kind of error messages you receive and how you fixed them, so you have a bank of solutions when you tackle errors independently. \n\nCreate and save a new R Markdown file for these activities. Delete the example code, so your file is blank from line 10.\n\n...\n\n## Words from this Chapter\n\nBelow you will find a list of words that were used in this chapter that might be new to you in case it helps to have somewhere to refer back to what they mean. The links in this table take you to the entry for the words in the [PsyTeachR Glossary](https://psyteachr.github.io/glossary/){target=\"_blank\"}. Note that the Glossary is written by numerous members of the team and as such may use slightly different terminology from that shown in the chapter.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n\n</div>\n:::\n:::\n\n\n## End of Chapter\n\nThat is the final chapter you will complete for Research Methods 1. \n\n",
    "supporting": [
      "11-screening-data_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}